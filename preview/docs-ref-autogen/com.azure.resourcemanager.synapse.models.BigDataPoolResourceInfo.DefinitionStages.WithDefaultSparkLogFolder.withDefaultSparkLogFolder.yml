### YamlMime:JavaMember
uid: "com.azure.resourcemanager.synapse.models.BigDataPoolResourceInfo.DefinitionStages.WithDefaultSparkLogFolder.withDefaultSparkLogFolder*"
fullName: "com.azure.resourcemanager.synapse.models.BigDataPoolResourceInfo.DefinitionStages.WithDefaultSparkLogFolder.withDefaultSparkLogFolder"
name: "withDefaultSparkLogFolder"
nameWithType: "BigDataPoolResourceInfo.DefinitionStages.WithDefaultSparkLogFolder.withDefaultSparkLogFolder"
members:
- uid: "com.azure.resourcemanager.synapse.models.BigDataPoolResourceInfo.DefinitionStages.WithDefaultSparkLogFolder.withDefaultSparkLogFolder(java.lang.String)"
  fullName: "com.azure.resourcemanager.synapse.models.BigDataPoolResourceInfo.DefinitionStages.WithDefaultSparkLogFolder.withDefaultSparkLogFolder(String defaultSparkLogFolder)"
  name: "withDefaultSparkLogFolder(String defaultSparkLogFolder)"
  nameWithType: "BigDataPoolResourceInfo.DefinitionStages.WithDefaultSparkLogFolder.withDefaultSparkLogFolder(String defaultSparkLogFolder)"
  summary: "Specifies the defaultSparkLogFolder property: The default folder where Spark logs will be written.."
  parameters:
  - description: "The default folder where Spark logs will be written."
    name: "defaultSparkLogFolder"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public abstract BigDataPoolResourceInfo.DefinitionStages.WithCreate withDefaultSparkLogFolder(String defaultSparkLogFolder)"
  returns:
    description: "the next definition stage."
    type: "<xref href=\"com.azure.resourcemanager.synapse.models.BigDataPoolResourceInfo.DefinitionStages.WithCreate?alt=com.azure.resourcemanager.synapse.models.BigDataPoolResourceInfo.DefinitionStages.WithCreate&text=WithCreate\" data-throw-if-not-resolved=\"False\" />"
type: "method"
metadata: {}
package: "com.azure.resourcemanager.synapse.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-synapse:1.0.0-beta.1
