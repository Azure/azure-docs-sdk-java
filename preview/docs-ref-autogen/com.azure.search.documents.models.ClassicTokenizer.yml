### YamlMime:ManagedReference
items:
- uid: "com.azure.search.documents.models.ClassicTokenizer"
  id: "ClassicTokenizer"
  parent: "com.azure.search.documents.models"
  children:
  - "com.azure.search.documents.models.ClassicTokenizer.ClassicTokenizer()"
  - "com.azure.search.documents.models.ClassicTokenizer.getMaxTokenLength()"
  - "com.azure.search.documents.models.ClassicTokenizer.setMaxTokenLength(java.lang.Integer)"
  langs:
  - "java"
  name: "ClassicTokenizer"
  nameWithType: "ClassicTokenizer"
  fullName: "com.azure.search.documents.models.ClassicTokenizer"
  type: "Class"
  package: "com.azure.search.documents.models"
  summary: "Grammar-based tokenizer that is suitable for processing most European-language documents. This tokenizer is implemented using Apache Lucene."
  syntax:
    content: "public final class ClassicTokenizer extends Tokenizer"
  inheritance:
  - "java.lang.Object"
  - "com.azure.search.documents.models.Tokenizer"
  inheritedMembers:
  - "com.azure.search.documents.models.Tokenizer.getName()"
  - "com.azure.search.documents.models.Tokenizer.setName(java.lang.String)"
  - "java.lang.Object.clone()"
  - "java.lang.Object.equals(java.lang.Object)"
  - "java.lang.Object.finalize()"
  - "java.lang.Object.getClass()"
  - "java.lang.Object.hashCode()"
  - "java.lang.Object.notify()"
  - "java.lang.Object.notifyAll()"
  - "java.lang.Object.toString()"
  - "java.lang.Object.wait()"
  - "java.lang.Object.wait(long)"
  - "java.lang.Object.wait(long,int)"
- uid: "com.azure.search.documents.models.ClassicTokenizer.ClassicTokenizer()"
  id: "ClassicTokenizer()"
  parent: "com.azure.search.documents.models.ClassicTokenizer"
  langs:
  - "java"
  name: "ClassicTokenizer()"
  nameWithType: "ClassicTokenizer.ClassicTokenizer()"
  fullName: "com.azure.search.documents.models.ClassicTokenizer.ClassicTokenizer()"
  overload: "com.azure.search.documents.models.ClassicTokenizer.ClassicTokenizer*"
  type: "Constructor"
  package: "com.azure.search.documents.models"
  syntax:
    content: "public ClassicTokenizer()"
- uid: "com.azure.search.documents.models.ClassicTokenizer.getMaxTokenLength()"
  id: "getMaxTokenLength()"
  parent: "com.azure.search.documents.models.ClassicTokenizer"
  langs:
  - "java"
  name: "getMaxTokenLength()"
  nameWithType: "ClassicTokenizer.getMaxTokenLength()"
  fullName: "com.azure.search.documents.models.ClassicTokenizer.getMaxTokenLength()"
  overload: "com.azure.search.documents.models.ClassicTokenizer.getMaxTokenLength*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the maxTokenLength property: The maximum token length. Default is 255. Tokens longer than the maximum length are split. The maximum token length that can be used is 300 characters."
  syntax:
    content: "public Integer getMaxTokenLength()"
    return:
      type: "java.lang.Integer"
      description: "the maxTokenLength value."
- uid: "com.azure.search.documents.models.ClassicTokenizer.setMaxTokenLength(java.lang.Integer)"
  id: "setMaxTokenLength(java.lang.Integer)"
  parent: "com.azure.search.documents.models.ClassicTokenizer"
  langs:
  - "java"
  name: "setMaxTokenLength(Integer maxTokenLength)"
  nameWithType: "ClassicTokenizer.setMaxTokenLength(Integer maxTokenLength)"
  fullName: "com.azure.search.documents.models.ClassicTokenizer.setMaxTokenLength(Integer maxTokenLength)"
  overload: "com.azure.search.documents.models.ClassicTokenizer.setMaxTokenLength*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the maxTokenLength property: The maximum token length. Default is 255. Tokens longer than the maximum length are split. The maximum token length that can be used is 300 characters."
  syntax:
    content: "public ClassicTokenizer setMaxTokenLength(Integer maxTokenLength)"
    parameters:
    - id: "maxTokenLength"
      type: "java.lang.Integer"
      description: "the maxTokenLength value to set."
    return:
      type: "com.azure.search.documents.models.ClassicTokenizer"
      description: "the ClassicTokenizer object itself."
references:
- uid: "com.azure.search.documents.models.ClassicTokenizer.ClassicTokenizer*"
  name: "ClassicTokenizer"
  nameWithType: "ClassicTokenizer.ClassicTokenizer"
  fullName: "com.azure.search.documents.models.ClassicTokenizer.ClassicTokenizer"
  package: "com.azure.search.documents.models"
- uid: "java.lang.Integer"
  spec.java:
  - uid: "java.lang.Integer"
    name: "Integer"
    fullName: "java.lang.Integer"
- uid: "com.azure.search.documents.models.ClassicTokenizer.getMaxTokenLength*"
  name: "getMaxTokenLength"
  nameWithType: "ClassicTokenizer.getMaxTokenLength"
  fullName: "com.azure.search.documents.models.ClassicTokenizer.getMaxTokenLength"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.ClassicTokenizer.setMaxTokenLength*"
  name: "setMaxTokenLength"
  nameWithType: "ClassicTokenizer.setMaxTokenLength"
  fullName: "com.azure.search.documents.models.ClassicTokenizer.setMaxTokenLength"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.Tokenizer"
  name: "Tokenizer"
  nameWithType: "Tokenizer"
  fullName: "com.azure.search.documents.models.Tokenizer"
- uid: "com.azure.search.documents.models.Tokenizer.getName()"
  name: "Tokenizer.getName()"
  nameWithType: "Tokenizer.getName()"
  fullName: "com.azure.search.documents.models.Tokenizer.getName()"
- uid: "java.lang.Object.notify()"
  name: "Object.notify()"
  nameWithType: "Object.notify()"
  fullName: "java.lang.Object.notify()"
- uid: "java.lang.Object.wait()"
  name: "Object.wait()"
  nameWithType: "Object.wait()"
  fullName: "java.lang.Object.wait()"
- uid: "java.lang.Object.finalize()"
  name: "Object.finalize()"
  nameWithType: "Object.finalize()"
  fullName: "java.lang.Object.finalize()"
- uid: "java.lang.Object.notifyAll()"
  name: "Object.notifyAll()"
  nameWithType: "Object.notifyAll()"
  fullName: "java.lang.Object.notifyAll()"
- uid: "com.azure.search.documents.models.Tokenizer.setName(java.lang.String)"
  name: "Tokenizer.setName(String)"
  nameWithType: "Tokenizer.setName(String)"
  fullName: "com.azure.search.documents.models.Tokenizer.setName(java.lang.String)"
- uid: "java.lang.Object.clone()"
  name: "Object.clone()"
  nameWithType: "Object.clone()"
  fullName: "java.lang.Object.clone()"
- uid: "java.lang.Object.equals(java.lang.Object)"
  name: "Object.equals(Object)"
  nameWithType: "Object.equals(Object)"
  fullName: "java.lang.Object.equals(java.lang.Object)"
- uid: "java.lang.Object.toString()"
  name: "Object.toString()"
  nameWithType: "Object.toString()"
  fullName: "java.lang.Object.toString()"
- uid: "java.lang.Object.getClass()"
  name: "Object.getClass()"
  nameWithType: "Object.getClass()"
  fullName: "java.lang.Object.getClass()"
- uid: "java.lang.Object.wait(long)"
  name: "Object.wait(long)"
  nameWithType: "Object.wait(long)"
  fullName: "java.lang.Object.wait(long)"
- uid: "java.lang.Object.hashCode()"
  name: "Object.hashCode()"
  nameWithType: "Object.hashCode()"
  fullName: "java.lang.Object.hashCode()"
- uid: "java.lang.Object.wait(long,int)"
  name: "Object.wait(long,int)"
  nameWithType: "Object.wait(long,int)"
  fullName: "java.lang.Object.wait(long,int)"
