### YamlMime:ManagedReference
items:
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  id: AnalyzeRequest
  artifact: com.azure:azure-search-documents:11.2.0-beta.3
  parent: com.azure.search.documents.indexes.implementation.models
  children:
  - com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.AnalyzeRequest(java.lang.String)
  - com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getAnalyzer()
  - com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getCharFilters()
  - com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getText()
  - com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenFilters()
  - com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenizer()
  - com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setAnalyzer(com.azure.search.documents.indexes.models.LexicalAnalyzerName)
  - com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setCharFilters(java.util.List<com.azure.search.documents.indexes.models.CharFilterName>)
  - com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenFilters(java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>)
  - com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenizer(com.azure.search.documents.indexes.models.LexicalTokenizerName)
  langs:
  - java
  name: AnalyzeRequest
  nameWithType: AnalyzeRequest
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  type: Class
  package: com.azure.search.documents.indexes.implementation.models
  summary: Specifies some text and analysis components used to break that text into tokens.
  syntax:
    content: public final class AnalyzeRequest
  inheritance:
  - java.lang.Object
  inheritedMembers:
  - java.lang.Object.clone()
  - java.lang.Object.equals(java.lang.Object)
  - java.lang.Object.finalize()
  - java.lang.Object.getClass()
  - java.lang.Object.hashCode()
  - java.lang.Object.notify()
  - java.lang.Object.notifyAll()
  - java.lang.Object.toString()
  - java.lang.Object.wait()
  - java.lang.Object.wait(long)
  - java.lang.Object.wait(long,int)
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.AnalyzeRequest(java.lang.String)
  id: AnalyzeRequest(java.lang.String)
  artifact: com.azure:azure-search-documents:11.2.0-beta.3
  parent: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  langs:
  - java
  name: AnalyzeRequest(String text)
  nameWithType: AnalyzeRequest.AnalyzeRequest(String text)
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.AnalyzeRequest(String text)
  overload: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.AnalyzeRequest*
  type: Constructor
  package: com.azure.search.documents.indexes.implementation.models
  summary: Creates an instance of AnalyzeRequest class.
  syntax:
    content: public AnalyzeRequest(String text)
    parameters:
    - id: text
      type: java.lang.String
      description: the text value to set.
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getAnalyzer()
  id: getAnalyzer()
  artifact: com.azure:azure-search-documents:11.2.0-beta.3
  parent: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  langs:
  - java
  name: getAnalyzer()
  nameWithType: AnalyzeRequest.getAnalyzer()
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getAnalyzer()
  overload: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getAnalyzer*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Get the analyzer property: The name of the analyzer to use to break the given text. If this parameter is not specified, you must specify a tokenizer instead. The tokenizer and analyzer parameters are mutually exclusive.'
  syntax:
    content: public LexicalAnalyzerName getAnalyzer()
    return:
      type: com.azure.search.documents.indexes.models.LexicalAnalyzerName
      description: the analyzer value.
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getCharFilters()
  id: getCharFilters()
  artifact: com.azure:azure-search-documents:11.2.0-beta.3
  parent: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  langs:
  - java
  name: getCharFilters()
  nameWithType: AnalyzeRequest.getCharFilters()
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getCharFilters()
  overload: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getCharFilters*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Get the charFilters property: An optional list of character filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter.'
  syntax:
    content: public List<CharFilterName> getCharFilters()
    return:
      type: java.util.List<com.azure.search.documents.indexes.models.CharFilterName>
      description: the charFilters value.
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getText()
  id: getText()
  artifact: com.azure:azure-search-documents:11.2.0-beta.3
  parent: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  langs:
  - java
  name: getText()
  nameWithType: AnalyzeRequest.getText()
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getText()
  overload: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getText*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Get the text property: The text to break into tokens.'
  syntax:
    content: public String getText()
    return:
      type: java.lang.String
      description: the text value.
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenFilters()
  id: getTokenFilters()
  artifact: com.azure:azure-search-documents:11.2.0-beta.3
  parent: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  langs:
  - java
  name: getTokenFilters()
  nameWithType: AnalyzeRequest.getTokenFilters()
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenFilters()
  overload: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenFilters*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Get the tokenFilters property: An optional list of token filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter.'
  syntax:
    content: public List<TokenFilterName> getTokenFilters()
    return:
      type: java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>
      description: the tokenFilters value.
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenizer()
  id: getTokenizer()
  artifact: com.azure:azure-search-documents:11.2.0-beta.3
  parent: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  langs:
  - java
  name: getTokenizer()
  nameWithType: AnalyzeRequest.getTokenizer()
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenizer()
  overload: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenizer*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Get the tokenizer property: The name of the tokenizer to use to break the given text. If this parameter is not specified, you must specify an analyzer instead. The tokenizer and analyzer parameters are mutually exclusive.'
  syntax:
    content: public LexicalTokenizerName getTokenizer()
    return:
      type: com.azure.search.documents.indexes.models.LexicalTokenizerName
      description: the tokenizer value.
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setAnalyzer(com.azure.search.documents.indexes.models.LexicalAnalyzerName)
  id: setAnalyzer(com.azure.search.documents.indexes.models.LexicalAnalyzerName)
  artifact: com.azure:azure-search-documents:11.2.0-beta.3
  parent: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  langs:
  - java
  name: setAnalyzer(LexicalAnalyzerName analyzer)
  nameWithType: AnalyzeRequest.setAnalyzer(LexicalAnalyzerName analyzer)
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setAnalyzer(LexicalAnalyzerName analyzer)
  overload: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setAnalyzer*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Set the analyzer property: The name of the analyzer to use to break the given text. If this parameter is not specified, you must specify a tokenizer instead. The tokenizer and analyzer parameters are mutually exclusive.'
  syntax:
    content: public AnalyzeRequest setAnalyzer(LexicalAnalyzerName analyzer)
    parameters:
    - id: analyzer
      type: com.azure.search.documents.indexes.models.LexicalAnalyzerName
      description: the analyzer value to set.
    return:
      type: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
      description: the AnalyzeRequest object itself.
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setCharFilters(java.util.List<com.azure.search.documents.indexes.models.CharFilterName>)
  id: setCharFilters(java.util.List<com.azure.search.documents.indexes.models.CharFilterName>)
  artifact: com.azure:azure-search-documents:11.2.0-beta.3
  parent: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  langs:
  - java
  name: setCharFilters(List<CharFilterName> charFilters)
  nameWithType: AnalyzeRequest.setCharFilters(List<CharFilterName> charFilters)
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setCharFilters(List<CharFilterName> charFilters)
  overload: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setCharFilters*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Set the charFilters property: An optional list of character filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter.'
  syntax:
    content: public AnalyzeRequest setCharFilters(List<CharFilterName> charFilters)
    parameters:
    - id: charFilters
      type: java.util.List<com.azure.search.documents.indexes.models.CharFilterName>
      description: the charFilters value to set.
    return:
      type: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
      description: the AnalyzeRequest object itself.
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenFilters(java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>)
  id: setTokenFilters(java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>)
  artifact: com.azure:azure-search-documents:11.2.0-beta.3
  parent: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  langs:
  - java
  name: setTokenFilters(List<TokenFilterName> tokenFilters)
  nameWithType: AnalyzeRequest.setTokenFilters(List<TokenFilterName> tokenFilters)
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenFilters(List<TokenFilterName> tokenFilters)
  overload: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenFilters*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Set the tokenFilters property: An optional list of token filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter.'
  syntax:
    content: public AnalyzeRequest setTokenFilters(List<TokenFilterName> tokenFilters)
    parameters:
    - id: tokenFilters
      type: java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>
      description: the tokenFilters value to set.
    return:
      type: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
      description: the AnalyzeRequest object itself.
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenizer(com.azure.search.documents.indexes.models.LexicalTokenizerName)
  id: setTokenizer(com.azure.search.documents.indexes.models.LexicalTokenizerName)
  artifact: com.azure:azure-search-documents:11.2.0-beta.3
  parent: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
  langs:
  - java
  name: setTokenizer(LexicalTokenizerName tokenizer)
  nameWithType: AnalyzeRequest.setTokenizer(LexicalTokenizerName tokenizer)
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenizer(LexicalTokenizerName tokenizer)
  overload: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenizer*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Set the tokenizer property: The name of the tokenizer to use to break the given text. If this parameter is not specified, you must specify an analyzer instead. The tokenizer and analyzer parameters are mutually exclusive.'
  syntax:
    content: public AnalyzeRequest setTokenizer(LexicalTokenizerName tokenizer)
    parameters:
    - id: tokenizer
      type: com.azure.search.documents.indexes.models.LexicalTokenizerName
      description: the tokenizer value to set.
    return:
      type: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest
      description: the AnalyzeRequest object itself.
references:
- uid: java.lang.String
  spec.java:
  - uid: java.lang.String
    name: String
    fullName: java.lang.String
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.AnalyzeRequest*
  name: AnalyzeRequest
  nameWithType: AnalyzeRequest.AnalyzeRequest
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.AnalyzeRequest
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getText*
  name: getText
  nameWithType: AnalyzeRequest.getText
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getText
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.models.LexicalAnalyzerName
  name: LexicalAnalyzerName
  nameWithType: LexicalAnalyzerName
  fullName: com.azure.search.documents.indexes.models.LexicalAnalyzerName
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getAnalyzer*
  name: getAnalyzer
  nameWithType: AnalyzeRequest.getAnalyzer
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getAnalyzer
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setAnalyzer*
  name: setAnalyzer
  nameWithType: AnalyzeRequest.setAnalyzer
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setAnalyzer
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.models.LexicalTokenizerName
  name: LexicalTokenizerName
  nameWithType: LexicalTokenizerName
  fullName: com.azure.search.documents.indexes.models.LexicalTokenizerName
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenizer*
  name: getTokenizer
  nameWithType: AnalyzeRequest.getTokenizer
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenizer
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenizer*
  name: setTokenizer
  nameWithType: AnalyzeRequest.setTokenizer
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenizer
  package: com.azure.search.documents.indexes.implementation.models
- uid: java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>
  spec.java:
  - uid: java.util.List
    name: List
    fullName: java.util.List
  - name: <
    fullName: <
  - uid: com.azure.search.documents.indexes.models.TokenFilterName
    name: TokenFilterName
    fullName: com.azure.search.documents.indexes.models.TokenFilterName
  - name: '>'
    fullName: '>'
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenFilters*
  name: getTokenFilters
  nameWithType: AnalyzeRequest.getTokenFilters
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getTokenFilters
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenFilters*
  name: setTokenFilters
  nameWithType: AnalyzeRequest.setTokenFilters
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setTokenFilters
  package: com.azure.search.documents.indexes.implementation.models
- uid: java.util.List<com.azure.search.documents.indexes.models.CharFilterName>
  spec.java:
  - uid: java.util.List
    name: List
    fullName: java.util.List
  - name: <
    fullName: <
  - uid: com.azure.search.documents.indexes.models.CharFilterName
    name: CharFilterName
    fullName: com.azure.search.documents.indexes.models.CharFilterName
  - name: '>'
    fullName: '>'
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getCharFilters*
  name: getCharFilters
  nameWithType: AnalyzeRequest.getCharFilters
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.getCharFilters
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setCharFilters*
  name: setCharFilters
  nameWithType: AnalyzeRequest.setCharFilters
  fullName: com.azure.search.documents.indexes.implementation.models.AnalyzeRequest.setCharFilters
  package: com.azure.search.documents.indexes.implementation.models
- uid: java.lang.Object.notify()
  name: Object.notify()
  nameWithType: Object.notify()
  fullName: java.lang.Object.notify()
- uid: java.lang.Object.wait()
  name: Object.wait()
  nameWithType: Object.wait()
  fullName: java.lang.Object.wait()
- uid: java.lang.Object.finalize()
  name: Object.finalize()
  nameWithType: Object.finalize()
  fullName: java.lang.Object.finalize()
- uid: java.lang.Object.clone()
  name: Object.clone()
  nameWithType: Object.clone()
  fullName: java.lang.Object.clone()
- uid: java.lang.Object.notifyAll()
  name: Object.notifyAll()
  nameWithType: Object.notifyAll()
  fullName: java.lang.Object.notifyAll()
- uid: java.lang.Object.equals(java.lang.Object)
  name: Object.equals(Object)
  nameWithType: Object.equals(Object)
  fullName: java.lang.Object.equals(java.lang.Object)
- uid: java.lang.Object.getClass()
  name: Object.getClass()
  nameWithType: Object.getClass()
  fullName: java.lang.Object.getClass()
- uid: java.lang.Object.wait(long)
  name: Object.wait(long)
  nameWithType: Object.wait(long)
  fullName: java.lang.Object.wait(long)
- uid: java.lang.Object.hashCode()
  name: Object.hashCode()
  nameWithType: Object.hashCode()
  fullName: java.lang.Object.hashCode()
- uid: java.lang.Object.wait(long,int)
  name: Object.wait(long,int)
  nameWithType: Object.wait(long,int)
  fullName: java.lang.Object.wait(long,int)
- uid: java.lang.Object.toString()
  name: Object.toString()
  nameWithType: Object.toString()
  fullName: java.lang.Object.toString()
- uid: java.util.List
  name: List
  nameWithType: List
  fullName: java.util.List
- uid: com.azure.search.documents.indexes.models.TokenFilterName
  name: TokenFilterName
  nameWithType: TokenFilterName
  fullName: com.azure.search.documents.indexes.models.TokenFilterName
- uid: com.azure.search.documents.indexes.models.CharFilterName
  name: CharFilterName
  nameWithType: CharFilterName
  fullName: com.azure.search.documents.indexes.models.CharFilterName
