### YamlMime:ManagedReference
items:
- uid: "com.azure.search.documents.models.NGramTokenizer"
  id: "NGramTokenizer"
  parent: "com.azure.search.documents.models"
  children:
  - "com.azure.search.documents.models.NGramTokenizer.NGramTokenizer()"
  - "com.azure.search.documents.models.NGramTokenizer.getMaxGram()"
  - "com.azure.search.documents.models.NGramTokenizer.getMinGram()"
  - "com.azure.search.documents.models.NGramTokenizer.getTokenChars()"
  - "com.azure.search.documents.models.NGramTokenizer.setMaxGram(java.lang.Integer)"
  - "com.azure.search.documents.models.NGramTokenizer.setMinGram(java.lang.Integer)"
  - "com.azure.search.documents.models.NGramTokenizer.setTokenChars(java.util.List<com.azure.search.documents.models.TokenCharacterKind>)"
  langs:
  - "java"
  name: "NGramTokenizer"
  nameWithType: "NGramTokenizer"
  fullName: "com.azure.search.documents.models.NGramTokenizer"
  type: "Class"
  package: "com.azure.search.documents.models"
  summary: "Tokenizes the input into n-grams of the given size(s). This tokenizer is implemented using Apache Lucene."
  syntax:
    content: "public final class NGramTokenizer extends Tokenizer"
  inheritance:
  - "java.lang.Object"
  - "com.azure.search.documents.models.Tokenizer"
  inheritedMembers:
  - "com.azure.search.documents.models.Tokenizer.getName()"
  - "com.azure.search.documents.models.Tokenizer.setName(java.lang.String)"
  - "java.lang.Object.clone()"
  - "java.lang.Object.equals(java.lang.Object)"
  - "java.lang.Object.finalize()"
  - "java.lang.Object.getClass()"
  - "java.lang.Object.hashCode()"
  - "java.lang.Object.notify()"
  - "java.lang.Object.notifyAll()"
  - "java.lang.Object.toString()"
  - "java.lang.Object.wait()"
  - "java.lang.Object.wait(long)"
  - "java.lang.Object.wait(long,int)"
- uid: "com.azure.search.documents.models.NGramTokenizer.NGramTokenizer()"
  id: "NGramTokenizer()"
  parent: "com.azure.search.documents.models.NGramTokenizer"
  langs:
  - "java"
  name: "NGramTokenizer()"
  nameWithType: "NGramTokenizer.NGramTokenizer()"
  fullName: "com.azure.search.documents.models.NGramTokenizer.NGramTokenizer()"
  overload: "com.azure.search.documents.models.NGramTokenizer.NGramTokenizer*"
  type: "Constructor"
  package: "com.azure.search.documents.models"
  syntax:
    content: "public NGramTokenizer()"
- uid: "com.azure.search.documents.models.NGramTokenizer.getMaxGram()"
  id: "getMaxGram()"
  parent: "com.azure.search.documents.models.NGramTokenizer"
  langs:
  - "java"
  name: "getMaxGram()"
  nameWithType: "NGramTokenizer.getMaxGram()"
  fullName: "com.azure.search.documents.models.NGramTokenizer.getMaxGram()"
  overload: "com.azure.search.documents.models.NGramTokenizer.getMaxGram*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the maxGram property: The maximum n-gram length. Default is 2. Maximum is 300."
  syntax:
    content: "public Integer getMaxGram()"
    return:
      type: "java.lang.Integer"
      description: "the maxGram value."
- uid: "com.azure.search.documents.models.NGramTokenizer.getMinGram()"
  id: "getMinGram()"
  parent: "com.azure.search.documents.models.NGramTokenizer"
  langs:
  - "java"
  name: "getMinGram()"
  nameWithType: "NGramTokenizer.getMinGram()"
  fullName: "com.azure.search.documents.models.NGramTokenizer.getMinGram()"
  overload: "com.azure.search.documents.models.NGramTokenizer.getMinGram*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the minGram property: The minimum n-gram length. Default is 1. Maximum is 300. Must be less than the value of maxGram."
  syntax:
    content: "public Integer getMinGram()"
    return:
      type: "java.lang.Integer"
      description: "the minGram value."
- uid: "com.azure.search.documents.models.NGramTokenizer.getTokenChars()"
  id: "getTokenChars()"
  parent: "com.azure.search.documents.models.NGramTokenizer"
  langs:
  - "java"
  name: "getTokenChars()"
  nameWithType: "NGramTokenizer.getTokenChars()"
  fullName: "com.azure.search.documents.models.NGramTokenizer.getTokenChars()"
  overload: "com.azure.search.documents.models.NGramTokenizer.getTokenChars*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the tokenChars property: Character classes to keep in the tokens."
  syntax:
    content: "public List<TokenCharacterKind> getTokenChars()"
    return:
      type: "java.util.List<com.azure.search.documents.models.TokenCharacterKind>"
      description: "the tokenChars value."
- uid: "com.azure.search.documents.models.NGramTokenizer.setMaxGram(java.lang.Integer)"
  id: "setMaxGram(java.lang.Integer)"
  parent: "com.azure.search.documents.models.NGramTokenizer"
  langs:
  - "java"
  name: "setMaxGram(Integer maxGram)"
  nameWithType: "NGramTokenizer.setMaxGram(Integer maxGram)"
  fullName: "com.azure.search.documents.models.NGramTokenizer.setMaxGram(Integer maxGram)"
  overload: "com.azure.search.documents.models.NGramTokenizer.setMaxGram*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the maxGram property: The maximum n-gram length. Default is 2. Maximum is 300."
  syntax:
    content: "public NGramTokenizer setMaxGram(Integer maxGram)"
    parameters:
    - id: "maxGram"
      type: "java.lang.Integer"
      description: "the maxGram value to set."
    return:
      type: "com.azure.search.documents.models.NGramTokenizer"
      description: "the NGramTokenizer object itself."
- uid: "com.azure.search.documents.models.NGramTokenizer.setMinGram(java.lang.Integer)"
  id: "setMinGram(java.lang.Integer)"
  parent: "com.azure.search.documents.models.NGramTokenizer"
  langs:
  - "java"
  name: "setMinGram(Integer minGram)"
  nameWithType: "NGramTokenizer.setMinGram(Integer minGram)"
  fullName: "com.azure.search.documents.models.NGramTokenizer.setMinGram(Integer minGram)"
  overload: "com.azure.search.documents.models.NGramTokenizer.setMinGram*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the minGram property: The minimum n-gram length. Default is 1. Maximum is 300. Must be less than the value of maxGram."
  syntax:
    content: "public NGramTokenizer setMinGram(Integer minGram)"
    parameters:
    - id: "minGram"
      type: "java.lang.Integer"
      description: "the minGram value to set."
    return:
      type: "com.azure.search.documents.models.NGramTokenizer"
      description: "the NGramTokenizer object itself."
- uid: "com.azure.search.documents.models.NGramTokenizer.setTokenChars(java.util.List<com.azure.search.documents.models.TokenCharacterKind>)"
  id: "setTokenChars(java.util.List<com.azure.search.documents.models.TokenCharacterKind>)"
  parent: "com.azure.search.documents.models.NGramTokenizer"
  langs:
  - "java"
  name: "setTokenChars(List<TokenCharacterKind> tokenChars)"
  nameWithType: "NGramTokenizer.setTokenChars(List<TokenCharacterKind> tokenChars)"
  fullName: "com.azure.search.documents.models.NGramTokenizer.setTokenChars(List<TokenCharacterKind> tokenChars)"
  overload: "com.azure.search.documents.models.NGramTokenizer.setTokenChars*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the tokenChars property: Character classes to keep in the tokens."
  syntax:
    content: "public NGramTokenizer setTokenChars(List<TokenCharacterKind> tokenChars)"
    parameters:
    - id: "tokenChars"
      type: "java.util.List<com.azure.search.documents.models.TokenCharacterKind>"
      description: "the tokenChars value to set."
    return:
      type: "com.azure.search.documents.models.NGramTokenizer"
      description: "the NGramTokenizer object itself."
references:
- uid: "com.azure.search.documents.models.NGramTokenizer.NGramTokenizer*"
  name: "NGramTokenizer"
  nameWithType: "NGramTokenizer.NGramTokenizer"
  fullName: "com.azure.search.documents.models.NGramTokenizer.NGramTokenizer"
  package: "com.azure.search.documents.models"
- uid: "java.lang.Integer"
  spec.java:
  - uid: "java.lang.Integer"
    name: "Integer"
    fullName: "java.lang.Integer"
- uid: "com.azure.search.documents.models.NGramTokenizer.getMinGram*"
  name: "getMinGram"
  nameWithType: "NGramTokenizer.getMinGram"
  fullName: "com.azure.search.documents.models.NGramTokenizer.getMinGram"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.NGramTokenizer.setMinGram*"
  name: "setMinGram"
  nameWithType: "NGramTokenizer.setMinGram"
  fullName: "com.azure.search.documents.models.NGramTokenizer.setMinGram"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.NGramTokenizer.getMaxGram*"
  name: "getMaxGram"
  nameWithType: "NGramTokenizer.getMaxGram"
  fullName: "com.azure.search.documents.models.NGramTokenizer.getMaxGram"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.NGramTokenizer.setMaxGram*"
  name: "setMaxGram"
  nameWithType: "NGramTokenizer.setMaxGram"
  fullName: "com.azure.search.documents.models.NGramTokenizer.setMaxGram"
  package: "com.azure.search.documents.models"
- uid: "java.util.List<com.azure.search.documents.models.TokenCharacterKind>"
  spec.java:
  - uid: "java.util.List"
    name: "List"
    fullName: "java.util.List"
  - name: "<"
    fullName: "<"
  - uid: "com.azure.search.documents.models.TokenCharacterKind"
    name: "TokenCharacterKind"
    fullName: "com.azure.search.documents.models.TokenCharacterKind"
  - name: ">"
    fullName: ">"
- uid: "com.azure.search.documents.models.NGramTokenizer.getTokenChars*"
  name: "getTokenChars"
  nameWithType: "NGramTokenizer.getTokenChars"
  fullName: "com.azure.search.documents.models.NGramTokenizer.getTokenChars"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.NGramTokenizer.setTokenChars*"
  name: "setTokenChars"
  nameWithType: "NGramTokenizer.setTokenChars"
  fullName: "com.azure.search.documents.models.NGramTokenizer.setTokenChars"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.Tokenizer"
  name: "Tokenizer"
  nameWithType: "Tokenizer"
  fullName: "com.azure.search.documents.models.Tokenizer"
- uid: "com.azure.search.documents.models.Tokenizer.getName()"
  name: "Tokenizer.getName()"
  nameWithType: "Tokenizer.getName()"
  fullName: "com.azure.search.documents.models.Tokenizer.getName()"
- uid: "java.lang.Object.notify()"
  name: "Object.notify()"
  nameWithType: "Object.notify()"
  fullName: "java.lang.Object.notify()"
- uid: "java.lang.Object.wait()"
  name: "Object.wait()"
  nameWithType: "Object.wait()"
  fullName: "java.lang.Object.wait()"
- uid: "java.lang.Object.finalize()"
  name: "Object.finalize()"
  nameWithType: "Object.finalize()"
  fullName: "java.lang.Object.finalize()"
- uid: "java.lang.Object.notifyAll()"
  name: "Object.notifyAll()"
  nameWithType: "Object.notifyAll()"
  fullName: "java.lang.Object.notifyAll()"
- uid: "com.azure.search.documents.models.Tokenizer.setName(java.lang.String)"
  name: "Tokenizer.setName(String)"
  nameWithType: "Tokenizer.setName(String)"
  fullName: "com.azure.search.documents.models.Tokenizer.setName(java.lang.String)"
- uid: "java.lang.Object.clone()"
  name: "Object.clone()"
  nameWithType: "Object.clone()"
  fullName: "java.lang.Object.clone()"
- uid: "java.lang.Object.equals(java.lang.Object)"
  name: "Object.equals(Object)"
  nameWithType: "Object.equals(Object)"
  fullName: "java.lang.Object.equals(java.lang.Object)"
- uid: "java.lang.Object.toString()"
  name: "Object.toString()"
  nameWithType: "Object.toString()"
  fullName: "java.lang.Object.toString()"
- uid: "java.lang.Object.getClass()"
  name: "Object.getClass()"
  nameWithType: "Object.getClass()"
  fullName: "java.lang.Object.getClass()"
- uid: "java.lang.Object.wait(long)"
  name: "Object.wait(long)"
  nameWithType: "Object.wait(long)"
  fullName: "java.lang.Object.wait(long)"
- uid: "java.lang.Object.hashCode()"
  name: "Object.hashCode()"
  nameWithType: "Object.hashCode()"
  fullName: "java.lang.Object.hashCode()"
- uid: "java.lang.Object.wait(long,int)"
  name: "Object.wait(long,int)"
  nameWithType: "Object.wait(long,int)"
  fullName: "java.lang.Object.wait(long,int)"
- uid: "java.util.List"
  name: "List"
  nameWithType: "List"
  fullName: "java.util.List"
- uid: "com.azure.search.documents.models.TokenCharacterKind"
  name: "TokenCharacterKind"
  nameWithType: "TokenCharacterKind"
  fullName: "com.azure.search.documents.models.TokenCharacterKind"
