### YamlMime:JavaMember
uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withLibraries*"
fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withLibraries"
name: "withLibraries"
nameWithType: "DatabricksSparkPythonActivity.withLibraries"
members:
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withLibraries(java.util.List<java.util.Map<java.lang.String,java.lang.Object>>)"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withLibraries(List<Map<String,Object>> libraries)"
  name: "withLibraries(List<Map<String,Object>> libraries)"
  nameWithType: "DatabricksSparkPythonActivity.withLibraries(List<Map<String,Object>> libraries)"
  summary: "Set the libraries property: A list of libraries to be installed on the cluster that will execute the job."
  parameters:
  - description: "the libraries value to set."
    name: "libraries"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
  syntax: "public DatabricksSparkPythonActivity withLibraries(List<Map<String,Object>> libraries)"
  returns:
    description: "the DatabricksSparkPythonActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity?alt=com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity&text=DatabricksSparkPythonActivity\" data-throw-if-not-resolved=\"False\" />"
type: "method"
metadata: {}
package: "com.azure.resourcemanager.datafactory.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.1
