### YamlMime:JavaType
uid: "com.azure.ai.vision.face.FaceAsyncClient"
fullName: "com.azure.ai.vision.face.FaceAsyncClient"
name: "FaceAsyncClient"
nameWithType: "FaceAsyncClient"
summary: "Initializes a new instance of the asynchronous Face<wbr>Client type."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedClassMethods:
- classRef: "java.lang.<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  methodsRef:
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#clone--\">clone</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#equals-java.lang.Object-\">equals</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#finalize--\">finalize</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#getClass--\">getClass</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#hashCode--\">hashCode</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#notify--\">notify</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#notifyAll--\">notifyAll</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#toString--\">toString</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#wait--\">wait</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#wait-long-\">wait</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#wait-long-int-\">wait</a>"
syntax: "public final class **FaceAsyncClient**"
methods:
- uid: "com.azure.ai.vision.face.FaceAsyncClient.detect(com.azure.core.util.BinaryData,com.azure.ai.vision.face.models.DetectOptions)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.detect(BinaryData imageContent, DetectOptions options)"
  name: "detect(BinaryData imageContent, DetectOptions options)"
  nameWithType: "FaceAsyncClient.detect(BinaryData imageContent, DetectOptions options)"
  summary: "Detect human faces in an image, return face rectangles, and optionally with face<wbr>Ids, landmarks, and attributes."
  parameters:
  - description: "The input image binary."
    name: "imageContent"
    type: "<xref href=\"com.azure.core.util.BinaryData?alt=com.azure.core.util.BinaryData&text=BinaryData\" data-throw-if-not-resolved=\"False\" />"
  - description: "Options for detect API."
    name: "options"
    type: "<xref href=\"com.azure.ai.vision.face.models.DetectOptions?alt=com.azure.ai.vision.face.models.DetectOptions&text=DetectOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<List<FaceDetectionResult>> detect(BinaryData imageContent, DetectOptions options)"
  desc: "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. > \\[!IMPORTANT\\] > To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. \\* \\* No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in \"Identify\", \"Verify\", and \"Find Similar\". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call. \\* Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate. \\* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB. \\* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size. \\* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small. \\* For optimal results when querying \"Identify\", \"Verify\", and \"Find Similar\" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes). \\* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model \\* 'detection\\_02': Face attributes and landmarks are disabled if you choose this detection model. \\* 'detection\\_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model. \\* Different 'recognitionModel' values are provided. If follow-up operations like \"Verify\", \"Identify\", \"Find Similar\" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition\\_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model."
  returns:
    description: "the response body on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceDetectionResult?alt=com.azure.ai.vision.face.models.FaceDetectionResult&text=FaceDetectionResult\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.detect(com.azure.core.util.BinaryData,com.azure.ai.vision.face.models.FaceDetectionModel,com.azure.ai.vision.face.models.FaceRecognitionModel,boolean)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId)"
  name: "detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId)"
  nameWithType: "FaceAsyncClient.detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId)"
  summary: "Detect human faces in an image, return face rectangles, and optionally with face<wbr>Ids, landmarks, and attributes."
  parameters:
  - description: "The input image binary."
    name: "imageContent"
    type: "<xref href=\"com.azure.core.util.BinaryData?alt=com.azure.core.util.BinaryData&text=BinaryData\" data-throw-if-not-resolved=\"False\" />"
  - description: "The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'\n values include 'detection_01', 'detection_02' and 'detection_03'."
    name: "detectionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceDetectionModel?alt=com.azure.ai.vision.face.models.FaceDetectionModel&text=FaceDetectionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'\n values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.\n 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with\n 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'."
    name: "recognitionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceRecognitionModel?alt=com.azure.ai.vision.face.models.FaceRecognitionModel&text=FaceRecognitionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "Return faceIds of the detected faces or not.\n 86400 seconds. The default value is 86400 (24 hours)."
    name: "returnFaceId"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<List<FaceDetectionResult>> detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId)"
  desc: "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. > \\[!IMPORTANT\\] > To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. \\* \\* No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in \"Identify\", \"Verify\", and \"Find Similar\". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call. \\* Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate. \\* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB. \\* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size. \\* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small. \\* For optimal results when querying \"Identify\", \"Verify\", and \"Find Similar\" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes). \\* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model \\* 'detection\\_02': Face attributes and landmarks are disabled if you choose this detection model. \\* 'detection\\_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model. \\* Different 'recognitionModel' values are provided. If follow-up operations like \"Verify\", \"Identify\", \"Find Similar\" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition\\_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model."
  returns:
    description: "the response body on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceDetectionResult?alt=com.azure.ai.vision.face.models.FaceDetectionResult&text=FaceDetectionResult\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.detect(com.azure.core.util.BinaryData,com.azure.ai.vision.face.models.FaceDetectionModel,com.azure.ai.vision.face.models.FaceRecognitionModel,boolean,java.util.List<com.azure.ai.vision.face.models.FaceAttributeType>)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes)"
  name: "detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes)"
  nameWithType: "FaceAsyncClient.detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes)"
  summary: "Detect human faces in an image, return face rectangles, and optionally with face<wbr>Ids, landmarks, and attributes."
  parameters:
  - description: "The input image binary."
    name: "imageContent"
    type: "<xref href=\"com.azure.core.util.BinaryData?alt=com.azure.core.util.BinaryData&text=BinaryData\" data-throw-if-not-resolved=\"False\" />"
  - description: "The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'\n values include 'detection_01', 'detection_02' and 'detection_03'."
    name: "detectionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceDetectionModel?alt=com.azure.ai.vision.face.models.FaceDetectionModel&text=FaceDetectionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'\n values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.\n 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with\n 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'."
    name: "recognitionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceRecognitionModel?alt=com.azure.ai.vision.face.models.FaceRecognitionModel&text=FaceRecognitionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "Return faceIds of the detected faces or not."
    name: "returnFaceId"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "Analyze and return the one or more specified face attributes in the comma-separated\n string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and\n time cost.\n 86400 seconds. The default value is 86400 (24 hours)."
    name: "returnFaceAttributes"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceAttributeType?alt=com.azure.ai.vision.face.models.FaceAttributeType&text=FaceAttributeType\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public Mono<List<FaceDetectionResult>> detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes)"
  desc: "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. > \\[!IMPORTANT\\] > To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. \\* \\* No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in \"Identify\", \"Verify\", and \"Find Similar\". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call. \\* Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate. \\* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB. \\* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size. \\* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small. \\* For optimal results when querying \"Identify\", \"Verify\", and \"Find Similar\" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes). \\* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model \\* 'detection\\_02': Face attributes and landmarks are disabled if you choose this detection model. \\* 'detection\\_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model. \\* Different 'recognitionModel' values are provided. If follow-up operations like \"Verify\", \"Identify\", \"Find Similar\" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition\\_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model."
  returns:
    description: "the response body on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceDetectionResult?alt=com.azure.ai.vision.face.models.FaceDetectionResult&text=FaceDetectionResult\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.detect(com.azure.core.util.BinaryData,com.azure.ai.vision.face.models.FaceDetectionModel,com.azure.ai.vision.face.models.FaceRecognitionModel,boolean,java.util.List<com.azure.ai.vision.face.models.FaceAttributeType>,java.lang.Boolean,java.lang.Boolean,java.lang.Integer)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes, Boolean returnFaceLandmarks, Boolean returnRecognitionModel, Integer faceIdTimeToLive)"
  name: "detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes, Boolean returnFaceLandmarks, Boolean returnRecognitionModel, Integer faceIdTimeToLive)"
  nameWithType: "FaceAsyncClient.detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes, Boolean returnFaceLandmarks, Boolean returnRecognitionModel, Integer faceIdTimeToLive)"
  summary: "Detect human faces in an image, return face rectangles, and optionally with face<wbr>Ids, landmarks, and attributes."
  parameters:
  - description: "The input image binary."
    name: "imageContent"
    type: "<xref href=\"com.azure.core.util.BinaryData?alt=com.azure.core.util.BinaryData&text=BinaryData\" data-throw-if-not-resolved=\"False\" />"
  - description: "The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'\n values include 'detection_01', 'detection_02' and 'detection_03'."
    name: "detectionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceDetectionModel?alt=com.azure.ai.vision.face.models.FaceDetectionModel&text=FaceDetectionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'\n values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.\n 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with\n 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'."
    name: "recognitionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceRecognitionModel?alt=com.azure.ai.vision.face.models.FaceRecognitionModel&text=FaceRecognitionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "Return faceIds of the detected faces or not."
    name: "returnFaceId"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "Analyze and return the one or more specified face attributes in the comma-separated\n string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and\n time cost."
    name: "returnFaceAttributes"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceAttributeType?alt=com.azure.ai.vision.face.models.FaceAttributeType&text=FaceAttributeType\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "Return face landmarks of the detected faces or not. The default value is false."
    name: "returnFaceLandmarks"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Boolean.html\">Boolean</a>"
  - description: "Return 'recognitionModel' or not. The default value is false."
    name: "returnRecognitionModel"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Boolean.html\">Boolean</a>"
  - description: "The number of seconds for the face ID being cached. Supported range from 60 seconds up to\n 86400 seconds. The default value is 86400 (24 hours)."
    name: "faceIdTimeToLive"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Integer.html\">Integer</a>"
  syntax: "public Mono<List<FaceDetectionResult>> detect(BinaryData imageContent, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes, Boolean returnFaceLandmarks, Boolean returnRecognitionModel, Integer faceIdTimeToLive)"
  desc: "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. > \\[!IMPORTANT\\] > To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. \\* \\* No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in \"Identify\", \"Verify\", and \"Find Similar\". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call. \\* Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate. \\* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB. \\* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size. \\* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small. \\* For optimal results when querying \"Identify\", \"Verify\", and \"Find Similar\" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes). \\* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model \\* 'detection\\_02': Face attributes and landmarks are disabled if you choose this detection model. \\* 'detection\\_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model. \\* Different 'recognitionModel' values are provided. If follow-up operations like \"Verify\", \"Identify\", \"Find Similar\" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition\\_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model."
  returns:
    description: "the response body on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceDetectionResult?alt=com.azure.ai.vision.face.models.FaceDetectionResult&text=FaceDetectionResult\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.detect(java.lang.String,com.azure.ai.vision.face.models.DetectOptions)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.detect(String url, DetectOptions options)"
  name: "detect(String url, DetectOptions options)"
  nameWithType: "FaceAsyncClient.detect(String url, DetectOptions options)"
  summary: "Detect human faces in an image, return face rectangles, and optionally with face<wbr>Ids, landmarks, and attributes."
  parameters:
  - description: "the URL of input image."
    name: "url"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>"
  - description: "Options for detect API."
    name: "options"
    type: "<xref href=\"com.azure.ai.vision.face.models.DetectOptions?alt=com.azure.ai.vision.face.models.DetectOptions&text=DetectOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<List<FaceDetectionResult>> detect(String url, DetectOptions options)"
  desc: "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. > \\[!IMPORTANT\\] > To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. \\* \\* No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in \"Identify\", \"Verify\", and \"Find Similar\". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call. \\* Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate. \\* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB. \\* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size. \\* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small. \\* For optimal results when querying \"Identify\", \"Verify\", and \"Find Similar\" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes). \\* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model \\* 'detection\\_02': Face attributes and landmarks are disabled if you choose this detection model. \\* 'detection\\_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model. \\* Different 'recognitionModel' values are provided. If follow-up operations like \"Verify\", \"Identify\", \"Find Similar\" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition\\_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model."
  returns:
    description: "the response body on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceDetectionResult?alt=com.azure.ai.vision.face.models.FaceDetectionResult&text=FaceDetectionResult\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.detect(java.lang.String,com.azure.ai.vision.face.models.FaceDetectionModel,com.azure.ai.vision.face.models.FaceRecognitionModel,boolean)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId)"
  name: "detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId)"
  nameWithType: "FaceAsyncClient.detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId)"
  summary: "Detect human faces in an image, return face rectangles, and optionally with face<wbr>Ids, landmarks, and attributes."
  parameters:
  - description: "the URL of input image."
    name: "url"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>"
  - description: "The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'\n values include 'detection_01', 'detection_02' and 'detection_03'."
    name: "detectionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceDetectionModel?alt=com.azure.ai.vision.face.models.FaceDetectionModel&text=FaceDetectionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'\n values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.\n 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with\n 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'."
    name: "recognitionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceRecognitionModel?alt=com.azure.ai.vision.face.models.FaceRecognitionModel&text=FaceRecognitionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "Return faceIds of the detected faces or not."
    name: "returnFaceId"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<List<FaceDetectionResult>> detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId)"
  desc: "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. > \\[!IMPORTANT\\] > To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. \\* \\* No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in \"Identify\", \"Verify\", and \"Find Similar\". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call. \\* Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate. \\* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB. \\* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size. \\* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small. \\* For optimal results when querying \"Identify\", \"Verify\", and \"Find Similar\" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes). \\* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model \\* 'detection\\_02': Face attributes and landmarks are disabled if you choose this detection model. \\* 'detection\\_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model. \\* Different 'recognitionModel' values are provided. If follow-up operations like \"Verify\", \"Identify\", \"Find Similar\" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition\\_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model."
  returns:
    description: "the response body on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceDetectionResult?alt=com.azure.ai.vision.face.models.FaceDetectionResult&text=FaceDetectionResult\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.detect(java.lang.String,com.azure.ai.vision.face.models.FaceDetectionModel,com.azure.ai.vision.face.models.FaceRecognitionModel,boolean,java.util.List<com.azure.ai.vision.face.models.FaceAttributeType>)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes)"
  name: "detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes)"
  nameWithType: "FaceAsyncClient.detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes)"
  summary: "Detect human faces in an image, return face rectangles, and optionally with face<wbr>Ids, landmarks, and attributes."
  parameters:
  - description: "the URL of input image."
    name: "url"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>"
  - description: "The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'\n values include 'detection_01', 'detection_02' and 'detection_03'."
    name: "detectionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceDetectionModel?alt=com.azure.ai.vision.face.models.FaceDetectionModel&text=FaceDetectionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'\n values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.\n 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with\n 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'."
    name: "recognitionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceRecognitionModel?alt=com.azure.ai.vision.face.models.FaceRecognitionModel&text=FaceRecognitionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "Return faceIds of the detected faces or not."
    name: "returnFaceId"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "Analyze and return the one or more specified face attributes in the comma-separated\n string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and\n time cost."
    name: "returnFaceAttributes"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceAttributeType?alt=com.azure.ai.vision.face.models.FaceAttributeType&text=FaceAttributeType\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public Mono<List<FaceDetectionResult>> detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes)"
  desc: "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. > \\[!IMPORTANT\\] > To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. \\* \\* No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in \"Identify\", \"Verify\", and \"Find Similar\". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call. \\* Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate. \\* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB. \\* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size. \\* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small. \\* For optimal results when querying \"Identify\", \"Verify\", and \"Find Similar\" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes). \\* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model \\* 'detection\\_02': Face attributes and landmarks are disabled if you choose this detection model. \\* 'detection\\_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model. \\* Different 'recognitionModel' values are provided. If follow-up operations like \"Verify\", \"Identify\", \"Find Similar\" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition\\_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model."
  returns:
    description: "the response body on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceDetectionResult?alt=com.azure.ai.vision.face.models.FaceDetectionResult&text=FaceDetectionResult\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.detect(java.lang.String,com.azure.ai.vision.face.models.FaceDetectionModel,com.azure.ai.vision.face.models.FaceRecognitionModel,boolean,java.util.List<com.azure.ai.vision.face.models.FaceAttributeType>,java.lang.Boolean,java.lang.Boolean,java.lang.Integer)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes, Boolean returnFaceLandmarks, Boolean returnRecognitionModel, Integer faceIdTimeToLive)"
  name: "detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes, Boolean returnFaceLandmarks, Boolean returnRecognitionModel, Integer faceIdTimeToLive)"
  nameWithType: "FaceAsyncClient.detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes, Boolean returnFaceLandmarks, Boolean returnRecognitionModel, Integer faceIdTimeToLive)"
  summary: "Detect human faces in an image, return face rectangles, and optionally with face<wbr>Ids, landmarks, and attributes."
  parameters:
  - description: "the URL of input image."
    name: "url"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>"
  - description: "The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'\n values include 'detection_01', 'detection_02' and 'detection_03'."
    name: "detectionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceDetectionModel?alt=com.azure.ai.vision.face.models.FaceDetectionModel&text=FaceDetectionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'\n values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.\n 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with\n 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'."
    name: "recognitionModel"
    type: "<xref href=\"com.azure.ai.vision.face.models.FaceRecognitionModel?alt=com.azure.ai.vision.face.models.FaceRecognitionModel&text=FaceRecognitionModel\" data-throw-if-not-resolved=\"False\" />"
  - description: "Return faceIds of the detected faces or not."
    name: "returnFaceId"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "Analyze and return the one or more specified face attributes in the comma-separated\n string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and\n time cost."
    name: "returnFaceAttributes"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceAttributeType?alt=com.azure.ai.vision.face.models.FaceAttributeType&text=FaceAttributeType\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "Return face landmarks of the detected faces or not. The default value is false."
    name: "returnFaceLandmarks"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Boolean.html\">Boolean</a>"
  - description: "Return 'recognitionModel' or not. The default value is false."
    name: "returnRecognitionModel"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Boolean.html\">Boolean</a>"
  - description: "The number of seconds for the face ID being cached. Supported range from 60 seconds up to\n 86400 seconds. The default value is 86400 (24 hours)."
    name: "faceIdTimeToLive"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Integer.html\">Integer</a>"
  syntax: "public Mono<List<FaceDetectionResult>> detect(String url, FaceDetectionModel detectionModel, FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes, Boolean returnFaceLandmarks, Boolean returnRecognitionModel, Integer faceIdTimeToLive)"
  desc: "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. > \\[!IMPORTANT\\] > To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. \\* \\* No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in \"Identify\", \"Verify\", and \"Find Similar\". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call. \\* Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate. \\* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB. \\* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size. \\* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small. \\* For optimal results when querying \"Identify\", \"Verify\", and \"Find Similar\" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes). \\* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model \\* 'detection\\_02': Face attributes and landmarks are disabled if you choose this detection model. \\* 'detection\\_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model. \\* Different 'recognitionModel' values are provided. If follow-up operations like \"Verify\", \"Identify\", \"Find Similar\" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition\\_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model."
  returns:
    description: "the response body on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceDetectionResult?alt=com.azure.ai.vision.face.models.FaceDetectionResult&text=FaceDetectionResult\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.findSimilar(java.lang.String,java.util.List<java.lang.String>)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.findSimilar(String faceId, List<String> faceIds)"
  name: "findSimilar(String faceId, List<String> faceIds)"
  nameWithType: "FaceAsyncClient.findSimilar(String faceId, List<String> faceIds)"
  summary: "Given query face's face<wbr>Id, to search the similar-looking faces from a face<wbr>Id array."
  parameters:
  - description: "faceId of the query face. User needs to call \"Detect\" first to get a valid faceId. Note that this\n faceId is not persisted and will expire 24 hours after the detection call."
    name: "faceId"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>"
  - description: "An array of candidate faceIds. All of them are created by \"Detect\" and the faceIds will expire 24\n hours after the detection call. The number of faceIds is limited to 1000."
    name: "faceIds"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>&gt;"
  syntax: "public Mono<List<FaceFindSimilarResult>> findSimilar(String faceId, List<String> faceIds)"
  desc: "Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect. Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity. Find similar has two working modes, \"matchPerson\" and \"matchFace\". \"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces. The 'recognitionModel' associated with the query faceId should be the same as the 'recognitionModel' used by the target faceId array."
  returns:
    description: "the response body on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceFindSimilarResult?alt=com.azure.ai.vision.face.models.FaceFindSimilarResult&text=FaceFindSimilarResult\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.findSimilar(java.lang.String,java.util.List<java.lang.String>,java.lang.Integer,com.azure.ai.vision.face.models.FindSimilarMatchMode)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.findSimilar(String faceId, List<String> faceIds, Integer maxNumOfCandidatesReturned, FindSimilarMatchMode mode)"
  name: "findSimilar(String faceId, List<String> faceIds, Integer maxNumOfCandidatesReturned, FindSimilarMatchMode mode)"
  nameWithType: "FaceAsyncClient.findSimilar(String faceId, List<String> faceIds, Integer maxNumOfCandidatesReturned, FindSimilarMatchMode mode)"
  summary: "Given query face's face<wbr>Id, to search the similar-looking faces from a face<wbr>Id array."
  parameters:
  - description: "faceId of the query face. User needs to call \"Detect\" first to get a valid faceId. Note that this\n faceId is not persisted and will expire 24 hours after the detection call."
    name: "faceId"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>"
  - description: "An array of candidate faceIds. All of them are created by \"Detect\" and the faceIds will expire 24\n hours after the detection call. The number of faceIds is limited to 1000."
    name: "faceIds"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>&gt;"
  - description: "The number of top similar faces returned. The valid range is [1, 1000]. Default\n value is 20."
    name: "maxNumOfCandidatesReturned"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Integer.html\">Integer</a>"
  - description: "Similar face searching mode. It can be 'matchPerson' or 'matchFace'. Default value is 'matchPerson'."
    name: "mode"
    type: "<xref href=\"com.azure.ai.vision.face.models.FindSimilarMatchMode?alt=com.azure.ai.vision.face.models.FindSimilarMatchMode&text=FindSimilarMatchMode\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<List<FaceFindSimilarResult>> findSimilar(String faceId, List<String> faceIds, Integer maxNumOfCandidatesReturned, FindSimilarMatchMode mode)"
  desc: "Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect. Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity. Find similar has two working modes, \"matchPerson\" and \"matchFace\". \"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces. The 'recognitionModel' associated with the query faceId should be the same as the 'recognitionModel' used by the target faceId array."
  returns:
    description: "the response body on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceFindSimilarResult?alt=com.azure.ai.vision.face.models.FaceFindSimilarResult&text=FaceFindSimilarResult\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.findSimilarWithResponse(com.azure.core.util.BinaryData,com.azure.core.http.rest.RequestOptions)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.findSimilarWithResponse(BinaryData request, RequestOptions requestOptions)"
  name: "findSimilarWithResponse(BinaryData request, RequestOptions requestOptions)"
  nameWithType: "FaceAsyncClient.findSimilarWithResponse(BinaryData request, RequestOptions requestOptions)"
  summary: "Given query face's face<wbr>Id, to search the similar-looking faces from a face<wbr>Id array."
  parameters:
  - description: "The request parameter."
    name: "request"
    type: "<xref href=\"com.azure.core.util.BinaryData?alt=com.azure.core.util.BinaryData&text=BinaryData\" data-throw-if-not-resolved=\"False\" />"
  - description: "The options to configure the HTTP request before HTTP client sends it."
    name: "requestOptions"
    type: "<xref href=\"com.azure.core.http.rest.RequestOptions?alt=com.azure.core.http.rest.RequestOptions&text=RequestOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<BinaryData>> findSimilarWithResponse(BinaryData request, RequestOptions requestOptions)"
  desc: "Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect. Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity. Find similar has two working modes, \"matchPerson\" and \"matchFace\". \"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces. The 'recognitionModel' associated with the query faceId should be the same as the 'recognitionModel' used by the target faceId array.\n\n**Request Body Schema**\n\n```java\n{\n     faceId: String (Required)\n     maxNumOfCandidatesReturned: Integer (Optional)\n     mode: String(matchPerson/matchFace) (Optional)\n     faceIds (Required): [\n         String (Required)\n     ]\n }\n```\n\n**Response Body Schema**\n\n```java\n[\n      (Required){\n         confidence: double (Required)\n         faceId: String (Optional)\n         persistedFaceId: String (Optional)\n     }\n ]\n```"
  returns:
    description: "the response body along with <xref uid=\"com.azure.core.http.rest.Response\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Response\"></xref> on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.util.BinaryData?alt=com.azure.core.util.BinaryData&text=BinaryData\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.group(java.util.List<java.lang.String>)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.group(List<String> faceIds)"
  name: "group(List<String> faceIds)"
  nameWithType: "FaceAsyncClient.group(List<String> faceIds)"
  summary: "Divide candidate faces into groups based on face similarity."
  parameters:
  - description: "Array of candidate faceIds created by \"Detect\". The maximum is 1000 faces."
    name: "faceIds"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>&gt;"
  syntax: "public Mono<FaceGroupingResult> group(List<String> faceIds)"
  desc: "Divide candidate faces into groups based on face similarity. > \\* \\* The output is one or more disjointed face groups and a messyGroup. A face group contains faces that have similar looking, often of the same person. Face groups are ranked by group size, i.e. number of faces. Notice that faces belonging to a same person might be split into several groups in the result. \\* MessyGroup is a special face group containing faces that cannot find any similar counterpart face from original faces. The messyGroup will not appear in the result if all faces found their counterparts. \\* Group API needs at least 2 candidate faces and 1000 at most. We suggest to try \"Verify Face To Face\" when you only have 2 candidate faces. \\* The 'recognitionModel' associated with the query faces' faceIds should be the same."
  returns:
    description: "response body for group face operation on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceGroupingResult?alt=com.azure.ai.vision.face.models.FaceGroupingResult&text=FaceGroupingResult\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.groupWithResponse(com.azure.core.util.BinaryData,com.azure.core.http.rest.RequestOptions)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.groupWithResponse(BinaryData request, RequestOptions requestOptions)"
  name: "groupWithResponse(BinaryData request, RequestOptions requestOptions)"
  nameWithType: "FaceAsyncClient.groupWithResponse(BinaryData request, RequestOptions requestOptions)"
  summary: "Divide candidate faces into groups based on face similarity."
  parameters:
  - description: "The request parameter."
    name: "request"
    type: "<xref href=\"com.azure.core.util.BinaryData?alt=com.azure.core.util.BinaryData&text=BinaryData\" data-throw-if-not-resolved=\"False\" />"
  - description: "The options to configure the HTTP request before HTTP client sends it."
    name: "requestOptions"
    type: "<xref href=\"com.azure.core.http.rest.RequestOptions?alt=com.azure.core.http.rest.RequestOptions&text=RequestOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<BinaryData>> groupWithResponse(BinaryData request, RequestOptions requestOptions)"
  desc: "Divide candidate faces into groups based on face similarity. > \\* \\* The output is one or more disjointed face groups and a messyGroup. A face group contains faces that have similar looking, often of the same person. Face groups are ranked by group size, i.e. number of faces. Notice that faces belonging to a same person might be split into several groups in the result. \\* MessyGroup is a special face group containing faces that cannot find any similar counterpart face from original faces. The messyGroup will not appear in the result if all faces found their counterparts. \\* Group API needs at least 2 candidate faces and 1000 at most. We suggest to try \"Verify Face To Face\" when you only have 2 candidate faces. \\* The 'recognitionModel' associated with the query faces' faceIds should be the same.\n\n**Request Body Schema**\n\n```java\n{\n     faceIds (Required): [\n         String (Required)\n     ]\n }\n```\n\n**Response Body Schema**\n\n```java\n{\n     groups (Required): [\n          (Required)[\n             String (Required)\n         ]\n     ]\n     messyGroup (Required): [\n         String (Required)\n     ]\n }\n```"
  returns:
    description: "response body for group face operation along with <xref uid=\"com.azure.core.http.rest.Response\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Response\"></xref> on successful completion of\n <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.util.BinaryData?alt=com.azure.core.util.BinaryData&text=BinaryData\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.verifyFaceToFace(java.lang.String,java.lang.String)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.verifyFaceToFace(String faceId1, String faceId2)"
  name: "verifyFaceToFace(String faceId1, String faceId2)"
  nameWithType: "FaceAsyncClient.verifyFaceToFace(String faceId1, String faceId2)"
  summary: "Verify whether two faces belong to a same person."
  parameters:
  - description: "The faceId of one face, come from \"Detect\"."
    name: "faceId1"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>"
  - description: "The faceId of another face, come from \"Detect\"."
    name: "faceId2"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>"
  syntax: "public Mono<FaceVerificationResult> verifyFaceToFace(String faceId1, String faceId2)"
  desc: "Verify whether two faces belong to a same person. > \\[!NOTE\\] > > \\* > \\* Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger. > \\* For the scenarios that are sensitive to accuracy please make your own judgment. > \\* The 'recognitionModel' associated with the both faces should be the same."
  returns:
    description: "verify result on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<xref href=\"com.azure.ai.vision.face.models.FaceVerificationResult?alt=com.azure.ai.vision.face.models.FaceVerificationResult&text=FaceVerificationResult\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.ai.vision.face.FaceAsyncClient.verifyFaceToFaceWithResponse(com.azure.core.util.BinaryData,com.azure.core.http.rest.RequestOptions)"
  fullName: "com.azure.ai.vision.face.FaceAsyncClient.verifyFaceToFaceWithResponse(BinaryData request, RequestOptions requestOptions)"
  name: "verifyFaceToFaceWithResponse(BinaryData request, RequestOptions requestOptions)"
  nameWithType: "FaceAsyncClient.verifyFaceToFaceWithResponse(BinaryData request, RequestOptions requestOptions)"
  summary: "Verify whether two faces belong to a same person."
  parameters:
  - description: "The request parameter."
    name: "request"
    type: "<xref href=\"com.azure.core.util.BinaryData?alt=com.azure.core.util.BinaryData&text=BinaryData\" data-throw-if-not-resolved=\"False\" />"
  - description: "The options to configure the HTTP request before HTTP client sends it."
    name: "requestOptions"
    type: "<xref href=\"com.azure.core.http.rest.RequestOptions?alt=com.azure.core.http.rest.RequestOptions&text=RequestOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<BinaryData>> verifyFaceToFaceWithResponse(BinaryData request, RequestOptions requestOptions)"
  desc: "Verify whether two faces belong to a same person. > \\[!NOTE\\] > > \\* > \\* Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger. > \\* For the scenarios that are sensitive to accuracy please make your own judgment. > \\* The 'recognitionModel' associated with the both faces should be the same.\n\n**Request Body Schema**\n\n```java\n{\n     faceId1: String (Required)\n     faceId2: String (Required)\n }\n```\n\n**Response Body Schema**\n\n```java\n{\n     isIdentical: boolean (Required)\n     confidence: double (Required)\n }\n```"
  returns:
    description: "verify result along with <xref uid=\"com.azure.core.http.rest.Response\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Response\"></xref> on successful completion of <xref uid=\"reactor.core.publisher.Mono\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Mono\"></xref>."
    type: "<a href=\"https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html\">Mono</a>&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.util.BinaryData?alt=com.azure.core.util.BinaryData&text=BinaryData\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
type: "class"
desc: "Initializes a new instance of the asynchronous FaceClient type."
metadata: {}
package: "com.azure.ai.vision.face"
artifact: com.azure:azure-ai-vision-face:1.0.0-beta.1
