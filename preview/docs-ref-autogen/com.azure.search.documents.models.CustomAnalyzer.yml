### YamlMime:ManagedReference
items:
- uid: "com.azure.search.documents.models.CustomAnalyzer"
  id: "CustomAnalyzer"
  parent: "com.azure.search.documents.models"
  children:
  - "com.azure.search.documents.models.CustomAnalyzer.CustomAnalyzer()"
  - "com.azure.search.documents.models.CustomAnalyzer.getCharFilters()"
  - "com.azure.search.documents.models.CustomAnalyzer.getTokenFilters()"
  - "com.azure.search.documents.models.CustomAnalyzer.getTokenizer()"
  - "com.azure.search.documents.models.CustomAnalyzer.setCharFilters(java.util.List<com.azure.search.documents.models.CharFilterName>)"
  - "com.azure.search.documents.models.CustomAnalyzer.setTokenFilters(java.util.List<com.azure.search.documents.models.TokenFilterName>)"
  - "com.azure.search.documents.models.CustomAnalyzer.setTokenizer(com.azure.search.documents.models.TokenizerName)"
  langs:
  - "java"
  name: "CustomAnalyzer"
  nameWithType: "CustomAnalyzer"
  fullName: "com.azure.search.documents.models.CustomAnalyzer"
  type: "Class"
  package: "com.azure.search.documents.models"
  summary: "Allows you to take control over the process of converting text into indexable/searchable tokens. It's a user-defined configuration consisting of a single predefined tokenizer and one or more filters. The tokenizer is responsible for breaking text into tokens, and the filters for modifying tokens emitted by the tokenizer."
  syntax:
    content: "public final class CustomAnalyzer extends Analyzer"
  inheritance:
  - "java.lang.Object"
  - "com.azure.search.documents.models.Analyzer"
  inheritedMembers:
  - "com.azure.search.documents.models.Analyzer.getName()"
  - "com.azure.search.documents.models.Analyzer.setName(java.lang.String)"
  - "java.lang.Object.clone()"
  - "java.lang.Object.equals(java.lang.Object)"
  - "java.lang.Object.finalize()"
  - "java.lang.Object.getClass()"
  - "java.lang.Object.hashCode()"
  - "java.lang.Object.notify()"
  - "java.lang.Object.notifyAll()"
  - "java.lang.Object.toString()"
  - "java.lang.Object.wait()"
  - "java.lang.Object.wait(long)"
  - "java.lang.Object.wait(long,int)"
- uid: "com.azure.search.documents.models.CustomAnalyzer.CustomAnalyzer()"
  id: "CustomAnalyzer()"
  parent: "com.azure.search.documents.models.CustomAnalyzer"
  langs:
  - "java"
  name: "CustomAnalyzer()"
  nameWithType: "CustomAnalyzer.CustomAnalyzer()"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.CustomAnalyzer()"
  overload: "com.azure.search.documents.models.CustomAnalyzer.CustomAnalyzer*"
  type: "Constructor"
  package: "com.azure.search.documents.models"
  syntax:
    content: "public CustomAnalyzer()"
- uid: "com.azure.search.documents.models.CustomAnalyzer.getCharFilters()"
  id: "getCharFilters()"
  parent: "com.azure.search.documents.models.CustomAnalyzer"
  langs:
  - "java"
  name: "getCharFilters()"
  nameWithType: "CustomAnalyzer.getCharFilters()"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.getCharFilters()"
  overload: "com.azure.search.documents.models.CustomAnalyzer.getCharFilters*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the charFilters property: A list of character filters used to prepare input text before it is processed by the tokenizer. For instance, they can replace certain characters or symbols. The filters are run in the order in which they are listed."
  syntax:
    content: "public List<CharFilterName> getCharFilters()"
    return:
      type: "java.util.List<com.azure.search.documents.models.CharFilterName>"
      description: "the charFilters value."
- uid: "com.azure.search.documents.models.CustomAnalyzer.getTokenFilters()"
  id: "getTokenFilters()"
  parent: "com.azure.search.documents.models.CustomAnalyzer"
  langs:
  - "java"
  name: "getTokenFilters()"
  nameWithType: "CustomAnalyzer.getTokenFilters()"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.getTokenFilters()"
  overload: "com.azure.search.documents.models.CustomAnalyzer.getTokenFilters*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the tokenFilters property: A list of token filters used to filter out or modify the tokens generated by a tokenizer. For example, you can specify a lowercase filter that converts all characters to lowercase. The filters are run in the order in which they are listed."
  syntax:
    content: "public List<TokenFilterName> getTokenFilters()"
    return:
      type: "java.util.List<com.azure.search.documents.models.TokenFilterName>"
      description: "the tokenFilters value."
- uid: "com.azure.search.documents.models.CustomAnalyzer.getTokenizer()"
  id: "getTokenizer()"
  parent: "com.azure.search.documents.models.CustomAnalyzer"
  langs:
  - "java"
  name: "getTokenizer()"
  nameWithType: "CustomAnalyzer.getTokenizer()"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.getTokenizer()"
  overload: "com.azure.search.documents.models.CustomAnalyzer.getTokenizer*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the tokenizer property: The name of the tokenizer to use to divide continuous text into a sequence of tokens, such as breaking a sentence into words. Possible values include: 'Classic', 'EdgeNGram', 'Keyword', 'Letter', 'Lowercase', 'MicrosoftLanguageTokenizer', 'MicrosoftLanguageStemmingTokenizer', 'NGram', 'PathHierarchy', 'Pattern', 'Standard', 'UaxUrlEmail', 'Whitespace'."
  syntax:
    content: "public TokenizerName getTokenizer()"
    return:
      type: "com.azure.search.documents.models.TokenizerName"
      description: "the tokenizer value."
- uid: "com.azure.search.documents.models.CustomAnalyzer.setCharFilters(java.util.List<com.azure.search.documents.models.CharFilterName>)"
  id: "setCharFilters(java.util.List<com.azure.search.documents.models.CharFilterName>)"
  parent: "com.azure.search.documents.models.CustomAnalyzer"
  langs:
  - "java"
  name: "setCharFilters(List<CharFilterName> charFilters)"
  nameWithType: "CustomAnalyzer.setCharFilters(List<CharFilterName> charFilters)"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.setCharFilters(List<CharFilterName> charFilters)"
  overload: "com.azure.search.documents.models.CustomAnalyzer.setCharFilters*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the charFilters property: A list of character filters used to prepare input text before it is processed by the tokenizer. For instance, they can replace certain characters or symbols. The filters are run in the order in which they are listed."
  syntax:
    content: "public CustomAnalyzer setCharFilters(List<CharFilterName> charFilters)"
    parameters:
    - id: "charFilters"
      type: "java.util.List<com.azure.search.documents.models.CharFilterName>"
      description: "the charFilters value to set."
    return:
      type: "com.azure.search.documents.models.CustomAnalyzer"
      description: "the CustomAnalyzer object itself."
- uid: "com.azure.search.documents.models.CustomAnalyzer.setTokenFilters(java.util.List<com.azure.search.documents.models.TokenFilterName>)"
  id: "setTokenFilters(java.util.List<com.azure.search.documents.models.TokenFilterName>)"
  parent: "com.azure.search.documents.models.CustomAnalyzer"
  langs:
  - "java"
  name: "setTokenFilters(List<TokenFilterName> tokenFilters)"
  nameWithType: "CustomAnalyzer.setTokenFilters(List<TokenFilterName> tokenFilters)"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.setTokenFilters(List<TokenFilterName> tokenFilters)"
  overload: "com.azure.search.documents.models.CustomAnalyzer.setTokenFilters*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the tokenFilters property: A list of token filters used to filter out or modify the tokens generated by a tokenizer. For example, you can specify a lowercase filter that converts all characters to lowercase. The filters are run in the order in which they are listed."
  syntax:
    content: "public CustomAnalyzer setTokenFilters(List<TokenFilterName> tokenFilters)"
    parameters:
    - id: "tokenFilters"
      type: "java.util.List<com.azure.search.documents.models.TokenFilterName>"
      description: "the tokenFilters value to set."
    return:
      type: "com.azure.search.documents.models.CustomAnalyzer"
      description: "the CustomAnalyzer object itself."
- uid: "com.azure.search.documents.models.CustomAnalyzer.setTokenizer(com.azure.search.documents.models.TokenizerName)"
  id: "setTokenizer(com.azure.search.documents.models.TokenizerName)"
  parent: "com.azure.search.documents.models.CustomAnalyzer"
  langs:
  - "java"
  name: "setTokenizer(TokenizerName tokenizer)"
  nameWithType: "CustomAnalyzer.setTokenizer(TokenizerName tokenizer)"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.setTokenizer(TokenizerName tokenizer)"
  overload: "com.azure.search.documents.models.CustomAnalyzer.setTokenizer*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the tokenizer property: The name of the tokenizer to use to divide continuous text into a sequence of tokens, such as breaking a sentence into words. Possible values include: 'Classic', 'EdgeNGram', 'Keyword', 'Letter', 'Lowercase', 'MicrosoftLanguageTokenizer', 'MicrosoftLanguageStemmingTokenizer', 'NGram', 'PathHierarchy', 'Pattern', 'Standard', 'UaxUrlEmail', 'Whitespace'."
  syntax:
    content: "public CustomAnalyzer setTokenizer(TokenizerName tokenizer)"
    parameters:
    - id: "tokenizer"
      type: "com.azure.search.documents.models.TokenizerName"
      description: "the tokenizer value to set."
    return:
      type: "com.azure.search.documents.models.CustomAnalyzer"
      description: "the CustomAnalyzer object itself."
references:
- uid: "com.azure.search.documents.models.CustomAnalyzer.CustomAnalyzer*"
  name: "CustomAnalyzer"
  nameWithType: "CustomAnalyzer.CustomAnalyzer"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.CustomAnalyzer"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.TokenizerName"
  name: "TokenizerName"
  nameWithType: "TokenizerName"
  fullName: "com.azure.search.documents.models.TokenizerName"
- uid: "com.azure.search.documents.models.CustomAnalyzer.getTokenizer*"
  name: "getTokenizer"
  nameWithType: "CustomAnalyzer.getTokenizer"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.getTokenizer"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.CustomAnalyzer.setTokenizer*"
  name: "setTokenizer"
  nameWithType: "CustomAnalyzer.setTokenizer"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.setTokenizer"
  package: "com.azure.search.documents.models"
- uid: "java.util.List<com.azure.search.documents.models.TokenFilterName>"
  spec.java:
  - uid: "java.util.List"
    name: "List"
    fullName: "java.util.List"
  - name: "<"
    fullName: "<"
  - uid: "com.azure.search.documents.models.TokenFilterName"
    name: "TokenFilterName"
    fullName: "com.azure.search.documents.models.TokenFilterName"
  - name: ">"
    fullName: ">"
- uid: "com.azure.search.documents.models.CustomAnalyzer.getTokenFilters*"
  name: "getTokenFilters"
  nameWithType: "CustomAnalyzer.getTokenFilters"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.getTokenFilters"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.CustomAnalyzer.setTokenFilters*"
  name: "setTokenFilters"
  nameWithType: "CustomAnalyzer.setTokenFilters"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.setTokenFilters"
  package: "com.azure.search.documents.models"
- uid: "java.util.List<com.azure.search.documents.models.CharFilterName>"
  spec.java:
  - uid: "java.util.List"
    name: "List"
    fullName: "java.util.List"
  - name: "<"
    fullName: "<"
  - uid: "com.azure.search.documents.models.CharFilterName"
    name: "CharFilterName"
    fullName: "com.azure.search.documents.models.CharFilterName"
  - name: ">"
    fullName: ">"
- uid: "com.azure.search.documents.models.CustomAnalyzer.getCharFilters*"
  name: "getCharFilters"
  nameWithType: "CustomAnalyzer.getCharFilters"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.getCharFilters"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.CustomAnalyzer.setCharFilters*"
  name: "setCharFilters"
  nameWithType: "CustomAnalyzer.setCharFilters"
  fullName: "com.azure.search.documents.models.CustomAnalyzer.setCharFilters"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.Analyzer"
  name: "Analyzer"
  nameWithType: "Analyzer"
  fullName: "com.azure.search.documents.models.Analyzer"
- uid: "java.lang.Object.notify()"
  name: "Object.notify()"
  nameWithType: "Object.notify()"
  fullName: "java.lang.Object.notify()"
- uid: "java.lang.Object.wait()"
  name: "Object.wait()"
  nameWithType: "Object.wait()"
  fullName: "java.lang.Object.wait()"
- uid: "java.lang.Object.finalize()"
  name: "Object.finalize()"
  nameWithType: "Object.finalize()"
  fullName: "java.lang.Object.finalize()"
- uid: "java.lang.Object.notifyAll()"
  name: "Object.notifyAll()"
  nameWithType: "Object.notifyAll()"
  fullName: "java.lang.Object.notifyAll()"
- uid: "java.lang.Object.clone()"
  name: "Object.clone()"
  nameWithType: "Object.clone()"
  fullName: "java.lang.Object.clone()"
- uid: "java.lang.Object.equals(java.lang.Object)"
  name: "Object.equals(Object)"
  nameWithType: "Object.equals(Object)"
  fullName: "java.lang.Object.equals(java.lang.Object)"
- uid: "java.lang.Object.toString()"
  name: "Object.toString()"
  nameWithType: "Object.toString()"
  fullName: "java.lang.Object.toString()"
- uid: "com.azure.search.documents.models.Analyzer.setName(java.lang.String)"
  name: "Analyzer.setName(String)"
  nameWithType: "Analyzer.setName(String)"
  fullName: "com.azure.search.documents.models.Analyzer.setName(java.lang.String)"
- uid: "java.lang.Object.getClass()"
  name: "Object.getClass()"
  nameWithType: "Object.getClass()"
  fullName: "java.lang.Object.getClass()"
- uid: "java.lang.Object.wait(long)"
  name: "Object.wait(long)"
  nameWithType: "Object.wait(long)"
  fullName: "java.lang.Object.wait(long)"
- uid: "java.lang.Object.hashCode()"
  name: "Object.hashCode()"
  nameWithType: "Object.hashCode()"
  fullName: "java.lang.Object.hashCode()"
- uid: "java.lang.Object.wait(long,int)"
  name: "Object.wait(long,int)"
  nameWithType: "Object.wait(long,int)"
  fullName: "java.lang.Object.wait(long,int)"
- uid: "com.azure.search.documents.models.Analyzer.getName()"
  name: "Analyzer.getName()"
  nameWithType: "Analyzer.getName()"
  fullName: "com.azure.search.documents.models.Analyzer.getName()"
- uid: "com.azure.search.documents.models.TokenFilterName"
  name: "TokenFilterName"
  nameWithType: "TokenFilterName"
  fullName: "com.azure.search.documents.models.TokenFilterName"
- uid: "java.util.List"
  name: "List"
  nameWithType: "List"
  fullName: "java.util.List"
- uid: "com.azure.search.documents.models.CharFilterName"
  name: "CharFilterName"
  nameWithType: "CharFilterName"
  fullName: "com.azure.search.documents.models.CharFilterName"
