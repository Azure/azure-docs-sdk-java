### YamlMime:JavaType
uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity"
fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity"
name: "DatabricksSparkPythonActivity"
nameWithType: "DatabricksSparkPythonActivity"
summary: "Databricks<wbr>Spark<wbr>Python activity."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
- "<xref href=\"com.azure.resourcemanager.datafactory.models.Activity?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
- "<xref href=\"com.azure.resourcemanager.datafactory.models.ExecutionActivity?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "com.azure.resourcemanager.datafactory.models.Activity.additionalProperties()"
- "com.azure.resourcemanager.datafactory.models.Activity.dependsOn()"
- "com.azure.resourcemanager.datafactory.models.Activity.description()"
- "com.azure.resourcemanager.datafactory.models.Activity.name()"
- "com.azure.resourcemanager.datafactory.models.Activity.userProperties()"
- "com.azure.resourcemanager.datafactory.models.Activity.withAdditionalProperties(java.util.Map<java.lang.String,java.lang.Object>)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.linkedServiceName()"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.policy()"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.validate()"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withDependsOn(java.util.List<com.azure.resourcemanager.datafactory.models.ActivityDependency>)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withDescription(java.lang.String)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withLinkedServiceName(com.azure.resourcemanager.datafactory.models.LinkedServiceReference)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withName(java.lang.String)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withPolicy(com.azure.resourcemanager.datafactory.models.ActivityPolicy)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withUserProperties(java.util.List<com.azure.resourcemanager.datafactory.models.UserProperty>)"
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class DatabricksSparkPythonActivity extends ExecutionActivity"
constructors:
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.DatabricksSparkPythonActivity()"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.DatabricksSparkPythonActivity()"
  name: "DatabricksSparkPythonActivity()"
  nameWithType: "DatabricksSparkPythonActivity.DatabricksSparkPythonActivity()"
  syntax: "public DatabricksSparkPythonActivity()"
methods:
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.libraries()"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.libraries()"
  name: "libraries()"
  nameWithType: "DatabricksSparkPythonActivity.libraries()"
  summary: "Get the libraries property: A list of libraries to be installed on the cluster that will execute the job."
  syntax: "public List<Map<String,Object>> libraries()"
  desc: "Get the libraries property: A list of libraries to be installed on the cluster that will execute the job."
  returns:
    description: "the libraries value."
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.parameters()"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.parameters()"
  name: "parameters()"
  nameWithType: "DatabricksSparkPythonActivity.parameters()"
  summary: "Get the parameters property: Command line parameters that will be passed to the Python file."
  syntax: "public List<Object> parameters()"
  desc: "Get the parameters property: Command line parameters that will be passed to the Python file."
  returns:
    description: "the parameters value."
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.pythonFile()"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.pythonFile()"
  name: "pythonFile()"
  nameWithType: "DatabricksSparkPythonActivity.pythonFile()"
  summary: "Get the python<wbr>File property: The URI of the Python file to be executed."
  syntax: "public Object pythonFile()"
  desc: "Get the pythonFile property: The URI of the Python file to be executed. DBFS paths are supported. Type: string (or Expression with resultType string)."
  returns:
    description: "the pythonFile value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.validate()"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.validate()"
  name: "validate()"
  nameWithType: "DatabricksSparkPythonActivity.validate()"
  summary: "Validates the instance."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.validate()"
  syntax: "public void validate()"
  desc: "Validates the instance."
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withDependsOn(java.util.List<com.azure.resourcemanager.datafactory.models.ActivityDependency>)"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withDependsOn(List<ActivityDependency> dependsOn)"
  name: "withDependsOn(List<ActivityDependency> dependsOn)"
  nameWithType: "DatabricksSparkPythonActivity.withDependsOn(List<ActivityDependency> dependsOn)"
  summary: "Set the depends<wbr>On property: Activity depends on condition."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withDependsOn(java.util.List<com.azure.resourcemanager.datafactory.models.ActivityDependency>)"
  parameters:
  - name: "dependsOn"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.resourcemanager.datafactory.models.ActivityDependency?alt=com.azure.resourcemanager.datafactory.models.ActivityDependency&text=ActivityDependency\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public DatabricksSparkPythonActivity withDependsOn(List<ActivityDependency> dependsOn)"
  desc: "Set the dependsOn property: Activity depends on condition."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity?alt=com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity&text=DatabricksSparkPythonActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withDescription(java.lang.String)"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withDescription(String description)"
  name: "withDescription(String description)"
  nameWithType: "DatabricksSparkPythonActivity.withDescription(String description)"
  summary: "Set the description property: Activity description."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withDescription(java.lang.String)"
  parameters:
  - name: "description"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DatabricksSparkPythonActivity withDescription(String description)"
  desc: "Set the description property: Activity description."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity?alt=com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity&text=DatabricksSparkPythonActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withLibraries(java.util.List<java.util.Map<java.lang.String,java.lang.Object>>)"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withLibraries(List<Map<String,Object>> libraries)"
  name: "withLibraries(List<Map<String,Object>> libraries)"
  nameWithType: "DatabricksSparkPythonActivity.withLibraries(List<Map<String,Object>> libraries)"
  summary: "Set the libraries property: A list of libraries to be installed on the cluster that will execute the job."
  parameters:
  - description: "the libraries value to set."
    name: "libraries"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
  syntax: "public DatabricksSparkPythonActivity withLibraries(List<Map<String,Object>> libraries)"
  desc: "Set the libraries property: A list of libraries to be installed on the cluster that will execute the job."
  returns:
    description: "the DatabricksSparkPythonActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity?alt=com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity&text=DatabricksSparkPythonActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withLinkedServiceName(com.azure.resourcemanager.datafactory.models.LinkedServiceReference)"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withLinkedServiceName(LinkedServiceReference linkedServiceName)"
  name: "withLinkedServiceName(LinkedServiceReference linkedServiceName)"
  nameWithType: "DatabricksSparkPythonActivity.withLinkedServiceName(LinkedServiceReference linkedServiceName)"
  summary: "Set the linked<wbr>Service<wbr>Name property: Linked service reference."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withLinkedServiceName(com.azure.resourcemanager.datafactory.models.LinkedServiceReference)"
  parameters:
  - name: "linkedServiceName"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.LinkedServiceReference?alt=com.azure.resourcemanager.datafactory.models.LinkedServiceReference&text=LinkedServiceReference\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DatabricksSparkPythonActivity withLinkedServiceName(LinkedServiceReference linkedServiceName)"
  desc: "Set the linkedServiceName property: Linked service reference."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity?alt=com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity&text=DatabricksSparkPythonActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withName(java.lang.String)"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withName(String name)"
  name: "withName(String name)"
  nameWithType: "DatabricksSparkPythonActivity.withName(String name)"
  summary: "Set the name property: Activity name."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withName(java.lang.String)"
  parameters:
  - name: "name"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DatabricksSparkPythonActivity withName(String name)"
  desc: "Set the name property: Activity name."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity?alt=com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity&text=DatabricksSparkPythonActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withParameters(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withParameters(List<Object> parameters)"
  name: "withParameters(List<Object> parameters)"
  nameWithType: "DatabricksSparkPythonActivity.withParameters(List<Object> parameters)"
  summary: "Set the parameters property: Command line parameters that will be passed to the Python file."
  parameters:
  - description: "the parameters value to set."
    name: "parameters"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public DatabricksSparkPythonActivity withParameters(List<Object> parameters)"
  desc: "Set the parameters property: Command line parameters that will be passed to the Python file."
  returns:
    description: "the DatabricksSparkPythonActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity?alt=com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity&text=DatabricksSparkPythonActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withPolicy(com.azure.resourcemanager.datafactory.models.ActivityPolicy)"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withPolicy(ActivityPolicy policy)"
  name: "withPolicy(ActivityPolicy policy)"
  nameWithType: "DatabricksSparkPythonActivity.withPolicy(ActivityPolicy policy)"
  summary: "Set the policy property: Activity policy."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withPolicy(com.azure.resourcemanager.datafactory.models.ActivityPolicy)"
  parameters:
  - name: "policy"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.ActivityPolicy?alt=com.azure.resourcemanager.datafactory.models.ActivityPolicy&text=ActivityPolicy\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DatabricksSparkPythonActivity withPolicy(ActivityPolicy policy)"
  desc: "Set the policy property: Activity policy."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity?alt=com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity&text=DatabricksSparkPythonActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withPythonFile(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withPythonFile(Object pythonFile)"
  name: "withPythonFile(Object pythonFile)"
  nameWithType: "DatabricksSparkPythonActivity.withPythonFile(Object pythonFile)"
  summary: "Set the python<wbr>File property: The URI of the Python file to be executed."
  parameters:
  - description: "the pythonFile value to set."
    name: "pythonFile"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DatabricksSparkPythonActivity withPythonFile(Object pythonFile)"
  desc: "Set the pythonFile property: The URI of the Python file to be executed. DBFS paths are supported. Type: string (or Expression with resultType string)."
  returns:
    description: "the DatabricksSparkPythonActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity?alt=com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity&text=DatabricksSparkPythonActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withUserProperties(java.util.List<com.azure.resourcemanager.datafactory.models.UserProperty>)"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withUserProperties(List<UserProperty> userProperties)"
  name: "withUserProperties(List<UserProperty> userProperties)"
  nameWithType: "DatabricksSparkPythonActivity.withUserProperties(List<UserProperty> userProperties)"
  summary: "Set the user<wbr>Properties property: Activity user properties."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withUserProperties(java.util.List<com.azure.resourcemanager.datafactory.models.UserProperty>)"
  parameters:
  - name: "userProperties"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.resourcemanager.datafactory.models.UserProperty?alt=com.azure.resourcemanager.datafactory.models.UserProperty&text=UserProperty\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public DatabricksSparkPythonActivity withUserProperties(List<UserProperty> userProperties)"
  desc: "Set the userProperties property: Activity user properties."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity?alt=com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity&text=DatabricksSparkPythonActivity\" data-throw-if-not-resolved=\"False\" />"
type: "class"
desc: "DatabricksSparkPython activity."
metadata: {}
package: "com.azure.resourcemanager.datafactory.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.16
