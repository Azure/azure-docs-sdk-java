### YamlMime:JavaType
uid: "com.azure.analytics.synapse.spark.SparkSessionClient"
fullName: "com.azure.analytics.synapse.spark.SparkSessionClient"
name: "SparkSessionClient"
nameWithType: "SparkSessionClient"
summary: "Initializes a new instance of the synchronous Spark<wbr>Client type."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class SparkSessionClient"
methods:
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.cancelSparkSession(int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.cancelSparkSession(int sessionId)"
  name: "cancelSparkSession(int sessionId)"
  nameWithType: "SparkSessionClient.cancelSparkSession(int sessionId)"
  summary: "Cancels a running spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public void cancelSparkSession(int sessionId)"
  desc: "Cancels a running spark session."
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.cancelSparkSessionWithResponse(int,com.azure.core.util.Context)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.cancelSparkSessionWithResponse(int sessionId, Context context)"
  name: "cancelSparkSessionWithResponse(int sessionId, Context context)"
  nameWithType: "SparkSessionClient.cancelSparkSessionWithResponse(int sessionId, Context context)"
  summary: "Cancels a running spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<Void> cancelSparkSessionWithResponse(int sessionId, Context context)"
  desc: "Cancels a running spark session."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.cancelSparkStatement(int,int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.cancelSparkStatement(int sessionId, int statementId)"
  name: "cancelSparkStatement(int sessionId, int statementId)"
  nameWithType: "SparkSessionClient.cancelSparkStatement(int sessionId, int statementId)"
  summary: "Kill a statement within a session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Identifier for the statement."
    name: "statementId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkStatementCancellationResult cancelSparkStatement(int sessionId, int statementId)"
  desc: "Kill a statement within a session."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementCancellationResult?alt=com.azure.analytics.synapse.spark.models.SparkStatementCancellationResult&text=SparkStatementCancellationResult\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.cancelSparkStatementWithResponse(int,int,com.azure.core.util.Context)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.cancelSparkStatementWithResponse(int sessionId, int statementId, Context context)"
  name: "cancelSparkStatementWithResponse(int sessionId, int statementId, Context context)"
  nameWithType: "SparkSessionClient.cancelSparkStatementWithResponse(int sessionId, int statementId, Context context)"
  summary: "Kill a statement within a session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Identifier for the statement."
    name: "statementId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<SparkStatementCancellationResult> cancelSparkStatementWithResponse(int sessionId, int statementId, Context context)"
  desc: "Kill a statement within a session."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementCancellationResult?alt=com.azure.analytics.synapse.spark.models.SparkStatementCancellationResult&text=SparkStatementCancellationResult\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.createSparkSession(com.azure.analytics.synapse.spark.models.SparkSessionOptions)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.createSparkSession(SparkSessionOptions sparkSessionOptions)"
  name: "createSparkSession(SparkSessionOptions sparkSessionOptions)"
  nameWithType: "SparkSessionClient.createSparkSession(SparkSessionOptions sparkSessionOptions)"
  summary: "Create new spark session."
  parameters:
  - description: "Livy compatible batch job request payload."
    name: "sparkSessionOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionOptions?alt=com.azure.analytics.synapse.spark.models.SparkSessionOptions&text=SparkSessionOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkSession createSparkSession(SparkSessionOptions sparkSessionOptions)"
  desc: "Create new spark session."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.createSparkSession(com.azure.analytics.synapse.spark.models.SparkSessionOptions,java.lang.Boolean)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.createSparkSession(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  name: "createSparkSession(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  nameWithType: "SparkSessionClient.createSparkSession(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  summary: "Create new spark session."
  parameters:
  - description: "Livy compatible batch job request payload."
    name: "sparkSessionOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionOptions?alt=com.azure.analytics.synapse.spark.models.SparkSessionOptions&text=SparkSessionOptions\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkSession createSparkSession(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  desc: "Create new spark session."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.createSparkSessionWithResponse(com.azure.analytics.synapse.spark.models.SparkSessionOptions,java.lang.Boolean,com.azure.core.util.Context)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.createSparkSessionWithResponse(SparkSessionOptions sparkSessionOptions, Boolean detailed, Context context)"
  name: "createSparkSessionWithResponse(SparkSessionOptions sparkSessionOptions, Boolean detailed, Context context)"
  nameWithType: "SparkSessionClient.createSparkSessionWithResponse(SparkSessionOptions sparkSessionOptions, Boolean detailed, Context context)"
  summary: "Create new spark session."
  parameters:
  - description: "Livy compatible batch job request payload."
    name: "sparkSessionOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionOptions?alt=com.azure.analytics.synapse.spark.models.SparkSessionOptions&text=SparkSessionOptions\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<SparkSession> createSparkSessionWithResponse(SparkSessionOptions sparkSessionOptions, Boolean detailed, Context context)"
  desc: "Create new spark session."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.createSparkStatement(int,com.azure.analytics.synapse.spark.models.SparkStatementOptions)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  name: "createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  nameWithType: "SparkSessionClient.createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  summary: "Create statement within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Livy compatible batch job request payload."
    name: "sparkStatementOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementOptions?alt=com.azure.analytics.synapse.spark.models.SparkStatementOptions&text=SparkStatementOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkStatement createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  desc: "Create statement within a spark session."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatement?alt=com.azure.analytics.synapse.spark.models.SparkStatement&text=SparkStatement\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.createSparkStatementWithResponse(int,com.azure.analytics.synapse.spark.models.SparkStatementOptions,com.azure.core.util.Context)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.createSparkStatementWithResponse(int sessionId, SparkStatementOptions sparkStatementOptions, Context context)"
  name: "createSparkStatementWithResponse(int sessionId, SparkStatementOptions sparkStatementOptions, Context context)"
  nameWithType: "SparkSessionClient.createSparkStatementWithResponse(int sessionId, SparkStatementOptions sparkStatementOptions, Context context)"
  summary: "Create statement within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Livy compatible batch job request payload."
    name: "sparkStatementOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementOptions?alt=com.azure.analytics.synapse.spark.models.SparkStatementOptions&text=SparkStatementOptions\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<SparkStatement> createSparkStatementWithResponse(int sessionId, SparkStatementOptions sparkStatementOptions, Context context)"
  desc: "Create statement within a spark session."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatement?alt=com.azure.analytics.synapse.spark.models.SparkStatement&text=SparkStatement\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSession(int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSession(int sessionId)"
  name: "getSparkSession(int sessionId)"
  nameWithType: "SparkSessionClient.getSparkSession(int sessionId)"
  summary: "Gets a single spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkSession getSparkSession(int sessionId)"
  desc: "Gets a single spark session."
  returns:
    description: "a single spark session."
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSession(int,java.lang.Boolean)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSession(int sessionId, Boolean detailed)"
  name: "getSparkSession(int sessionId, Boolean detailed)"
  nameWithType: "SparkSessionClient.getSparkSession(int sessionId, Boolean detailed)"
  summary: "Gets a single spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkSession getSparkSession(int sessionId, Boolean detailed)"
  desc: "Gets a single spark session."
  returns:
    description: "a single spark session."
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSessionWithResponse(int,java.lang.Boolean,com.azure.core.util.Context)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSessionWithResponse(int sessionId, Boolean detailed, Context context)"
  name: "getSparkSessionWithResponse(int sessionId, Boolean detailed, Context context)"
  nameWithType: "SparkSessionClient.getSparkSessionWithResponse(int sessionId, Boolean detailed, Context context)"
  summary: "Gets a single spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<SparkSession> getSparkSessionWithResponse(int sessionId, Boolean detailed, Context context)"
  desc: "Gets a single spark session."
  returns:
    description: "a single spark session."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSessions()"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSessions()"
  name: "getSparkSessions()"
  nameWithType: "SparkSessionClient.getSparkSessions()"
  summary: "List all spark sessions which are running under a particular spark pool."
  syntax: "public SparkSessionCollection getSparkSessions()"
  desc: "List all spark sessions which are running under a particular spark pool."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionCollection?alt=com.azure.analytics.synapse.spark.models.SparkSessionCollection&text=SparkSessionCollection\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSessions(java.lang.Integer,java.lang.Integer,java.lang.Boolean)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSessions(Integer from, Integer size, Boolean detailed)"
  name: "getSparkSessions(Integer from, Integer size, Boolean detailed)"
  nameWithType: "SparkSessionClient.getSparkSessions(Integer from, Integer size, Boolean detailed)"
  summary: "List all spark sessions which are running under a particular spark pool."
  parameters:
  - description: "Optional param specifying which index the list should begin from."
    name: "from"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional param specifying the size of the returned list. By default it is 20 and that is the maximum."
    name: "size"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkSessionCollection getSparkSessions(Integer from, Integer size, Boolean detailed)"
  desc: "List all spark sessions which are running under a particular spark pool."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionCollection?alt=com.azure.analytics.synapse.spark.models.SparkSessionCollection&text=SparkSessionCollection\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSessionsWithResponse(java.lang.Integer,java.lang.Integer,java.lang.Boolean,com.azure.core.util.Context)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkSessionsWithResponse(Integer from, Integer size, Boolean detailed, Context context)"
  name: "getSparkSessionsWithResponse(Integer from, Integer size, Boolean detailed, Context context)"
  nameWithType: "SparkSessionClient.getSparkSessionsWithResponse(Integer from, Integer size, Boolean detailed, Context context)"
  summary: "List all spark sessions which are running under a particular spark pool."
  parameters:
  - description: "Optional param specifying which index the list should begin from."
    name: "from"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional param specifying the size of the returned list. By default it is 20 and that is the maximum."
    name: "size"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<SparkSessionCollection> getSparkSessionsWithResponse(Integer from, Integer size, Boolean detailed, Context context)"
  desc: "List all spark sessions which are running under a particular spark pool."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionCollection?alt=com.azure.analytics.synapse.spark.models.SparkSessionCollection&text=SparkSessionCollection\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkStatement(int,int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkStatement(int sessionId, int statementId)"
  name: "getSparkStatement(int sessionId, int statementId)"
  nameWithType: "SparkSessionClient.getSparkStatement(int sessionId, int statementId)"
  summary: "Gets a single statement within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Identifier for the statement."
    name: "statementId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkStatement getSparkStatement(int sessionId, int statementId)"
  desc: "Gets a single statement within a spark session."
  returns:
    description: "a single statement within a spark session."
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatement?alt=com.azure.analytics.synapse.spark.models.SparkStatement&text=SparkStatement\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkStatementWithResponse(int,int,com.azure.core.util.Context)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkStatementWithResponse(int sessionId, int statementId, Context context)"
  name: "getSparkStatementWithResponse(int sessionId, int statementId, Context context)"
  nameWithType: "SparkSessionClient.getSparkStatementWithResponse(int sessionId, int statementId, Context context)"
  summary: "Gets a single statement within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Identifier for the statement."
    name: "statementId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<SparkStatement> getSparkStatementWithResponse(int sessionId, int statementId, Context context)"
  desc: "Gets a single statement within a spark session."
  returns:
    description: "a single statement within a spark session."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatement?alt=com.azure.analytics.synapse.spark.models.SparkStatement&text=SparkStatement\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkStatements(int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkStatements(int sessionId)"
  name: "getSparkStatements(int sessionId)"
  nameWithType: "SparkSessionClient.getSparkStatements(int sessionId)"
  summary: "Gets a list of statements within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkStatementCollection getSparkStatements(int sessionId)"
  desc: "Gets a list of statements within a spark session."
  returns:
    description: "a list of statements within a spark session."
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementCollection?alt=com.azure.analytics.synapse.spark.models.SparkStatementCollection&text=SparkStatementCollection\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkStatementsWithResponse(int,com.azure.core.util.Context)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.getSparkStatementsWithResponse(int sessionId, Context context)"
  name: "getSparkStatementsWithResponse(int sessionId, Context context)"
  nameWithType: "SparkSessionClient.getSparkStatementsWithResponse(int sessionId, Context context)"
  summary: "Gets a list of statements within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<SparkStatementCollection> getSparkStatementsWithResponse(int sessionId, Context context)"
  desc: "Gets a list of statements within a spark session."
  returns:
    description: "a list of statements within a spark session."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementCollection?alt=com.azure.analytics.synapse.spark.models.SparkStatementCollection&text=SparkStatementCollection\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.resetSparkSessionTimeout(int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.resetSparkSessionTimeout(int sessionId)"
  name: "resetSparkSessionTimeout(int sessionId)"
  nameWithType: "SparkSessionClient.resetSparkSessionTimeout(int sessionId)"
  summary: "Sends a keep alive call to the current session to reset the session timeout."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public void resetSparkSessionTimeout(int sessionId)"
  desc: "Sends a keep alive call to the current session to reset the session timeout."
- uid: "com.azure.analytics.synapse.spark.SparkSessionClient.resetSparkSessionTimeoutWithResponse(int,com.azure.core.util.Context)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionClient.resetSparkSessionTimeoutWithResponse(int sessionId, Context context)"
  name: "resetSparkSessionTimeoutWithResponse(int sessionId, Context context)"
  nameWithType: "SparkSessionClient.resetSparkSessionTimeoutWithResponse(int sessionId, Context context)"
  summary: "Sends a keep alive call to the current session to reset the session timeout."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<Void> resetSparkSessionTimeoutWithResponse(int sessionId, Context context)"
  desc: "Sends a keep alive call to the current session to reset the session timeout."
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
type: "class"
desc: "Initializes a new instance of the synchronous SparkClient type."
metadata: {}
package: "com.azure.analytics.synapse.spark"
artifact: com.azure:azure-analytics-synapse-spark:1.0.0-beta.5
