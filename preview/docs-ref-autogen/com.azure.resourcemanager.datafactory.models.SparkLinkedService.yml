### YamlMime:JavaType
uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService"
fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService"
name: "SparkLinkedService"
nameWithType: "SparkLinkedService"
summary: "Spark Server linked service."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
- "<xref href=\"com.azure.resourcemanager.datafactory.models.LinkedService?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "com.azure.resourcemanager.datafactory.models.LinkedService.additionalProperties()"
- "com.azure.resourcemanager.datafactory.models.LinkedService.annotations()"
- "com.azure.resourcemanager.datafactory.models.LinkedService.connectVia()"
- "com.azure.resourcemanager.datafactory.models.LinkedService.description()"
- "com.azure.resourcemanager.datafactory.models.LinkedService.parameters()"
- "com.azure.resourcemanager.datafactory.models.LinkedService.validate()"
- "com.azure.resourcemanager.datafactory.models.LinkedService.withAdditionalProperties(java.util.Map<java.lang.String,java.lang.Object>)"
- "com.azure.resourcemanager.datafactory.models.LinkedService.withAnnotations(java.util.List<java.lang.Object>)"
- "com.azure.resourcemanager.datafactory.models.LinkedService.withConnectVia(com.azure.resourcemanager.datafactory.models.IntegrationRuntimeReference)"
- "com.azure.resourcemanager.datafactory.models.LinkedService.withDescription(java.lang.String)"
- "com.azure.resourcemanager.datafactory.models.LinkedService.withParameters(java.util.Map<java.lang.String,com.azure.resourcemanager.datafactory.models.ParameterSpecification>)"
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class SparkLinkedService extends LinkedService"
constructors:
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.SparkLinkedService()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.SparkLinkedService()"
  name: "SparkLinkedService()"
  nameWithType: "SparkLinkedService.SparkLinkedService()"
  syntax: "public SparkLinkedService()"
methods:
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.allowHostnameCNMismatch()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.allowHostnameCNMismatch()"
  name: "allowHostnameCNMismatch()"
  nameWithType: "SparkLinkedService.allowHostnameCNMismatch()"
  summary: "Get the allow<wbr>Hostname<wbr>CNMismatch property: Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL."
  syntax: "public Object allowHostnameCNMismatch()"
  desc: "Get the allowHostnameCNMismatch property: Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL. The default value is false."
  returns:
    description: "the allowHostnameCNMismatch value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.allowSelfSignedServerCert()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.allowSelfSignedServerCert()"
  name: "allowSelfSignedServerCert()"
  nameWithType: "SparkLinkedService.allowSelfSignedServerCert()"
  summary: "Get the allow<wbr>Self<wbr>Signed<wbr>Server<wbr>Cert property: Specifies whether to allow self-signed certificates from the server."
  syntax: "public Object allowSelfSignedServerCert()"
  desc: "Get the allowSelfSignedServerCert property: Specifies whether to allow self-signed certificates from the server. The default value is false."
  returns:
    description: "the allowSelfSignedServerCert value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.authenticationType()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.authenticationType()"
  name: "authenticationType()"
  nameWithType: "SparkLinkedService.authenticationType()"
  summary: "Get the authentication<wbr>Type property: The authentication method used to access the Spark server."
  syntax: "public SparkAuthenticationType authenticationType()"
  desc: "Get the authenticationType property: The authentication method used to access the Spark server."
  returns:
    description: "the authenticationType value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkAuthenticationType?alt=com.azure.resourcemanager.datafactory.models.SparkAuthenticationType&text=SparkAuthenticationType\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.enableSsl()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.enableSsl()"
  name: "enableSsl()"
  nameWithType: "SparkLinkedService.enableSsl()"
  summary: "Get the enable<wbr>Ssl property: Specifies whether the connections to the server are encrypted using SSL."
  syntax: "public Object enableSsl()"
  desc: "Get the enableSsl property: Specifies whether the connections to the server are encrypted using SSL. The default value is false."
  returns:
    description: "the enableSsl value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.encryptedCredential()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.encryptedCredential()"
  name: "encryptedCredential()"
  nameWithType: "SparkLinkedService.encryptedCredential()"
  summary: "Get the encrypted<wbr>Credential property: The encrypted credential used for authentication."
  syntax: "public Object encryptedCredential()"
  desc: "Get the encryptedCredential property: The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string)."
  returns:
    description: "the encryptedCredential value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.host()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.host()"
  name: "host()"
  nameWithType: "SparkLinkedService.host()"
  summary: "Get the host property: IP address or host name of the Spark server."
  syntax: "public Object host()"
  desc: "Get the host property: IP address or host name of the Spark server."
  returns:
    description: "the host value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.httpPath()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.httpPath()"
  name: "httpPath()"
  nameWithType: "SparkLinkedService.httpPath()"
  summary: "Get the http<wbr>Path property: The partial URL corresponding to the Spark server."
  syntax: "public Object httpPath()"
  desc: "Get the httpPath property: The partial URL corresponding to the Spark server."
  returns:
    description: "the httpPath value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.password()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.password()"
  name: "password()"
  nameWithType: "SparkLinkedService.password()"
  summary: "Get the password property: The password corresponding to the user name that you provided in the Username field."
  syntax: "public SecretBase password()"
  desc: "Get the password property: The password corresponding to the user name that you provided in the Username field."
  returns:
    description: "the password value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SecretBase?alt=com.azure.resourcemanager.datafactory.models.SecretBase&text=SecretBase\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.port()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.port()"
  name: "port()"
  nameWithType: "SparkLinkedService.port()"
  summary: "Get the port property: The TCP port that the Spark server uses to listen for client connections."
  syntax: "public Object port()"
  desc: "Get the port property: The TCP port that the Spark server uses to listen for client connections."
  returns:
    description: "the port value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.serverType()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.serverType()"
  name: "serverType()"
  nameWithType: "SparkLinkedService.serverType()"
  summary: "Get the server<wbr>Type property: The type of Spark server."
  syntax: "public SparkServerType serverType()"
  desc: "Get the serverType property: The type of Spark server."
  returns:
    description: "the serverType value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkServerType?alt=com.azure.resourcemanager.datafactory.models.SparkServerType&text=SparkServerType\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.thriftTransportProtocol()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.thriftTransportProtocol()"
  name: "thriftTransportProtocol()"
  nameWithType: "SparkLinkedService.thriftTransportProtocol()"
  summary: "Get the thrift<wbr>Transport<wbr>Protocol property: The transport protocol to use in the Thrift layer."
  syntax: "public SparkThriftTransportProtocol thriftTransportProtocol()"
  desc: "Get the thriftTransportProtocol property: The transport protocol to use in the Thrift layer."
  returns:
    description: "the thriftTransportProtocol value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkThriftTransportProtocol?alt=com.azure.resourcemanager.datafactory.models.SparkThriftTransportProtocol&text=SparkThriftTransportProtocol\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.trustedCertPath()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.trustedCertPath()"
  name: "trustedCertPath()"
  nameWithType: "SparkLinkedService.trustedCertPath()"
  summary: "Get the trusted<wbr>Cert<wbr>Path property: The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL."
  syntax: "public Object trustedCertPath()"
  desc: "Get the trustedCertPath property: The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR."
  returns:
    description: "the trustedCertPath value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.useSystemTrustStore()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.useSystemTrustStore()"
  name: "useSystemTrustStore()"
  nameWithType: "SparkLinkedService.useSystemTrustStore()"
  summary: "Get the use<wbr>System<wbr>Trust<wbr>Store property: Specifies whether to use a CA certificate from the system trust store or from a specified PEM file."
  syntax: "public Object useSystemTrustStore()"
  desc: "Get the useSystemTrustStore property: Specifies whether to use a CA certificate from the system trust store or from a specified PEM file. The default value is false."
  returns:
    description: "the useSystemTrustStore value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.username()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.username()"
  name: "username()"
  nameWithType: "SparkLinkedService.username()"
  summary: "Get the username property: The user name that you use to access Spark Server."
  syntax: "public Object username()"
  desc: "Get the username property: The user name that you use to access Spark Server."
  returns:
    description: "the username value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.validate()"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.validate()"
  name: "validate()"
  nameWithType: "SparkLinkedService.validate()"
  summary: "Validates the instance."
  overridden: "com.azure.resourcemanager.datafactory.models.LinkedService.validate()"
  syntax: "public void validate()"
  desc: "Validates the instance."
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withAllowHostnameCNMismatch(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withAllowHostnameCNMismatch(Object allowHostnameCNMismatch)"
  name: "withAllowHostnameCNMismatch(Object allowHostnameCNMismatch)"
  nameWithType: "SparkLinkedService.withAllowHostnameCNMismatch(Object allowHostnameCNMismatch)"
  summary: "Set the allow<wbr>Hostname<wbr>CNMismatch property: Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL."
  parameters:
  - description: "the allowHostnameCNMismatch value to set."
    name: "allowHostnameCNMismatch"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withAllowHostnameCNMismatch(Object allowHostnameCNMismatch)"
  desc: "Set the allowHostnameCNMismatch property: Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL. The default value is false."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withAllowSelfSignedServerCert(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withAllowSelfSignedServerCert(Object allowSelfSignedServerCert)"
  name: "withAllowSelfSignedServerCert(Object allowSelfSignedServerCert)"
  nameWithType: "SparkLinkedService.withAllowSelfSignedServerCert(Object allowSelfSignedServerCert)"
  summary: "Set the allow<wbr>Self<wbr>Signed<wbr>Server<wbr>Cert property: Specifies whether to allow self-signed certificates from the server."
  parameters:
  - description: "the allowSelfSignedServerCert value to set."
    name: "allowSelfSignedServerCert"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withAllowSelfSignedServerCert(Object allowSelfSignedServerCert)"
  desc: "Set the allowSelfSignedServerCert property: Specifies whether to allow self-signed certificates from the server. The default value is false."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withAnnotations(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withAnnotations(List<Object> annotations)"
  name: "withAnnotations(List<Object> annotations)"
  nameWithType: "SparkLinkedService.withAnnotations(List<Object> annotations)"
  summary: "Set the annotations property: List of tags that can be used for describing the linked service."
  overridden: "com.azure.resourcemanager.datafactory.models.LinkedService.withAnnotations(java.util.List<java.lang.Object>)"
  parameters:
  - name: "annotations"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public SparkLinkedService withAnnotations(List<Object> annotations)"
  desc: "Set the annotations property: List of tags that can be used for describing the linked service."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withAuthenticationType(com.azure.resourcemanager.datafactory.models.SparkAuthenticationType)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withAuthenticationType(SparkAuthenticationType authenticationType)"
  name: "withAuthenticationType(SparkAuthenticationType authenticationType)"
  nameWithType: "SparkLinkedService.withAuthenticationType(SparkAuthenticationType authenticationType)"
  summary: "Set the authentication<wbr>Type property: The authentication method used to access the Spark server."
  parameters:
  - description: "the authenticationType value to set."
    name: "authenticationType"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkAuthenticationType?alt=com.azure.resourcemanager.datafactory.models.SparkAuthenticationType&text=SparkAuthenticationType\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withAuthenticationType(SparkAuthenticationType authenticationType)"
  desc: "Set the authenticationType property: The authentication method used to access the Spark server."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withConnectVia(com.azure.resourcemanager.datafactory.models.IntegrationRuntimeReference)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withConnectVia(IntegrationRuntimeReference connectVia)"
  name: "withConnectVia(IntegrationRuntimeReference connectVia)"
  nameWithType: "SparkLinkedService.withConnectVia(IntegrationRuntimeReference connectVia)"
  summary: "Set the connect<wbr>Via property: The integration runtime reference."
  overridden: "com.azure.resourcemanager.datafactory.models.LinkedService.withConnectVia(com.azure.resourcemanager.datafactory.models.IntegrationRuntimeReference)"
  parameters:
  - name: "connectVia"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.IntegrationRuntimeReference?alt=com.azure.resourcemanager.datafactory.models.IntegrationRuntimeReference&text=IntegrationRuntimeReference\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withConnectVia(IntegrationRuntimeReference connectVia)"
  desc: "Set the connectVia property: The integration runtime reference."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withDescription(java.lang.String)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withDescription(String description)"
  name: "withDescription(String description)"
  nameWithType: "SparkLinkedService.withDescription(String description)"
  summary: "Set the description property: Linked service description."
  overridden: "com.azure.resourcemanager.datafactory.models.LinkedService.withDescription(java.lang.String)"
  parameters:
  - name: "description"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withDescription(String description)"
  desc: "Set the description property: Linked service description."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withEnableSsl(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withEnableSsl(Object enableSsl)"
  name: "withEnableSsl(Object enableSsl)"
  nameWithType: "SparkLinkedService.withEnableSsl(Object enableSsl)"
  summary: "Set the enable<wbr>Ssl property: Specifies whether the connections to the server are encrypted using SSL."
  parameters:
  - description: "the enableSsl value to set."
    name: "enableSsl"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withEnableSsl(Object enableSsl)"
  desc: "Set the enableSsl property: Specifies whether the connections to the server are encrypted using SSL. The default value is false."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withEncryptedCredential(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withEncryptedCredential(Object encryptedCredential)"
  name: "withEncryptedCredential(Object encryptedCredential)"
  nameWithType: "SparkLinkedService.withEncryptedCredential(Object encryptedCredential)"
  summary: "Set the encrypted<wbr>Credential property: The encrypted credential used for authentication."
  parameters:
  - description: "the encryptedCredential value to set."
    name: "encryptedCredential"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withEncryptedCredential(Object encryptedCredential)"
  desc: "Set the encryptedCredential property: The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string)."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withHost(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withHost(Object host)"
  name: "withHost(Object host)"
  nameWithType: "SparkLinkedService.withHost(Object host)"
  summary: "Set the host property: IP address or host name of the Spark server."
  parameters:
  - description: "the host value to set."
    name: "host"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withHost(Object host)"
  desc: "Set the host property: IP address or host name of the Spark server."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withHttpPath(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withHttpPath(Object httpPath)"
  name: "withHttpPath(Object httpPath)"
  nameWithType: "SparkLinkedService.withHttpPath(Object httpPath)"
  summary: "Set the http<wbr>Path property: The partial URL corresponding to the Spark server."
  parameters:
  - description: "the httpPath value to set."
    name: "httpPath"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withHttpPath(Object httpPath)"
  desc: "Set the httpPath property: The partial URL corresponding to the Spark server."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withParameters(java.util.Map<java.lang.String,com.azure.resourcemanager.datafactory.models.ParameterSpecification>)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withParameters(Map<String,ParameterSpecification> parameters)"
  name: "withParameters(Map<String,ParameterSpecification> parameters)"
  nameWithType: "SparkLinkedService.withParameters(Map<String,ParameterSpecification> parameters)"
  summary: "Set the parameters property: Parameters for linked service."
  overridden: "com.azure.resourcemanager.datafactory.models.LinkedService.withParameters(java.util.Map<java.lang.String,com.azure.resourcemanager.datafactory.models.ParameterSpecification>)"
  parameters:
  - name: "parameters"
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"com.azure.resourcemanager.datafactory.models.ParameterSpecification?alt=com.azure.resourcemanager.datafactory.models.ParameterSpecification&text=ParameterSpecification\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public SparkLinkedService withParameters(Map<String,ParameterSpecification> parameters)"
  desc: "Set the parameters property: Parameters for linked service."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withPassword(com.azure.resourcemanager.datafactory.models.SecretBase)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withPassword(SecretBase password)"
  name: "withPassword(SecretBase password)"
  nameWithType: "SparkLinkedService.withPassword(SecretBase password)"
  summary: "Set the password property: The password corresponding to the user name that you provided in the Username field."
  parameters:
  - description: "the password value to set."
    name: "password"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SecretBase?alt=com.azure.resourcemanager.datafactory.models.SecretBase&text=SecretBase\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withPassword(SecretBase password)"
  desc: "Set the password property: The password corresponding to the user name that you provided in the Username field."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withPort(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withPort(Object port)"
  name: "withPort(Object port)"
  nameWithType: "SparkLinkedService.withPort(Object port)"
  summary: "Set the port property: The TCP port that the Spark server uses to listen for client connections."
  parameters:
  - description: "the port value to set."
    name: "port"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withPort(Object port)"
  desc: "Set the port property: The TCP port that the Spark server uses to listen for client connections."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withServerType(com.azure.resourcemanager.datafactory.models.SparkServerType)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withServerType(SparkServerType serverType)"
  name: "withServerType(SparkServerType serverType)"
  nameWithType: "SparkLinkedService.withServerType(SparkServerType serverType)"
  summary: "Set the server<wbr>Type property: The type of Spark server."
  parameters:
  - description: "the serverType value to set."
    name: "serverType"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkServerType?alt=com.azure.resourcemanager.datafactory.models.SparkServerType&text=SparkServerType\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withServerType(SparkServerType serverType)"
  desc: "Set the serverType property: The type of Spark server."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withThriftTransportProtocol(com.azure.resourcemanager.datafactory.models.SparkThriftTransportProtocol)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withThriftTransportProtocol(SparkThriftTransportProtocol thriftTransportProtocol)"
  name: "withThriftTransportProtocol(SparkThriftTransportProtocol thriftTransportProtocol)"
  nameWithType: "SparkLinkedService.withThriftTransportProtocol(SparkThriftTransportProtocol thriftTransportProtocol)"
  summary: "Set the thrift<wbr>Transport<wbr>Protocol property: The transport protocol to use in the Thrift layer."
  parameters:
  - description: "the thriftTransportProtocol value to set."
    name: "thriftTransportProtocol"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkThriftTransportProtocol?alt=com.azure.resourcemanager.datafactory.models.SparkThriftTransportProtocol&text=SparkThriftTransportProtocol\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withThriftTransportProtocol(SparkThriftTransportProtocol thriftTransportProtocol)"
  desc: "Set the thriftTransportProtocol property: The transport protocol to use in the Thrift layer."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withTrustedCertPath(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withTrustedCertPath(Object trustedCertPath)"
  name: "withTrustedCertPath(Object trustedCertPath)"
  nameWithType: "SparkLinkedService.withTrustedCertPath(Object trustedCertPath)"
  summary: "Set the trusted<wbr>Cert<wbr>Path property: The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL."
  parameters:
  - description: "the trustedCertPath value to set."
    name: "trustedCertPath"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withTrustedCertPath(Object trustedCertPath)"
  desc: "Set the trustedCertPath property: The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withUseSystemTrustStore(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withUseSystemTrustStore(Object useSystemTrustStore)"
  name: "withUseSystemTrustStore(Object useSystemTrustStore)"
  nameWithType: "SparkLinkedService.withUseSystemTrustStore(Object useSystemTrustStore)"
  summary: "Set the use<wbr>System<wbr>Trust<wbr>Store property: Specifies whether to use a CA certificate from the system trust store or from a specified PEM file."
  parameters:
  - description: "the useSystemTrustStore value to set."
    name: "useSystemTrustStore"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withUseSystemTrustStore(Object useSystemTrustStore)"
  desc: "Set the useSystemTrustStore property: Specifies whether to use a CA certificate from the system trust store or from a specified PEM file. The default value is false."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withUsername(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SparkLinkedService.withUsername(Object username)"
  name: "withUsername(Object username)"
  nameWithType: "SparkLinkedService.withUsername(Object username)"
  summary: "Set the username property: The user name that you use to access Spark Server."
  parameters:
  - description: "the username value to set."
    name: "username"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedService withUsername(Object username)"
  desc: "Set the username property: The user name that you use to access Spark Server."
  returns:
    description: "the SparkLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkLinkedService?alt=com.azure.resourcemanager.datafactory.models.SparkLinkedService&text=SparkLinkedService\" data-throw-if-not-resolved=\"False\" />"
type: "class"
desc: "Spark Server linked service."
metadata: {}
package: "com.azure.resourcemanager.datafactory.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.16
