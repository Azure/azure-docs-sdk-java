### YamlMime:ManagedReference
items:
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient
  id: DataLakeDirectoryClient
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake
  children:
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile(java.lang.String,boolean)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory(java.lang.String,boolean)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.delete()
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse(java.lang.String,boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName()
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath()
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl()
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.rename(java.lang.String,java.lang.String)
  - com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  langs:
  - java
  name: DataLakeDirectoryClient
  nameWithType: DataLakeDirectoryClient
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient
  type: Class
  package: com.azure.storage.file.datalake
  summary: >-
    This class provides a client that contains directory operations for Azure Storage Data Lake. Operations provided by this client include creating a directory, deleting a directory, renaming a directory, setting metadata and http headers, setting and retrieving access control, getting properties and creating and deleting files and subdirectories.


    This client is instantiated through <xref uid="com.azure.storage.file.datalake.DataLakePathClientBuilder" data-throw-if-not-resolved="false">DataLakePathClientBuilder</xref> or retrieved via <xref uid="com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient(java.lang.String)" data-throw-if-not-resolved="false">getDirectoryClient</xref>.


    Please refer to the [Azure Docs][] for more information.



    [Azure Docs]: https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction?toc=%2fazure%2fstorage%2fblobs%2ftoc.json
  syntax:
    content: public class DataLakeDirectoryClient extends DataLakePathClient
  inheritance:
  - java.lang.Object
  - com.azure.storage.file.datalake.DataLakePathClient
  inheritedMembers:
  - com.azure.storage.file.datalake.DataLakePathClient.create()
  - com.azure.storage.file.datalake.DataLakePathClient.create(boolean)
  - com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakePathClient.exists()
  - com.azure.storage.file.datalake.DataLakePathClient.existsWithResponse(java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakePathClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)
  - com.azure.storage.file.datalake.DataLakePathClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)
  - com.azure.storage.file.datalake.DataLakePathClient.getAccessControl()
  - com.azure.storage.file.datalake.DataLakePathClient.getAccessControlWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakePathClient.getAccountName()
  - com.azure.storage.file.datalake.DataLakePathClient.getFileSystemName()
  - com.azure.storage.file.datalake.DataLakePathClient.getHttpPipeline()
  - com.azure.storage.file.datalake.DataLakePathClient.getProperties()
  - com.azure.storage.file.datalake.DataLakePathClient.getPropertiesWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakePathClient.getServiceVersion()
  - com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)
  - com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakePathClient.setHttpHeaders(com.azure.storage.file.datalake.models.PathHttpHeaders)
  - com.azure.storage.file.datalake.DataLakePathClient.setHttpHeadersWithResponse(com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)
  - com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakePathClient.setPermissions(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String)
  - com.azure.storage.file.datalake.DataLakePathClient.setPermissionsWithResponse(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - java.lang.Object.clone()
  - java.lang.Object.equals(java.lang.Object)
  - java.lang.Object.finalize()
  - java.lang.Object.getClass()
  - java.lang.Object.hashCode()
  - java.lang.Object.notify()
  - java.lang.Object.notifyAll()
  - java.lang.Object.toString()
  - java.lang.Object.wait()
  - java.lang.Object.wait(long)
  - java.lang.Object.wait(long,int)
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient(com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient,com.azure.storage.blob.specialized.BlockBlobClient)
  id: DataLakeDirectoryClient(com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient,com.azure.storage.blob.specialized.BlockBlobClient)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: DataLakeDirectoryClient(DataLakeDirectoryAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)
  nameWithType: DataLakeDirectoryClient.DataLakeDirectoryClient(DataLakeDirectoryAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient(DataLakeDirectoryAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient*
  type: Constructor
  package: com.azure.storage.file.datalake
  syntax:
    content: " DataLakeDirectoryClient(DataLakeDirectoryAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)"
    parameters:
    - id: pathAsyncClient
      type: com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient
    - id: blockBlobClient
      type: com.azure.storage.blob.specialized.BlockBlobClient
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient(com.azure.storage.file.datalake.DataLakePathClient)
  id: DataLakeDirectoryClient(com.azure.storage.file.datalake.DataLakePathClient)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: DataLakeDirectoryClient(DataLakePathClient dataLakePathClient)
  nameWithType: DataLakeDirectoryClient.DataLakeDirectoryClient(DataLakePathClient dataLakePathClient)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient(DataLakePathClient dataLakePathClient)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient*
  type: Constructor
  package: com.azure.storage.file.datalake
  syntax:
    content: private DataLakeDirectoryClient(DataLakePathClient dataLakePathClient)
    parameters:
    - id: dataLakePathClient
      type: com.azure.storage.file.datalake.DataLakePathClient
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile(java.lang.String)
  id: createFile(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: createFile(String fileName)
  nameWithType: DataLakeDirectoryClient.createFile(String fileName)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile(String fileName)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new file within a directory. By default this method will not overwrite an existing file. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    DataLakeFileClient fileClient = client.createFile(fileName);

    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public DataLakeFileClient createFile(String fileName)
    parameters:
    - id: fileName
      type: java.lang.String
      description: Name of the file to create.
    return:
      type: com.azure.storage.file.datalake.DataLakeFileClient
      description: A <xref uid="com.azure.storage.file.datalake.DataLakeFileClient" data-throw-if-not-resolved="false">DataLakeFileClient</xref> used to interact with the file created.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile(java.lang.String,boolean)
  id: createFile(java.lang.String,boolean)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: createFile(String fileName, boolean overwrite)
  nameWithType: DataLakeDirectoryClient.createFile(String fileName, boolean overwrite)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile(String fileName, boolean overwrite)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new file within a directory. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    boolean overwrite = false; /* Default value. */
     DataLakeFileClient fClient = client.createFile(fileName, overwrite);
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public DataLakeFileClient createFile(String fileName, boolean overwrite)
    parameters:
    - id: fileName
      type: java.lang.String
      description: Name of the file to create.
    - id: overwrite
      type: boolean
      description: Whether or not to overwrite, should a file exist.
    return:
      type: com.azure.storage.file.datalake.DataLakeFileClient
      description: A <xref uid="com.azure.storage.file.datalake.DataLakeFileClient" data-throw-if-not-resolved="false">DataLakeFileClient</xref> used to interact with the file created.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: createFileWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeDirectoryClient.createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new file within a directory. If a file with the same name already exists, the file will be overwritten. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    PathHttpHeaders httpHeaders = new PathHttpHeaders()
         .setContentLanguage("en-US")
         .setContentType("binary");
     DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()
         .setLeaseId(leaseId);
     String permissions = "permissions";
     String umask = "umask";
     Response<DataLakeFileClient> newFileClient = client.createFileWithResponse(fileName, permissions, umask, httpHeaders,
         Collections.singletonMap("metadata", "value"), requestConditions,
         timeout, new Context(key1, value1));
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public Response<DataLakeFileClient> createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: fileName
      type: java.lang.String
      description: Name of the file to create.
    - id: permissions
      type: java.lang.String
      description: POSIX access permissions for the file owner, the file owning group, and others.
    - id: umask
      type: java.lang.String
      description: Restricts permissions of the file to be created.
    - id: headers
      type: com.azure.storage.file.datalake.models.PathHttpHeaders
      description: <xref uid="com.azure.storage.file.datalake.models.PathHttpHeaders" data-throw-if-not-resolved="false">PathHttpHeaders</xref>
    - id: metadata
      type: java.util.Map<java.lang.String,java.lang.String>
      description: Metadata to associate with the file.
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeFileClient>
      description: >-
        A <xref uid="com.azure.core.http.rest.Response" data-throw-if-not-resolved="false">Response</xref> whose <xref uid="com.azure.core.http.rest.Response.getValue*" data-throw-if-not-resolved="false">value</xref> contains the <xref uid="com.azure.storage.file.datalake.DataLakeFileClient" data-throw-if-not-resolved="false">DataLakeFileClient</xref> used
         to interact with the file created.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory(java.lang.String)
  id: createSubdirectory(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: createSubdirectory(String subdirectoryName)
  nameWithType: DataLakeDirectoryClient.createSubdirectory(String subdirectoryName)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory(String subdirectoryName)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new sub-directory within a directory. By default this method will not overwrite an existing sub-directory. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    DataLakeDirectoryClient directoryClient = client.createSubdirectory(directoryName);

    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public DataLakeDirectoryClient createSubdirectory(String subdirectoryName)
    parameters:
    - id: subdirectoryName
      type: java.lang.String
      description: Name of the sub-directory to create.
    return:
      type: com.azure.storage.file.datalake.DataLakeDirectoryClient
      description: A <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref> used to interact with the sub-directory created.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory(java.lang.String,boolean)
  id: createSubdirectory(java.lang.String,boolean)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: createSubdirectory(String subdirectoryName, boolean overwrite)
  nameWithType: DataLakeDirectoryClient.createSubdirectory(String subdirectoryName, boolean overwrite)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory(String subdirectoryName, boolean overwrite)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new sub-directory within a directory. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    boolean overwrite = false; /* Default value. */
     DataLakeDirectoryClient dClient = client.createSubdirectory(fileName, overwrite);
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public DataLakeDirectoryClient createSubdirectory(String subdirectoryName, boolean overwrite)
    parameters:
    - id: subdirectoryName
      type: java.lang.String
      description: Name of the sub-directory to create.
    - id: overwrite
      type: boolean
      description: Whether or not to overwrite, should the sub-directory exist.
    return:
      type: com.azure.storage.file.datalake.DataLakeDirectoryClient
      description: A <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref> used to interact with the sub-directory created.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: createSubdirectoryWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: createSubdirectoryWithResponse(String subdirectoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeDirectoryClient.createSubdirectoryWithResponse(String subdirectoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse(String subdirectoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new sub-directory within a directory. If a sub-directory with the same name already exists, the sub-directory will be overwritten. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    PathHttpHeaders httpHeaders = new PathHttpHeaders()
         .setContentLanguage("en-US")
         .setContentType("binary");
     DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()
         .setLeaseId(leaseId);
     String permissions = "permissions";
     String umask = "umask";
     Response<DataLakeDirectoryClient> newDirectoryClient = client.createSubdirectoryWithResponse(directoryName,
         permissions, umask, httpHeaders, Collections.singletonMap("metadata", "value"), requestConditions, timeout,
         new Context(key1, value1));
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public Response<DataLakeDirectoryClient> createSubdirectoryWithResponse(String subdirectoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: subdirectoryName
      type: java.lang.String
      description: Name of the sub-directory to create.
    - id: permissions
      type: java.lang.String
      description: >-
        POSIX access permissions for the sub-directory owner, the sub-directory owning group, and
         others.
    - id: umask
      type: java.lang.String
      description: Restricts permissions of the sub-directory to be created.
    - id: headers
      type: com.azure.storage.file.datalake.models.PathHttpHeaders
      description: <xref uid="com.azure.storage.file.datalake.models.PathHttpHeaders" data-throw-if-not-resolved="false">PathHttpHeaders</xref>
    - id: metadata
      type: java.util.Map<java.lang.String,java.lang.String>
      description: Metadata to associate with the sub-directory.
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeDirectoryClient>
      description: >-
        A <xref uid="com.azure.core.http.rest.Response" data-throw-if-not-resolved="false">Response</xref> whose <xref uid="com.azure.core.http.rest.Response.getValue*" data-throw-if-not-resolved="false">value</xref> contains a <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref>
         used to interact with the sub-directory created.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.delete()
  id: delete()
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: delete()
  nameWithType: DataLakeDirectoryClient.delete()
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.delete()
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.delete*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Deletes a directory.


    **Code Samples**


    ```java

    client.delete();
     System.out.println("Delete request completed");
    ```


    For more information see the [Azure Docs][]



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete
  syntax:
    content: public void delete()
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile(java.lang.String)
  id: deleteFile(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: deleteFile(String fileName)
  nameWithType: DataLakeDirectoryClient.deleteFile(String fileName)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile(String fileName)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Deletes the specified file in the directory. If the file doesn't exist the operation fails. For more information see the [Azure Docs][].


    **Code Samples**


    ```java

    client.deleteFile(fileName);
     System.out.println("Delete request completed");
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete
  syntax:
    content: public void deleteFile(String fileName)
    parameters:
    - id: fileName
      type: java.lang.String
      description: Name of the file to delete.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: deleteFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeDirectoryClient.deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Deletes the specified file in the directory. If the file doesn't exist the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId);\n \n client.deleteFileWithResponse(fileName, requestConditions, timeout, new Context(key1, value1));\n System.out.println(\"Delete request completed\");\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: public Response<Void> deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: fileName
      type: java.lang.String
      description: Name of the file to delete.
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<java.lang.Void>
      description: A response containing status code and HTTP headers
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory(java.lang.String)
  id: deleteSubdirectory(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: deleteSubdirectory(String subdirectoryName)
  nameWithType: DataLakeDirectoryClient.deleteSubdirectory(String subdirectoryName)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory(String subdirectoryName)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Deletes the specified sub-directory in the directory. If the sub-directory doesn't exist or is not empty the operation fails. For more information see the [Azure Docs][].


    **Code Samples**


    ```java

    client.deleteSubdirectory(directoryName);
     System.out.println("Delete request completed");
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete
  syntax:
    content: public void deleteSubdirectory(String subdirectoryName)
    parameters:
    - id: subdirectoryName
      type: java.lang.String
      description: Name of the sub-directory to delete.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse(java.lang.String,boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: deleteSubdirectoryWithResponse(java.lang.String,boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: deleteSubdirectoryWithResponse(String subdirectoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeDirectoryClient.deleteSubdirectoryWithResponse(String subdirectoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse(String subdirectoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Deletes the specified sub-directory in the directory. If the sub-directory doesn't exist or is not empty the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId);\n boolean recursive = false; // Default value\n \n client.deleteSubdirectoryWithResponse(directoryName, recursive, requestConditions, timeout,\n     new Context(key1, value1));\n System.out.println(\"Delete request completed\");\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: public Response<Void> deleteSubdirectoryWithResponse(String subdirectoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: subdirectoryName
      type: java.lang.String
      description: Name of the sub-directory to delete.
    - id: recursive
      type: boolean
      description: Whether or not to delete all paths beneath the sub-directory.
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<java.lang.Void>
      description: A response containing status code and HTTP headers
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: deleteWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: deleteWithResponse(boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeDirectoryClient.deleteWithResponse(boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse(boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Deletes a directory.\n\n**Code Samples**\n\n```java\nDataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId);\n boolean recursive = false; // Default value\n \n client.deleteWithResponse(recursive, requestConditions, timeout, new Context(key1, value1));\n System.out.println(\"Delete request completed\");\n```\n\nFor more information see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: public Response<Void> deleteWithResponse(boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: recursive
      type: boolean
      description: Whether or not to delete all paths beneath the directory.
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<java.lang.Void>
      description: A reactive response signalling completion.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName()
  id: getDirectoryName()
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: getDirectoryName()
  nameWithType: DataLakeDirectoryClient.getDirectoryName()
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName()
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName*
  type: Method
  package: com.azure.storage.file.datalake
  summary: Gets the name of this directory, not including its full path.
  syntax:
    content: public String getDirectoryName()
    return:
      type: java.lang.String
      description: The name of the directory.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath()
  id: getDirectoryPath()
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: getDirectoryPath()
  nameWithType: DataLakeDirectoryClient.getDirectoryPath()
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath()
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath*
  type: Method
  package: com.azure.storage.file.datalake
  summary: Gets the path of this directory, not including the name of the resource itself.
  syntax:
    content: public String getDirectoryPath()
    return:
      type: java.lang.String
      description: The path of the directory.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl()
  id: getDirectoryUrl()
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: getDirectoryUrl()
  nameWithType: DataLakeDirectoryClient.getDirectoryUrl()
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl()
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl*
  type: Method
  package: com.azure.storage.file.datalake
  summary: Gets the URL of the directory represented by this client on the Data Lake service.
  syntax:
    content: public String getDirectoryUrl()
    return:
      type: java.lang.String
      description: the URL.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient(java.lang.String)
  id: getFileClient(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: getFileClient(String fileName)
  nameWithType: DataLakeDirectoryClient.getFileClient(String fileName)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient(String fileName)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient*
  type: Method
  package: com.azure.storage.file.datalake
  summary: Initializes a new DataLakeFileClient object by concatenating fileName to the end of DataLakeDirectoryClient's URL. The new DataLakeFileClient uses the same request policy pipeline as the DataLakeDirectoryClient.
  syntax:
    content: public DataLakeFileClient getFileClient(String fileName)
    parameters:
    - id: fileName
      type: java.lang.String
      description: >-
        A <code>String</code> representing the name of the file.

         <p><strong>Code Samples</strong></p>

         <pre>
         DataLakeFileClient dataLakeFileClient = client.getFileClient&#40;fileName&#41;;
         </pre>
    return:
      type: com.azure.storage.file.datalake.DataLakeFileClient
      description: >-
        A new <xref uid="com.azure.storage.file.datalake.DataLakeFileClient" data-throw-if-not-resolved="false">DataLakeFileClient</xref> object which references the file with the specified name in this
         directory.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient(java.lang.String)
  id: getSubdirectoryClient(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: getSubdirectoryClient(String subdirectoryName)
  nameWithType: DataLakeDirectoryClient.getSubdirectoryClient(String subdirectoryName)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient(String subdirectoryName)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient*
  type: Method
  package: com.azure.storage.file.datalake
  summary: Initializes a new DataLakeDirectoryClient object by concatenating directoryName to the end of DataLakeDirectoryClient's URL. The new DataLakeDirectoryClient uses the same request policy pipeline as the DataLakeDirectoryClient.
  syntax:
    content: public DataLakeDirectoryClient getSubdirectoryClient(String subdirectoryName)
    parameters:
    - id: subdirectoryName
      type: java.lang.String
      description: >-
        A <code>String</code> representing the name of the sub-directory.

         <p><strong>Code Samples</strong></p>

         <pre>
         DataLakeDirectoryClient dataLakeDirectoryClient = client.getSubdirectoryClient&#40;directoryName&#41;;
         </pre>
    return:
      type: com.azure.storage.file.datalake.DataLakeDirectoryClient
      description: >-
        A new <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref> object which references the sub-directory with the specified name
         in this directory
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.rename(java.lang.String,java.lang.String)
  id: rename(java.lang.String,java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: rename(String destinationFileSystem, String destinationPath)
  nameWithType: DataLakeDirectoryClient.rename(String destinationFileSystem, String destinationPath)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.rename(String destinationFileSystem, String destinationPath)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.rename*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Moves the directory to another location within the file system. For more information see the [Azure Docs][].


    **Code Samples**


    ```java

    DataLakeDirectoryClient renamedClient = client.rename(fileSystemName, destinationPath);
     System.out.println("Directory Client has been renamed");
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public DataLakeDirectoryClient rename(String destinationFileSystem, String destinationPath)
    parameters:
    - id: destinationFileSystem
      type: java.lang.String
      description: >-
        The file system of the destination within the account.
         <code>null</code> for the current file system.
    - id: destinationPath
      type: java.lang.String
      description: >-
        Relative path from the file system to rename the directory to, excludes the file system
         name. For example if you want to move a directory with fileSystem = "myfilesystem", path = "mydir/mysubdir" to
         another path in myfilesystem (ex: newdir) then set the destinationPath = "newdir"
    return:
      type: com.azure.storage.file.datalake.DataLakeDirectoryClient
      description: A <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref> used to interact with the new directory created.
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.2.0-beta.1
  parent: com.azure.storage.file.datalake.DataLakeDirectoryClient
  langs:
  - java
  name: renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)
  nameWithType: DataLakeDirectoryClient.renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Moves the directory to another location within the file system. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeRequestConditions sourceRequestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId);\n DataLakeRequestConditions destinationRequestConditions = new DataLakeRequestConditions();\n \n DataLakeDirectoryClient newRenamedClient = client.renameWithResponse(fileSystemName, destinationPath,\n     sourceRequestConditions, destinationRequestConditions, timeout, new Context(key1, value1)).getValue();\n System.out.println(\"Directory Client has been renamed\");\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create"
  syntax:
    content: public Response<DataLakeDirectoryClient> renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)
    parameters:
    - id: destinationFileSystem
      type: java.lang.String
      description: >-
        The file system of the destination within the account.
         <code>null</code> for the current file system.
    - id: destinationPath
      type: java.lang.String
      description: >-
        Relative path from the file system to rename the directory to, excludes the file system
         name. For example if you want to move a directory with fileSystem = "myfilesystem", path = "mydir/mysubdir" to
         another path in myfilesystem (ex: newdir) then set the destinationPath = "newdir"
    - id: sourceRequestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref> against the source.
    - id: destinationRequestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref> against the destination.
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeDirectoryClient>
      description: >-
        A <xref uid="com.azure.core.http.rest.Response" data-throw-if-not-resolved="false">Response</xref> whose <xref uid="com.azure.core.http.rest.Response.getValue*" data-throw-if-not-resolved="false">value</xref> that contains a
         <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref> used to interact with the directory created.
references:
- uid: com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient
  name: DataLakeDirectoryAsyncClient
  nameWithType: DataLakeDirectoryAsyncClient
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient
- uid: com.azure.storage.blob.specialized.BlockBlobClient
  spec.java:
  - uid: com.azure.storage.blob.specialized.BlockBlobClient
    name: BlockBlobClient
    fullName: com.azure.storage.blob.specialized.BlockBlobClient
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient*
  name: DataLakeDirectoryClient
  nameWithType: DataLakeDirectoryClient.DataLakeDirectoryClient
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakePathClient
  name: DataLakePathClient
  nameWithType: DataLakePathClient
  fullName: com.azure.storage.file.datalake.DataLakePathClient
- uid: java.lang.String
  spec.java:
  - uid: java.lang.String
    name: String
    fullName: java.lang.String
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl*
  name: getDirectoryUrl
  nameWithType: DataLakeDirectoryClient.getDirectoryUrl
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath*
  name: getDirectoryPath
  nameWithType: DataLakeDirectoryClient.getDirectoryPath
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName*
  name: getDirectoryName
  nameWithType: DataLakeDirectoryClient.getDirectoryName
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.delete*
  name: delete
  nameWithType: DataLakeDirectoryClient.delete
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.delete
  package: com.azure.storage.file.datalake
- uid: boolean
  spec.java:
  - uid: boolean
    name: boolean
    fullName: boolean
- uid: com.azure.storage.file.datalake.models.DataLakeRequestConditions
  name: DataLakeRequestConditions
  nameWithType: DataLakeRequestConditions
  fullName: com.azure.storage.file.datalake.models.DataLakeRequestConditions
- uid: java.time.Duration
  spec.java:
  - uid: java.time.Duration
    name: Duration
    fullName: java.time.Duration
- uid: com.azure.core.util.Context
  spec.java:
  - uid: com.azure.core.util.Context
    name: Context
    fullName: com.azure.core.util.Context
- uid: com.azure.core.http.rest.Response<java.lang.Void>
  spec.java:
  - uid: com.azure.core.http.rest.Response
    name: Response
    fullName: com.azure.core.http.rest.Response
  - name: <
    fullName: <
  - uid: java.lang.Void
    name: Void
    fullName: java.lang.Void
  - name: '>'
    fullName: '>'
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse*
  name: deleteWithResponse
  nameWithType: DataLakeDirectoryClient.deleteWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileClient
  name: DataLakeFileClient
  nameWithType: DataLakeFileClient
  fullName: com.azure.storage.file.datalake.DataLakeFileClient
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient*
  name: getFileClient
  nameWithType: DataLakeDirectoryClient.getFileClient
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile*
  name: createFile
  nameWithType: DataLakeDirectoryClient.createFile
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.models.PathHttpHeaders
  name: PathHttpHeaders
  nameWithType: PathHttpHeaders
  fullName: com.azure.storage.file.datalake.models.PathHttpHeaders
- uid: java.util.Map<java.lang.String,java.lang.String>
  spec.java:
  - uid: java.util.Map
    name: Map
    fullName: java.util.Map
  - name: <
    fullName: <
  - uid: java.lang.String
    name: String
    fullName: java.lang.String
  - name: ','
    fullName: ','
  - uid: java.lang.String
    name: String
    fullName: java.lang.String
  - name: '>'
    fullName: '>'
- uid: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeFileClient>
  spec.java:
  - uid: com.azure.core.http.rest.Response
    name: Response
    fullName: com.azure.core.http.rest.Response
  - name: <
    fullName: <
  - uid: com.azure.storage.file.datalake.DataLakeFileClient
    name: DataLakeFileClient
    fullName: com.azure.storage.file.datalake.DataLakeFileClient
  - name: '>'
    fullName: '>'
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse*
  name: createFileWithResponse
  nameWithType: DataLakeDirectoryClient.createFileWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile*
  name: deleteFile
  nameWithType: DataLakeDirectoryClient.deleteFile
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse*
  name: deleteFileWithResponse
  nameWithType: DataLakeDirectoryClient.deleteFileWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient*
  name: getSubdirectoryClient
  nameWithType: DataLakeDirectoryClient.getSubdirectoryClient
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory*
  name: createSubdirectory
  nameWithType: DataLakeDirectoryClient.createSubdirectory
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory
  package: com.azure.storage.file.datalake
- uid: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeDirectoryClient>
  spec.java:
  - uid: com.azure.core.http.rest.Response
    name: Response
    fullName: com.azure.core.http.rest.Response
  - name: <
    fullName: <
  - uid: com.azure.storage.file.datalake.DataLakeDirectoryClient
    name: DataLakeDirectoryClient
    fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient
  - name: '>'
    fullName: '>'
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse*
  name: createSubdirectoryWithResponse
  nameWithType: DataLakeDirectoryClient.createSubdirectoryWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory*
  name: deleteSubdirectory
  nameWithType: DataLakeDirectoryClient.deleteSubdirectory
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse*
  name: deleteSubdirectoryWithResponse
  nameWithType: DataLakeDirectoryClient.deleteSubdirectoryWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.rename*
  name: rename
  nameWithType: DataLakeDirectoryClient.rename
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.rename
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse*
  name: renameWithResponse
  nameWithType: DataLakeDirectoryClient.renameWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse
  package: com.azure.storage.file.datalake
- uid: java.lang.Object.wait()
  name: Object.wait()
  nameWithType: Object.wait()
  fullName: java.lang.Object.wait()
- uid: java.lang.Object.finalize()
  name: Object.finalize()
  nameWithType: Object.finalize()
  fullName: java.lang.Object.finalize()
- uid: java.lang.Object.clone()
  name: Object.clone()
  nameWithType: Object.clone()
  fullName: java.lang.Object.clone()
- uid: com.azure.storage.file.datalake.DataLakePathClient.getProperties()
  name: DataLakePathClient.getProperties()
  nameWithType: DataLakePathClient.getProperties()
  fullName: com.azure.storage.file.datalake.DataLakePathClient.getProperties()
- uid: com.azure.storage.file.datalake.DataLakePathClient.existsWithResponse(java.time.Duration,com.azure.core.util.Context)
  name: DataLakePathClient.existsWithResponse(Duration,Context)
  nameWithType: DataLakePathClient.existsWithResponse(Duration,Context)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.existsWithResponse(java.time.Duration,com.azure.core.util.Context)
- uid: com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)
  name: DataLakePathClient.setAccessControlList(List<PathAccessControlEntry>,String,String)
  nameWithType: DataLakePathClient.setAccessControlList(List<PathAccessControlEntry>,String,String)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)
- uid: com.azure.storage.file.datalake.DataLakePathClient.create()
  name: DataLakePathClient.create()
  nameWithType: DataLakePathClient.create()
  fullName: com.azure.storage.file.datalake.DataLakePathClient.create()
- uid: com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  name: DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map<String,String>,DataLakeRequestConditions,Duration,Context)
  nameWithType: DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map<String,String>,DataLakeRequestConditions,Duration,Context)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
- uid: com.azure.storage.file.datalake.DataLakePathClient.getAccessControl()
  name: DataLakePathClient.getAccessControl()
  nameWithType: DataLakePathClient.getAccessControl()
  fullName: com.azure.storage.file.datalake.DataLakePathClient.getAccessControl()
- uid: com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  name: DataLakePathClient.setMetadataWithResponse(Map<String,String>,DataLakeRequestConditions,Duration,Context)
  nameWithType: DataLakePathClient.setMetadataWithResponse(Map<String,String>,DataLakeRequestConditions,Duration,Context)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
- uid: java.lang.Object.wait(long)
  name: Object.wait(long)
  nameWithType: Object.wait(long)
  fullName: java.lang.Object.wait(long)
- uid: java.lang.Object.getClass()
  name: Object.getClass()
  nameWithType: Object.getClass()
  fullName: java.lang.Object.getClass()
- uid: java.lang.Object.hashCode()
  name: Object.hashCode()
  nameWithType: Object.hashCode()
  fullName: java.lang.Object.hashCode()
- uid: com.azure.storage.file.datalake.DataLakePathClient.getServiceVersion()
  name: DataLakePathClient.getServiceVersion()
  nameWithType: DataLakePathClient.getServiceVersion()
  fullName: com.azure.storage.file.datalake.DataLakePathClient.getServiceVersion()
- uid: java.lang.Object.wait(long,int)
  name: Object.wait(long,int)
  nameWithType: Object.wait(long,int)
  fullName: java.lang.Object.wait(long,int)
- uid: com.azure.storage.file.datalake.DataLakePathClient.getAccountName()
  name: DataLakePathClient.getAccountName()
  nameWithType: DataLakePathClient.getAccountName()
  fullName: com.azure.storage.file.datalake.DataLakePathClient.getAccountName()
- uid: java.lang.Object.notify()
  name: Object.notify()
  nameWithType: Object.notify()
  fullName: java.lang.Object.notify()
- uid: com.azure.storage.file.datalake.DataLakePathClient.getAccessControlWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  name: DataLakePathClient.getAccessControlWithResponse(boolean,DataLakeRequestConditions,Duration,Context)
  nameWithType: DataLakePathClient.getAccessControlWithResponse(boolean,DataLakeRequestConditions,Duration,Context)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.getAccessControlWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
- uid: java.lang.Object.notifyAll()
  name: Object.notifyAll()
  nameWithType: Object.notifyAll()
  fullName: java.lang.Object.notifyAll()
- uid: com.azure.storage.file.datalake.DataLakePathClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)
  name: DataLakePathClient.generateSas(DataLakeServiceSasSignatureValues)
  nameWithType: DataLakePathClient.generateSas(DataLakeServiceSasSignatureValues)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)
- uid: java.lang.Object.equals(java.lang.Object)
  name: Object.equals(Object)
  nameWithType: Object.equals(Object)
  fullName: java.lang.Object.equals(java.lang.Object)
- uid: com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)
  name: DataLakePathClient.setMetadata(Map<String,String>)
  nameWithType: DataLakePathClient.setMetadata(Map<String,String>)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)
- uid: com.azure.storage.file.datalake.DataLakePathClient.setHttpHeadersWithResponse(com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  name: DataLakePathClient.setHttpHeadersWithResponse(PathHttpHeaders,DataLakeRequestConditions,Duration,Context)
  nameWithType: DataLakePathClient.setHttpHeadersWithResponse(PathHttpHeaders,DataLakeRequestConditions,Duration,Context)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setHttpHeadersWithResponse(com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
- uid: com.azure.storage.file.datalake.DataLakePathClient.exists()
  name: DataLakePathClient.exists()
  nameWithType: DataLakePathClient.exists()
  fullName: com.azure.storage.file.datalake.DataLakePathClient.exists()
- uid: com.azure.storage.file.datalake.DataLakePathClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)
  name: DataLakePathClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues,UserDelegationKey)
  nameWithType: DataLakePathClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues,UserDelegationKey)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)
- uid: com.azure.storage.file.datalake.DataLakePathClient.setPermissions(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String)
  name: DataLakePathClient.setPermissions(PathPermissions,String,String)
  nameWithType: DataLakePathClient.setPermissions(PathPermissions,String,String)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setPermissions(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String)
- uid: java.lang.Object.toString()
  name: Object.toString()
  nameWithType: Object.toString()
  fullName: java.lang.Object.toString()
- uid: com.azure.storage.file.datalake.DataLakePathClient.getFileSystemName()
  name: DataLakePathClient.getFileSystemName()
  nameWithType: DataLakePathClient.getFileSystemName()
  fullName: com.azure.storage.file.datalake.DataLakePathClient.getFileSystemName()
- uid: com.azure.storage.file.datalake.DataLakePathClient.create(boolean)
  name: DataLakePathClient.create(boolean)
  nameWithType: DataLakePathClient.create(boolean)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.create(boolean)
- uid: com.azure.storage.file.datalake.DataLakePathClient.setPermissionsWithResponse(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  name: DataLakePathClient.setPermissionsWithResponse(PathPermissions,String,String,DataLakeRequestConditions,Duration,Context)
  nameWithType: DataLakePathClient.setPermissionsWithResponse(PathPermissions,String,String,DataLakeRequestConditions,Duration,Context)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setPermissionsWithResponse(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
- uid: com.azure.storage.file.datalake.DataLakePathClient.setHttpHeaders(com.azure.storage.file.datalake.models.PathHttpHeaders)
  name: DataLakePathClient.setHttpHeaders(PathHttpHeaders)
  nameWithType: DataLakePathClient.setHttpHeaders(PathHttpHeaders)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setHttpHeaders(com.azure.storage.file.datalake.models.PathHttpHeaders)
- uid: com.azure.storage.file.datalake.DataLakePathClient.getHttpPipeline()
  name: DataLakePathClient.getHttpPipeline()
  nameWithType: DataLakePathClient.getHttpPipeline()
  fullName: com.azure.storage.file.datalake.DataLakePathClient.getHttpPipeline()
- uid: com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  name: DataLakePathClient.setAccessControlListWithResponse(List<PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)
  nameWithType: DataLakePathClient.setAccessControlListWithResponse(List<PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
- uid: com.azure.storage.file.datalake.DataLakePathClient.getPropertiesWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  name: DataLakePathClient.getPropertiesWithResponse(DataLakeRequestConditions,Duration,Context)
  nameWithType: DataLakePathClient.getPropertiesWithResponse(DataLakeRequestConditions,Duration,Context)
  fullName: com.azure.storage.file.datalake.DataLakePathClient.getPropertiesWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
- uid: java.lang.Void
  name: Void
  nameWithType: Void
  fullName: java.lang.Void
- uid: com.azure.core.http.rest.Response
  name: Response
  nameWithType: Response
  fullName: com.azure.core.http.rest.Response
- uid: java.util.Map
  name: Map
  nameWithType: Map
  fullName: java.util.Map
- uid: java.lang.String,java.lang.String
  name: String,String
  nameWithType: String,String
  fullName: java.lang.String,java.lang.String
- uid: com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)
  name: PathAccessControlEntry>,String,String)
  nameWithType: PathAccessControlEntry>,String,String)
  fullName: com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)
- uid: com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List
  name: DataLakePathClient.setAccessControlList(List
  nameWithType: DataLakePathClient.setAccessControlList(List
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List
- uid: com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map
  name: DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map
  nameWithType: DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map
  fullName: com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map
- uid: java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  name: String,String>,DataLakeRequestConditions,Duration,Context)
  nameWithType: String,String>,DataLakeRequestConditions,Duration,Context)
  fullName: java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
- uid: com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map
  name: DataLakePathClient.setMetadataWithResponse(Map
  nameWithType: DataLakePathClient.setMetadataWithResponse(Map
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map
- uid: java.lang.String,java.lang.String>)
  name: String,String>)
  nameWithType: String,String>)
  fullName: java.lang.String,java.lang.String>)
- uid: com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map
  name: DataLakePathClient.setMetadata(Map
  nameWithType: DataLakePathClient.setMetadata(Map
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map
- uid: com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List
  name: DataLakePathClient.setAccessControlListWithResponse(List
  nameWithType: DataLakePathClient.setAccessControlListWithResponse(List
  fullName: com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List
- uid: com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  name: PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)
  nameWithType: PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)
  fullName: com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
