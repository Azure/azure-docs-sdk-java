### YamlMime:JavaType
uid: "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink"
fullName: "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink"
name: "AzureDatabricksDeltaLakeSink"
nameWithType: "AzureDatabricksDeltaLakeSink"
summary: "A copy activity Azure Databricks Delta Lake sink."
inheritances:
- "<xref href=\"java.lang.Object\" data-throw-if-not-resolved=\"False\" />"
- "<xref href=\"com.azure.resourcemanager.datafactory.models.CopySink\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "com.azure.resourcemanager.datafactory.models.CopySink.additionalProperties()"
- "com.azure.resourcemanager.datafactory.models.CopySink.maxConcurrentConnections()"
- "com.azure.resourcemanager.datafactory.models.CopySink.sinkRetryCount()"
- "com.azure.resourcemanager.datafactory.models.CopySink.sinkRetryWait()"
- "com.azure.resourcemanager.datafactory.models.CopySink.validate()"
- "com.azure.resourcemanager.datafactory.models.CopySink.withAdditionalProperties(java.util.Map<java.lang.String,java.lang.Object>)"
- "com.azure.resourcemanager.datafactory.models.CopySink.withMaxConcurrentConnections(java.lang.Object)"
- "com.azure.resourcemanager.datafactory.models.CopySink.withSinkRetryCount(java.lang.Object)"
- "com.azure.resourcemanager.datafactory.models.CopySink.withSinkRetryWait(java.lang.Object)"
- "com.azure.resourcemanager.datafactory.models.CopySink.withWriteBatchSize(java.lang.Object)"
- "com.azure.resourcemanager.datafactory.models.CopySink.withWriteBatchTimeout(java.lang.Object)"
- "com.azure.resourcemanager.datafactory.models.CopySink.writeBatchSize()"
- "com.azure.resourcemanager.datafactory.models.CopySink.writeBatchTimeout()"
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class AzureDatabricksDeltaLakeSink extends CopySink"
constructors:
- "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink.AzureDatabricksDeltaLakeSink()"
methods:
- "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink.importSettings()"
- "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink.preCopyScript()"
- "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink.validate()"
- "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink.withImportSettings(com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeImportCommand)"
- "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink.withMaxConcurrentConnections(java.lang.Object)"
- "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink.withPreCopyScript(java.lang.Object)"
- "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink.withSinkRetryCount(java.lang.Object)"
- "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink.withSinkRetryWait(java.lang.Object)"
- "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink.withWriteBatchSize(java.lang.Object)"
- "com.azure.resourcemanager.datafactory.models.AzureDatabricksDeltaLakeSink.withWriteBatchTimeout(java.lang.Object)"
type: "class"
metadata: {}
package: "com.azure.resourcemanager.datafactory.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.1
