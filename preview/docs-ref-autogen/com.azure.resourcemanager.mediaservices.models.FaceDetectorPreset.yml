### YamlMime:JavaType
uid: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset"
fullName: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset"
name: "FaceDetectorPreset"
nameWithType: "FaceDetectorPreset"
summary: "Describes all the settings to be used when analyzing a video in order to detect (and optionally redact) all the faces present."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
- "<xref href=\"com.azure.resourcemanager.mediaservices.models.Preset?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "com.azure.resourcemanager.mediaservices.models.Preset.validate()"
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class FaceDetectorPreset extends Preset"
constructors:
- uid: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.FaceDetectorPreset()"
  fullName: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.FaceDetectorPreset()"
  name: "FaceDetectorPreset()"
  nameWithType: "FaceDetectorPreset.FaceDetectorPreset()"
  syntax: "public FaceDetectorPreset()"
methods:
- uid: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.blurType()"
  fullName: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.blurType()"
  name: "blurType()"
  nameWithType: "FaceDetectorPreset.blurType()"
  summary: "Get the blur<wbr>Type property: Blur type."
  syntax: "public BlurType blurType()"
  desc: "Get the blurType property: Blur type."
  returns:
    description: "the blurType value."
    type: "<xref href=\"com.azure.resourcemanager.mediaservices.models.BlurType?alt=com.azure.resourcemanager.mediaservices.models.BlurType&text=BlurType\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.experimentalOptions()"
  fullName: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.experimentalOptions()"
  name: "experimentalOptions()"
  nameWithType: "FaceDetectorPreset.experimentalOptions()"
  summary: "Get the experimental<wbr>Options property: Dictionary containing key value pairs for parameters not exposed in the preset itself."
  syntax: "public Map<String,String> experimentalOptions()"
  desc: "Get the experimentalOptions property: Dictionary containing key value pairs for parameters not exposed in the preset itself."
  returns:
    description: "the experimentalOptions value."
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.mode()"
  fullName: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.mode()"
  name: "mode()"
  nameWithType: "FaceDetectorPreset.mode()"
  summary: "Get the mode property: This mode provides the ability to choose between the following settings: 1) Analyze - For detection only.<wbr>This mode generates a metadata JSON file marking appearances of faces throughout the video.<wbr>Where possible, appearances of the same person are assigned the same ID."
  syntax: "public FaceRedactorMode mode()"
  desc: "Get the mode property: This mode provides the ability to choose between the following settings: 1) Analyze - For detection only.This mode generates a metadata JSON file marking appearances of faces throughout the video.Where possible, appearances of the same person are assigned the same ID. 2) Combined - Additionally redacts(blurs) detected faces. 3) Redact - This enables a 2-pass process, allowing for selective redaction of a subset of detected faces.It takes in the metadata file from a prior analyze pass, along with the source video, and a user-selected subset of IDs that require redaction."
  returns:
    description: "the mode value."
    type: "<xref href=\"com.azure.resourcemanager.mediaservices.models.FaceRedactorMode?alt=com.azure.resourcemanager.mediaservices.models.FaceRedactorMode&text=FaceRedactorMode\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.resolution()"
  fullName: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.resolution()"
  name: "resolution()"
  nameWithType: "FaceDetectorPreset.resolution()"
  summary: "Get the resolution property: Specifies the maximum resolution at which your video is analyzed."
  syntax: "public AnalysisResolution resolution()"
  desc: "Get the resolution property: Specifies the maximum resolution at which your video is analyzed. The default behavior is \"SourceResolution,\" which will keep the input video at its original resolution when analyzed. Using \"StandardDefinition\" will resize input videos to standard definition while preserving the appropriate aspect ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled to 640x360 before processing. Switching to \"StandardDefinition\" will reduce the time it takes to process high resolution video. It may also reduce the cost of using this component (see https://azure.microsoft.com/en-us/pricing/details/media-services/\\#analytics for details). However, faces that end up being too small in the resized video may not be detected."
  returns:
    description: "the resolution value."
    type: "<xref href=\"com.azure.resourcemanager.mediaservices.models.AnalysisResolution?alt=com.azure.resourcemanager.mediaservices.models.AnalysisResolution&text=AnalysisResolution\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.validate()"
  fullName: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.validate()"
  name: "validate()"
  nameWithType: "FaceDetectorPreset.validate()"
  summary: "Validates the instance."
  overridden: "com.azure.resourcemanager.mediaservices.models.Preset.validate()"
  syntax: "public void validate()"
  desc: "Validates the instance."
- uid: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.withBlurType(com.azure.resourcemanager.mediaservices.models.BlurType)"
  fullName: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.withBlurType(BlurType blurType)"
  name: "withBlurType(BlurType blurType)"
  nameWithType: "FaceDetectorPreset.withBlurType(BlurType blurType)"
  summary: "Set the blur<wbr>Type property: Blur type."
  parameters:
  - description: "the blurType value to set."
    name: "blurType"
    type: "<xref href=\"com.azure.resourcemanager.mediaservices.models.BlurType?alt=com.azure.resourcemanager.mediaservices.models.BlurType&text=BlurType\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public FaceDetectorPreset withBlurType(BlurType blurType)"
  desc: "Set the blurType property: Blur type."
  returns:
    description: "the FaceDetectorPreset object itself."
    type: "<xref href=\"com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset?alt=com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset&text=FaceDetectorPreset\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.withExperimentalOptions(java.util.Map<java.lang.String,java.lang.String>)"
  fullName: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.withExperimentalOptions(Map<String,String> experimentalOptions)"
  name: "withExperimentalOptions(Map<String,String> experimentalOptions)"
  nameWithType: "FaceDetectorPreset.withExperimentalOptions(Map<String,String> experimentalOptions)"
  summary: "Set the experimental<wbr>Options property: Dictionary containing key value pairs for parameters not exposed in the preset itself."
  parameters:
  - description: "the experimentalOptions value to set."
    name: "experimentalOptions"
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public FaceDetectorPreset withExperimentalOptions(Map<String,String> experimentalOptions)"
  desc: "Set the experimentalOptions property: Dictionary containing key value pairs for parameters not exposed in the preset itself."
  returns:
    description: "the FaceDetectorPreset object itself."
    type: "<xref href=\"com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset?alt=com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset&text=FaceDetectorPreset\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.withMode(com.azure.resourcemanager.mediaservices.models.FaceRedactorMode)"
  fullName: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.withMode(FaceRedactorMode mode)"
  name: "withMode(FaceRedactorMode mode)"
  nameWithType: "FaceDetectorPreset.withMode(FaceRedactorMode mode)"
  summary: "Set the mode property: This mode provides the ability to choose between the following settings: 1) Analyze - For detection only.<wbr>This mode generates a metadata JSON file marking appearances of faces throughout the video.<wbr>Where possible, appearances of the same person are assigned the same ID."
  parameters:
  - description: "the mode value to set."
    name: "mode"
    type: "<xref href=\"com.azure.resourcemanager.mediaservices.models.FaceRedactorMode?alt=com.azure.resourcemanager.mediaservices.models.FaceRedactorMode&text=FaceRedactorMode\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public FaceDetectorPreset withMode(FaceRedactorMode mode)"
  desc: "Set the mode property: This mode provides the ability to choose between the following settings: 1) Analyze - For detection only.This mode generates a metadata JSON file marking appearances of faces throughout the video.Where possible, appearances of the same person are assigned the same ID. 2) Combined - Additionally redacts(blurs) detected faces. 3) Redact - This enables a 2-pass process, allowing for selective redaction of a subset of detected faces.It takes in the metadata file from a prior analyze pass, along with the source video, and a user-selected subset of IDs that require redaction."
  returns:
    description: "the FaceDetectorPreset object itself."
    type: "<xref href=\"com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset?alt=com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset&text=FaceDetectorPreset\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.withResolution(com.azure.resourcemanager.mediaservices.models.AnalysisResolution)"
  fullName: "com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset.withResolution(AnalysisResolution resolution)"
  name: "withResolution(AnalysisResolution resolution)"
  nameWithType: "FaceDetectorPreset.withResolution(AnalysisResolution resolution)"
  summary: "Set the resolution property: Specifies the maximum resolution at which your video is analyzed."
  parameters:
  - description: "the resolution value to set."
    name: "resolution"
    type: "<xref href=\"com.azure.resourcemanager.mediaservices.models.AnalysisResolution?alt=com.azure.resourcemanager.mediaservices.models.AnalysisResolution&text=AnalysisResolution\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public FaceDetectorPreset withResolution(AnalysisResolution resolution)"
  desc: "Set the resolution property: Specifies the maximum resolution at which your video is analyzed. The default behavior is \"SourceResolution,\" which will keep the input video at its original resolution when analyzed. Using \"StandardDefinition\" will resize input videos to standard definition while preserving the appropriate aspect ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled to 640x360 before processing. Switching to \"StandardDefinition\" will reduce the time it takes to process high resolution video. It may also reduce the cost of using this component (see https://azure.microsoft.com/en-us/pricing/details/media-services/\\#analytics for details). However, faces that end up being too small in the resized video may not be detected."
  returns:
    description: "the FaceDetectorPreset object itself."
    type: "<xref href=\"com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset?alt=com.azure.resourcemanager.mediaservices.models.FaceDetectorPreset&text=FaceDetectorPreset\" data-throw-if-not-resolved=\"False\" />"
type: "class"
desc: "Describes all the settings to be used when analyzing a video in order to detect (and optionally redact) all the faces present."
metadata: {}
package: "com.azure.resourcemanager.mediaservices.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-mediaservices:2.1.0-beta.1
