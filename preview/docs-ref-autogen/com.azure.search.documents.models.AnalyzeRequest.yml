### YamlMime:ManagedReference
items:
- uid: "com.azure.search.documents.models.AnalyzeRequest"
  id: "AnalyzeRequest"
  parent: "com.azure.search.documents.models"
  children:
  - "com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest()"
  - "com.azure.search.documents.models.AnalyzeRequest.getAnalyzer()"
  - "com.azure.search.documents.models.AnalyzeRequest.getCharFilters()"
  - "com.azure.search.documents.models.AnalyzeRequest.getText()"
  - "com.azure.search.documents.models.AnalyzeRequest.getTokenFilters()"
  - "com.azure.search.documents.models.AnalyzeRequest.getTokenizer()"
  - "com.azure.search.documents.models.AnalyzeRequest.setAnalyzer(com.azure.search.documents.models.AnalyzerName)"
  - "com.azure.search.documents.models.AnalyzeRequest.setCharFilters(java.util.List<com.azure.search.documents.models.CharFilterName>)"
  - "com.azure.search.documents.models.AnalyzeRequest.setText(java.lang.String)"
  - "com.azure.search.documents.models.AnalyzeRequest.setTokenFilters(java.util.List<com.azure.search.documents.models.TokenFilterName>)"
  - "com.azure.search.documents.models.AnalyzeRequest.setTokenizer(com.azure.search.documents.models.TokenizerName)"
  langs:
  - "java"
  name: "AnalyzeRequest"
  nameWithType: "AnalyzeRequest"
  fullName: "com.azure.search.documents.models.AnalyzeRequest"
  type: "Class"
  package: "com.azure.search.documents.models"
  summary: "Specifies some text and analysis components used to break that text into tokens."
  syntax:
    content: "public final class AnalyzeRequest"
  inheritance:
  - "java.lang.Object"
  inheritedMembers:
  - "java.lang.Object.clone()"
  - "java.lang.Object.equals(java.lang.Object)"
  - "java.lang.Object.finalize()"
  - "java.lang.Object.getClass()"
  - "java.lang.Object.hashCode()"
  - "java.lang.Object.notify()"
  - "java.lang.Object.notifyAll()"
  - "java.lang.Object.toString()"
  - "java.lang.Object.wait()"
  - "java.lang.Object.wait(long)"
  - "java.lang.Object.wait(long,int)"
- uid: "com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest()"
  id: "AnalyzeRequest()"
  parent: "com.azure.search.documents.models.AnalyzeRequest"
  langs:
  - "java"
  name: "AnalyzeRequest()"
  nameWithType: "AnalyzeRequest.AnalyzeRequest()"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest()"
  overload: "com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest*"
  type: "Constructor"
  package: "com.azure.search.documents.models"
  syntax:
    content: "public AnalyzeRequest()"
- uid: "com.azure.search.documents.models.AnalyzeRequest.getAnalyzer()"
  id: "getAnalyzer()"
  parent: "com.azure.search.documents.models.AnalyzeRequest"
  langs:
  - "java"
  name: "getAnalyzer()"
  nameWithType: "AnalyzeRequest.getAnalyzer()"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.getAnalyzer()"
  overload: "com.azure.search.documents.models.AnalyzeRequest.getAnalyzer*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the analyzer property: The name of the analyzer to use to break the given text. If this parameter is not specified, you must specify a tokenizer instead. The tokenizer and analyzer parameters are mutually exclusive. Possible values include: 'ArMicrosoft', 'ArLucene', 'HyLucene', 'BnMicrosoft', 'EuLucene', 'BgMicrosoft', 'BgLucene', 'CaMicrosoft', 'CaLucene', 'ZhHansMicrosoft', 'ZhHansLucene', 'ZhHantMicrosoft', 'ZhHantLucene', 'HrMicrosoft', 'CsMicrosoft', 'CsLucene', 'DaMicrosoft', 'DaLucene', 'NlMicrosoft', 'NlLucene', 'EnMicrosoft', 'EnLucene', 'EtMicrosoft', 'FiMicrosoft', 'FiLucene', 'FrMicrosoft', 'FrLucene', 'GlLucene', 'DeMicrosoft', 'DeLucene', 'ElMicrosoft', 'ElLucene', 'GuMicrosoft', 'HeMicrosoft', 'HiMicrosoft', 'HiLucene', 'HuMicrosoft', 'HuLucene', 'IsMicrosoft', 'IdMicrosoft', 'IdLucene', 'GaLucene', 'ItMicrosoft', 'ItLucene', 'JaMicrosoft', 'JaLucene', 'KnMicrosoft', 'KoMicrosoft', 'KoLucene', 'LvMicrosoft', 'LvLucene', 'LtMicrosoft', 'MlMicrosoft', 'MsMicrosoft', 'MrMicrosoft', 'NbMicrosoft', 'NoLucene', 'FaLucene', 'PlMicrosoft', 'PlLucene', 'PtBrMicrosoft', 'PtBrLucene', 'PtPtMicrosoft', 'PtPtLucene', 'PaMicrosoft', 'RoMicrosoft', 'RoLucene', 'RuMicrosoft', 'RuLucene', 'SrCyrillicMicrosoft', 'SrLatinMicrosoft', 'SkMicrosoft', 'SlMicrosoft', 'EsMicrosoft', 'EsLucene', 'SvMicrosoft', 'SvLucene', 'TaMicrosoft', 'TeMicrosoft', 'ThMicrosoft', 'ThLucene', 'TrMicrosoft', 'TrLucene', 'UkMicrosoft', 'UrMicrosoft', 'ViMicrosoft', 'StandardLucene', 'StandardAsciiFoldingLucene', 'Keyword', 'Pattern', 'Simple', 'Stop', 'Whitespace'."
  syntax:
    content: "public AnalyzerName getAnalyzer()"
    return:
      type: "com.azure.search.documents.models.AnalyzerName"
      description: "the analyzer value."
- uid: "com.azure.search.documents.models.AnalyzeRequest.getCharFilters()"
  id: "getCharFilters()"
  parent: "com.azure.search.documents.models.AnalyzeRequest"
  langs:
  - "java"
  name: "getCharFilters()"
  nameWithType: "AnalyzeRequest.getCharFilters()"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.getCharFilters()"
  overload: "com.azure.search.documents.models.AnalyzeRequest.getCharFilters*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the charFilters property: An optional list of character filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter."
  syntax:
    content: "public List<CharFilterName> getCharFilters()"
    return:
      type: "java.util.List<com.azure.search.documents.models.CharFilterName>"
      description: "the charFilters value."
- uid: "com.azure.search.documents.models.AnalyzeRequest.getText()"
  id: "getText()"
  parent: "com.azure.search.documents.models.AnalyzeRequest"
  langs:
  - "java"
  name: "getText()"
  nameWithType: "AnalyzeRequest.getText()"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.getText()"
  overload: "com.azure.search.documents.models.AnalyzeRequest.getText*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the text property: The text to break into tokens."
  syntax:
    content: "public String getText()"
    return:
      type: "java.lang.String"
      description: "the text value."
- uid: "com.azure.search.documents.models.AnalyzeRequest.getTokenFilters()"
  id: "getTokenFilters()"
  parent: "com.azure.search.documents.models.AnalyzeRequest"
  langs:
  - "java"
  name: "getTokenFilters()"
  nameWithType: "AnalyzeRequest.getTokenFilters()"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.getTokenFilters()"
  overload: "com.azure.search.documents.models.AnalyzeRequest.getTokenFilters*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the tokenFilters property: An optional list of token filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter."
  syntax:
    content: "public List<TokenFilterName> getTokenFilters()"
    return:
      type: "java.util.List<com.azure.search.documents.models.TokenFilterName>"
      description: "the tokenFilters value."
- uid: "com.azure.search.documents.models.AnalyzeRequest.getTokenizer()"
  id: "getTokenizer()"
  parent: "com.azure.search.documents.models.AnalyzeRequest"
  langs:
  - "java"
  name: "getTokenizer()"
  nameWithType: "AnalyzeRequest.getTokenizer()"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.getTokenizer()"
  overload: "com.azure.search.documents.models.AnalyzeRequest.getTokenizer*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Get the tokenizer property: The name of the tokenizer to use to break the given text. If this parameter is not specified, you must specify an analyzer instead. The tokenizer and analyzer parameters are mutually exclusive. Possible values include: 'Classic', 'EdgeNGram', 'Keyword', 'Letter', 'Lowercase', 'MicrosoftLanguageTokenizer', 'MicrosoftLanguageStemmingTokenizer', 'NGram', 'PathHierarchy', 'Pattern', 'Standard', 'UaxUrlEmail', 'Whitespace'."
  syntax:
    content: "public TokenizerName getTokenizer()"
    return:
      type: "com.azure.search.documents.models.TokenizerName"
      description: "the tokenizer value."
- uid: "com.azure.search.documents.models.AnalyzeRequest.setAnalyzer(com.azure.search.documents.models.AnalyzerName)"
  id: "setAnalyzer(com.azure.search.documents.models.AnalyzerName)"
  parent: "com.azure.search.documents.models.AnalyzeRequest"
  langs:
  - "java"
  name: "setAnalyzer(AnalyzerName analyzer)"
  nameWithType: "AnalyzeRequest.setAnalyzer(AnalyzerName analyzer)"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.setAnalyzer(AnalyzerName analyzer)"
  overload: "com.azure.search.documents.models.AnalyzeRequest.setAnalyzer*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the analyzer property: The name of the analyzer to use to break the given text. If this parameter is not specified, you must specify a tokenizer instead. The tokenizer and analyzer parameters are mutually exclusive. Possible values include: 'ArMicrosoft', 'ArLucene', 'HyLucene', 'BnMicrosoft', 'EuLucene', 'BgMicrosoft', 'BgLucene', 'CaMicrosoft', 'CaLucene', 'ZhHansMicrosoft', 'ZhHansLucene', 'ZhHantMicrosoft', 'ZhHantLucene', 'HrMicrosoft', 'CsMicrosoft', 'CsLucene', 'DaMicrosoft', 'DaLucene', 'NlMicrosoft', 'NlLucene', 'EnMicrosoft', 'EnLucene', 'EtMicrosoft', 'FiMicrosoft', 'FiLucene', 'FrMicrosoft', 'FrLucene', 'GlLucene', 'DeMicrosoft', 'DeLucene', 'ElMicrosoft', 'ElLucene', 'GuMicrosoft', 'HeMicrosoft', 'HiMicrosoft', 'HiLucene', 'HuMicrosoft', 'HuLucene', 'IsMicrosoft', 'IdMicrosoft', 'IdLucene', 'GaLucene', 'ItMicrosoft', 'ItLucene', 'JaMicrosoft', 'JaLucene', 'KnMicrosoft', 'KoMicrosoft', 'KoLucene', 'LvMicrosoft', 'LvLucene', 'LtMicrosoft', 'MlMicrosoft', 'MsMicrosoft', 'MrMicrosoft', 'NbMicrosoft', 'NoLucene', 'FaLucene', 'PlMicrosoft', 'PlLucene', 'PtBrMicrosoft', 'PtBrLucene', 'PtPtMicrosoft', 'PtPtLucene', 'PaMicrosoft', 'RoMicrosoft', 'RoLucene', 'RuMicrosoft', 'RuLucene', 'SrCyrillicMicrosoft', 'SrLatinMicrosoft', 'SkMicrosoft', 'SlMicrosoft', 'EsMicrosoft', 'EsLucene', 'SvMicrosoft', 'SvLucene', 'TaMicrosoft', 'TeMicrosoft', 'ThMicrosoft', 'ThLucene', 'TrMicrosoft', 'TrLucene', 'UkMicrosoft', 'UrMicrosoft', 'ViMicrosoft', 'StandardLucene', 'StandardAsciiFoldingLucene', 'Keyword', 'Pattern', 'Simple', 'Stop', 'Whitespace'."
  syntax:
    content: "public AnalyzeRequest setAnalyzer(AnalyzerName analyzer)"
    parameters:
    - id: "analyzer"
      type: "com.azure.search.documents.models.AnalyzerName"
      description: "the analyzer value to set."
    return:
      type: "com.azure.search.documents.models.AnalyzeRequest"
      description: "the AnalyzeRequest object itself."
- uid: "com.azure.search.documents.models.AnalyzeRequest.setCharFilters(java.util.List<com.azure.search.documents.models.CharFilterName>)"
  id: "setCharFilters(java.util.List<com.azure.search.documents.models.CharFilterName>)"
  parent: "com.azure.search.documents.models.AnalyzeRequest"
  langs:
  - "java"
  name: "setCharFilters(List<CharFilterName> charFilters)"
  nameWithType: "AnalyzeRequest.setCharFilters(List<CharFilterName> charFilters)"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.setCharFilters(List<CharFilterName> charFilters)"
  overload: "com.azure.search.documents.models.AnalyzeRequest.setCharFilters*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the charFilters property: An optional list of character filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter."
  syntax:
    content: "public AnalyzeRequest setCharFilters(List<CharFilterName> charFilters)"
    parameters:
    - id: "charFilters"
      type: "java.util.List<com.azure.search.documents.models.CharFilterName>"
      description: "the charFilters value to set."
    return:
      type: "com.azure.search.documents.models.AnalyzeRequest"
      description: "the AnalyzeRequest object itself."
- uid: "com.azure.search.documents.models.AnalyzeRequest.setText(java.lang.String)"
  id: "setText(java.lang.String)"
  parent: "com.azure.search.documents.models.AnalyzeRequest"
  langs:
  - "java"
  name: "setText(String text)"
  nameWithType: "AnalyzeRequest.setText(String text)"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.setText(String text)"
  overload: "com.azure.search.documents.models.AnalyzeRequest.setText*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the text property: The text to break into tokens."
  syntax:
    content: "public AnalyzeRequest setText(String text)"
    parameters:
    - id: "text"
      type: "java.lang.String"
      description: "the text value to set."
    return:
      type: "com.azure.search.documents.models.AnalyzeRequest"
      description: "the AnalyzeRequest object itself."
- uid: "com.azure.search.documents.models.AnalyzeRequest.setTokenFilters(java.util.List<com.azure.search.documents.models.TokenFilterName>)"
  id: "setTokenFilters(java.util.List<com.azure.search.documents.models.TokenFilterName>)"
  parent: "com.azure.search.documents.models.AnalyzeRequest"
  langs:
  - "java"
  name: "setTokenFilters(List<TokenFilterName> tokenFilters)"
  nameWithType: "AnalyzeRequest.setTokenFilters(List<TokenFilterName> tokenFilters)"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.setTokenFilters(List<TokenFilterName> tokenFilters)"
  overload: "com.azure.search.documents.models.AnalyzeRequest.setTokenFilters*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the tokenFilters property: An optional list of token filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter."
  syntax:
    content: "public AnalyzeRequest setTokenFilters(List<TokenFilterName> tokenFilters)"
    parameters:
    - id: "tokenFilters"
      type: "java.util.List<com.azure.search.documents.models.TokenFilterName>"
      description: "the tokenFilters value to set."
    return:
      type: "com.azure.search.documents.models.AnalyzeRequest"
      description: "the AnalyzeRequest object itself."
- uid: "com.azure.search.documents.models.AnalyzeRequest.setTokenizer(com.azure.search.documents.models.TokenizerName)"
  id: "setTokenizer(com.azure.search.documents.models.TokenizerName)"
  parent: "com.azure.search.documents.models.AnalyzeRequest"
  langs:
  - "java"
  name: "setTokenizer(TokenizerName tokenizer)"
  nameWithType: "AnalyzeRequest.setTokenizer(TokenizerName tokenizer)"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.setTokenizer(TokenizerName tokenizer)"
  overload: "com.azure.search.documents.models.AnalyzeRequest.setTokenizer*"
  type: "Method"
  package: "com.azure.search.documents.models"
  summary: "Set the tokenizer property: The name of the tokenizer to use to break the given text. If this parameter is not specified, you must specify an analyzer instead. The tokenizer and analyzer parameters are mutually exclusive. Possible values include: 'Classic', 'EdgeNGram', 'Keyword', 'Letter', 'Lowercase', 'MicrosoftLanguageTokenizer', 'MicrosoftLanguageStemmingTokenizer', 'NGram', 'PathHierarchy', 'Pattern', 'Standard', 'UaxUrlEmail', 'Whitespace'."
  syntax:
    content: "public AnalyzeRequest setTokenizer(TokenizerName tokenizer)"
    parameters:
    - id: "tokenizer"
      type: "com.azure.search.documents.models.TokenizerName"
      description: "the tokenizer value to set."
    return:
      type: "com.azure.search.documents.models.AnalyzeRequest"
      description: "the AnalyzeRequest object itself."
references:
- uid: "com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest*"
  name: "AnalyzeRequest"
  nameWithType: "AnalyzeRequest.AnalyzeRequest"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest"
  package: "com.azure.search.documents.models"
- uid: "java.lang.String"
  spec.java:
  - uid: "java.lang.String"
    name: "String"
    fullName: "java.lang.String"
- uid: "com.azure.search.documents.models.AnalyzeRequest.getText*"
  name: "getText"
  nameWithType: "AnalyzeRequest.getText"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.getText"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.AnalyzeRequest.setText*"
  name: "setText"
  nameWithType: "AnalyzeRequest.setText"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.setText"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.AnalyzerName"
  name: "AnalyzerName"
  nameWithType: "AnalyzerName"
  fullName: "com.azure.search.documents.models.AnalyzerName"
- uid: "com.azure.search.documents.models.AnalyzeRequest.getAnalyzer*"
  name: "getAnalyzer"
  nameWithType: "AnalyzeRequest.getAnalyzer"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.getAnalyzer"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.AnalyzeRequest.setAnalyzer*"
  name: "setAnalyzer"
  nameWithType: "AnalyzeRequest.setAnalyzer"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.setAnalyzer"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.TokenizerName"
  name: "TokenizerName"
  nameWithType: "TokenizerName"
  fullName: "com.azure.search.documents.models.TokenizerName"
- uid: "com.azure.search.documents.models.AnalyzeRequest.getTokenizer*"
  name: "getTokenizer"
  nameWithType: "AnalyzeRequest.getTokenizer"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.getTokenizer"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.AnalyzeRequest.setTokenizer*"
  name: "setTokenizer"
  nameWithType: "AnalyzeRequest.setTokenizer"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.setTokenizer"
  package: "com.azure.search.documents.models"
- uid: "java.util.List<com.azure.search.documents.models.TokenFilterName>"
  spec.java:
  - uid: "java.util.List"
    name: "List"
    fullName: "java.util.List"
  - name: "<"
    fullName: "<"
  - uid: "com.azure.search.documents.models.TokenFilterName"
    name: "TokenFilterName"
    fullName: "com.azure.search.documents.models.TokenFilterName"
  - name: ">"
    fullName: ">"
- uid: "com.azure.search.documents.models.AnalyzeRequest.getTokenFilters*"
  name: "getTokenFilters"
  nameWithType: "AnalyzeRequest.getTokenFilters"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.getTokenFilters"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.AnalyzeRequest.setTokenFilters*"
  name: "setTokenFilters"
  nameWithType: "AnalyzeRequest.setTokenFilters"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.setTokenFilters"
  package: "com.azure.search.documents.models"
- uid: "java.util.List<com.azure.search.documents.models.CharFilterName>"
  spec.java:
  - uid: "java.util.List"
    name: "List"
    fullName: "java.util.List"
  - name: "<"
    fullName: "<"
  - uid: "com.azure.search.documents.models.CharFilterName"
    name: "CharFilterName"
    fullName: "com.azure.search.documents.models.CharFilterName"
  - name: ">"
    fullName: ">"
- uid: "com.azure.search.documents.models.AnalyzeRequest.getCharFilters*"
  name: "getCharFilters"
  nameWithType: "AnalyzeRequest.getCharFilters"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.getCharFilters"
  package: "com.azure.search.documents.models"
- uid: "com.azure.search.documents.models.AnalyzeRequest.setCharFilters*"
  name: "setCharFilters"
  nameWithType: "AnalyzeRequest.setCharFilters"
  fullName: "com.azure.search.documents.models.AnalyzeRequest.setCharFilters"
  package: "com.azure.search.documents.models"
- uid: "java.lang.Object.notify()"
  name: "Object.notify()"
  nameWithType: "Object.notify()"
  fullName: "java.lang.Object.notify()"
- uid: "java.lang.Object.wait()"
  name: "Object.wait()"
  nameWithType: "Object.wait()"
  fullName: "java.lang.Object.wait()"
- uid: "java.lang.Object.finalize()"
  name: "Object.finalize()"
  nameWithType: "Object.finalize()"
  fullName: "java.lang.Object.finalize()"
- uid: "java.lang.Object.clone()"
  name: "Object.clone()"
  nameWithType: "Object.clone()"
  fullName: "java.lang.Object.clone()"
- uid: "java.lang.Object.notifyAll()"
  name: "Object.notifyAll()"
  nameWithType: "Object.notifyAll()"
  fullName: "java.lang.Object.notifyAll()"
- uid: "java.lang.Object.equals(java.lang.Object)"
  name: "Object.equals(Object)"
  nameWithType: "Object.equals(Object)"
  fullName: "java.lang.Object.equals(java.lang.Object)"
- uid: "java.lang.Object.getClass()"
  name: "Object.getClass()"
  nameWithType: "Object.getClass()"
  fullName: "java.lang.Object.getClass()"
- uid: "java.lang.Object.wait(long)"
  name: "Object.wait(long)"
  nameWithType: "Object.wait(long)"
  fullName: "java.lang.Object.wait(long)"
- uid: "java.lang.Object.hashCode()"
  name: "Object.hashCode()"
  nameWithType: "Object.hashCode()"
  fullName: "java.lang.Object.hashCode()"
- uid: "java.lang.Object.wait(long,int)"
  name: "Object.wait(long,int)"
  nameWithType: "Object.wait(long,int)"
  fullName: "java.lang.Object.wait(long,int)"
- uid: "java.lang.Object.toString()"
  name: "Object.toString()"
  nameWithType: "Object.toString()"
  fullName: "java.lang.Object.toString()"
- uid: "com.azure.search.documents.models.TokenFilterName"
  name: "TokenFilterName"
  nameWithType: "TokenFilterName"
  fullName: "com.azure.search.documents.models.TokenFilterName"
- uid: "java.util.List"
  name: "List"
  nameWithType: "List"
  fullName: "java.util.List"
- uid: "com.azure.search.documents.models.CharFilterName"
  name: "CharFilterName"
  nameWithType: "CharFilterName"
  fullName: "com.azure.search.documents.models.CharFilterName"
