### YamlMime:ManagedReference
items:
- uid: com.azure.search.documents.models.AnalyzeRequest
  id: AnalyzeRequest
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models
  children:
  - com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest()
  - com.azure.search.documents.models.AnalyzeRequest.getAnalyzer()
  - com.azure.search.documents.models.AnalyzeRequest.getCharFilters()
  - com.azure.search.documents.models.AnalyzeRequest.getText()
  - com.azure.search.documents.models.AnalyzeRequest.getTokenFilters()
  - com.azure.search.documents.models.AnalyzeRequest.getTokenizer()
  - com.azure.search.documents.models.AnalyzeRequest.setAnalyzer(com.azure.search.documents.models.AnalyzerName)
  - com.azure.search.documents.models.AnalyzeRequest.setCharFilters(java.util.List<com.azure.search.documents.models.CharFilterName>)
  - com.azure.search.documents.models.AnalyzeRequest.setText(java.lang.String)
  - com.azure.search.documents.models.AnalyzeRequest.setTokenFilters(java.util.List<com.azure.search.documents.models.TokenFilterName>)
  - com.azure.search.documents.models.AnalyzeRequest.setTokenizer(com.azure.search.documents.models.TokenizerName)
  langs:
  - java
  name: AnalyzeRequest
  nameWithType: AnalyzeRequest
  fullName: com.azure.search.documents.models.AnalyzeRequest
  type: Class
  package: com.azure.search.documents.models
  summary: Specifies some text and analysis components used to break that text into tokens.
  syntax:
    content: public final class AnalyzeRequest
  inheritance:
  - java.lang.Object
  inheritedMembers:
  - java.lang.Object.clone()
  - java.lang.Object.equals(java.lang.Object)
  - java.lang.Object.finalize()
  - java.lang.Object.getClass()
  - java.lang.Object.hashCode()
  - java.lang.Object.notify()
  - java.lang.Object.notifyAll()
  - java.lang.Object.toString()
  - java.lang.Object.wait()
  - java.lang.Object.wait(long)
  - java.lang.Object.wait(long,int)
- uid: com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest()
  id: AnalyzeRequest()
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models.AnalyzeRequest
  langs:
  - java
  name: AnalyzeRequest()
  nameWithType: AnalyzeRequest.AnalyzeRequest()
  fullName: com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest()
  overload: com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest*
  type: Constructor
  package: com.azure.search.documents.models
  syntax:
    content: public AnalyzeRequest()
- uid: com.azure.search.documents.models.AnalyzeRequest.getAnalyzer()
  id: getAnalyzer()
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models.AnalyzeRequest
  langs:
  - java
  name: getAnalyzer()
  nameWithType: AnalyzeRequest.getAnalyzer()
  fullName: com.azure.search.documents.models.AnalyzeRequest.getAnalyzer()
  overload: com.azure.search.documents.models.AnalyzeRequest.getAnalyzer*
  type: Method
  package: com.azure.search.documents.models
  summary: "Get the analyzer property: The name of the analyzer to use to break the given text. If this parameter is not specified, you must specify a tokenizer instead. The tokenizer and analyzer parameters are mutually exclusive. Possible values include: 'ArMicrosoft', 'ArLucene', 'HyLucene', 'BnMicrosoft', 'EuLucene', 'BgMicrosoft', 'BgLucene', 'CaMicrosoft', 'CaLucene', 'ZhHansMicrosoft', 'ZhHansLucene', 'ZhHantMicrosoft', 'ZhHantLucene', 'HrMicrosoft', 'CsMicrosoft', 'CsLucene', 'DaMicrosoft', 'DaLucene', 'NlMicrosoft', 'NlLucene', 'EnMicrosoft', 'EnLucene', 'EtMicrosoft', 'FiMicrosoft', 'FiLucene', 'FrMicrosoft', 'FrLucene', 'GlLucene', 'DeMicrosoft', 'DeLucene', 'ElMicrosoft', 'ElLucene', 'GuMicrosoft', 'HeMicrosoft', 'HiMicrosoft', 'HiLucene', 'HuMicrosoft', 'HuLucene', 'IsMicrosoft', 'IdMicrosoft', 'IdLucene', 'GaLucene', 'ItMicrosoft', 'ItLucene', 'JaMicrosoft', 'JaLucene', 'KnMicrosoft', 'KoMicrosoft', 'KoLucene', 'LvMicrosoft', 'LvLucene', 'LtMicrosoft', 'MlMicrosoft', 'MsMicrosoft', 'MrMicrosoft', 'NbMicrosoft', 'NoLucene', 'FaLucene', 'PlMicrosoft', 'PlLucene', 'PtBrMicrosoft', 'PtBrLucene', 'PtPtMicrosoft', 'PtPtLucene', 'PaMicrosoft', 'RoMicrosoft', 'RoLucene', 'RuMicrosoft', 'RuLucene', 'SrCyrillicMicrosoft', 'SrLatinMicrosoft', 'SkMicrosoft', 'SlMicrosoft', 'EsMicrosoft', 'EsLucene', 'SvMicrosoft', 'SvLucene', 'TaMicrosoft', 'TeMicrosoft', 'ThMicrosoft', 'ThLucene', 'TrMicrosoft', 'TrLucene', 'UkMicrosoft', 'UrMicrosoft', 'ViMicrosoft', 'StandardLucene', 'StandardAsciiFoldingLucene', 'Keyword', 'Pattern', 'Simple', 'Stop', 'Whitespace'."
  syntax:
    content: public AnalyzerName getAnalyzer()
    return:
      type: com.azure.search.documents.models.AnalyzerName
      description: the analyzer value.
- uid: com.azure.search.documents.models.AnalyzeRequest.getCharFilters()
  id: getCharFilters()
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models.AnalyzeRequest
  langs:
  - java
  name: getCharFilters()
  nameWithType: AnalyzeRequest.getCharFilters()
  fullName: com.azure.search.documents.models.AnalyzeRequest.getCharFilters()
  overload: com.azure.search.documents.models.AnalyzeRequest.getCharFilters*
  type: Method
  package: com.azure.search.documents.models
  summary: 'Get the charFilters property: An optional list of character filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter.'
  syntax:
    content: public List<CharFilterName> getCharFilters()
    return:
      type: java.util.List<com.azure.search.documents.models.CharFilterName>
      description: the charFilters value.
- uid: com.azure.search.documents.models.AnalyzeRequest.getText()
  id: getText()
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models.AnalyzeRequest
  langs:
  - java
  name: getText()
  nameWithType: AnalyzeRequest.getText()
  fullName: com.azure.search.documents.models.AnalyzeRequest.getText()
  overload: com.azure.search.documents.models.AnalyzeRequest.getText*
  type: Method
  package: com.azure.search.documents.models
  summary: 'Get the text property: The text to break into tokens.'
  syntax:
    content: public String getText()
    return:
      type: java.lang.String
      description: the text value.
- uid: com.azure.search.documents.models.AnalyzeRequest.getTokenFilters()
  id: getTokenFilters()
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models.AnalyzeRequest
  langs:
  - java
  name: getTokenFilters()
  nameWithType: AnalyzeRequest.getTokenFilters()
  fullName: com.azure.search.documents.models.AnalyzeRequest.getTokenFilters()
  overload: com.azure.search.documents.models.AnalyzeRequest.getTokenFilters*
  type: Method
  package: com.azure.search.documents.models
  summary: 'Get the tokenFilters property: An optional list of token filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter.'
  syntax:
    content: public List<TokenFilterName> getTokenFilters()
    return:
      type: java.util.List<com.azure.search.documents.models.TokenFilterName>
      description: the tokenFilters value.
- uid: com.azure.search.documents.models.AnalyzeRequest.getTokenizer()
  id: getTokenizer()
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models.AnalyzeRequest
  langs:
  - java
  name: getTokenizer()
  nameWithType: AnalyzeRequest.getTokenizer()
  fullName: com.azure.search.documents.models.AnalyzeRequest.getTokenizer()
  overload: com.azure.search.documents.models.AnalyzeRequest.getTokenizer*
  type: Method
  package: com.azure.search.documents.models
  summary: "Get the tokenizer property: The name of the tokenizer to use to break the given text. If this parameter is not specified, you must specify an analyzer instead. The tokenizer and analyzer parameters are mutually exclusive. Possible values include: 'Classic', 'EdgeNGram', 'Keyword', 'Letter', 'Lowercase', 'MicrosoftLanguageTokenizer', 'MicrosoftLanguageStemmingTokenizer', 'NGram', 'PathHierarchy', 'Pattern', 'Standard', 'UaxUrlEmail', 'Whitespace'."
  syntax:
    content: public TokenizerName getTokenizer()
    return:
      type: com.azure.search.documents.models.TokenizerName
      description: the tokenizer value.
- uid: com.azure.search.documents.models.AnalyzeRequest.setAnalyzer(com.azure.search.documents.models.AnalyzerName)
  id: setAnalyzer(com.azure.search.documents.models.AnalyzerName)
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models.AnalyzeRequest
  langs:
  - java
  name: setAnalyzer(AnalyzerName analyzer)
  nameWithType: AnalyzeRequest.setAnalyzer(AnalyzerName analyzer)
  fullName: com.azure.search.documents.models.AnalyzeRequest.setAnalyzer(AnalyzerName analyzer)
  overload: com.azure.search.documents.models.AnalyzeRequest.setAnalyzer*
  type: Method
  package: com.azure.search.documents.models
  summary: "Set the analyzer property: The name of the analyzer to use to break the given text. If this parameter is not specified, you must specify a tokenizer instead. The tokenizer and analyzer parameters are mutually exclusive. Possible values include: 'ArMicrosoft', 'ArLucene', 'HyLucene', 'BnMicrosoft', 'EuLucene', 'BgMicrosoft', 'BgLucene', 'CaMicrosoft', 'CaLucene', 'ZhHansMicrosoft', 'ZhHansLucene', 'ZhHantMicrosoft', 'ZhHantLucene', 'HrMicrosoft', 'CsMicrosoft', 'CsLucene', 'DaMicrosoft', 'DaLucene', 'NlMicrosoft', 'NlLucene', 'EnMicrosoft', 'EnLucene', 'EtMicrosoft', 'FiMicrosoft', 'FiLucene', 'FrMicrosoft', 'FrLucene', 'GlLucene', 'DeMicrosoft', 'DeLucene', 'ElMicrosoft', 'ElLucene', 'GuMicrosoft', 'HeMicrosoft', 'HiMicrosoft', 'HiLucene', 'HuMicrosoft', 'HuLucene', 'IsMicrosoft', 'IdMicrosoft', 'IdLucene', 'GaLucene', 'ItMicrosoft', 'ItLucene', 'JaMicrosoft', 'JaLucene', 'KnMicrosoft', 'KoMicrosoft', 'KoLucene', 'LvMicrosoft', 'LvLucene', 'LtMicrosoft', 'MlMicrosoft', 'MsMicrosoft', 'MrMicrosoft', 'NbMicrosoft', 'NoLucene', 'FaLucene', 'PlMicrosoft', 'PlLucene', 'PtBrMicrosoft', 'PtBrLucene', 'PtPtMicrosoft', 'PtPtLucene', 'PaMicrosoft', 'RoMicrosoft', 'RoLucene', 'RuMicrosoft', 'RuLucene', 'SrCyrillicMicrosoft', 'SrLatinMicrosoft', 'SkMicrosoft', 'SlMicrosoft', 'EsMicrosoft', 'EsLucene', 'SvMicrosoft', 'SvLucene', 'TaMicrosoft', 'TeMicrosoft', 'ThMicrosoft', 'ThLucene', 'TrMicrosoft', 'TrLucene', 'UkMicrosoft', 'UrMicrosoft', 'ViMicrosoft', 'StandardLucene', 'StandardAsciiFoldingLucene', 'Keyword', 'Pattern', 'Simple', 'Stop', 'Whitespace'."
  syntax:
    content: public AnalyzeRequest setAnalyzer(AnalyzerName analyzer)
    parameters:
    - id: analyzer
      type: com.azure.search.documents.models.AnalyzerName
      description: the analyzer value to set.
    return:
      type: com.azure.search.documents.models.AnalyzeRequest
      description: the AnalyzeRequest object itself.
- uid: com.azure.search.documents.models.AnalyzeRequest.setCharFilters(java.util.List<com.azure.search.documents.models.CharFilterName>)
  id: setCharFilters(java.util.List<com.azure.search.documents.models.CharFilterName>)
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models.AnalyzeRequest
  langs:
  - java
  name: setCharFilters(List<CharFilterName> charFilters)
  nameWithType: AnalyzeRequest.setCharFilters(List<CharFilterName> charFilters)
  fullName: com.azure.search.documents.models.AnalyzeRequest.setCharFilters(List<CharFilterName> charFilters)
  overload: com.azure.search.documents.models.AnalyzeRequest.setCharFilters*
  type: Method
  package: com.azure.search.documents.models
  summary: 'Set the charFilters property: An optional list of character filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter.'
  syntax:
    content: public AnalyzeRequest setCharFilters(List<CharFilterName> charFilters)
    parameters:
    - id: charFilters
      type: java.util.List<com.azure.search.documents.models.CharFilterName>
      description: the charFilters value to set.
    return:
      type: com.azure.search.documents.models.AnalyzeRequest
      description: the AnalyzeRequest object itself.
- uid: com.azure.search.documents.models.AnalyzeRequest.setText(java.lang.String)
  id: setText(java.lang.String)
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models.AnalyzeRequest
  langs:
  - java
  name: setText(String text)
  nameWithType: AnalyzeRequest.setText(String text)
  fullName: com.azure.search.documents.models.AnalyzeRequest.setText(String text)
  overload: com.azure.search.documents.models.AnalyzeRequest.setText*
  type: Method
  package: com.azure.search.documents.models
  summary: 'Set the text property: The text to break into tokens.'
  syntax:
    content: public AnalyzeRequest setText(String text)
    parameters:
    - id: text
      type: java.lang.String
      description: the text value to set.
    return:
      type: com.azure.search.documents.models.AnalyzeRequest
      description: the AnalyzeRequest object itself.
- uid: com.azure.search.documents.models.AnalyzeRequest.setTokenFilters(java.util.List<com.azure.search.documents.models.TokenFilterName>)
  id: setTokenFilters(java.util.List<com.azure.search.documents.models.TokenFilterName>)
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models.AnalyzeRequest
  langs:
  - java
  name: setTokenFilters(List<TokenFilterName> tokenFilters)
  nameWithType: AnalyzeRequest.setTokenFilters(List<TokenFilterName> tokenFilters)
  fullName: com.azure.search.documents.models.AnalyzeRequest.setTokenFilters(List<TokenFilterName> tokenFilters)
  overload: com.azure.search.documents.models.AnalyzeRequest.setTokenFilters*
  type: Method
  package: com.azure.search.documents.models
  summary: 'Set the tokenFilters property: An optional list of token filters to use when breaking the given text. This parameter can only be set when using the tokenizer parameter.'
  syntax:
    content: public AnalyzeRequest setTokenFilters(List<TokenFilterName> tokenFilters)
    parameters:
    - id: tokenFilters
      type: java.util.List<com.azure.search.documents.models.TokenFilterName>
      description: the tokenFilters value to set.
    return:
      type: com.azure.search.documents.models.AnalyzeRequest
      description: the AnalyzeRequest object itself.
- uid: com.azure.search.documents.models.AnalyzeRequest.setTokenizer(com.azure.search.documents.models.TokenizerName)
  id: setTokenizer(com.azure.search.documents.models.TokenizerName)
  artifact: com.azure:azure-search-documents:1.0.0-beta.3
  parent: com.azure.search.documents.models.AnalyzeRequest
  langs:
  - java
  name: setTokenizer(TokenizerName tokenizer)
  nameWithType: AnalyzeRequest.setTokenizer(TokenizerName tokenizer)
  fullName: com.azure.search.documents.models.AnalyzeRequest.setTokenizer(TokenizerName tokenizer)
  overload: com.azure.search.documents.models.AnalyzeRequest.setTokenizer*
  type: Method
  package: com.azure.search.documents.models
  summary: "Set the tokenizer property: The name of the tokenizer to use to break the given text. If this parameter is not specified, you must specify an analyzer instead. The tokenizer and analyzer parameters are mutually exclusive. Possible values include: 'Classic', 'EdgeNGram', 'Keyword', 'Letter', 'Lowercase', 'MicrosoftLanguageTokenizer', 'MicrosoftLanguageStemmingTokenizer', 'NGram', 'PathHierarchy', 'Pattern', 'Standard', 'UaxUrlEmail', 'Whitespace'."
  syntax:
    content: public AnalyzeRequest setTokenizer(TokenizerName tokenizer)
    parameters:
    - id: tokenizer
      type: com.azure.search.documents.models.TokenizerName
      description: the tokenizer value to set.
    return:
      type: com.azure.search.documents.models.AnalyzeRequest
      description: the AnalyzeRequest object itself.
references:
- uid: com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest*
  name: AnalyzeRequest
  nameWithType: AnalyzeRequest.AnalyzeRequest
  fullName: com.azure.search.documents.models.AnalyzeRequest.AnalyzeRequest
  package: com.azure.search.documents.models
- uid: java.lang.String
  spec.java:
  - uid: java.lang.String
    name: String
    fullName: java.lang.String
- uid: com.azure.search.documents.models.AnalyzeRequest.getText*
  name: getText
  nameWithType: AnalyzeRequest.getText
  fullName: com.azure.search.documents.models.AnalyzeRequest.getText
  package: com.azure.search.documents.models
- uid: com.azure.search.documents.models.AnalyzeRequest.setText*
  name: setText
  nameWithType: AnalyzeRequest.setText
  fullName: com.azure.search.documents.models.AnalyzeRequest.setText
  package: com.azure.search.documents.models
- uid: com.azure.search.documents.models.AnalyzerName
  name: AnalyzerName
  nameWithType: AnalyzerName
  fullName: com.azure.search.documents.models.AnalyzerName
- uid: com.azure.search.documents.models.AnalyzeRequest.getAnalyzer*
  name: getAnalyzer
  nameWithType: AnalyzeRequest.getAnalyzer
  fullName: com.azure.search.documents.models.AnalyzeRequest.getAnalyzer
  package: com.azure.search.documents.models
- uid: com.azure.search.documents.models.AnalyzeRequest.setAnalyzer*
  name: setAnalyzer
  nameWithType: AnalyzeRequest.setAnalyzer
  fullName: com.azure.search.documents.models.AnalyzeRequest.setAnalyzer
  package: com.azure.search.documents.models
- uid: com.azure.search.documents.models.TokenizerName
  name: TokenizerName
  nameWithType: TokenizerName
  fullName: com.azure.search.documents.models.TokenizerName
- uid: com.azure.search.documents.models.AnalyzeRequest.getTokenizer*
  name: getTokenizer
  nameWithType: AnalyzeRequest.getTokenizer
  fullName: com.azure.search.documents.models.AnalyzeRequest.getTokenizer
  package: com.azure.search.documents.models
- uid: com.azure.search.documents.models.AnalyzeRequest.setTokenizer*
  name: setTokenizer
  nameWithType: AnalyzeRequest.setTokenizer
  fullName: com.azure.search.documents.models.AnalyzeRequest.setTokenizer
  package: com.azure.search.documents.models
- uid: java.util.List<com.azure.search.documents.models.TokenFilterName>
  spec.java:
  - uid: java.util.List
    name: List
    fullName: java.util.List
  - name: <
    fullName: <
  - uid: com.azure.search.documents.models.TokenFilterName
    name: TokenFilterName
    fullName: com.azure.search.documents.models.TokenFilterName
  - name: '>'
    fullName: '>'
- uid: com.azure.search.documents.models.AnalyzeRequest.getTokenFilters*
  name: getTokenFilters
  nameWithType: AnalyzeRequest.getTokenFilters
  fullName: com.azure.search.documents.models.AnalyzeRequest.getTokenFilters
  package: com.azure.search.documents.models
- uid: com.azure.search.documents.models.AnalyzeRequest.setTokenFilters*
  name: setTokenFilters
  nameWithType: AnalyzeRequest.setTokenFilters
  fullName: com.azure.search.documents.models.AnalyzeRequest.setTokenFilters
  package: com.azure.search.documents.models
- uid: java.util.List<com.azure.search.documents.models.CharFilterName>
  spec.java:
  - uid: java.util.List
    name: List
    fullName: java.util.List
  - name: <
    fullName: <
  - uid: com.azure.search.documents.models.CharFilterName
    name: CharFilterName
    fullName: com.azure.search.documents.models.CharFilterName
  - name: '>'
    fullName: '>'
- uid: com.azure.search.documents.models.AnalyzeRequest.getCharFilters*
  name: getCharFilters
  nameWithType: AnalyzeRequest.getCharFilters
  fullName: com.azure.search.documents.models.AnalyzeRequest.getCharFilters
  package: com.azure.search.documents.models
- uid: com.azure.search.documents.models.AnalyzeRequest.setCharFilters*
  name: setCharFilters
  nameWithType: AnalyzeRequest.setCharFilters
  fullName: com.azure.search.documents.models.AnalyzeRequest.setCharFilters
  package: com.azure.search.documents.models
- uid: java.lang.Object.notify()
  name: Object.notify()
  nameWithType: Object.notify()
  fullName: java.lang.Object.notify()
- uid: java.lang.Object.wait()
  name: Object.wait()
  nameWithType: Object.wait()
  fullName: java.lang.Object.wait()
- uid: java.lang.Object.finalize()
  name: Object.finalize()
  nameWithType: Object.finalize()
  fullName: java.lang.Object.finalize()
- uid: java.lang.Object.clone()
  name: Object.clone()
  nameWithType: Object.clone()
  fullName: java.lang.Object.clone()
- uid: java.lang.Object.notifyAll()
  name: Object.notifyAll()
  nameWithType: Object.notifyAll()
  fullName: java.lang.Object.notifyAll()
- uid: java.lang.Object.equals(java.lang.Object)
  name: Object.equals(Object)
  nameWithType: Object.equals(Object)
  fullName: java.lang.Object.equals(java.lang.Object)
- uid: java.lang.Object.getClass()
  name: Object.getClass()
  nameWithType: Object.getClass()
  fullName: java.lang.Object.getClass()
- uid: java.lang.Object.wait(long)
  name: Object.wait(long)
  nameWithType: Object.wait(long)
  fullName: java.lang.Object.wait(long)
- uid: java.lang.Object.hashCode()
  name: Object.hashCode()
  nameWithType: Object.hashCode()
  fullName: java.lang.Object.hashCode()
- uid: java.lang.Object.wait(long,int)
  name: Object.wait(long,int)
  nameWithType: Object.wait(long,int)
  fullName: java.lang.Object.wait(long,int)
- uid: java.lang.Object.toString()
  name: Object.toString()
  nameWithType: Object.toString()
  fullName: java.lang.Object.toString()
- uid: com.azure.search.documents.models.TokenFilterName
  name: TokenFilterName
  nameWithType: TokenFilterName
  fullName: com.azure.search.documents.models.TokenFilterName
- uid: java.util.List
  name: List
  nameWithType: List
  fullName: java.util.List
- uid: com.azure.search.documents.models.CharFilterName
  name: CharFilterName
  nameWithType: CharFilterName
  fullName: com.azure.search.documents.models.CharFilterName
