### YamlMime:JavaMember
uid: "com.azure.resourcemanager.machinelearning.models.InferenceContainerProperties.withScoringRoute*"
fullName: "com.azure.resourcemanager.machinelearning.models.InferenceContainerProperties.withScoringRoute"
name: "withScoringRoute"
nameWithType: "InferenceContainerProperties.withScoringRoute"
members:
- uid: "com.azure.resourcemanager.machinelearning.models.InferenceContainerProperties.withScoringRoute(com.azure.resourcemanager.machinelearning.models.Route)"
  fullName: "com.azure.resourcemanager.machinelearning.models.InferenceContainerProperties.withScoringRoute(Route scoringRoute)"
  name: "withScoringRoute(Route scoringRoute)"
  nameWithType: "InferenceContainerProperties.withScoringRoute(Route scoringRoute)"
  summary: "Set the scoringRoute property: The port to send the scoring requests to, within the inference server container."
  parameters:
  - description: "the scoringRoute value to set."
    name: "scoringRoute"
    type: "<xref href=\"com.azure.resourcemanager.machinelearning.models.Route?alt=com.azure.resourcemanager.machinelearning.models.Route&text=Route\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public InferenceContainerProperties withScoringRoute(Route scoringRoute)"
  desc: "Set the scoringRoute property: The port to send the scoring requests to, within the inference server container."
  returns:
    description: "the InferenceContainerProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.machinelearning.models.InferenceContainerProperties?alt=com.azure.resourcemanager.machinelearning.models.InferenceContainerProperties&text=InferenceContainerProperties\" data-throw-if-not-resolved=\"False\" />"
type: "method"
metadata: {}
package: "com.azure.resourcemanager.machinelearning.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-machinelearning:1.0.0-beta.2
