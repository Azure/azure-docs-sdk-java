### YamlMime:JavaMember
uid: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponse*"
fullName: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponse"
name: "analyzeReceiptAsyncWithResponse"
nameWithType: "FormRecognizerClientImpl.analyzeReceiptAsyncWithResponse"
members:
- uid: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponse(com.azure.ai.formrecognizer.implementation.models.ContentType,reactor.core.publisher.Flux<java.nio.ByteBuffer>,long,java.lang.Boolean,com.azure.ai.formrecognizer.implementation.models.Locale,java.util.List<java.lang.String>,com.azure.core.util.Context)"
  fullName: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponse(ContentType contentType, Flux<ByteBuffer> fileStream, long contentLength, Boolean includeTextDetails, Locale locale, List<String> pages, Context context)"
  name: "analyzeReceiptAsyncWithResponse(ContentType contentType, Flux<ByteBuffer> fileStream, long contentLength, Boolean includeTextDetails, Locale locale, List<String> pages, Context context)"
  nameWithType: "FormRecognizerClientImpl.analyzeReceiptAsyncWithResponse(ContentType contentType, Flux<ByteBuffer> fileStream, long contentLength, Boolean includeTextDetails, Locale locale, List<String> pages, Context context)"
  summary: "Extract field text and semantic values from a given receipt document. The input document must be of one of the supported content types - 'application/pdf', 'image/jpeg', 'image/png', 'image/tiff' or 'image/bmp'. Alternatively, use 'application/json' type to specify the location (Uri) of the document to be analyzed."
  parameters:
  - description: "Upload file type."
    name: "contentType"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.ContentType?alt=com.azure.ai.formrecognizer.implementation.models.ContentType&text=ContentType\" data-throw-if-not-resolved=\"False\" />"
  - description: ".json, .pdf, .jpg, .png, .tiff or .bmp type file stream."
    name: "fileStream"
    type: "<xref href=\"reactor.core.publisher.Flux?alt=reactor.core.publisher.Flux&text=Flux\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.nio.ByteBuffer?alt=java.nio.ByteBuffer&text=ByteBuffer\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "The contentLength parameter."
    name: "contentLength"
    type: "<xref href=\"long?alt=long&text=long\" data-throw-if-not-resolved=\"False\" />"
  - description: "Include text lines and element references in the result."
    name: "includeTextDetails"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "Locale of the input document. Supported locales include: en-AU, en-CA, en-GB, en-IN,\n     en-US(default)."
    name: "locale"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.Locale?alt=com.azure.ai.formrecognizer.implementation.models.Locale&text=Locale\" data-throw-if-not-resolved=\"False\" />"
  - description: "Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to\n     get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma."
    name: "pages"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<Void> analyzeReceiptAsyncWithResponse(ContentType contentType, Flux<ByteBuffer> fileStream, long contentLength, Boolean includeTextDetails, Locale locale, List<String> pages, Context context)"
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponse(java.lang.Boolean,com.azure.ai.formrecognizer.implementation.models.Locale,java.util.List<java.lang.String>,com.azure.ai.formrecognizer.implementation.models.SourcePath,com.azure.core.util.Context)"
  fullName: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponse(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream, Context context)"
  name: "analyzeReceiptAsyncWithResponse(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream, Context context)"
  nameWithType: "FormRecognizerClientImpl.analyzeReceiptAsyncWithResponse(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream, Context context)"
  summary: "Extract field text and semantic values from a given receipt document. The input document must be of one of the supported content types - 'application/pdf', 'image/jpeg', 'image/png', 'image/tiff' or 'image/bmp'. Alternatively, use 'application/json' type to specify the location (Uri) of the document to be analyzed."
  parameters:
  - description: "Include text lines and element references in the result."
    name: "includeTextDetails"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "Locale of the input document. Supported locales include: en-AU, en-CA, en-GB, en-IN,\n     en-US(default)."
    name: "locale"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.Locale?alt=com.azure.ai.formrecognizer.implementation.models.Locale&text=Locale\" data-throw-if-not-resolved=\"False\" />"
  - description: "Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to\n     get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma."
    name: "pages"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: ".json, .pdf, .jpg, .png, .tiff or .bmp type file stream."
    name: "fileStream"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.SourcePath?alt=com.azure.ai.formrecognizer.implementation.models.SourcePath&text=SourcePath\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<Void> analyzeReceiptAsyncWithResponse(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream, Context context)"
  returns:
    description: "the response."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
type: "method"
metadata: {}
package: "com.azure.ai.formrecognizer.implementation"
artifact: com.azure:azure-ai-formrecognizer:3.1.0-beta.3
