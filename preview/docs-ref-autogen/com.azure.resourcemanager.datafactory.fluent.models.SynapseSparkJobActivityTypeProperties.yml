### YamlMime:JavaType
uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties"
fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties"
name: "SynapseSparkJobActivityTypeProperties"
nameWithType: "SynapseSparkJobActivityTypeProperties"
summary: "Execute spark job activity properties."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class SynapseSparkJobActivityTypeProperties"
constructors:
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.SynapseSparkJobActivityTypeProperties()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.SynapseSparkJobActivityTypeProperties()"
  name: "SynapseSparkJobActivityTypeProperties()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.SynapseSparkJobActivityTypeProperties()"
  syntax: "public SynapseSparkJobActivityTypeProperties()"
methods:
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.arguments()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.arguments()"
  name: "arguments()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.arguments()"
  summary: "Get the arguments property: User specified arguments to Synapse<wbr>Spark<wbr>Job<wbr>Definition<wbr>Activity."
  syntax: "public List<Object> arguments()"
  desc: "Get the arguments property: User specified arguments to SynapseSparkJobDefinitionActivity."
  returns:
    description: "the arguments value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.className()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.className()"
  name: "className()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.className()"
  summary: "Get the class<wbr>Name property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'class<wbr>Name' of the spark job definition you provide."
  syntax: "public Object className()"
  desc: "Get the className property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'className' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the className value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.conf()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.conf()"
  name: "conf()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.conf()"
  summary: "Get the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  syntax: "public Object conf()"
  desc: "Get the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  returns:
    description: "the conf value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.driverSize()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.driverSize()"
  name: "driverSize()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.driverSize()"
  summary: "Get the driver<wbr>Size property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driver<wbr>Cores' and 'driver<wbr>Memory' of the spark job definition you provide."
  syntax: "public Object driverSize()"
  desc: "Get the driverSize property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driverCores' and 'driverMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the driverSize value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.executorSize()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.executorSize()"
  name: "executorSize()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.executorSize()"
  summary: "Get the executor<wbr>Size property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executor<wbr>Cores' and 'executor<wbr>Memory' of the spark job definition you provide."
  syntax: "public Object executorSize()"
  desc: "Get the executorSize property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executorCores' and 'executorMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the executorSize value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.file()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.file()"
  name: "file()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.file()"
  summary: "Get the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide."
  syntax: "public Object file()"
  desc: "Get the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the file value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.files()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.files()"
  name: "files()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.files()"
  summary: "Get the files property: Additional files used for reference in the main definition file, which will override the 'files' of the spark job definition you provide."
  syntax: "public List<Object> files()"
  desc: "Get the files property: Additional files used for reference in the main definition file, which will override the 'files' of the spark job definition you provide."
  returns:
    description: "the files value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.numExecutors()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.numExecutors()"
  name: "numExecutors()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.numExecutors()"
  summary: "Get the num<wbr>Executors property: Number of executors to launch for this job, which will override the 'num<wbr>Executors' of the spark job definition you provide."
  syntax: "public Integer numExecutors()"
  desc: "Get the numExecutors property: Number of executors to launch for this job, which will override the 'numExecutors' of the spark job definition you provide."
  returns:
    description: "the numExecutors value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Integer.html\">Integer</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.sparkJob()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.sparkJob()"
  name: "sparkJob()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.sparkJob()"
  summary: "Get the spark<wbr>Job property: Synapse spark job reference."
  syntax: "public SynapseSparkJobReference sparkJob()"
  desc: "Get the sparkJob property: Synapse spark job reference."
  returns:
    description: "the sparkJob value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference&text=SynapseSparkJobReference\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.targetBigDataPool()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.targetBigDataPool()"
  name: "targetBigDataPool()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.targetBigDataPool()"
  summary: "Get the target<wbr>Big<wbr>Data<wbr>Pool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'target<wbr>Big<wbr>Data<wbr>Pool' of the spark job definition you provide."
  syntax: "public BigDataPoolParametrizationReference targetBigDataPool()"
  desc: "Get the targetBigDataPool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'targetBigDataPool' of the spark job definition you provide."
  returns:
    description: "the targetBigDataPool value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference?alt=com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference&text=BigDataPoolParametrizationReference\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.validate()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.validate()"
  name: "validate()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.validate()"
  summary: "Validates the instance."
  syntax: "public void validate()"
  desc: "Validates the instance."
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withArguments(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withArguments(List<Object> arguments)"
  name: "withArguments(List<Object> arguments)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withArguments(List<Object> arguments)"
  summary: "Set the arguments property: User specified arguments to Synapse<wbr>Spark<wbr>Job<wbr>Definition<wbr>Activity."
  parameters:
  - description: "the arguments value to set."
    name: "arguments"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
  syntax: "public SynapseSparkJobActivityTypeProperties withArguments(List<Object> arguments)"
  desc: "Set the arguments property: User specified arguments to SynapseSparkJobDefinitionActivity."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withClassName(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withClassName(Object className)"
  name: "withClassName(Object className)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withClassName(Object className)"
  summary: "Set the class<wbr>Name property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'class<wbr>Name' of the spark job definition you provide."
  parameters:
  - description: "the className value to set."
    name: "className"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withClassName(Object className)"
  desc: "Set the className property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'className' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withConf(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withConf(Object conf)"
  name: "withConf(Object conf)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withConf(Object conf)"
  summary: "Set the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  parameters:
  - description: "the conf value to set."
    name: "conf"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withConf(Object conf)"
  desc: "Set the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withDriverSize(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withDriverSize(Object driverSize)"
  name: "withDriverSize(Object driverSize)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withDriverSize(Object driverSize)"
  summary: "Set the driver<wbr>Size property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driver<wbr>Cores' and 'driver<wbr>Memory' of the spark job definition you provide."
  parameters:
  - description: "the driverSize value to set."
    name: "driverSize"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withDriverSize(Object driverSize)"
  desc: "Set the driverSize property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driverCores' and 'driverMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withExecutorSize(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withExecutorSize(Object executorSize)"
  name: "withExecutorSize(Object executorSize)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withExecutorSize(Object executorSize)"
  summary: "Set the executor<wbr>Size property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executor<wbr>Cores' and 'executor<wbr>Memory' of the spark job definition you provide."
  parameters:
  - description: "the executorSize value to set."
    name: "executorSize"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withExecutorSize(Object executorSize)"
  desc: "Set the executorSize property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executorCores' and 'executorMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withFile(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withFile(Object file)"
  name: "withFile(Object file)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withFile(Object file)"
  summary: "Set the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide."
  parameters:
  - description: "the file value to set."
    name: "file"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withFile(Object file)"
  desc: "Set the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withFiles(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withFiles(List<Object> files)"
  name: "withFiles(List<Object> files)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withFiles(List<Object> files)"
  summary: "Set the files property: Additional files used for reference in the main definition file, which will override the 'files' of the spark job definition you provide."
  parameters:
  - description: "the files value to set."
    name: "files"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
  syntax: "public SynapseSparkJobActivityTypeProperties withFiles(List<Object> files)"
  desc: "Set the files property: Additional files used for reference in the main definition file, which will override the 'files' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withNumExecutors(java.lang.Integer)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withNumExecutors(Integer numExecutors)"
  name: "withNumExecutors(Integer numExecutors)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withNumExecutors(Integer numExecutors)"
  summary: "Set the num<wbr>Executors property: Number of executors to launch for this job, which will override the 'num<wbr>Executors' of the spark job definition you provide."
  parameters:
  - description: "the numExecutors value to set."
    name: "numExecutors"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Integer.html\">Integer</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withNumExecutors(Integer numExecutors)"
  desc: "Set the numExecutors property: Number of executors to launch for this job, which will override the 'numExecutors' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withSparkJob(com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withSparkJob(SynapseSparkJobReference sparkJob)"
  name: "withSparkJob(SynapseSparkJobReference sparkJob)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withSparkJob(SynapseSparkJobReference sparkJob)"
  summary: "Set the spark<wbr>Job property: Synapse spark job reference."
  parameters:
  - description: "the sparkJob value to set."
    name: "sparkJob"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference&text=SynapseSparkJobReference\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SynapseSparkJobActivityTypeProperties withSparkJob(SynapseSparkJobReference sparkJob)"
  desc: "Set the sparkJob property: Synapse spark job reference."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withTargetBigDataPool(com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  name: "withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  summary: "Set the target<wbr>Big<wbr>Data<wbr>Pool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'target<wbr>Big<wbr>Data<wbr>Pool' of the spark job definition you provide."
  parameters:
  - description: "the targetBigDataPool value to set."
    name: "targetBigDataPool"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference?alt=com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference&text=BigDataPoolParametrizationReference\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SynapseSparkJobActivityTypeProperties withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  desc: "Set the targetBigDataPool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'targetBigDataPool' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
type: "class"
desc: "Execute spark job activity properties."
metadata: {}
package: "com.azure.resourcemanager.datafactory.fluent.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.17
