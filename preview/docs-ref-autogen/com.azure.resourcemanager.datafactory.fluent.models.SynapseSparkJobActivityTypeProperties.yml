### YamlMime:JavaType
uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties"
fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties"
name: "SynapseSparkJobActivityTypeProperties"
nameWithType: "SynapseSparkJobActivityTypeProperties"
summary: "Execute spark job activity properties."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedClassMethods:
- classRef: "java.lang.<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  methodsRef:
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#clone--\">clone</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#equals-java.lang.Object-\">equals</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#finalize--\">finalize</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#getClass--\">getClass</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#hashCode--\">hashCode</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#notify--\">notify</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#notifyAll--\">notifyAll</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#toString--\">toString</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#wait--\">wait</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#wait-long-\">wait</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#wait-long-int-\">wait</a>"
syntax: "public final class **SynapseSparkJobActivityTypeProperties**</br> implements <xref href=\"com.azure.json.JsonSerializable?alt=com.azure.json.JsonSerializable&text=JsonSerializable\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />&gt;"
constructors:
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.SynapseSparkJobActivityTypeProperties()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.SynapseSparkJobActivityTypeProperties()"
  name: "SynapseSparkJobActivityTypeProperties()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.SynapseSparkJobActivityTypeProperties()"
  summary: "Creates an instance of Synapse<wbr>Spark<wbr>Job<wbr>Activity<wbr>Type<wbr>Properties class."
  syntax: "public SynapseSparkJobActivityTypeProperties()"
  desc: "Creates an instance of SynapseSparkJobActivityTypeProperties class."
methods:
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.arguments()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.arguments()"
  name: "arguments()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.arguments()"
  summary: "Get the arguments property: User specified arguments to Synapse<wbr>Spark<wbr>Job<wbr>Definition<wbr>Activity."
  syntax: "public List<Object> arguments()"
  desc: "Get the arguments property: User specified arguments to SynapseSparkJobDefinitionActivity."
  returns:
    description: "the arguments value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.className()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.className()"
  name: "className()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.className()"
  summary: "Get the class<wbr>Name property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'class<wbr>Name' of the spark job definition you provide."
  syntax: "public Object className()"
  desc: "Get the className property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'className' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the className value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.conf()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.conf()"
  name: "conf()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.conf()"
  summary: "Get the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  syntax: "public Object conf()"
  desc: "Get the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  returns:
    description: "the conf value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.configurationType()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.configurationType()"
  name: "configurationType()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.configurationType()"
  summary: "Get the configuration<wbr>Type property: The type of the spark config."
  syntax: "public ConfigurationType configurationType()"
  desc: "Get the configurationType property: The type of the spark config."
  returns:
    description: "the configurationType value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.ConfigurationType?alt=com.azure.resourcemanager.datafactory.models.ConfigurationType&text=ConfigurationType\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.driverSize()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.driverSize()"
  name: "driverSize()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.driverSize()"
  summary: "Get the driver<wbr>Size property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driver<wbr>Cores' and 'driver<wbr>Memory' of the spark job definition you provide."
  syntax: "public Object driverSize()"
  desc: "Get the driverSize property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driverCores' and 'driverMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the driverSize value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.executorSize()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.executorSize()"
  name: "executorSize()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.executorSize()"
  summary: "Get the executor<wbr>Size property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executor<wbr>Cores' and 'executor<wbr>Memory' of the spark job definition you provide."
  syntax: "public Object executorSize()"
  desc: "Get the executorSize property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executorCores' and 'executorMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the executorSize value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.file()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.file()"
  name: "file()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.file()"
  summary: "Get the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide."
  syntax: "public Object file()"
  desc: "Get the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the file value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.files()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.files()"
  name: "files()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.files()"
  summary: "Get the files property: (Deprecated."
  syntax: "public List<Object> files()"
  desc: "Get the files property: (Deprecated. Please use pythonCodeReference and filesV2) Additional files used for reference in the main definition file, which will override the 'files' of the spark job definition you provide."
  returns:
    description: "the files value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.filesV2()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.filesV2()"
  name: "filesV2()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.filesV2()"
  summary: "Get the filesV2 property: Additional files used for reference in the main definition file, which will override the 'jars' and 'files' of the spark job definition you provide."
  syntax: "public List<Object> filesV2()"
  desc: "Get the filesV2 property: Additional files used for reference in the main definition file, which will override the 'jars' and 'files' of the spark job definition you provide."
  returns:
    description: "the filesV2 value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.fromJson(com.azure.json.JsonReader)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.fromJson(JsonReader jsonReader)"
  name: "fromJson(JsonReader jsonReader)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.fromJson(JsonReader jsonReader)"
  summary: "Reads an instance of Synapse<wbr>Spark<wbr>Job<wbr>Activity<wbr>Type<wbr>Properties from the Json<wbr>Reader."
  modifiers:
  - "static"
  parameters:
  - description: "The JsonReader being read."
    name: "jsonReader"
    type: "<xref href=\"com.azure.json.JsonReader?alt=com.azure.json.JsonReader&text=JsonReader\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public static SynapseSparkJobActivityTypeProperties fromJson(JsonReader jsonReader)"
  exceptions:
  - description: "If the deserialized JSON object was missing any required properties."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/io/IOException.html\">IOException</a>"
  desc: "Reads an instance of SynapseSparkJobActivityTypeProperties from the JsonReader."
  returns:
    description: "An instance of SynapseSparkJobActivityTypeProperties if the JsonReader was pointing to an instance of it,\n or null if it was pointing to JSON null."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.numExecutors()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.numExecutors()"
  name: "numExecutors()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.numExecutors()"
  summary: "Get the num<wbr>Executors property: Number of executors to launch for this job, which will override the 'num<wbr>Executors' of the spark job definition you provide."
  syntax: "public Object numExecutors()"
  desc: "Get the numExecutors property: Number of executors to launch for this job, which will override the 'numExecutors' of the spark job definition you provide. Type: integer (or Expression with resultType integer)."
  returns:
    description: "the numExecutors value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.pythonCodeReference()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.pythonCodeReference()"
  name: "pythonCodeReference()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.pythonCodeReference()"
  summary: "Get the python<wbr>Code<wbr>Reference property: Additional python code files used for reference in the main definition file, which will override the 'py<wbr>Files' of the spark job definition you provide."
  syntax: "public List<Object> pythonCodeReference()"
  desc: "Get the pythonCodeReference property: Additional python code files used for reference in the main definition file, which will override the 'pyFiles' of the spark job definition you provide."
  returns:
    description: "the pythonCodeReference value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.scanFolder()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.scanFolder()"
  name: "scanFolder()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.scanFolder()"
  summary: "Get the scan<wbr>Folder property: Scanning subfolders from the root folder of the main definition file, these files will be added as reference files."
  syntax: "public Object scanFolder()"
  desc: "Get the scanFolder property: Scanning subfolders from the root folder of the main definition file, these files will be added as reference files. The folders named 'jars', 'pyFiles', 'files' or 'archives' will be scanned, and the folders name are case sensitive. Type: boolean (or Expression with resultType boolean)."
  returns:
    description: "the scanFolder value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.sparkConfig()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.sparkConfig()"
  name: "sparkConfig()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.sparkConfig()"
  summary: "Get the spark<wbr>Config property: Spark configuration property."
  syntax: "public Map<String,Object> sparkConfig()"
  desc: "Get the sparkConfig property: Spark configuration property."
  returns:
    description: "the sparkConfig value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/Map.html\">Map</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>,<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.sparkJob()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.sparkJob()"
  name: "sparkJob()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.sparkJob()"
  summary: "Get the spark<wbr>Job property: Synapse spark job reference."
  syntax: "public SynapseSparkJobReference sparkJob()"
  desc: "Get the sparkJob property: Synapse spark job reference."
  returns:
    description: "the sparkJob value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference&text=SynapseSparkJobReference\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.targetBigDataPool()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.targetBigDataPool()"
  name: "targetBigDataPool()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.targetBigDataPool()"
  summary: "Get the target<wbr>Big<wbr>Data<wbr>Pool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'target<wbr>Big<wbr>Data<wbr>Pool' of the spark job definition you provide."
  syntax: "public BigDataPoolParametrizationReference targetBigDataPool()"
  desc: "Get the targetBigDataPool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'targetBigDataPool' of the spark job definition you provide."
  returns:
    description: "the targetBigDataPool value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference?alt=com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference&text=BigDataPoolParametrizationReference\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.targetSparkConfiguration()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.targetSparkConfiguration()"
  name: "targetSparkConfiguration()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.targetSparkConfiguration()"
  summary: "Get the target<wbr>Spark<wbr>Configuration property: The spark configuration of the spark job."
  syntax: "public SparkConfigurationParametrizationReference targetSparkConfiguration()"
  desc: "Get the targetSparkConfiguration property: The spark configuration of the spark job."
  returns:
    description: "the targetSparkConfiguration value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkConfigurationParametrizationReference?alt=com.azure.resourcemanager.datafactory.models.SparkConfigurationParametrizationReference&text=SparkConfigurationParametrizationReference\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.toJson(com.azure.json.JsonWriter)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.toJson(JsonWriter jsonWriter)"
  name: "toJson(JsonWriter jsonWriter)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.toJson(JsonWriter jsonWriter)"
  parameters:
  - name: "jsonWriter"
    type: "<xref href=\"com.azure.json.JsonWriter?alt=com.azure.json.JsonWriter&text=JsonWriter\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public JsonWriter toJson(JsonWriter jsonWriter)"
  exceptions:
  - type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/io/IOException.html\">IOException</a>"
  returns:
    type: "<xref href=\"com.azure.json.JsonWriter?alt=com.azure.json.JsonWriter&text=JsonWriter\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.validate()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.validate()"
  name: "validate()"
  nameWithType: "SynapseSparkJobActivityTypeProperties.validate()"
  summary: "Validates the instance."
  syntax: "public void validate()"
  desc: "Validates the instance."
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withArguments(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withArguments(List<Object> arguments)"
  name: "withArguments(List<Object> arguments)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withArguments(List<Object> arguments)"
  summary: "Set the arguments property: User specified arguments to Synapse<wbr>Spark<wbr>Job<wbr>Definition<wbr>Activity."
  parameters:
  - description: "the arguments value to set."
    name: "arguments"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
  syntax: "public SynapseSparkJobActivityTypeProperties withArguments(List<Object> arguments)"
  desc: "Set the arguments property: User specified arguments to SynapseSparkJobDefinitionActivity."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withClassName(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withClassName(Object className)"
  name: "withClassName(Object className)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withClassName(Object className)"
  summary: "Set the class<wbr>Name property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'class<wbr>Name' of the spark job definition you provide."
  parameters:
  - description: "the className value to set."
    name: "className"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withClassName(Object className)"
  desc: "Set the className property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'className' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withConf(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withConf(Object conf)"
  name: "withConf(Object conf)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withConf(Object conf)"
  summary: "Set the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  parameters:
  - description: "the conf value to set."
    name: "conf"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withConf(Object conf)"
  desc: "Set the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withConfigurationType(com.azure.resourcemanager.datafactory.models.ConfigurationType)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withConfigurationType(ConfigurationType configurationType)"
  name: "withConfigurationType(ConfigurationType configurationType)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withConfigurationType(ConfigurationType configurationType)"
  summary: "Set the configuration<wbr>Type property: The type of the spark config."
  parameters:
  - description: "the configurationType value to set."
    name: "configurationType"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.ConfigurationType?alt=com.azure.resourcemanager.datafactory.models.ConfigurationType&text=ConfigurationType\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SynapseSparkJobActivityTypeProperties withConfigurationType(ConfigurationType configurationType)"
  desc: "Set the configurationType property: The type of the spark config."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withDriverSize(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withDriverSize(Object driverSize)"
  name: "withDriverSize(Object driverSize)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withDriverSize(Object driverSize)"
  summary: "Set the driver<wbr>Size property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driver<wbr>Cores' and 'driver<wbr>Memory' of the spark job definition you provide."
  parameters:
  - description: "the driverSize value to set."
    name: "driverSize"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withDriverSize(Object driverSize)"
  desc: "Set the driverSize property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driverCores' and 'driverMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withExecutorSize(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withExecutorSize(Object executorSize)"
  name: "withExecutorSize(Object executorSize)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withExecutorSize(Object executorSize)"
  summary: "Set the executor<wbr>Size property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executor<wbr>Cores' and 'executor<wbr>Memory' of the spark job definition you provide."
  parameters:
  - description: "the executorSize value to set."
    name: "executorSize"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withExecutorSize(Object executorSize)"
  desc: "Set the executorSize property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executorCores' and 'executorMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withFile(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withFile(Object file)"
  name: "withFile(Object file)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withFile(Object file)"
  summary: "Set the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide."
  parameters:
  - description: "the file value to set."
    name: "file"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withFile(Object file)"
  desc: "Set the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withFiles(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withFiles(List<Object> files)"
  name: "withFiles(List<Object> files)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withFiles(List<Object> files)"
  summary: "Set the files property: (Deprecated."
  parameters:
  - description: "the files value to set."
    name: "files"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
  syntax: "public SynapseSparkJobActivityTypeProperties withFiles(List<Object> files)"
  desc: "Set the files property: (Deprecated. Please use pythonCodeReference and filesV2) Additional files used for reference in the main definition file, which will override the 'files' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withFilesV2(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withFilesV2(List<Object> filesV2)"
  name: "withFilesV2(List<Object> filesV2)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withFilesV2(List<Object> filesV2)"
  summary: "Set the filesV2 property: Additional files used for reference in the main definition file, which will override the 'jars' and 'files' of the spark job definition you provide."
  parameters:
  - description: "the filesV2 value to set."
    name: "filesV2"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
  syntax: "public SynapseSparkJobActivityTypeProperties withFilesV2(List<Object> filesV2)"
  desc: "Set the filesV2 property: Additional files used for reference in the main definition file, which will override the 'jars' and 'files' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withNumExecutors(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withNumExecutors(Object numExecutors)"
  name: "withNumExecutors(Object numExecutors)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withNumExecutors(Object numExecutors)"
  summary: "Set the num<wbr>Executors property: Number of executors to launch for this job, which will override the 'num<wbr>Executors' of the spark job definition you provide."
  parameters:
  - description: "the numExecutors value to set."
    name: "numExecutors"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withNumExecutors(Object numExecutors)"
  desc: "Set the numExecutors property: Number of executors to launch for this job, which will override the 'numExecutors' of the spark job definition you provide. Type: integer (or Expression with resultType integer)."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withPythonCodeReference(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withPythonCodeReference(List<Object> pythonCodeReference)"
  name: "withPythonCodeReference(List<Object> pythonCodeReference)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withPythonCodeReference(List<Object> pythonCodeReference)"
  summary: "Set the python<wbr>Code<wbr>Reference property: Additional python code files used for reference in the main definition file, which will override the 'py<wbr>Files' of the spark job definition you provide."
  parameters:
  - description: "the pythonCodeReference value to set."
    name: "pythonCodeReference"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
  syntax: "public SynapseSparkJobActivityTypeProperties withPythonCodeReference(List<Object> pythonCodeReference)"
  desc: "Set the pythonCodeReference property: Additional python code files used for reference in the main definition file, which will override the 'pyFiles' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withScanFolder(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withScanFolder(Object scanFolder)"
  name: "withScanFolder(Object scanFolder)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withScanFolder(Object scanFolder)"
  summary: "Set the scan<wbr>Folder property: Scanning subfolders from the root folder of the main definition file, these files will be added as reference files."
  parameters:
  - description: "the scanFolder value to set."
    name: "scanFolder"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobActivityTypeProperties withScanFolder(Object scanFolder)"
  desc: "Set the scanFolder property: Scanning subfolders from the root folder of the main definition file, these files will be added as reference files. The folders named 'jars', 'pyFiles', 'files' or 'archives' will be scanned, and the folders name are case sensitive. Type: boolean (or Expression with resultType boolean)."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withSparkConfig(java.util.Map<java.lang.String,java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withSparkConfig(Map<String,Object> sparkConfig)"
  name: "withSparkConfig(Map<String,Object> sparkConfig)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withSparkConfig(Map<String,Object> sparkConfig)"
  summary: "Set the spark<wbr>Config property: Spark configuration property."
  parameters:
  - description: "the sparkConfig value to set."
    name: "sparkConfig"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/Map.html\">Map</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>,<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
  syntax: "public SynapseSparkJobActivityTypeProperties withSparkConfig(Map<String,Object> sparkConfig)"
  desc: "Set the sparkConfig property: Spark configuration property."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withSparkJob(com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withSparkJob(SynapseSparkJobReference sparkJob)"
  name: "withSparkJob(SynapseSparkJobReference sparkJob)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withSparkJob(SynapseSparkJobReference sparkJob)"
  summary: "Set the spark<wbr>Job property: Synapse spark job reference."
  parameters:
  - description: "the sparkJob value to set."
    name: "sparkJob"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference&text=SynapseSparkJobReference\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SynapseSparkJobActivityTypeProperties withSparkJob(SynapseSparkJobReference sparkJob)"
  desc: "Set the sparkJob property: Synapse spark job reference."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withTargetBigDataPool(com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  name: "withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  summary: "Set the target<wbr>Big<wbr>Data<wbr>Pool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'target<wbr>Big<wbr>Data<wbr>Pool' of the spark job definition you provide."
  parameters:
  - description: "the targetBigDataPool value to set."
    name: "targetBigDataPool"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference?alt=com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference&text=BigDataPoolParametrizationReference\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SynapseSparkJobActivityTypeProperties withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  desc: "Set the targetBigDataPool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'targetBigDataPool' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withTargetSparkConfiguration(com.azure.resourcemanager.datafactory.models.SparkConfigurationParametrizationReference)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties.withTargetSparkConfiguration(SparkConfigurationParametrizationReference targetSparkConfiguration)"
  name: "withTargetSparkConfiguration(SparkConfigurationParametrizationReference targetSparkConfiguration)"
  nameWithType: "SynapseSparkJobActivityTypeProperties.withTargetSparkConfiguration(SparkConfigurationParametrizationReference targetSparkConfiguration)"
  summary: "Set the target<wbr>Spark<wbr>Configuration property: The spark configuration of the spark job."
  parameters:
  - description: "the targetSparkConfiguration value to set."
    name: "targetSparkConfiguration"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkConfigurationParametrizationReference?alt=com.azure.resourcemanager.datafactory.models.SparkConfigurationParametrizationReference&text=SparkConfigurationParametrizationReference\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SynapseSparkJobActivityTypeProperties withTargetSparkConfiguration(SparkConfigurationParametrizationReference targetSparkConfiguration)"
  desc: "Set the targetSparkConfiguration property: The spark configuration of the spark job."
  returns:
    description: "the SynapseSparkJobActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
type: "class"
desc: "Execute spark job activity properties."
implements:
- "<xref href=\"com.azure.json.JsonSerializable?alt=com.azure.json.JsonSerializable&text=JsonSerializable\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SynapseSparkJobActivityTypeProperties&text=SynapseSparkJobActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />&gt;"
metadata: {}
package: "com.azure.resourcemanager.datafactory.fluent.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.30
