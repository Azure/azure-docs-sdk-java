### YamlMime:JavaMember
uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withParameters*"
fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withParameters"
name: "withParameters"
nameWithType: "DatabricksSparkPythonActivity.withParameters"
members:
- uid: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withParameters(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity.withParameters(List<Object> parameters)"
  name: "withParameters(List<Object> parameters)"
  nameWithType: "DatabricksSparkPythonActivity.withParameters(List<Object> parameters)"
  summary: "Set the parameters property: Command line parameters that will be passed to the Python file."
  parameters:
  - description: "the parameters value to set."
    name: "parameters"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public DatabricksSparkPythonActivity withParameters(List<Object> parameters)"
  returns:
    description: "the DatabricksSparkPythonActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity?alt=com.azure.resourcemanager.datafactory.models.DatabricksSparkPythonActivity&text=DatabricksSparkPythonActivity\" data-throw-if-not-resolved=\"False\" />"
type: "method"
metadata: {}
package: "com.azure.resourcemanager.datafactory.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.1
