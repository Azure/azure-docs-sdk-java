### YamlMime:JavaMember
uid: "com.azure.resourcemanager.datafactory.models.AzureDatabricksLinkedService.newClusterSparkEnvVars*"
fullName: "com.azure.resourcemanager.datafactory.models.AzureDatabricksLinkedService.newClusterSparkEnvVars"
name: "newClusterSparkEnvVars"
nameWithType: "AzureDatabricksLinkedService.newClusterSparkEnvVars"
members:
- uid: "com.azure.resourcemanager.datafactory.models.AzureDatabricksLinkedService.newClusterSparkEnvVars()"
  fullName: "com.azure.resourcemanager.datafactory.models.AzureDatabricksLinkedService.newClusterSparkEnvVars()"
  name: "newClusterSparkEnvVars()"
  nameWithType: "AzureDatabricksLinkedService.newClusterSparkEnvVars()"
  summary: "Get the newClusterSparkEnvVars property: A set of optional, user-specified Spark environment variables key-value pairs."
  syntax: "public Map<String,Object> newClusterSparkEnvVars()"
  returns:
    description: "the newClusterSparkEnvVars value."
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;"
type: "method"
metadata: {}
package: "com.azure.resourcemanager.datafactory.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.10
