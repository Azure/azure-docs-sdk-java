### YamlMime:JavaMember
uid: "com.azure.storage.file.datalake.DataLakeFileClient.upload*"
fullName: "com.azure.storage.file.datalake.DataLakeFileClient.upload"
name: "upload"
nameWithType: "DataLakeFileClient.upload"
members:
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.upload(java.io.InputStream,long)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.upload(InputStream data, long length)"
  name: "upload(InputStream data, long length)"
  nameWithType: "DataLakeFileClient.upload(InputStream data, long length)"
  summary: "Creates a new file. By default this method will not overwrite an existing file.\n\n**Code Samples**\n\n```java\ntry {\n     client.upload(data, length);\n     System.out.println(\"Upload from file succeeded\");\n } catch (UncheckedIOException ex) {\n     System.err.printf(\"Failed to upload from file %s%n\", ex.getMessage());\n }\n```"
  parameters:
  - description: "The data to write to the blob. The data must be markable. This is in order to support retries. If\n the data is not markable, consider wrapping your data source in a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"java.io.BufferedInputStream\"></xref> to add mark\n support."
    name: "data"
    type: "<xref href=\"java.io.InputStream?alt=java.io.InputStream&text=InputStream\" data-throw-if-not-resolved=\"False\" />"
  - description: "The exact length of the data. It is important that this value match precisely the length of the\n data provided in the <xref uid=\"java.io.InputStream\" data-throw-if-not-resolved=\"false\" data-raw-source=\"InputStream\"></xref>."
    name: "length"
    type: "<xref href=\"long?alt=long&text=long\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public PathInfo upload(InputStream data, long length)"
  returns:
    description: "Information about the uploaded path."
    type: "<xref href=\"com.azure.storage.file.datalake.models.PathInfo?alt=com.azure.storage.file.datalake.models.PathInfo&text=PathInfo\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.upload(java.io.InputStream,long,boolean)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.upload(InputStream data, long length, boolean overwrite)"
  name: "upload(InputStream data, long length, boolean overwrite)"
  nameWithType: "DataLakeFileClient.upload(InputStream data, long length, boolean overwrite)"
  summary: "Creates a new file, or updates the content of an existing file.\n\n**Code Samples**\n\n```java\ntry {\n     boolean overwrite = false;\n     client.upload(data, length, overwrite);\n     System.out.println(\"Upload from file succeeded\");\n } catch (UncheckedIOException ex) {\n     System.err.printf(\"Failed to upload from file %s%n\", ex.getMessage());\n }\n```"
  parameters:
  - description: "The data to write to the blob. The data must be markable. This is in order to support retries. If\n the data is not markable, consider wrapping your data source in a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"java.io.BufferedInputStream\"></xref> to add mark\n support."
    name: "data"
    type: "<xref href=\"java.io.InputStream?alt=java.io.InputStream&text=InputStream\" data-throw-if-not-resolved=\"False\" />"
  - description: "The exact length of the data. It is important that this value match precisely the length of the\n data provided in the <xref uid=\"java.io.InputStream\" data-throw-if-not-resolved=\"false\" data-raw-source=\"InputStream\"></xref>."
    name: "length"
    type: "<xref href=\"long?alt=long&text=long\" data-throw-if-not-resolved=\"False\" />"
  - description: "Whether or not to overwrite, should data exist on the bfilelob."
    name: "overwrite"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public PathInfo upload(InputStream data, long length, boolean overwrite)"
  returns:
    description: "Information about the uploaded path."
    type: "<xref href=\"com.azure.storage.file.datalake.models.PathInfo?alt=com.azure.storage.file.datalake.models.PathInfo&text=PathInfo\" data-throw-if-not-resolved=\"False\" />"
type: "method"
metadata: {}
package: "com.azure.storage.file.datalake"
artifact: com.azure:azure-storage-file-datalake:12.3.0-beta.1
