### YamlMime:JavaMember
uid: "com.azure.storage.file.datalake.options.FileParallelUploadOptions.FileParallelUploadOptions*"
fullName: "com.azure.storage.file.datalake.options.FileParallelUploadOptions.FileParallelUploadOptions"
name: "FileParallelUploadOptions"
nameWithType: "FileParallelUploadOptions.FileParallelUploadOptions"
members:
- uid: "com.azure.storage.file.datalake.options.FileParallelUploadOptions.FileParallelUploadOptions(java.io.InputStream,long)"
  fullName: "com.azure.storage.file.datalake.options.FileParallelUploadOptions.FileParallelUploadOptions(InputStream dataStream, long length)"
  name: "FileParallelUploadOptions(InputStream dataStream, long length)"
  nameWithType: "FileParallelUploadOptions.FileParallelUploadOptions(InputStream dataStream, long length)"
  summary: "Constructs a new `FileParallelUploadOptions`."
  parameters:
  - description: "The data to write to the blob. The data must be markable. This is in order to support retries.\n If the data is not markable, consider wrapping your data source in a <xref uid=\"\" data-throw-if-not-resolved=\"false\">java.io.BufferedInputStream</xref> to add\n mark support."
    name: "dataStream"
    type: "<xref href=\"java.io.InputStream?alt=java.io.InputStream&text=InputStream\" data-throw-if-not-resolved=\"False\" />"
  - description: "The exact length of the data. It is important that this value match precisely the length of the\n data provided in the <xref uid=\"java.io.InputStream\" data-throw-if-not-resolved=\"false\">InputStream</xref>."
    name: "length"
    type: "<xref href=\"long?alt=long&text=long\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public FileParallelUploadOptions(InputStream dataStream, long length)"
- uid: "com.azure.storage.file.datalake.options.FileParallelUploadOptions.FileParallelUploadOptions(reactor.core.publisher.Flux<java.nio.ByteBuffer>)"
  fullName: "com.azure.storage.file.datalake.options.FileParallelUploadOptions.FileParallelUploadOptions(Flux<ByteBuffer> dataFlux)"
  name: "FileParallelUploadOptions(Flux<ByteBuffer> dataFlux)"
  nameWithType: "FileParallelUploadOptions.FileParallelUploadOptions(Flux<ByteBuffer> dataFlux)"
  summary: "Constructs a new `FileParallelUploadOptions`."
  parameters:
  - description: "The data to write to the file. Unlike other upload methods, this method does not require that\n the <code>Flux</code> be replayable. In other words, it does not have to support multiple subscribers and is not\n expected to produce the same values across subscriptions."
    name: "dataFlux"
    type: "<xref href=\"reactor.core.publisher.Flux?alt=reactor.core.publisher.Flux&text=Flux\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.nio.ByteBuffer?alt=java.nio.ByteBuffer&text=ByteBuffer\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public FileParallelUploadOptions(Flux<ByteBuffer> dataFlux)"
type: "constructor"
metadata: {}
package: "com.azure.storage.file.datalake.options"
artifact: com.azure:azure-storage-file-datalake:12.3.0-beta.1
