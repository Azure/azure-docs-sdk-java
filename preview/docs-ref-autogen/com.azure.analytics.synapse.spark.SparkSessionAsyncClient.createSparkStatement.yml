### YamlMime:JavaMember
uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkStatement*"
fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkStatement"
name: "createSparkStatement"
nameWithType: "SparkSessionAsyncClient.createSparkStatement"
members:
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkStatement(int,com.azure.analytics.synapse.spark.models.SparkStatementOptions)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  name: "createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  nameWithType: "SparkSessionAsyncClient.createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  summary: "Create statement within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Livy compatible batch job request payload."
    name: "sparkStatementOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementOptions?alt=com.azure.analytics.synapse.spark.models.SparkStatementOptions&text=SparkStatementOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkStatement> createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatement?alt=com.azure.analytics.synapse.spark.models.SparkStatement&text=SparkStatement\" data-throw-if-not-resolved=\"False\" />&gt;"
type: "method"
metadata: {}
package: "com.azure.analytics.synapse.spark"
artifact: com.azure:azure-analytics-synapse-spark:1.0.0-beta.5
