### YamlMime:JavaType
uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity"
fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity"
name: "SynapseSparkJobDefinitionActivity"
nameWithType: "SynapseSparkJobDefinitionActivity"
summary: "Execute spark job activity."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
- "<xref href=\"com.azure.resourcemanager.datafactory.models.Activity?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
- "<xref href=\"com.azure.resourcemanager.datafactory.models.ExecutionActivity?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "com.azure.resourcemanager.datafactory.models.Activity.additionalProperties()"
- "com.azure.resourcemanager.datafactory.models.Activity.dependsOn()"
- "com.azure.resourcemanager.datafactory.models.Activity.description()"
- "com.azure.resourcemanager.datafactory.models.Activity.name()"
- "com.azure.resourcemanager.datafactory.models.Activity.userProperties()"
- "com.azure.resourcemanager.datafactory.models.Activity.withAdditionalProperties(java.util.Map<java.lang.String,java.lang.Object>)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.linkedServiceName()"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.policy()"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.validate()"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withDependsOn(java.util.List<com.azure.resourcemanager.datafactory.models.ActivityDependency>)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withDescription(java.lang.String)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withLinkedServiceName(com.azure.resourcemanager.datafactory.models.LinkedServiceReference)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withName(java.lang.String)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withPolicy(com.azure.resourcemanager.datafactory.models.ActivityPolicy)"
- "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withUserProperties(java.util.List<com.azure.resourcemanager.datafactory.models.UserProperty>)"
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class SynapseSparkJobDefinitionActivity extends ExecutionActivity"
constructors:
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.SynapseSparkJobDefinitionActivity()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.SynapseSparkJobDefinitionActivity()"
  name: "SynapseSparkJobDefinitionActivity()"
  nameWithType: "SynapseSparkJobDefinitionActivity.SynapseSparkJobDefinitionActivity()"
  syntax: "public SynapseSparkJobDefinitionActivity()"
methods:
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.arguments()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.arguments()"
  name: "arguments()"
  nameWithType: "SynapseSparkJobDefinitionActivity.arguments()"
  summary: "Get the arguments property: User specified arguments to Synapse<wbr>Spark<wbr>Job<wbr>Definition<wbr>Activity."
  syntax: "public List<Object> arguments()"
  desc: "Get the arguments property: User specified arguments to SynapseSparkJobDefinitionActivity."
  returns:
    description: "the arguments value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.className()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.className()"
  name: "className()"
  nameWithType: "SynapseSparkJobDefinitionActivity.className()"
  summary: "Get the class<wbr>Name property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'class<wbr>Name' of the spark job definition you provide."
  syntax: "public Object className()"
  desc: "Get the className property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'className' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the className value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.conf()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.conf()"
  name: "conf()"
  nameWithType: "SynapseSparkJobDefinitionActivity.conf()"
  summary: "Get the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  syntax: "public Object conf()"
  desc: "Get the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  returns:
    description: "the conf value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.driverSize()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.driverSize()"
  name: "driverSize()"
  nameWithType: "SynapseSparkJobDefinitionActivity.driverSize()"
  summary: "Get the driver<wbr>Size property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driver<wbr>Cores' and 'driver<wbr>Memory' of the spark job definition you provide."
  syntax: "public Object driverSize()"
  desc: "Get the driverSize property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driverCores' and 'driverMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the driverSize value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.executorSize()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.executorSize()"
  name: "executorSize()"
  nameWithType: "SynapseSparkJobDefinitionActivity.executorSize()"
  summary: "Get the executor<wbr>Size property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executor<wbr>Cores' and 'executor<wbr>Memory' of the spark job definition you provide."
  syntax: "public Object executorSize()"
  desc: "Get the executorSize property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executorCores' and 'executorMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the executorSize value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.file()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.file()"
  name: "file()"
  nameWithType: "SynapseSparkJobDefinitionActivity.file()"
  summary: "Get the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide."
  syntax: "public Object file()"
  desc: "Get the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the file value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.files()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.files()"
  name: "files()"
  nameWithType: "SynapseSparkJobDefinitionActivity.files()"
  summary: "Get the files property: Additional files used for reference in the main definition file, which will override the 'files' of the spark job definition you provide."
  syntax: "public List<Object> files()"
  desc: "Get the files property: Additional files used for reference in the main definition file, which will override the 'files' of the spark job definition you provide."
  returns:
    description: "the files value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.numExecutors()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.numExecutors()"
  name: "numExecutors()"
  nameWithType: "SynapseSparkJobDefinitionActivity.numExecutors()"
  summary: "Get the num<wbr>Executors property: Number of executors to launch for this job, which will override the 'num<wbr>Executors' of the spark job definition you provide."
  syntax: "public Integer numExecutors()"
  desc: "Get the numExecutors property: Number of executors to launch for this job, which will override the 'numExecutors' of the spark job definition you provide."
  returns:
    description: "the numExecutors value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Integer.html\">Integer</a>"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.sparkJob()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.sparkJob()"
  name: "sparkJob()"
  nameWithType: "SynapseSparkJobDefinitionActivity.sparkJob()"
  summary: "Get the spark<wbr>Job property: Synapse spark job reference."
  syntax: "public SynapseSparkJobReference sparkJob()"
  desc: "Get the sparkJob property: Synapse spark job reference."
  returns:
    description: "the sparkJob value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference&text=SynapseSparkJobReference\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.targetBigDataPool()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.targetBigDataPool()"
  name: "targetBigDataPool()"
  nameWithType: "SynapseSparkJobDefinitionActivity.targetBigDataPool()"
  summary: "Get the target<wbr>Big<wbr>Data<wbr>Pool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'target<wbr>Big<wbr>Data<wbr>Pool' of the spark job definition you provide."
  syntax: "public BigDataPoolParametrizationReference targetBigDataPool()"
  desc: "Get the targetBigDataPool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'targetBigDataPool' of the spark job definition you provide."
  returns:
    description: "the targetBigDataPool value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference?alt=com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference&text=BigDataPoolParametrizationReference\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.validate()"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.validate()"
  name: "validate()"
  nameWithType: "SynapseSparkJobDefinitionActivity.validate()"
  summary: "Validates the instance."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.validate()"
  syntax: "public void validate()"
  desc: "Validates the instance."
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withArguments(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withArguments(List<Object> arguments)"
  name: "withArguments(List<Object> arguments)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withArguments(List<Object> arguments)"
  summary: "Set the arguments property: User specified arguments to Synapse<wbr>Spark<wbr>Job<wbr>Definition<wbr>Activity."
  parameters:
  - description: "the arguments value to set."
    name: "arguments"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
  syntax: "public SynapseSparkJobDefinitionActivity withArguments(List<Object> arguments)"
  desc: "Set the arguments property: User specified arguments to SynapseSparkJobDefinitionActivity."
  returns:
    description: "the SynapseSparkJobDefinitionActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withClassName(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withClassName(Object className)"
  name: "withClassName(Object className)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withClassName(Object className)"
  summary: "Set the class<wbr>Name property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'class<wbr>Name' of the spark job definition you provide."
  parameters:
  - description: "the className value to set."
    name: "className"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobDefinitionActivity withClassName(Object className)"
  desc: "Set the className property: The fully-qualified identifier or the main class that is in the main definition file, which will override the 'className' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobDefinitionActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withConf(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withConf(Object conf)"
  name: "withConf(Object conf)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withConf(Object conf)"
  summary: "Set the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  parameters:
  - description: "the conf value to set."
    name: "conf"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobDefinitionActivity withConf(Object conf)"
  desc: "Set the conf property: Spark configuration properties, which will override the 'conf' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobDefinitionActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withDependsOn(java.util.List<com.azure.resourcemanager.datafactory.models.ActivityDependency>)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withDependsOn(List<ActivityDependency> dependsOn)"
  name: "withDependsOn(List<ActivityDependency> dependsOn)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withDependsOn(List<ActivityDependency> dependsOn)"
  summary: "Set the depends<wbr>On property: Activity depends on condition."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withDependsOn(java.util.List<com.azure.resourcemanager.datafactory.models.ActivityDependency>)"
  parameters:
  - name: "dependsOn"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.resourcemanager.datafactory.models.ActivityDependency?alt=com.azure.resourcemanager.datafactory.models.ActivityDependency&text=ActivityDependency\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public SynapseSparkJobDefinitionActivity withDependsOn(List<ActivityDependency> dependsOn)"
  desc: "Set the dependsOn property: Activity depends on condition."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withDescription(java.lang.String)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withDescription(String description)"
  name: "withDescription(String description)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withDescription(String description)"
  summary: "Set the description property: Activity description."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withDescription(java.lang.String)"
  parameters:
  - name: "description"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>"
  syntax: "public SynapseSparkJobDefinitionActivity withDescription(String description)"
  desc: "Set the description property: Activity description."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withDriverSize(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withDriverSize(Object driverSize)"
  name: "withDriverSize(Object driverSize)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withDriverSize(Object driverSize)"
  summary: "Set the driver<wbr>Size property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driver<wbr>Cores' and 'driver<wbr>Memory' of the spark job definition you provide."
  parameters:
  - description: "the driverSize value to set."
    name: "driverSize"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobDefinitionActivity withDriverSize(Object driverSize)"
  desc: "Set the driverSize property: Number of core and memory to be used for driver allocated in the specified Spark pool for the job, which will be used for overriding 'driverCores' and 'driverMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobDefinitionActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withExecutorSize(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withExecutorSize(Object executorSize)"
  name: "withExecutorSize(Object executorSize)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withExecutorSize(Object executorSize)"
  summary: "Set the executor<wbr>Size property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executor<wbr>Cores' and 'executor<wbr>Memory' of the spark job definition you provide."
  parameters:
  - description: "the executorSize value to set."
    name: "executorSize"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobDefinitionActivity withExecutorSize(Object executorSize)"
  desc: "Set the executorSize property: Number of core and memory to be used for executors allocated in the specified Spark pool for the job, which will be used for overriding 'executorCores' and 'executorMemory' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobDefinitionActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withFile(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withFile(Object file)"
  name: "withFile(Object file)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withFile(Object file)"
  summary: "Set the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide."
  parameters:
  - description: "the file value to set."
    name: "file"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  syntax: "public SynapseSparkJobDefinitionActivity withFile(Object file)"
  desc: "Set the file property: The main file used for the job, which will override the 'file' of the spark job definition you provide. Type: string (or Expression with resultType string)."
  returns:
    description: "the SynapseSparkJobDefinitionActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withFiles(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withFiles(List<Object> files)"
  name: "withFiles(List<Object> files)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withFiles(List<Object> files)"
  summary: "Set the files property: Additional files used for reference in the main definition file, which will override the 'files' of the spark job definition you provide."
  parameters:
  - description: "the files value to set."
    name: "files"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>&gt;"
  syntax: "public SynapseSparkJobDefinitionActivity withFiles(List<Object> files)"
  desc: "Set the files property: Additional files used for reference in the main definition file, which will override the 'files' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobDefinitionActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withLinkedServiceName(com.azure.resourcemanager.datafactory.models.LinkedServiceReference)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withLinkedServiceName(LinkedServiceReference linkedServiceName)"
  name: "withLinkedServiceName(LinkedServiceReference linkedServiceName)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withLinkedServiceName(LinkedServiceReference linkedServiceName)"
  summary: "Set the linked<wbr>Service<wbr>Name property: Linked service reference."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withLinkedServiceName(com.azure.resourcemanager.datafactory.models.LinkedServiceReference)"
  parameters:
  - name: "linkedServiceName"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.LinkedServiceReference?alt=com.azure.resourcemanager.datafactory.models.LinkedServiceReference&text=LinkedServiceReference\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SynapseSparkJobDefinitionActivity withLinkedServiceName(LinkedServiceReference linkedServiceName)"
  desc: "Set the linkedServiceName property: Linked service reference."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withName(java.lang.String)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withName(String name)"
  name: "withName(String name)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withName(String name)"
  summary: "Set the name property: Activity name."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withName(java.lang.String)"
  parameters:
  - name: "name"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>"
  syntax: "public SynapseSparkJobDefinitionActivity withName(String name)"
  desc: "Set the name property: Activity name."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withNumExecutors(java.lang.Integer)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withNumExecutors(Integer numExecutors)"
  name: "withNumExecutors(Integer numExecutors)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withNumExecutors(Integer numExecutors)"
  summary: "Set the num<wbr>Executors property: Number of executors to launch for this job, which will override the 'num<wbr>Executors' of the spark job definition you provide."
  parameters:
  - description: "the numExecutors value to set."
    name: "numExecutors"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Integer.html\">Integer</a>"
  syntax: "public SynapseSparkJobDefinitionActivity withNumExecutors(Integer numExecutors)"
  desc: "Set the numExecutors property: Number of executors to launch for this job, which will override the 'numExecutors' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobDefinitionActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withPolicy(com.azure.resourcemanager.datafactory.models.ActivityPolicy)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withPolicy(ActivityPolicy policy)"
  name: "withPolicy(ActivityPolicy policy)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withPolicy(ActivityPolicy policy)"
  summary: "Set the policy property: Activity policy."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withPolicy(com.azure.resourcemanager.datafactory.models.ActivityPolicy)"
  parameters:
  - name: "policy"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.ActivityPolicy?alt=com.azure.resourcemanager.datafactory.models.ActivityPolicy&text=ActivityPolicy\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SynapseSparkJobDefinitionActivity withPolicy(ActivityPolicy policy)"
  desc: "Set the policy property: Activity policy."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withSparkJob(com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withSparkJob(SynapseSparkJobReference sparkJob)"
  name: "withSparkJob(SynapseSparkJobReference sparkJob)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withSparkJob(SynapseSparkJobReference sparkJob)"
  summary: "Set the spark<wbr>Job property: Synapse spark job reference."
  parameters:
  - description: "the sparkJob value to set."
    name: "sparkJob"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobReference&text=SynapseSparkJobReference\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SynapseSparkJobDefinitionActivity withSparkJob(SynapseSparkJobReference sparkJob)"
  desc: "Set the sparkJob property: Synapse spark job reference."
  returns:
    description: "the SynapseSparkJobDefinitionActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withTargetBigDataPool(com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  name: "withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  summary: "Set the target<wbr>Big<wbr>Data<wbr>Pool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'target<wbr>Big<wbr>Data<wbr>Pool' of the spark job definition you provide."
  parameters:
  - description: "the targetBigDataPool value to set."
    name: "targetBigDataPool"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference?alt=com.azure.resourcemanager.datafactory.models.BigDataPoolParametrizationReference&text=BigDataPoolParametrizationReference\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SynapseSparkJobDefinitionActivity withTargetBigDataPool(BigDataPoolParametrizationReference targetBigDataPool)"
  desc: "Set the targetBigDataPool property: The name of the big data pool which will be used to execute the spark batch job, which will override the 'targetBigDataPool' of the spark job definition you provide."
  returns:
    description: "the SynapseSparkJobDefinitionActivity object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withUserProperties(java.util.List<com.azure.resourcemanager.datafactory.models.UserProperty>)"
  fullName: "com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity.withUserProperties(List<UserProperty> userProperties)"
  name: "withUserProperties(List<UserProperty> userProperties)"
  nameWithType: "SynapseSparkJobDefinitionActivity.withUserProperties(List<UserProperty> userProperties)"
  summary: "Set the user<wbr>Properties property: Activity user properties."
  overridden: "com.azure.resourcemanager.datafactory.models.ExecutionActivity.withUserProperties(java.util.List<com.azure.resourcemanager.datafactory.models.UserProperty>)"
  parameters:
  - name: "userProperties"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.resourcemanager.datafactory.models.UserProperty?alt=com.azure.resourcemanager.datafactory.models.UserProperty&text=UserProperty\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public SynapseSparkJobDefinitionActivity withUserProperties(List<UserProperty> userProperties)"
  desc: "Set the userProperties property: Activity user properties."
  returns:
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity?alt=com.azure.resourcemanager.datafactory.models.SynapseSparkJobDefinitionActivity&text=SynapseSparkJobDefinitionActivity\" data-throw-if-not-resolved=\"False\" />"
type: "class"
desc: "Execute spark job activity."
metadata: {}
package: "com.azure.resourcemanager.datafactory.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.17
