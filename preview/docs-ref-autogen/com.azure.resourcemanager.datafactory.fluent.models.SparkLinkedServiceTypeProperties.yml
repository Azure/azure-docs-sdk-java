### YamlMime:JavaType
uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties"
fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties"
name: "SparkLinkedServiceTypeProperties"
nameWithType: "SparkLinkedServiceTypeProperties"
summary: "Spark Server linked service properties."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class SparkLinkedServiceTypeProperties"
constructors:
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.SparkLinkedServiceTypeProperties()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.SparkLinkedServiceTypeProperties()"
  name: "SparkLinkedServiceTypeProperties()"
  nameWithType: "SparkLinkedServiceTypeProperties.SparkLinkedServiceTypeProperties()"
  syntax: "public SparkLinkedServiceTypeProperties()"
methods:
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.allowHostnameCNMismatch()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.allowHostnameCNMismatch()"
  name: "allowHostnameCNMismatch()"
  nameWithType: "SparkLinkedServiceTypeProperties.allowHostnameCNMismatch()"
  summary: "Get the allowHostnameCNMismatch property: Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL. The default value is false."
  syntax: "public Object allowHostnameCNMismatch()"
  returns:
    description: "the allowHostnameCNMismatch value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.allowSelfSignedServerCert()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.allowSelfSignedServerCert()"
  name: "allowSelfSignedServerCert()"
  nameWithType: "SparkLinkedServiceTypeProperties.allowSelfSignedServerCert()"
  summary: "Get the allowSelfSignedServerCert property: Specifies whether to allow self-signed certificates from the server. The default value is false."
  syntax: "public Object allowSelfSignedServerCert()"
  returns:
    description: "the allowSelfSignedServerCert value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.authenticationType()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.authenticationType()"
  name: "authenticationType()"
  nameWithType: "SparkLinkedServiceTypeProperties.authenticationType()"
  summary: "Get the authenticationType property: The authentication method used to access the Spark server."
  syntax: "public SparkAuthenticationType authenticationType()"
  returns:
    description: "the authenticationType value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkAuthenticationType?alt=com.azure.resourcemanager.datafactory.models.SparkAuthenticationType&text=SparkAuthenticationType\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.enableSsl()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.enableSsl()"
  name: "enableSsl()"
  nameWithType: "SparkLinkedServiceTypeProperties.enableSsl()"
  summary: "Get the enableSsl property: Specifies whether the connections to the server are encrypted using SSL. The default value is false."
  syntax: "public Object enableSsl()"
  returns:
    description: "the enableSsl value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.encryptedCredential()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.encryptedCredential()"
  name: "encryptedCredential()"
  nameWithType: "SparkLinkedServiceTypeProperties.encryptedCredential()"
  summary: "Get the encryptedCredential property: The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string)."
  syntax: "public Object encryptedCredential()"
  returns:
    description: "the encryptedCredential value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.host()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.host()"
  name: "host()"
  nameWithType: "SparkLinkedServiceTypeProperties.host()"
  summary: "Get the host property: IP address or host name of the Spark server."
  syntax: "public Object host()"
  returns:
    description: "the host value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.httpPath()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.httpPath()"
  name: "httpPath()"
  nameWithType: "SparkLinkedServiceTypeProperties.httpPath()"
  summary: "Get the httpPath property: The partial URL corresponding to the Spark server."
  syntax: "public Object httpPath()"
  returns:
    description: "the httpPath value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.password()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.password()"
  name: "password()"
  nameWithType: "SparkLinkedServiceTypeProperties.password()"
  summary: "Get the password property: The password corresponding to the user name that you provided in the Username field."
  syntax: "public SecretBase password()"
  returns:
    description: "the password value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SecretBase?alt=com.azure.resourcemanager.datafactory.models.SecretBase&text=SecretBase\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.port()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.port()"
  name: "port()"
  nameWithType: "SparkLinkedServiceTypeProperties.port()"
  summary: "Get the port property: The TCP port that the Spark server uses to listen for client connections."
  syntax: "public Object port()"
  returns:
    description: "the port value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.serverType()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.serverType()"
  name: "serverType()"
  nameWithType: "SparkLinkedServiceTypeProperties.serverType()"
  summary: "Get the serverType property: The type of Spark server."
  syntax: "public SparkServerType serverType()"
  returns:
    description: "the serverType value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkServerType?alt=com.azure.resourcemanager.datafactory.models.SparkServerType&text=SparkServerType\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.thriftTransportProtocol()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.thriftTransportProtocol()"
  name: "thriftTransportProtocol()"
  nameWithType: "SparkLinkedServiceTypeProperties.thriftTransportProtocol()"
  summary: "Get the thriftTransportProtocol property: The transport protocol to use in the Thrift layer."
  syntax: "public SparkThriftTransportProtocol thriftTransportProtocol()"
  returns:
    description: "the thriftTransportProtocol value."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkThriftTransportProtocol?alt=com.azure.resourcemanager.datafactory.models.SparkThriftTransportProtocol&text=SparkThriftTransportProtocol\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.trustedCertPath()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.trustedCertPath()"
  name: "trustedCertPath()"
  nameWithType: "SparkLinkedServiceTypeProperties.trustedCertPath()"
  summary: "Get the trustedCertPath property: The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR."
  syntax: "public Object trustedCertPath()"
  returns:
    description: "the trustedCertPath value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.useSystemTrustStore()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.useSystemTrustStore()"
  name: "useSystemTrustStore()"
  nameWithType: "SparkLinkedServiceTypeProperties.useSystemTrustStore()"
  summary: "Get the useSystemTrustStore property: Specifies whether to use a CA certificate from the system trust store or from a specified PEM file. The default value is false."
  syntax: "public Object useSystemTrustStore()"
  returns:
    description: "the useSystemTrustStore value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.username()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.username()"
  name: "username()"
  nameWithType: "SparkLinkedServiceTypeProperties.username()"
  summary: "Get the username property: The user name that you use to access Spark Server."
  syntax: "public Object username()"
  returns:
    description: "the username value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.validate()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.validate()"
  name: "validate()"
  nameWithType: "SparkLinkedServiceTypeProperties.validate()"
  summary: "Validates the instance."
  syntax: "public void validate()"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withAllowHostnameCNMismatch(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withAllowHostnameCNMismatch(Object allowHostnameCNMismatch)"
  name: "withAllowHostnameCNMismatch(Object allowHostnameCNMismatch)"
  nameWithType: "SparkLinkedServiceTypeProperties.withAllowHostnameCNMismatch(Object allowHostnameCNMismatch)"
  summary: "Set the allowHostnameCNMismatch property: Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL. The default value is false."
  parameters:
  - description: "the allowHostnameCNMismatch value to set."
    name: "allowHostnameCNMismatch"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withAllowHostnameCNMismatch(Object allowHostnameCNMismatch)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withAllowSelfSignedServerCert(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withAllowSelfSignedServerCert(Object allowSelfSignedServerCert)"
  name: "withAllowSelfSignedServerCert(Object allowSelfSignedServerCert)"
  nameWithType: "SparkLinkedServiceTypeProperties.withAllowSelfSignedServerCert(Object allowSelfSignedServerCert)"
  summary: "Set the allowSelfSignedServerCert property: Specifies whether to allow self-signed certificates from the server. The default value is false."
  parameters:
  - description: "the allowSelfSignedServerCert value to set."
    name: "allowSelfSignedServerCert"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withAllowSelfSignedServerCert(Object allowSelfSignedServerCert)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withAuthenticationType(com.azure.resourcemanager.datafactory.models.SparkAuthenticationType)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withAuthenticationType(SparkAuthenticationType authenticationType)"
  name: "withAuthenticationType(SparkAuthenticationType authenticationType)"
  nameWithType: "SparkLinkedServiceTypeProperties.withAuthenticationType(SparkAuthenticationType authenticationType)"
  summary: "Set the authenticationType property: The authentication method used to access the Spark server."
  parameters:
  - description: "the authenticationType value to set."
    name: "authenticationType"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkAuthenticationType?alt=com.azure.resourcemanager.datafactory.models.SparkAuthenticationType&text=SparkAuthenticationType\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withAuthenticationType(SparkAuthenticationType authenticationType)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withEnableSsl(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withEnableSsl(Object enableSsl)"
  name: "withEnableSsl(Object enableSsl)"
  nameWithType: "SparkLinkedServiceTypeProperties.withEnableSsl(Object enableSsl)"
  summary: "Set the enableSsl property: Specifies whether the connections to the server are encrypted using SSL. The default value is false."
  parameters:
  - description: "the enableSsl value to set."
    name: "enableSsl"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withEnableSsl(Object enableSsl)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withEncryptedCredential(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withEncryptedCredential(Object encryptedCredential)"
  name: "withEncryptedCredential(Object encryptedCredential)"
  nameWithType: "SparkLinkedServiceTypeProperties.withEncryptedCredential(Object encryptedCredential)"
  summary: "Set the encryptedCredential property: The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string)."
  parameters:
  - description: "the encryptedCredential value to set."
    name: "encryptedCredential"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withEncryptedCredential(Object encryptedCredential)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withHost(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withHost(Object host)"
  name: "withHost(Object host)"
  nameWithType: "SparkLinkedServiceTypeProperties.withHost(Object host)"
  summary: "Set the host property: IP address or host name of the Spark server."
  parameters:
  - description: "the host value to set."
    name: "host"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withHost(Object host)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withHttpPath(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withHttpPath(Object httpPath)"
  name: "withHttpPath(Object httpPath)"
  nameWithType: "SparkLinkedServiceTypeProperties.withHttpPath(Object httpPath)"
  summary: "Set the httpPath property: The partial URL corresponding to the Spark server."
  parameters:
  - description: "the httpPath value to set."
    name: "httpPath"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withHttpPath(Object httpPath)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withPassword(com.azure.resourcemanager.datafactory.models.SecretBase)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withPassword(SecretBase password)"
  name: "withPassword(SecretBase password)"
  nameWithType: "SparkLinkedServiceTypeProperties.withPassword(SecretBase password)"
  summary: "Set the password property: The password corresponding to the user name that you provided in the Username field."
  parameters:
  - description: "the password value to set."
    name: "password"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SecretBase?alt=com.azure.resourcemanager.datafactory.models.SecretBase&text=SecretBase\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withPassword(SecretBase password)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withPort(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withPort(Object port)"
  name: "withPort(Object port)"
  nameWithType: "SparkLinkedServiceTypeProperties.withPort(Object port)"
  summary: "Set the port property: The TCP port that the Spark server uses to listen for client connections."
  parameters:
  - description: "the port value to set."
    name: "port"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withPort(Object port)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withServerType(com.azure.resourcemanager.datafactory.models.SparkServerType)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withServerType(SparkServerType serverType)"
  name: "withServerType(SparkServerType serverType)"
  nameWithType: "SparkLinkedServiceTypeProperties.withServerType(SparkServerType serverType)"
  summary: "Set the serverType property: The type of Spark server."
  parameters:
  - description: "the serverType value to set."
    name: "serverType"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkServerType?alt=com.azure.resourcemanager.datafactory.models.SparkServerType&text=SparkServerType\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withServerType(SparkServerType serverType)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withThriftTransportProtocol(com.azure.resourcemanager.datafactory.models.SparkThriftTransportProtocol)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withThriftTransportProtocol(SparkThriftTransportProtocol thriftTransportProtocol)"
  name: "withThriftTransportProtocol(SparkThriftTransportProtocol thriftTransportProtocol)"
  nameWithType: "SparkLinkedServiceTypeProperties.withThriftTransportProtocol(SparkThriftTransportProtocol thriftTransportProtocol)"
  summary: "Set the thriftTransportProtocol property: The transport protocol to use in the Thrift layer."
  parameters:
  - description: "the thriftTransportProtocol value to set."
    name: "thriftTransportProtocol"
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.SparkThriftTransportProtocol?alt=com.azure.resourcemanager.datafactory.models.SparkThriftTransportProtocol&text=SparkThriftTransportProtocol\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withThriftTransportProtocol(SparkThriftTransportProtocol thriftTransportProtocol)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withTrustedCertPath(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withTrustedCertPath(Object trustedCertPath)"
  name: "withTrustedCertPath(Object trustedCertPath)"
  nameWithType: "SparkLinkedServiceTypeProperties.withTrustedCertPath(Object trustedCertPath)"
  summary: "Set the trustedCertPath property: The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR."
  parameters:
  - description: "the trustedCertPath value to set."
    name: "trustedCertPath"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withTrustedCertPath(Object trustedCertPath)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withUseSystemTrustStore(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withUseSystemTrustStore(Object useSystemTrustStore)"
  name: "withUseSystemTrustStore(Object useSystemTrustStore)"
  nameWithType: "SparkLinkedServiceTypeProperties.withUseSystemTrustStore(Object useSystemTrustStore)"
  summary: "Set the useSystemTrustStore property: Specifies whether to use a CA certificate from the system trust store or from a specified PEM file. The default value is false."
  parameters:
  - description: "the useSystemTrustStore value to set."
    name: "useSystemTrustStore"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withUseSystemTrustStore(Object useSystemTrustStore)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withUsername(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties.withUsername(Object username)"
  name: "withUsername(Object username)"
  nameWithType: "SparkLinkedServiceTypeProperties.withUsername(Object username)"
  summary: "Set the username property: The user name that you use to access Spark Server."
  parameters:
  - description: "the username value to set."
    name: "username"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public SparkLinkedServiceTypeProperties withUsername(Object username)"
  returns:
    description: "the SparkLinkedServiceTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.SparkLinkedServiceTypeProperties&text=SparkLinkedServiceTypeProperties\" data-throw-if-not-resolved=\"False\" />"
type: "class"
metadata: {}
package: "com.azure.resourcemanager.datafactory.fluent.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.16
