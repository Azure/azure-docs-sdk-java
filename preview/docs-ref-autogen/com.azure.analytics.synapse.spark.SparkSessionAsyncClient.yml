### YamlMime:JavaType
uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient"
fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient"
name: "SparkSessionAsyncClient"
nameWithType: "SparkSessionAsyncClient"
summary: "Initializes a new instance of the asynchronous Spark<wbr>Client type."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class SparkSessionAsyncClient"
methods:
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.cancelSparkSession(int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.cancelSparkSession(int sessionId)"
  name: "cancelSparkSession(int sessionId)"
  nameWithType: "SparkSessionAsyncClient.cancelSparkSession(int sessionId)"
  summary: "Cancels a running spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Void> cancelSparkSession(int sessionId)"
  desc: "Cancels a running spark session."
  returns:
    description: "the completion."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.cancelSparkSessionWithResponse(int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.cancelSparkSessionWithResponse(int sessionId)"
  name: "cancelSparkSessionWithResponse(int sessionId)"
  nameWithType: "SparkSessionAsyncClient.cancelSparkSessionWithResponse(int sessionId)"
  summary: "Cancels a running spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<Void>> cancelSparkSessionWithResponse(int sessionId)"
  desc: "Cancels a running spark session."
  returns:
    description: "the completion."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.cancelSparkStatement(int,int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.cancelSparkStatement(int sessionId, int statementId)"
  name: "cancelSparkStatement(int sessionId, int statementId)"
  nameWithType: "SparkSessionAsyncClient.cancelSparkStatement(int sessionId, int statementId)"
  summary: "Kill a statement within a session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Identifier for the statement."
    name: "statementId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkStatementCancellationResult> cancelSparkStatement(int sessionId, int statementId)"
  desc: "Kill a statement within a session."
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementCancellationResult?alt=com.azure.analytics.synapse.spark.models.SparkStatementCancellationResult&text=SparkStatementCancellationResult\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.cancelSparkStatementWithResponse(int,int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.cancelSparkStatementWithResponse(int sessionId, int statementId)"
  name: "cancelSparkStatementWithResponse(int sessionId, int statementId)"
  nameWithType: "SparkSessionAsyncClient.cancelSparkStatementWithResponse(int sessionId, int statementId)"
  summary: "Kill a statement within a session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Identifier for the statement."
    name: "statementId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<SparkStatementCancellationResult>> cancelSparkStatementWithResponse(int sessionId, int statementId)"
  desc: "Kill a statement within a session."
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementCancellationResult?alt=com.azure.analytics.synapse.spark.models.SparkStatementCancellationResult&text=SparkStatementCancellationResult\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkSession(com.azure.analytics.synapse.spark.models.SparkSessionOptions)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkSession(SparkSessionOptions sparkSessionOptions)"
  name: "createSparkSession(SparkSessionOptions sparkSessionOptions)"
  nameWithType: "SparkSessionAsyncClient.createSparkSession(SparkSessionOptions sparkSessionOptions)"
  summary: "Create new spark session."
  parameters:
  - description: "Livy compatible batch job request payload."
    name: "sparkSessionOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionOptions?alt=com.azure.analytics.synapse.spark.models.SparkSessionOptions&text=SparkSessionOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkSession> createSparkSession(SparkSessionOptions sparkSessionOptions)"
  desc: "Create new spark session."
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkSession(com.azure.analytics.synapse.spark.models.SparkSessionOptions,java.lang.Boolean)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkSession(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  name: "createSparkSession(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  nameWithType: "SparkSessionAsyncClient.createSparkSession(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  summary: "Create new spark session."
  parameters:
  - description: "Livy compatible batch job request payload."
    name: "sparkSessionOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionOptions?alt=com.azure.analytics.synapse.spark.models.SparkSessionOptions&text=SparkSessionOptions\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkSession> createSparkSession(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  desc: "Create new spark session."
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkSessionWithResponse(com.azure.analytics.synapse.spark.models.SparkSessionOptions,java.lang.Boolean)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkSessionWithResponse(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  name: "createSparkSessionWithResponse(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  nameWithType: "SparkSessionAsyncClient.createSparkSessionWithResponse(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  summary: "Create new spark session."
  parameters:
  - description: "Livy compatible batch job request payload."
    name: "sparkSessionOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionOptions?alt=com.azure.analytics.synapse.spark.models.SparkSessionOptions&text=SparkSessionOptions\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<SparkSession>> createSparkSessionWithResponse(SparkSessionOptions sparkSessionOptions, Boolean detailed)"
  desc: "Create new spark session."
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkStatement(int,com.azure.analytics.synapse.spark.models.SparkStatementOptions)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  name: "createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  nameWithType: "SparkSessionAsyncClient.createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  summary: "Create statement within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Livy compatible batch job request payload."
    name: "sparkStatementOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementOptions?alt=com.azure.analytics.synapse.spark.models.SparkStatementOptions&text=SparkStatementOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkStatement> createSparkStatement(int sessionId, SparkStatementOptions sparkStatementOptions)"
  desc: "Create statement within a spark session."
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatement?alt=com.azure.analytics.synapse.spark.models.SparkStatement&text=SparkStatement\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkStatementWithResponse(int,com.azure.analytics.synapse.spark.models.SparkStatementOptions)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.createSparkStatementWithResponse(int sessionId, SparkStatementOptions sparkStatementOptions)"
  name: "createSparkStatementWithResponse(int sessionId, SparkStatementOptions sparkStatementOptions)"
  nameWithType: "SparkSessionAsyncClient.createSparkStatementWithResponse(int sessionId, SparkStatementOptions sparkStatementOptions)"
  summary: "Create statement within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Livy compatible batch job request payload."
    name: "sparkStatementOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementOptions?alt=com.azure.analytics.synapse.spark.models.SparkStatementOptions&text=SparkStatementOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<SparkStatement>> createSparkStatementWithResponse(int sessionId, SparkStatementOptions sparkStatementOptions)"
  desc: "Create statement within a spark session."
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatement?alt=com.azure.analytics.synapse.spark.models.SparkStatement&text=SparkStatement\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSession(int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSession(int sessionId)"
  name: "getSparkSession(int sessionId)"
  nameWithType: "SparkSessionAsyncClient.getSparkSession(int sessionId)"
  summary: "Gets a single spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkSession> getSparkSession(int sessionId)"
  desc: "Gets a single spark session."
  returns:
    description: "a single spark session."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSession(int,java.lang.Boolean)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSession(int sessionId, Boolean detailed)"
  name: "getSparkSession(int sessionId, Boolean detailed)"
  nameWithType: "SparkSessionAsyncClient.getSparkSession(int sessionId, Boolean detailed)"
  summary: "Gets a single spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkSession> getSparkSession(int sessionId, Boolean detailed)"
  desc: "Gets a single spark session."
  returns:
    description: "a single spark session."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSessionWithResponse(int,java.lang.Boolean)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSessionWithResponse(int sessionId, Boolean detailed)"
  name: "getSparkSessionWithResponse(int sessionId, Boolean detailed)"
  nameWithType: "SparkSessionAsyncClient.getSparkSessionWithResponse(int sessionId, Boolean detailed)"
  summary: "Gets a single spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<SparkSession>> getSparkSessionWithResponse(int sessionId, Boolean detailed)"
  desc: "Gets a single spark session."
  returns:
    description: "a single spark session."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSession?alt=com.azure.analytics.synapse.spark.models.SparkSession&text=SparkSession\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSessions()"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSessions()"
  name: "getSparkSessions()"
  nameWithType: "SparkSessionAsyncClient.getSparkSessions()"
  summary: "List all spark sessions which are running under a particular spark pool."
  syntax: "public Mono<SparkSessionCollection> getSparkSessions()"
  desc: "List all spark sessions which are running under a particular spark pool."
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionCollection?alt=com.azure.analytics.synapse.spark.models.SparkSessionCollection&text=SparkSessionCollection\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSessions(java.lang.Integer,java.lang.Integer,java.lang.Boolean)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSessions(Integer from, Integer size, Boolean detailed)"
  name: "getSparkSessions(Integer from, Integer size, Boolean detailed)"
  nameWithType: "SparkSessionAsyncClient.getSparkSessions(Integer from, Integer size, Boolean detailed)"
  summary: "List all spark sessions which are running under a particular spark pool."
  parameters:
  - description: "Optional param specifying which index the list should begin from."
    name: "from"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional param specifying the size of the returned list. By default it is 20 and that is the maximum."
    name: "size"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkSessionCollection> getSparkSessions(Integer from, Integer size, Boolean detailed)"
  desc: "List all spark sessions which are running under a particular spark pool."
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionCollection?alt=com.azure.analytics.synapse.spark.models.SparkSessionCollection&text=SparkSessionCollection\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSessionsWithResponse(java.lang.Integer,java.lang.Integer,java.lang.Boolean)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkSessionsWithResponse(Integer from, Integer size, Boolean detailed)"
  name: "getSparkSessionsWithResponse(Integer from, Integer size, Boolean detailed)"
  nameWithType: "SparkSessionAsyncClient.getSparkSessionsWithResponse(Integer from, Integer size, Boolean detailed)"
  summary: "List all spark sessions which are running under a particular spark pool."
  parameters:
  - description: "Optional param specifying which index the list should begin from."
    name: "from"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional param specifying the size of the returned list. By default it is 20 and that is the maximum."
    name: "size"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  - description: "Optional query param specifying whether detailed response is returned beyond plain livy."
    name: "detailed"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<SparkSessionCollection>> getSparkSessionsWithResponse(Integer from, Integer size, Boolean detailed)"
  desc: "List all spark sessions which are running under a particular spark pool."
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkSessionCollection?alt=com.azure.analytics.synapse.spark.models.SparkSessionCollection&text=SparkSessionCollection\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkStatement(int,int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkStatement(int sessionId, int statementId)"
  name: "getSparkStatement(int sessionId, int statementId)"
  nameWithType: "SparkSessionAsyncClient.getSparkStatement(int sessionId, int statementId)"
  summary: "Gets a single statement within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Identifier for the statement."
    name: "statementId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkStatement> getSparkStatement(int sessionId, int statementId)"
  desc: "Gets a single statement within a spark session."
  returns:
    description: "a single statement within a spark session."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatement?alt=com.azure.analytics.synapse.spark.models.SparkStatement&text=SparkStatement\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkStatementWithResponse(int,int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkStatementWithResponse(int sessionId, int statementId)"
  name: "getSparkStatementWithResponse(int sessionId, int statementId)"
  nameWithType: "SparkSessionAsyncClient.getSparkStatementWithResponse(int sessionId, int statementId)"
  summary: "Gets a single statement within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Identifier for the statement."
    name: "statementId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<SparkStatement>> getSparkStatementWithResponse(int sessionId, int statementId)"
  desc: "Gets a single statement within a spark session."
  returns:
    description: "a single statement within a spark session."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatement?alt=com.azure.analytics.synapse.spark.models.SparkStatement&text=SparkStatement\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkStatements(int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkStatements(int sessionId)"
  name: "getSparkStatements(int sessionId)"
  nameWithType: "SparkSessionAsyncClient.getSparkStatements(int sessionId)"
  summary: "Gets a list of statements within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkStatementCollection> getSparkStatements(int sessionId)"
  desc: "Gets a list of statements within a spark session."
  returns:
    description: "a list of statements within a spark session."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementCollection?alt=com.azure.analytics.synapse.spark.models.SparkStatementCollection&text=SparkStatementCollection\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkStatementsWithResponse(int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.getSparkStatementsWithResponse(int sessionId)"
  name: "getSparkStatementsWithResponse(int sessionId)"
  nameWithType: "SparkSessionAsyncClient.getSparkStatementsWithResponse(int sessionId)"
  summary: "Gets a list of statements within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<SparkStatementCollection>> getSparkStatementsWithResponse(int sessionId)"
  desc: "Gets a list of statements within a spark session."
  returns:
    description: "a list of statements within a spark session."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementCollection?alt=com.azure.analytics.synapse.spark.models.SparkStatementCollection&text=SparkStatementCollection\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.resetSparkSessionTimeout(int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.resetSparkSessionTimeout(int sessionId)"
  name: "resetSparkSessionTimeout(int sessionId)"
  nameWithType: "SparkSessionAsyncClient.resetSparkSessionTimeout(int sessionId)"
  summary: "Sends a keep alive call to the current session to reset the session timeout."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Void> resetSparkSessionTimeout(int sessionId)"
  desc: "Sends a keep alive call to the current session to reset the session timeout."
  returns:
    description: "the completion."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.resetSparkSessionTimeoutWithResponse(int)"
  fullName: "com.azure.analytics.synapse.spark.SparkSessionAsyncClient.resetSparkSessionTimeoutWithResponse(int sessionId)"
  name: "resetSparkSessionTimeoutWithResponse(int sessionId)"
  nameWithType: "SparkSessionAsyncClient.resetSparkSessionTimeoutWithResponse(int sessionId)"
  summary: "Sends a keep alive call to the current session to reset the session timeout."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<Void>> resetSparkSessionTimeoutWithResponse(int sessionId)"
  desc: "Sends a keep alive call to the current session to reset the session timeout."
  returns:
    description: "the completion."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
type: "class"
desc: "Initializes a new instance of the asynchronous SparkClient type."
metadata: {}
package: "com.azure.analytics.synapse.spark"
artifact: com.azure:azure-analytics-synapse-spark:1.0.0-beta.5
