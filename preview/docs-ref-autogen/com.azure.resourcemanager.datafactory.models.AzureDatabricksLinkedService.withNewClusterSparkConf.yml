### YamlMime:JavaMember
uid: "com.azure.resourcemanager.datafactory.models.AzureDatabricksLinkedService.withNewClusterSparkConf*"
fullName: "com.azure.resourcemanager.datafactory.models.AzureDatabricksLinkedService.withNewClusterSparkConf"
name: "withNewClusterSparkConf"
nameWithType: "AzureDatabricksLinkedService.withNewClusterSparkConf"
members:
- uid: "com.azure.resourcemanager.datafactory.models.AzureDatabricksLinkedService.withNewClusterSparkConf(java.util.Map<java.lang.String,java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.models.AzureDatabricksLinkedService.withNewClusterSparkConf(Map<String,Object> newClusterSparkConf)"
  name: "withNewClusterSparkConf(Map<String,Object> newClusterSparkConf)"
  nameWithType: "AzureDatabricksLinkedService.withNewClusterSparkConf(Map<String,Object> newClusterSparkConf)"
  summary: "Set the newClusterSparkConf property: A set of optional, user-specified Spark configuration key-value pairs."
  parameters:
  - description: "the newClusterSparkConf value to set."
    name: "newClusterSparkConf"
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public AzureDatabricksLinkedService withNewClusterSparkConf(Map<String,Object> newClusterSparkConf)"
  returns:
    description: "the AzureDatabricksLinkedService object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.models.AzureDatabricksLinkedService?alt=com.azure.resourcemanager.datafactory.models.AzureDatabricksLinkedService&text=AzureDatabricksLinkedService\" data-throw-if-not-resolved=\"False\" />"
type: "method"
metadata: {}
package: "com.azure.resourcemanager.datafactory.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.12
