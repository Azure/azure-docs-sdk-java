### YamlMime:JavaType
uid: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties"
fullName: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties"
name: "DatabricksSparkPythonActivityTypeProperties"
nameWithType: "DatabricksSparkPythonActivityTypeProperties"
summary: "Databricks Spark<wbr>Python activity properties."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class DatabricksSparkPythonActivityTypeProperties"
constructors:
- uid: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.DatabricksSparkPythonActivityTypeProperties()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.DatabricksSparkPythonActivityTypeProperties()"
  name: "DatabricksSparkPythonActivityTypeProperties()"
  nameWithType: "DatabricksSparkPythonActivityTypeProperties.DatabricksSparkPythonActivityTypeProperties()"
  syntax: "public DatabricksSparkPythonActivityTypeProperties()"
methods:
- uid: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.libraries()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.libraries()"
  name: "libraries()"
  nameWithType: "DatabricksSparkPythonActivityTypeProperties.libraries()"
  summary: "Get the libraries property: A list of libraries to be installed on the cluster that will execute the job."
  syntax: "public List<Map<String,Object>> libraries()"
  desc: "Get the libraries property: A list of libraries to be installed on the cluster that will execute the job."
  returns:
    description: "the libraries value."
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.parameters()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.parameters()"
  name: "parameters()"
  nameWithType: "DatabricksSparkPythonActivityTypeProperties.parameters()"
  summary: "Get the parameters property: Command line parameters that will be passed to the Python file."
  syntax: "public List<Object> parameters()"
  desc: "Get the parameters property: Command line parameters that will be passed to the Python file."
  returns:
    description: "the parameters value."
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.pythonFile()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.pythonFile()"
  name: "pythonFile()"
  nameWithType: "DatabricksSparkPythonActivityTypeProperties.pythonFile()"
  summary: "Get the python<wbr>File property: The URI of the Python file to be executed."
  syntax: "public Object pythonFile()"
  desc: "Get the pythonFile property: The URI of the Python file to be executed. DBFS paths are supported. Type: string (or Expression with resultType string)."
  returns:
    description: "the pythonFile value."
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.validate()"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.validate()"
  name: "validate()"
  nameWithType: "DatabricksSparkPythonActivityTypeProperties.validate()"
  summary: "Validates the instance."
  syntax: "public void validate()"
  desc: "Validates the instance."
- uid: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.withLibraries(java.util.List<java.util.Map<java.lang.String,java.lang.Object>>)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.withLibraries(List<Map<String,Object>> libraries)"
  name: "withLibraries(List<Map<String,Object>> libraries)"
  nameWithType: "DatabricksSparkPythonActivityTypeProperties.withLibraries(List<Map<String,Object>> libraries)"
  summary: "Set the libraries property: A list of libraries to be installed on the cluster that will execute the job."
  parameters:
  - description: "the libraries value to set."
    name: "libraries"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
  syntax: "public DatabricksSparkPythonActivityTypeProperties withLibraries(List<Map<String,Object>> libraries)"
  desc: "Set the libraries property: A list of libraries to be installed on the cluster that will execute the job."
  returns:
    description: "the DatabricksSparkPythonActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties&text=DatabricksSparkPythonActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.withParameters(java.util.List<java.lang.Object>)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.withParameters(List<Object> parameters)"
  name: "withParameters(List<Object> parameters)"
  nameWithType: "DatabricksSparkPythonActivityTypeProperties.withParameters(List<Object> parameters)"
  summary: "Set the parameters property: Command line parameters that will be passed to the Python file."
  parameters:
  - description: "the parameters value to set."
    name: "parameters"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public DatabricksSparkPythonActivityTypeProperties withParameters(List<Object> parameters)"
  desc: "Set the parameters property: Command line parameters that will be passed to the Python file."
  returns:
    description: "the DatabricksSparkPythonActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties&text=DatabricksSparkPythonActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.withPythonFile(java.lang.Object)"
  fullName: "com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties.withPythonFile(Object pythonFile)"
  name: "withPythonFile(Object pythonFile)"
  nameWithType: "DatabricksSparkPythonActivityTypeProperties.withPythonFile(Object pythonFile)"
  summary: "Set the python<wbr>File property: The URI of the Python file to be executed."
  parameters:
  - description: "the pythonFile value to set."
    name: "pythonFile"
    type: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DatabricksSparkPythonActivityTypeProperties withPythonFile(Object pythonFile)"
  desc: "Set the pythonFile property: The URI of the Python file to be executed. DBFS paths are supported. Type: string (or Expression with resultType string)."
  returns:
    description: "the DatabricksSparkPythonActivityTypeProperties object itself."
    type: "<xref href=\"com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties?alt=com.azure.resourcemanager.datafactory.fluent.models.DatabricksSparkPythonActivityTypeProperties&text=DatabricksSparkPythonActivityTypeProperties\" data-throw-if-not-resolved=\"False\" />"
type: "class"
desc: "Databricks SparkPython activity properties."
metadata: {}
package: "com.azure.resourcemanager.datafactory.fluent.models"
artifact: com.azure.resourcemanager:azure-resourcemanager-datafactory:1.0.0-beta.16
