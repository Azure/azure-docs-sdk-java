### YamlMime:JavaType
uid: "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions"
fullName: "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions"
name: "SparkBatchJobOptions"
nameWithType: "SparkBatchJobOptions"
summary: "The SparkBatchJobOptions model."
inheritances:
- "<xref href=\"java.lang.Object\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class SparkBatchJobOptions"
constructors:
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.SparkBatchJobOptions()"
methods:
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getArchives()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getArguments()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getArtifactId()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getClassName()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getConfiguration()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getDriverCores()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getDriverMemory()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getExecutorCores()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getExecutorCount()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getExecutorMemory()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getFile()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getFiles()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getJars()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getName()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getPythonFiles()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.getTags()"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setArchives(java.util.List<java.lang.String>)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setArguments(java.util.List<java.lang.String>)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setArtifactId(java.lang.String)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setClassName(java.lang.String)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setConfiguration(java.util.Map<java.lang.String,java.lang.String>)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setDriverCores(java.lang.Integer)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setDriverMemory(java.lang.String)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setExecutorCores(java.lang.Integer)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setExecutorCount(java.lang.Integer)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setExecutorMemory(java.lang.String)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setFile(java.lang.String)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setFiles(java.util.List<java.lang.String>)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setJars(java.util.List<java.lang.String>)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setName(java.lang.String)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setPythonFiles(java.util.List<java.lang.String>)"
- "com.azure.analytics.synapse.spark.models.SparkBatchJobOptions.setTags(java.util.Map<java.lang.String,java.lang.String>)"
type: "class"
metadata: {}
package: "com.azure.analytics.synapse.spark.models"
artifact: com.azure:azure-analytics-synapse-spark:1.0.0-beta.3
