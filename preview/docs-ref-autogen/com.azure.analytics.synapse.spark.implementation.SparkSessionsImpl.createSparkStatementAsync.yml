### YamlMime:JavaMember
uid: "com.azure.analytics.synapse.spark.implementation.SparkSessionsImpl.createSparkStatementAsync*"
fullName: "com.azure.analytics.synapse.spark.implementation.SparkSessionsImpl.createSparkStatementAsync"
name: "createSparkStatementAsync"
nameWithType: "SparkSessionsImpl.createSparkStatementAsync"
members:
- uid: "com.azure.analytics.synapse.spark.implementation.SparkSessionsImpl.createSparkStatementAsync(int,com.azure.analytics.synapse.spark.models.SparkStatementOptions)"
  fullName: "com.azure.analytics.synapse.spark.implementation.SparkSessionsImpl.createSparkStatementAsync(int sessionId, SparkStatementOptions sparkStatementOptions)"
  name: "createSparkStatementAsync(int sessionId, SparkStatementOptions sparkStatementOptions)"
  nameWithType: "SparkSessionsImpl.createSparkStatementAsync(int sessionId, SparkStatementOptions sparkStatementOptions)"
  summary: "Create statement within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Livy compatible batch job request payload."
    name: "sparkStatementOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementOptions?alt=com.azure.analytics.synapse.spark.models.SparkStatementOptions&text=SparkStatementOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkStatement> createSparkStatementAsync(int sessionId, SparkStatementOptions sparkStatementOptions)"
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatement?alt=com.azure.analytics.synapse.spark.models.SparkStatement&text=SparkStatement\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.analytics.synapse.spark.implementation.SparkSessionsImpl.createSparkStatementAsync(int,com.azure.analytics.synapse.spark.models.SparkStatementOptions,com.azure.core.util.Context)"
  fullName: "com.azure.analytics.synapse.spark.implementation.SparkSessionsImpl.createSparkStatementAsync(int sessionId, SparkStatementOptions sparkStatementOptions, Context context)"
  name: "createSparkStatementAsync(int sessionId, SparkStatementOptions sparkStatementOptions, Context context)"
  nameWithType: "SparkSessionsImpl.createSparkStatementAsync(int sessionId, SparkStatementOptions sparkStatementOptions, Context context)"
  summary: "Create statement within a spark session."
  parameters:
  - description: "Identifier for the session."
    name: "sessionId"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
  - description: "Livy compatible batch job request payload."
    name: "sparkStatementOptions"
    type: "<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatementOptions?alt=com.azure.analytics.synapse.spark.models.SparkStatementOptions&text=SparkStatementOptions\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<SparkStatement> createSparkStatementAsync(int sessionId, SparkStatementOptions sparkStatementOptions, Context context)"
  returns:
    description: "the response."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.analytics.synapse.spark.models.SparkStatement?alt=com.azure.analytics.synapse.spark.models.SparkStatement&text=SparkStatement\" data-throw-if-not-resolved=\"False\" />&gt;"
type: "method"
metadata: {}
package: "com.azure.analytics.synapse.spark.implementation"
artifact: com.azure:azure-analytics-synapse-spark:1.0.0-beta.5
