### YamlMime:ManagedReference
items:
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  id: "DataLakeDirectoryClient"
  parent: "com.azure.storage.file.datalake"
  children:
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient(com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient,com.azure.storage.blob.specialized.BlockBlobClient)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile(java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory(java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.delete()"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile(java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory(java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse(java.lang.String,boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName()"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath()"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl()"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient(java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient(java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.rename(java.lang.String,java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  langs:
  - "java"
  name: "DataLakeDirectoryClient"
  nameWithType: "DataLakeDirectoryClient"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  type: "Class"
  package: "com.azure.storage.file.datalake"
  summary: "This class provides a client that contains directory operations for Azure Storage Data Lake. Operations provided by this client include creating a directory, deleting a directory, renaming a directory, setting metadata and http headers, setting and retrieving access control, getting properties and creating and deleting files and subdirectories.\n\nThis client is instantiated through <xref uid=\"com.azure.storage.file.datalake.DataLakePathClientBuilder\" data-throw-if-not-resolved=\"false\">DataLakePathClientBuilder</xref> or retrieved via <xref uid=\"com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient(java.lang.String)\" data-throw-if-not-resolved=\"false\">getDirectoryClient</xref>.\n\nPlease refer to the [Azure Docs][] for more information.\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction?toc=%2fazure%2fstorage%2fblobs%2ftoc.json"
  syntax:
    content: "public class DataLakeDirectoryClient extends DataLakePathClient"
  inheritance:
  - "java.lang.Object"
  - "com.azure.storage.file.datalake.DataLakePathClient"
  inheritedMembers:
  - "com.azure.storage.file.datalake.DataLakePathClient.create()"
  - "com.azure.storage.file.datalake.DataLakePathClient.create(boolean)"
  - "com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.exists()"
  - "com.azure.storage.file.datalake.DataLakePathClient.existsWithResponse(java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)"
  - "com.azure.storage.file.datalake.DataLakePathClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)"
  - "com.azure.storage.file.datalake.DataLakePathClient.getAccessControl()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getAccessControlWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.getAccountName()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getBlockBlobClient()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getFileSystemName()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getHttpPipeline()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getObjectName()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getObjectPath()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getPathUrl()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getProperties()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getPropertiesWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.getServiceVersion()"
  - "com.azure.storage.file.datalake.DataLakePathClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeaders(com.azure.storage.file.datalake.models.PathHttpHeaders)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeadersWithResponse(com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setPermissions(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setPermissionsWithResponse(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "java.lang.Object.clone()"
  - "java.lang.Object.equals(java.lang.Object)"
  - "java.lang.Object.finalize()"
  - "java.lang.Object.getClass()"
  - "java.lang.Object.hashCode()"
  - "java.lang.Object.notify()"
  - "java.lang.Object.notifyAll()"
  - "java.lang.Object.toString()"
  - "java.lang.Object.wait()"
  - "java.lang.Object.wait(long)"
  - "java.lang.Object.wait(long,int)"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient(com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient,com.azure.storage.blob.specialized.BlockBlobClient)"
  id: "DataLakeDirectoryClient(com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient,com.azure.storage.blob.specialized.BlockBlobClient)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "DataLakeDirectoryClient(DataLakeDirectoryAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)"
  nameWithType: "DataLakeDirectoryClient.DataLakeDirectoryClient(DataLakeDirectoryAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient(DataLakeDirectoryAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient*"
  type: "Constructor"
  package: "com.azure.storage.file.datalake"
  syntax:
    content: " DataLakeDirectoryClient(DataLakeDirectoryAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)"
    parameters:
    - id: "pathAsyncClient"
      type: "com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient"
    - id: "blockBlobClient"
      type: "com.azure.storage.blob.specialized.BlockBlobClient"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient(com.azure.storage.file.datalake.DataLakePathClient)"
  id: "DataLakeDirectoryClient(com.azure.storage.file.datalake.DataLakePathClient)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "DataLakeDirectoryClient(DataLakePathClient dataLakePathClient)"
  nameWithType: "DataLakeDirectoryClient.DataLakeDirectoryClient(DataLakePathClient dataLakePathClient)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient(DataLakePathClient dataLakePathClient)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient*"
  type: "Constructor"
  package: "com.azure.storage.file.datalake"
  syntax:
    content: "private DataLakeDirectoryClient(DataLakePathClient dataLakePathClient)"
    parameters:
    - id: "dataLakePathClient"
      type: "com.azure.storage.file.datalake.DataLakePathClient"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile(java.lang.String)"
  id: "createFile(java.lang.String)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "createFile(String fileName)"
  nameWithType: "DataLakeDirectoryClient.createFile(String fileName)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile(String fileName)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Creates a new file within a directory. If a file with the same name already exists, the file will be overwritten. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile\\#String\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create"
  syntax:
    content: "public DataLakeFileClient createFile(String fileName)"
    parameters:
    - id: "fileName"
      type: "java.lang.String"
      description: "Name of the file to create."
    return:
      type: "com.azure.storage.file.datalake.DataLakeFileClient"
      description: "A <xref uid=\"com.azure.storage.file.datalake.DataLakeFileClient\" data-throw-if-not-resolved=\"false\">DataLakeFileClient</xref> used to interact with the file created."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  id: "createFileWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeDirectoryClient.createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Creates a new file within a directory. If a file with the same name already exists, the file will be overwritten. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse\\#String-String-String-PathHttpHeaders-Map-DataLakeRequestConditions-Duration-Context\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create"
  syntax:
    content: "public Response<DataLakeFileClient> createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
    parameters:
    - id: "fileName"
      type: "java.lang.String"
      description: "Name of the file to create."
    - id: "permissions"
      type: "java.lang.String"
      description: "POSIX access permissions for the file owner, the file owning group, and others."
    - id: "umask"
      type: "java.lang.String"
      description: "Restricts permissions of the file to be created."
    - id: "headers"
      type: "com.azure.storage.file.datalake.models.PathHttpHeaders"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.PathHttpHeaders\" data-throw-if-not-resolved=\"false\">PathHttpHeaders</xref>"
    - id: "metadata"
      type: "java.util.Map<java.lang.String,java.lang.String>"
      description: "Metadata to associate with the file."
    - id: "requestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref>"
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeFileClient>"
      description: "A <xref uid=\"com.azure.core.http.rest.Response\" data-throw-if-not-resolved=\"false\">Response</xref> whose <xref uid=\"\" data-throw-if-not-resolved=\"false\">value</xref> contains the <xref uid=\"com.azure.storage.file.datalake.DataLakeFileClient\" data-throw-if-not-resolved=\"false\">DataLakeFileClient</xref> used\n to interact with the file created."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory(java.lang.String)"
  id: "createSubdirectory(java.lang.String)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "createSubdirectory(String subdirectoryName)"
  nameWithType: "DataLakeDirectoryClient.createSubdirectory(String subdirectoryName)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory(String subdirectoryName)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Creates a new sub-directory within a directory. If a sub-directory with the same name already exists, the sub-directory will be overwritten. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory\\#String\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create"
  syntax:
    content: "public DataLakeDirectoryClient createSubdirectory(String subdirectoryName)"
    parameters:
    - id: "subdirectoryName"
      type: "java.lang.String"
      description: "Name of the sub-directory to create."
    return:
      type: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
      description: "A <xref uid=\"com.azure.storage.file.datalake.DataLakeDirectoryClient\" data-throw-if-not-resolved=\"false\">DataLakeDirectoryClient</xref> used to interact with the sub-directory created."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  id: "createSubdirectoryWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "createSubdirectoryWithResponse(String subdirectoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeDirectoryClient.createSubdirectoryWithResponse(String subdirectoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse(String subdirectoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Creates a new sub-directory within a directory. If a sub-directory with the same name already exists, the sub-directory will be overwritten. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse\\#String-String-String-PathHttpHeaders-Map-DataLakeRequestConditions-Duration-Context\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create"
  syntax:
    content: "public Response<DataLakeDirectoryClient> createSubdirectoryWithResponse(String subdirectoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
    parameters:
    - id: "subdirectoryName"
      type: "java.lang.String"
      description: "Name of the sub-directory to create."
    - id: "permissions"
      type: "java.lang.String"
      description: "POSIX access permissions for the sub-directory owner, the sub-directory owning group, and\n others."
    - id: "umask"
      type: "java.lang.String"
      description: "Restricts permissions of the sub-directory to be created."
    - id: "headers"
      type: "com.azure.storage.file.datalake.models.PathHttpHeaders"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.PathHttpHeaders\" data-throw-if-not-resolved=\"false\">PathHttpHeaders</xref>"
    - id: "metadata"
      type: "java.util.Map<java.lang.String,java.lang.String>"
      description: "Metadata to associate with the sub-directory."
    - id: "requestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref>"
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeDirectoryClient>"
      description: "A <xref uid=\"com.azure.core.http.rest.Response\" data-throw-if-not-resolved=\"false\">Response</xref> whose <xref uid=\"\" data-throw-if-not-resolved=\"false\">value</xref> contains a <xref uid=\"com.azure.storage.file.datalake.DataLakeDirectoryClient\" data-throw-if-not-resolved=\"false\">DataLakeDirectoryClient</xref>\n used to interact with the sub-directory created."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.delete()"
  id: "delete()"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "delete()"
  nameWithType: "DataLakeDirectoryClient.delete()"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.delete()"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.delete*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Deletes a directory.\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.delete\\}\n\nFor more information see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: "public void delete()"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile(java.lang.String)"
  id: "deleteFile(java.lang.String)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "deleteFile(String fileName)"
  nameWithType: "DataLakeDirectoryClient.deleteFile(String fileName)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile(String fileName)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Deletes the specified file in the directory. If the file doesn't exist the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile\\#String\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: "public void deleteFile(String fileName)"
    parameters:
    - id: "fileName"
      type: "java.lang.String"
      description: "Name of the file to delete."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  id: "deleteFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeDirectoryClient.deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Deletes the specified file in the directory. If the file doesn't exist the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse\\#String-DataLakeRequestConditions-Duration-Context\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: "public Response<Void> deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
    parameters:
    - id: "fileName"
      type: "java.lang.String"
      description: "Name of the file to delete."
    - id: "requestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref>"
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.core.http.rest.Response<java.lang.Void>"
      description: "A response containing status code and HTTP headers"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory(java.lang.String)"
  id: "deleteSubdirectory(java.lang.String)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "deleteSubdirectory(String subdirectoryName)"
  nameWithType: "DataLakeDirectoryClient.deleteSubdirectory(String subdirectoryName)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory(String subdirectoryName)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Deletes the specified sub-directory in the directory. If the sub-directory doesn't exist or is not empty the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory\\#String\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: "public void deleteSubdirectory(String subdirectoryName)"
    parameters:
    - id: "subdirectoryName"
      type: "java.lang.String"
      description: "Name of the sub-directory to delete."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse(java.lang.String,boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  id: "deleteSubdirectoryWithResponse(java.lang.String,boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "deleteSubdirectoryWithResponse(String subdirectoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeDirectoryClient.deleteSubdirectoryWithResponse(String subdirectoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse(String subdirectoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Deletes the specified sub-directory in the directory. If the sub-directory doesn't exist or is not empty the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse\\#String-boolean-DataLakeRequestConditions-Duration-Context\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: "public Response<Void> deleteSubdirectoryWithResponse(String subdirectoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
    parameters:
    - id: "subdirectoryName"
      type: "java.lang.String"
      description: "Name of the sub-directory to delete."
    - id: "recursive"
      type: "boolean"
      description: "Whether or not to delete all paths beneath the sub-directory."
    - id: "requestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref>"
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.core.http.rest.Response<java.lang.Void>"
      description: "A response containing status code and HTTP headers"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  id: "deleteWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "deleteWithResponse(boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeDirectoryClient.deleteWithResponse(boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse(boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Deletes a directory.\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse\\#boolean-DataLakeRequestConditions-Duration-Context\\}\n\nFor more information see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: "public Response<Void> deleteWithResponse(boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
    parameters:
    - id: "recursive"
      type: "boolean"
      description: "Whether or not to delete all paths beneath the directory."
    - id: "requestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref>"
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.core.http.rest.Response<java.lang.Void>"
      description: "A reactive response signalling completion."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName()"
  id: "getDirectoryName()"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "getDirectoryName()"
  nameWithType: "DataLakeDirectoryClient.getDirectoryName()"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName()"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Gets the name of this directory, not including its full path."
  syntax:
    content: "public String getDirectoryName()"
    return:
      type: "java.lang.String"
      description: "The name of the directory."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath()"
  id: "getDirectoryPath()"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "getDirectoryPath()"
  nameWithType: "DataLakeDirectoryClient.getDirectoryPath()"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath()"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Gets the path of this directory, not including the name of the resource itself."
  syntax:
    content: "public String getDirectoryPath()"
    return:
      type: "java.lang.String"
      description: "The path of the directory."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl()"
  id: "getDirectoryUrl()"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "getDirectoryUrl()"
  nameWithType: "DataLakeDirectoryClient.getDirectoryUrl()"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl()"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Gets the URL of the directory represented by this client on the Data Lake service."
  syntax:
    content: "public String getDirectoryUrl()"
    return:
      type: "java.lang.String"
      description: "the URL."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient(java.lang.String)"
  id: "getFileClient(java.lang.String)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "getFileClient(String fileName)"
  nameWithType: "DataLakeDirectoryClient.getFileClient(String fileName)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient(String fileName)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Initializes a new DataLakeFileClient object by concatenating fileName to the end of DataLakeDirectoryClient's URL. The new DataLakeFileClient uses the same request policy pipeline as the DataLakeDirectoryClient."
  syntax:
    content: "public DataLakeFileClient getFileClient(String fileName)"
    parameters:
    - id: "fileName"
      type: "java.lang.String"
      description: "A <code>String</code> representing the name of the file.\n\n <p><strong>Code Samples</strong></p>\n\n {@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient#String}"
    return:
      type: "com.azure.storage.file.datalake.DataLakeFileClient"
      description: "A new <xref uid=\"com.azure.storage.file.datalake.DataLakeFileClient\" data-throw-if-not-resolved=\"false\">DataLakeFileClient</xref> object which references the file with the specified name in this\n directory."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient(java.lang.String)"
  id: "getSubdirectoryClient(java.lang.String)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "getSubdirectoryClient(String subdirectoryName)"
  nameWithType: "DataLakeDirectoryClient.getSubdirectoryClient(String subdirectoryName)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient(String subdirectoryName)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Initializes a new DataLakeDirectoryClient object by concatenating directoryName to the end of DataLakeDirectoryClient's URL. The new DataLakeDirectoryClient uses the same request policy pipeline as the DataLakeDirectoryClient."
  syntax:
    content: "public DataLakeDirectoryClient getSubdirectoryClient(String subdirectoryName)"
    parameters:
    - id: "subdirectoryName"
      type: "java.lang.String"
      description: "A <code>String</code> representing the name of the sub-directory.\n\n <p><strong>Code Samples</strong></p>\n\n {@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient#String}"
    return:
      type: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
      description: "A new <xref uid=\"com.azure.storage.file.datalake.DataLakeDirectoryClient\" data-throw-if-not-resolved=\"false\">DataLakeDirectoryClient</xref> object which references the sub-directory with the specified name\n in this directory"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.rename(java.lang.String,java.lang.String)"
  id: "rename(java.lang.String,java.lang.String)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "rename(String destinationFileSystem, String destinationPath)"
  nameWithType: "DataLakeDirectoryClient.rename(String destinationFileSystem, String destinationPath)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.rename(String destinationFileSystem, String destinationPath)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.rename*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Moves the directory to another location within the file system. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.rename\\#String-String\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create"
  syntax:
    content: "public DataLakeDirectoryClient rename(String destinationFileSystem, String destinationPath)"
    parameters:
    - id: "destinationFileSystem"
      type: "java.lang.String"
      description: "The file system of the destination within the account.\n <code>null</code> for the current file system."
    - id: "destinationPath"
      type: "java.lang.String"
      description: "Relative path from the file system to rename the directory to, excludes the file system\n name. For example if you want to move a directory with fileSystem = \"myfilesystem\", path = \"mydir/mysubdir\" to\n another path in myfilesystem (ex: newdir) then set the destinationPath = \"newdir\""
    return:
      type: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
      description: "A <xref uid=\"com.azure.storage.file.datalake.DataLakeDirectoryClient\" data-throw-if-not-resolved=\"false\">DataLakeDirectoryClient</xref> used to interact with the new directory created."
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  id: "renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  langs:
  - "java"
  name: "renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeDirectoryClient.renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Moves the directory to another location within the file system. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse\\#String-String-DataLakeRequestConditions-DataLakeRequestConditions-Duration-Context\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create"
  syntax:
    content: "public Response<DataLakeDirectoryClient> renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)"
    parameters:
    - id: "destinationFileSystem"
      type: "java.lang.String"
      description: "The file system of the destination within the account.\n <code>null</code> for the current file system."
    - id: "destinationPath"
      type: "java.lang.String"
      description: "Relative path from the file system to rename the directory to, excludes the file system\n name. For example if you want to move a directory with fileSystem = \"myfilesystem\", path = \"mydir/mysubdir\" to\n another path in myfilesystem (ex: newdir) then set the destinationPath = \"newdir\""
    - id: "sourceRequestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref> against the source."
    - id: "destinationRequestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref> against the destination."
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeDirectoryClient>"
      description: "A <xref uid=\"com.azure.core.http.rest.Response\" data-throw-if-not-resolved=\"false\">Response</xref> whose <xref uid=\"\" data-throw-if-not-resolved=\"false\">value</xref> that contains a\n <xref uid=\"com.azure.storage.file.datalake.DataLakeDirectoryClient\" data-throw-if-not-resolved=\"false\">DataLakeDirectoryClient</xref> used to interact with the directory created."
references:
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient"
  name: "DataLakeDirectoryAsyncClient"
  nameWithType: "DataLakeDirectoryAsyncClient"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient"
- uid: "com.azure.storage.blob.specialized.BlockBlobClient"
  spec.java:
  - uid: "com.azure.storage.blob.specialized.BlockBlobClient"
    name: "BlockBlobClient"
    fullName: "com.azure.storage.blob.specialized.BlockBlobClient"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient*"
  name: "DataLakeDirectoryClient"
  nameWithType: "DataLakeDirectoryClient.DataLakeDirectoryClient"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.DataLakeDirectoryClient"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakePathClient"
  name: "DataLakePathClient"
  nameWithType: "DataLakePathClient"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient"
- uid: "java.lang.String"
  spec.java:
  - uid: "java.lang.String"
    name: "String"
    fullName: "java.lang.String"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl*"
  name: "getDirectoryUrl"
  nameWithType: "DataLakeDirectoryClient.getDirectoryUrl"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryUrl"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath*"
  name: "getDirectoryPath"
  nameWithType: "DataLakeDirectoryClient.getDirectoryPath"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryPath"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName*"
  name: "getDirectoryName"
  nameWithType: "DataLakeDirectoryClient.getDirectoryName"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getDirectoryName"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.delete*"
  name: "delete"
  nameWithType: "DataLakeDirectoryClient.delete"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.delete"
  package: "com.azure.storage.file.datalake"
- uid: "boolean"
  spec.java:
  - uid: "boolean"
    name: "boolean"
    fullName: "boolean"
- uid: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
  name: "DataLakeRequestConditions"
  nameWithType: "DataLakeRequestConditions"
  fullName: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
- uid: "java.time.Duration"
  spec.java:
  - uid: "java.time.Duration"
    name: "Duration"
    fullName: "java.time.Duration"
- uid: "com.azure.core.util.Context"
  spec.java:
  - uid: "com.azure.core.util.Context"
    name: "Context"
    fullName: "com.azure.core.util.Context"
- uid: "com.azure.core.http.rest.Response<java.lang.Void>"
  spec.java:
  - uid: "com.azure.core.http.rest.Response"
    name: "Response"
    fullName: "com.azure.core.http.rest.Response"
  - name: "<"
    fullName: "<"
  - uid: "java.lang.Void"
    name: "Void"
    fullName: "java.lang.Void"
  - name: ">"
    fullName: ">"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse*"
  name: "deleteWithResponse"
  nameWithType: "DataLakeDirectoryClient.deleteWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient"
  name: "DataLakeFileClient"
  nameWithType: "DataLakeFileClient"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient*"
  name: "getFileClient"
  nameWithType: "DataLakeDirectoryClient.getFileClient"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getFileClient"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile*"
  name: "createFile"
  nameWithType: "DataLakeDirectoryClient.createFile"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFile"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.models.PathHttpHeaders"
  name: "PathHttpHeaders"
  nameWithType: "PathHttpHeaders"
  fullName: "com.azure.storage.file.datalake.models.PathHttpHeaders"
- uid: "java.util.Map<java.lang.String,java.lang.String>"
  spec.java:
  - uid: "java.util.Map"
    name: "Map"
    fullName: "java.util.Map"
  - name: "<"
    fullName: "<"
  - uid: "java.lang.String"
    name: "String"
    fullName: "java.lang.String"
  - name: ","
    fullName: ","
  - uid: "java.lang.String"
    name: "String"
    fullName: "java.lang.String"
  - name: ">"
    fullName: ">"
- uid: "com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeFileClient>"
  spec.java:
  - uid: "com.azure.core.http.rest.Response"
    name: "Response"
    fullName: "com.azure.core.http.rest.Response"
  - name: "<"
    fullName: "<"
  - uid: "com.azure.storage.file.datalake.DataLakeFileClient"
    name: "DataLakeFileClient"
    fullName: "com.azure.storage.file.datalake.DataLakeFileClient"
  - name: ">"
    fullName: ">"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse*"
  name: "createFileWithResponse"
  nameWithType: "DataLakeDirectoryClient.createFileWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createFileWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile*"
  name: "deleteFile"
  nameWithType: "DataLakeDirectoryClient.deleteFile"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFile"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse*"
  name: "deleteFileWithResponse"
  nameWithType: "DataLakeDirectoryClient.deleteFileWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteFileWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient*"
  name: "getSubdirectoryClient"
  nameWithType: "DataLakeDirectoryClient.getSubdirectoryClient"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.getSubdirectoryClient"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory*"
  name: "createSubdirectory"
  nameWithType: "DataLakeDirectoryClient.createSubdirectory"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectory"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeDirectoryClient>"
  spec.java:
  - uid: "com.azure.core.http.rest.Response"
    name: "Response"
    fullName: "com.azure.core.http.rest.Response"
  - name: "<"
    fullName: "<"
  - uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
    name: "DataLakeDirectoryClient"
    fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient"
  - name: ">"
    fullName: ">"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse*"
  name: "createSubdirectoryWithResponse"
  nameWithType: "DataLakeDirectoryClient.createSubdirectoryWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.createSubdirectoryWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory*"
  name: "deleteSubdirectory"
  nameWithType: "DataLakeDirectoryClient.deleteSubdirectory"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectory"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse*"
  name: "deleteSubdirectoryWithResponse"
  nameWithType: "DataLakeDirectoryClient.deleteSubdirectoryWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.deleteSubdirectoryWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.rename*"
  name: "rename"
  nameWithType: "DataLakeDirectoryClient.rename"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.rename"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse*"
  name: "renameWithResponse"
  nameWithType: "DataLakeDirectoryClient.renameWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeDirectoryClient.renameWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "java.lang.Object.wait()"
  name: "Object.wait()"
  nameWithType: "Object.wait()"
  fullName: "java.lang.Object.wait()"
- uid: "java.lang.Object.finalize()"
  name: "Object.finalize()"
  nameWithType: "Object.finalize()"
  fullName: "java.lang.Object.finalize()"
- uid: "java.lang.Object.clone()"
  name: "Object.clone()"
  nameWithType: "Object.clone()"
  fullName: "java.lang.Object.clone()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getProperties()"
  name: "DataLakePathClient.getProperties()"
  nameWithType: "DataLakePathClient.getProperties()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getProperties()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getObjectName()"
  name: "DataLakePathClient.getObjectName()"
  nameWithType: "DataLakePathClient.getObjectName()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getObjectName()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.existsWithResponse(java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.existsWithResponse(Duration,Context)"
  nameWithType: "DataLakePathClient.existsWithResponse(Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.existsWithResponse(java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)"
  name: "DataLakePathClient.setAccessControlList(List<PathAccessControlEntry>,String,String)"
  nameWithType: "DataLakePathClient.setAccessControlList(List<PathAccessControlEntry>,String,String)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.create()"
  name: "DataLakePathClient.create()"
  nameWithType: "DataLakePathClient.create()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.create()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.core.util.Context)"
  name: "DataLakePathClient.renameWithResponse(String,String,DataLakeRequestConditions,DataLakeRequestConditions,Context)"
  nameWithType: "DataLakePathClient.renameWithResponse(String,String,DataLakeRequestConditions,DataLakeRequestConditions,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getPathUrl()"
  name: "DataLakePathClient.getPathUrl()"
  nameWithType: "DataLakePathClient.getPathUrl()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getPathUrl()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map<String,String>,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map<String,String>,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getAccessControl()"
  name: "DataLakePathClient.getAccessControl()"
  nameWithType: "DataLakePathClient.getAccessControl()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getAccessControl()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.setMetadataWithResponse(Map<String,String>,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.setMetadataWithResponse(Map<String,String>,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "java.lang.Object.wait(long)"
  name: "Object.wait(long)"
  nameWithType: "Object.wait(long)"
  fullName: "java.lang.Object.wait(long)"
- uid: "java.lang.Object.getClass()"
  name: "Object.getClass()"
  nameWithType: "Object.getClass()"
  fullName: "java.lang.Object.getClass()"
- uid: "java.lang.Object.hashCode()"
  name: "Object.hashCode()"
  nameWithType: "Object.hashCode()"
  fullName: "java.lang.Object.hashCode()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getServiceVersion()"
  name: "DataLakePathClient.getServiceVersion()"
  nameWithType: "DataLakePathClient.getServiceVersion()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getServiceVersion()"
- uid: "java.lang.Object.wait(long,int)"
  name: "Object.wait(long,int)"
  nameWithType: "Object.wait(long,int)"
  fullName: "java.lang.Object.wait(long,int)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getAccountName()"
  name: "DataLakePathClient.getAccountName()"
  nameWithType: "DataLakePathClient.getAccountName()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getAccountName()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getBlockBlobClient()"
  name: "DataLakePathClient.getBlockBlobClient()"
  nameWithType: "DataLakePathClient.getBlockBlobClient()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getBlockBlobClient()"
- uid: "java.lang.Object.notify()"
  name: "Object.notify()"
  nameWithType: "Object.notify()"
  fullName: "java.lang.Object.notify()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getAccessControlWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.getAccessControlWithResponse(boolean,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.getAccessControlWithResponse(boolean,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getAccessControlWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "java.lang.Object.notifyAll()"
  name: "Object.notifyAll()"
  nameWithType: "Object.notifyAll()"
  fullName: "java.lang.Object.notifyAll()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)"
  name: "DataLakePathClient.generateSas(DataLakeServiceSasSignatureValues)"
  nameWithType: "DataLakePathClient.generateSas(DataLakeServiceSasSignatureValues)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)"
- uid: "java.lang.Object.equals(java.lang.Object)"
  name: "Object.equals(Object)"
  nameWithType: "Object.equals(Object)"
  fullName: "java.lang.Object.equals(java.lang.Object)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)"
  name: "DataLakePathClient.setMetadata(Map<String,String>)"
  nameWithType: "DataLakePathClient.setMetadata(Map<String,String>)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeadersWithResponse(com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.setHttpHeadersWithResponse(PathHttpHeaders,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.setHttpHeadersWithResponse(PathHttpHeaders,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeadersWithResponse(com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.exists()"
  name: "DataLakePathClient.exists()"
  nameWithType: "DataLakePathClient.exists()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.exists()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)"
  name: "DataLakePathClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues,UserDelegationKey)"
  nameWithType: "DataLakePathClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues,UserDelegationKey)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setPermissions(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String)"
  name: "DataLakePathClient.setPermissions(PathPermissions,String,String)"
  nameWithType: "DataLakePathClient.setPermissions(PathPermissions,String,String)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setPermissions(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String)"
- uid: "java.lang.Object.toString()"
  name: "Object.toString()"
  nameWithType: "Object.toString()"
  fullName: "java.lang.Object.toString()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getFileSystemName()"
  name: "DataLakePathClient.getFileSystemName()"
  nameWithType: "DataLakePathClient.getFileSystemName()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getFileSystemName()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.create(boolean)"
  name: "DataLakePathClient.create(boolean)"
  nameWithType: "DataLakePathClient.create(boolean)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.create(boolean)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setPermissionsWithResponse(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.setPermissionsWithResponse(PathPermissions,String,String,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.setPermissionsWithResponse(PathPermissions,String,String,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setPermissionsWithResponse(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeaders(com.azure.storage.file.datalake.models.PathHttpHeaders)"
  name: "DataLakePathClient.setHttpHeaders(PathHttpHeaders)"
  nameWithType: "DataLakePathClient.setHttpHeaders(PathHttpHeaders)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeaders(com.azure.storage.file.datalake.models.PathHttpHeaders)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getHttpPipeline()"
  name: "DataLakePathClient.getHttpPipeline()"
  nameWithType: "DataLakePathClient.getHttpPipeline()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getHttpPipeline()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.setAccessControlListWithResponse(List<PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.setAccessControlListWithResponse(List<PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getObjectPath()"
  name: "DataLakePathClient.getObjectPath()"
  nameWithType: "DataLakePathClient.getObjectPath()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getObjectPath()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getPropertiesWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.getPropertiesWithResponse(DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.getPropertiesWithResponse(DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getPropertiesWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "java.lang.Void"
  name: "Void"
  nameWithType: "Void"
  fullName: "java.lang.Void"
- uid: "com.azure.core.http.rest.Response"
  name: "Response"
  nameWithType: "Response"
  fullName: "com.azure.core.http.rest.Response"
- uid: "java.util.Map"
  name: "Map"
  nameWithType: "Map"
  fullName: "java.util.Map"
- uid: "java.lang.String,java.lang.String"
  name: "String,String"
  nameWithType: "String,String"
  fullName: "java.lang.String,java.lang.String"
- uid: "com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)"
  name: "PathAccessControlEntry>,String,String)"
  nameWithType: "PathAccessControlEntry>,String,String)"
  fullName: "com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List"
  name: "DataLakePathClient.setAccessControlList(List"
  nameWithType: "DataLakePathClient.setAccessControlList(List"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map"
  name: "DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map"
  nameWithType: "DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map"
- uid: "java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "String,String>,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "String,String>,DataLakeRequestConditions,Duration,Context)"
  fullName: "java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map"
  name: "DataLakePathClient.setMetadataWithResponse(Map"
  nameWithType: "DataLakePathClient.setMetadataWithResponse(Map"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map"
- uid: "java.lang.String,java.lang.String>)"
  name: "String,String>)"
  nameWithType: "String,String>)"
  fullName: "java.lang.String,java.lang.String>)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map"
  name: "DataLakePathClient.setMetadata(Map"
  nameWithType: "DataLakePathClient.setMetadata(Map"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List"
  name: "DataLakePathClient.setAccessControlListWithResponse(List"
  nameWithType: "DataLakePathClient.setAccessControlListWithResponse(List"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List"
- uid: "com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
