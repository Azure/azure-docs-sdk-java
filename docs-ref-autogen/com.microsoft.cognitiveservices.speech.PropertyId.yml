### YamlMime:JavaEnum
fields:
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_AudioProcessingOptions
  name: AudioConfig_AudioProcessingOptions
  nameWithType: PropertyId.AudioConfig_AudioProcessingOptions
  summary: <p>Audio processing options in JSON format. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_AudioProcessingOptions
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForRender
  name: AudioConfig_DeviceNameForRender
  nameWithType: PropertyId.AudioConfig_DeviceNameForRender
  summary: <p>The device name for audio render. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.audio.AudioConfig.fromSpeakerOutput(String)" data-throw-if-not-resolved="false" data-raw-source="AudioConfig.fromSpeakerOutput"></xref>. Added in version 1.17.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForRender
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_PlaybackBufferLengthInMs
  name: AudioConfig_PlaybackBufferLengthInMs
  nameWithType: PropertyId.AudioConfig_PlaybackBufferLengthInMs
  summary: <p>Playback buffer length in milliseconds, default is 50 milliseconds. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_PlaybackBufferLengthInMs
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_Reason
  name: CancellationDetails_Reason
  nameWithType: PropertyId.CancellationDetails_Reason
  summary: <p>The cancellation reason. Currently unused. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_Reason
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonDetailedText
  name: CancellationDetails_ReasonDetailedText
  nameWithType: PropertyId.CancellationDetails_ReasonDetailedText
  summary: <p>The cancellation detailed text. Currently unused. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonDetailedText
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonText
  name: CancellationDetails_ReasonText
  nameWithType: PropertyId.CancellationDetails_ReasonText
  summary: <p>The cancellation text. Currently unused. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonText
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_ApplicationId
  name: Conversation_ApplicationId
  nameWithType: PropertyId.Conversation_ApplicationId
  summary: <p>Identifier used to connect to the backend service. Added in version 1.5.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_ApplicationId
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Connection_Id
  name: Conversation_Connection_Id
  nameWithType: PropertyId.Conversation_Connection_Id
  summary: <p>Additional identifying information, such as a Direct Line token, used to authenticate with the backend service. Added in version 1.16.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Connection_Id
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Conversation_Id
  name: Conversation_Conversation_Id
  nameWithType: PropertyId.Conversation_Conversation_Id
  summary: <p>ConversationId for the session. Added in version 1.8.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Conversation_Id
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Custom_Voice_Deployment_Ids
  name: Conversation_Custom_Voice_Deployment_Ids
  nameWithType: PropertyId.Conversation_Custom_Voice_Deployment_Ids
  summary: <p>Comma separated list of custom voice deployment ids. Added in version 1.8.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Custom_Voice_Deployment_Ids
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_DialogType
  name: Conversation_DialogType
  nameWithType: PropertyId.Conversation_DialogType
  summary: <p>Type of dialog backend to connect to. Added in version 1.7.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_DialogType
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_From_Id
  name: Conversation_From_Id
  nameWithType: PropertyId.Conversation_From_Id
  summary: <p>From id to be used on speech recognition activities Added in version 1.5.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_From_Id
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Initial_Silence_Timeout
  name: Conversation_Initial_Silence_Timeout
  nameWithType: PropertyId.Conversation_Initial_Silence_Timeout
  summary: <p>Silence timeout for listening Added in version 1.5.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Initial_Silence_Timeout
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Request_Bot_Status_Messages
  name: Conversation_Request_Bot_Status_Messages
  nameWithType: PropertyId.Conversation_Request_Bot_Status_Messages
  summary: <p>A boolean value that specifies whether the client should receive status messages and generate corresponding turnStatusReceived events. Defaults to true. Added in version 1.15.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Request_Bot_Status_Messages
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Speech_Activity_Template
  name: Conversation_Speech_Activity_Template
  nameWithType: PropertyId.Conversation_Speech_Activity_Template
  summary: <p>Speech activity template, stamp properties in the template on the activity generated by the service for speech. Added in version 1.10.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Speech_Activity_Template
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.DataBuffer_TimeStamp
  name: DataBuffer_TimeStamp
  nameWithType: PropertyId.DataBuffer_TimeStamp
  summary: <p>The time stamp associated to data buffer written by client when using Pull/Push audio mode streams. The time stamp is a 64-bit value with a resolution of 90 kHz. The same as the presentation timestamp in an MPEG transport stream. See <a href="https://en.wikipedia.org/wiki/Presentation_timestamp">https://en.wikipedia.org/wiki/Presentation_timestamp</a>. Added in version 1.5.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.DataBuffer_TimeStamp
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.DataBuffer_UserId
  name: DataBuffer_UserId
  nameWithType: PropertyId.DataBuffer_UserId
  summary: <p>The user id associated to data buffer written by client when using Pull/Push audio mode streams. Added in version 1.5.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.DataBuffer_UserId
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult
  name: LanguageUnderstandingServiceResponse_JsonResult
  nameWithType: PropertyId.LanguageUnderstandingServiceResponse_JsonResult
  summary: <p>The Language Understanding Service response output (in JSON format). Available via IntentRecognitionResult.Properties. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_EnableMiscue
  name: PronunciationAssessment_EnableMiscue
  nameWithType: PropertyId.PronunciationAssessment_EnableMiscue
  summary: <p>Defines if enable miscue calculation. With this enabled, the pronounced words will be compared to the reference text, and will be marked with omission/insertion based on the comparison. The default setting is False. Under normal circumstances, you shouldn't have to use this property directly. Added in version 1.14.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_EnableMiscue
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_GradingSystem
  name: PronunciationAssessment_GradingSystem
  nameWithType: PropertyId.PronunciationAssessment_GradingSystem
  summary: <p>The point system for pronunciation score calibration (FivePoint or HundredMark). Under normal circumstances, you shouldn't have to use this property directly. Added in version 1.14.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_GradingSystem
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Granularity
  name: PronunciationAssessment_Granularity
  nameWithType: PropertyId.PronunciationAssessment_Granularity
  summary: <p>The pronunciation evaluation granularity (Phoneme, Word, or FullText). Under normal circumstances, you shouldn't have to use this property directly. Added in version 1.14.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Granularity
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Json
  name: PronunciationAssessment_Json
  nameWithType: PropertyId.PronunciationAssessment_Json
  summary: <p>The json string of pronunciation assessment parameters Under normal circumstances, you shouldn't have to use this property directly. Added in version 1.14.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Json
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_NBestPhonemeCount
  name: PronunciationAssessment_NBestPhonemeCount
  nameWithType: PropertyId.PronunciationAssessment_NBestPhonemeCount
  summary: <p>The pronunciation evaluation nbest phoneme count. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.PronunciationAssessmentConfig.setNBestPhonemeCount(int)" data-throw-if-not-resolved="false" data-raw-source="PronunciationAssessmentConfig.setNBestPhonemeCount"></xref>. Added in version 1.20.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_NBestPhonemeCount
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Params
  name: PronunciationAssessment_Params
  nameWithType: PropertyId.PronunciationAssessment_Params
  summary: <p>Pronunciation assessment parameters. This property is intended to be read-only. The SDK is using it internally. Added in version 1.14.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Params
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_PhonemeAlphabet
  name: PronunciationAssessment_PhonemeAlphabet
  nameWithType: PropertyId.PronunciationAssessment_PhonemeAlphabet
  summary: <p>The pronunciation evaluation phoneme alphabet. The valid values are "SAPI" (default) and "IPA" Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.PronunciationAssessmentConfig.setPhonemeAlphabet(String)" data-throw-if-not-resolved="false" data-raw-source="PronunciationAssessmentConfig.setPhonemeAlphabet"></xref>. Added in version 1.20.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_PhonemeAlphabet
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_ReferenceText
  name: PronunciationAssessment_ReferenceText
  nameWithType: PropertyId.PronunciationAssessment_ReferenceText
  summary: <p>The reference text of the audio for pronunciation evaluation. For this and the following pronunciation assessment parameters, see <a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters">https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters</a> for details. Under normal circumstances, you shouldn't have to use this property directly. Added in version 1.14.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_ReferenceText
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeakerRecognition_Api_Version
  name: SpeakerRecognition_Api_Version
  nameWithType: PropertyId.SpeakerRecognition_Api_Version
  summary: <p>Version of Speaker Recognition to use. Added in version 1.18.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeakerRecognition_Api_Version
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.Speech_LogFilename
  name: Speech_LogFilename
  nameWithType: PropertyId.Speech_LogFilename
  summary: <p>The file name to write logs. Added in version 1.4.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.Speech_LogFilename
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.Speech_SessionId
  name: Speech_SessionId
  nameWithType: PropertyId.Speech_SessionId
  summary: <p>The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream and the underlying speech recognition instance to which its bound. Under normal circumstances, you shouldn't have to use this property directly. Instead use <xref uid="com.microsoft.cognitiveservices.speech.SessionEventArgs.getSessionId()" data-throw-if-not-resolved="false" data-raw-source="SessionEventArgs.getSessionId"></xref>. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.Speech_SessionId
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Token
  name: SpeechServiceAuthorization_Token
  nameWithType: PropertyId.SpeechServiceAuthorization_Token
  summary: <p>The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.SpeechConfig.fromAuthorizationToken(String,String)" data-throw-if-not-resolved="false" data-raw-source="SpeechConfig.fromAuthorizationToken"></xref>, <xref uid="com.microsoft.cognitiveservices.speech.SpeechRecognizer.setAuthorizationToken(String)" data-throw-if-not-resolved="false" data-raw-source="SpeechRecognizer.setAuthorizationToken"></xref>, IntentRecognizer.setAuthorizationToken, TranslationRecognizer.setAuthorizationToken. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Token
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Type
  name: SpeechServiceAuthorization_Type
  nameWithType: PropertyId.SpeechServiceAuthorization_Type
  summary: <p>The Cognitive Services Speech Service authorization type. Currently unused. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Type
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult
  name: SpeechServiceConnection_AutoDetectSourceLanguageResult
  nameWithType: PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult
  summary: <p>The auto detect source language result Added in version 1.8.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages
  name: SpeechServiceConnection_AutoDetectSourceLanguages
  nameWithType: PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages
  summary: <p>The auto detect source languages Added in version 1.8.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EnableAudioLogging
  name: SpeechServiceConnection_EnableAudioLogging
  nameWithType: PropertyId.SpeechServiceConnection_EnableAudioLogging
  summary: <p>A boolean value specifying whether audio logging is enabled in the service or not. Added in version 1.5.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EnableAudioLogging
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Endpoint
  name: SpeechServiceConnection_Endpoint
  nameWithType: PropertyId.SpeechServiceConnection_Endpoint
  summary: "<p>The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.fromEndpoint(java.net.URI,String)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"SpeechConfig.fromEndpoint\"></xref>. NOTE: This endpoint is not the same as the endpoint used to obtain an access token. </p>"
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Endpoint
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndpointId
  name: SpeechServiceConnection_EndpointId
  nameWithType: PropertyId.SpeechServiceConnection_EndpointId
  summary: "<p>The Cognitive Services Custom Speech or Custom Voice Service endpoint id. Under normal circumstances, you shouldn't have to use this property directly. Instead use <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.setEndpointId(String)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"SpeechConfig.setEndpointId\"></xref>. NOTE: The endpoint id is available in the Custom Speech Portal, listed under Endpoint Details. </p>"
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndpointId
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs
  name: SpeechServiceConnection_EndSilenceTimeoutMs
  nameWithType: PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs
  summary: <p>The end silence timeout value (in milliseconds) used by the service. Added in version 1.5.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Host
  name: SpeechServiceConnection_Host
  nameWithType: PropertyId.SpeechServiceConnection_Host
  summary: <p>The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.SpeechConfig.fromHost(java.net.URI,String)" data-throw-if-not-resolved="false" data-raw-source="SpeechConfig.fromHost"></xref>. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Host
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs
  name: SpeechServiceConnection_InitialSilenceTimeoutMs
  nameWithType: PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs
  summary: <p>The initial silence timeout value (in milliseconds) used by the service. Added in version 1.5.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_IntentRegion
  name: SpeechServiceConnection_IntentRegion
  nameWithType: PropertyId.SpeechServiceConnection_IntentRegion
  summary: <p>The Language Understanding Service region. Under normal circumstances, you shouldn't have to use this property directly. Instead, use LanguageUnderstandingModel. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_IntentRegion
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Key
  name: SpeechServiceConnection_Key
  nameWithType: PropertyId.SpeechServiceConnection_Key
  summary: <p>The Cognitive Services Speech Service subscription key. If you are using an intent recognizer, you need to specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.SpeechConfig.fromSubscription(String,String)" data-throw-if-not-resolved="false" data-raw-source="SpeechConfig.fromSubscription"></xref>. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Key
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostName
  name: SpeechServiceConnection_ProxyHostName
  nameWithType: PropertyId.SpeechServiceConnection_ProxyHostName
  summary: "<p>The host name of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.setProxy(String,int,String,String)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"SpeechConfig.setProxy\"></xref>. NOTE: This property id was added in version 1.1.0. </p>"
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostName
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPassword
  name: SpeechServiceConnection_ProxyPassword
  nameWithType: PropertyId.SpeechServiceConnection_ProxyPassword
  summary: "<p>The password of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.setProxy(String,int,String,String)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"SpeechConfig.setProxy\"></xref>. NOTE: This property id was added in version 1.1.0. </p>"
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPassword
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPort
  name: SpeechServiceConnection_ProxyPort
  nameWithType: PropertyId.SpeechServiceConnection_ProxyPort
  summary: "<p>The port of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.setProxy(String,int,String,String)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"SpeechConfig.setProxy\"></xref>. NOTE: This property id was added in version 1.1.0. </p>"
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPort
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyUserName
  name: SpeechServiceConnection_ProxyUserName
  nameWithType: PropertyId.SpeechServiceConnection_ProxyUserName
  summary: "<p>The user name of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.setProxy(String,int,String,String)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"SpeechConfig.setProxy\"></xref>. NOTE: This property id was added in version 1.1.0. </p>"
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyUserName
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoBackend
  name: SpeechServiceConnection_RecoBackend
  nameWithType: PropertyId.SpeechServiceConnection_RecoBackend
  summary: <p>The string to specify the backend to be used for speech recognition; allowed options are online and offline. Under normal circumstances, you shouldn't use this property directly. Currently the offline option is only valid when EmbeddedSpeechConfig is used. Added in version 1.19.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoBackend
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoLanguage
  name: SpeechServiceConnection_RecoLanguage
  nameWithType: PropertyId.SpeechServiceConnection_RecoLanguage
  summary: <p>The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.SpeechConfig.setSpeechRecognitionLanguage(String)" data-throw-if-not-resolved="false" data-raw-source="SpeechConfig.setSpeechRecognitionLanguage"></xref>. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoLanguage
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoMode
  name: SpeechServiceConnection_RecoMode
  nameWithType: PropertyId.SpeechServiceConnection_RecoMode
  summary: <p>The Cognitive Services Speech Service recognition mode. Can be "INTERACTIVE", "CONVERSATION", "DICTATION". This property is intended to be read-only. The SDK is using it internally. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoMode
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoModelKey
  name: SpeechServiceConnection_RecoModelKey
  nameWithType: PropertyId.SpeechServiceConnection_RecoModelKey
  summary: <p>The decryption key of the model to be used for speech recognition. Under normal circumstances, you shouldn't use this property directly. Currently this is only valid when EmbeddedSpeechConfig is used. Added in version 1.19.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoModelKey
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoModelName
  name: SpeechServiceConnection_RecoModelName
  nameWithType: PropertyId.SpeechServiceConnection_RecoModelName
  summary: <p>The name of the model to be used for speech recognition. Under normal circumstances, you shouldn't use this property directly. Currently this is only valid when EmbeddedSpeechConfig is used. Added in version 1.19.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoModelName
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Region
  name: SpeechServiceConnection_Region
  nameWithType: PropertyId.SpeechServiceConnection_Region
  summary: <p>The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.SpeechConfig.fromSubscription(String,String)" data-throw-if-not-resolved="false" data-raw-source="SpeechConfig.fromSubscription"></xref>, <xref uid="com.microsoft.cognitiveservices.speech.SpeechConfig.fromEndpoint(java.net.URI,String)" data-throw-if-not-resolved="false" data-raw-source="SpeechConfig.fromEndpoint"></xref>, <xref uid="com.microsoft.cognitiveservices.speech.SpeechConfig.fromHost(java.net.URI,String)" data-throw-if-not-resolved="false" data-raw-source="SpeechConfig.fromHost"></xref>, <xref uid="com.microsoft.cognitiveservices.speech.SpeechConfig.fromAuthorizationToken(String,String)" data-throw-if-not-resolved="false" data-raw-source="SpeechConfig.fromAuthorizationToken"></xref>. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Region
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthBackend
  name: SpeechServiceConnection_SynthBackend
  nameWithType: PropertyId.SpeechServiceConnection_SynthBackend
  summary: <p>The string to specify TTS backend; valid options are online and offline. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig.fromPath(String)" data-throw-if-not-resolved="false" data-raw-source="EmbeddedSpeechConfig.fromPath"></xref> or <xref uid="com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig.fromPaths(List&lt;String&gt;)" data-throw-if-not-resolved="false" data-raw-source="EmbeddedSpeechConfig.fromPaths"></xref> to set the synthesis backend to offline. Added in version 1.19.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthBackend
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthEnableCompressedAudioTransmission
  name: SpeechServiceConnection_SynthEnableCompressedAudioTransmission
  nameWithType: PropertyId.SpeechServiceConnection_SynthEnableCompressedAudioTransmission
  summary: <p>Indicates if use compressed audio format for speech synthesis audio transmission. This property only affects when SpeechServiceConnection_SynthOutputFormat is set to a pcm format. If this property is not set and GStreamer is available, SDK will use compressed format for synthesized audio transmission, and decode it. You can set this property to "false" to use raw pcm format for transmission on wire. Added in version 1.16.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthEnableCompressedAudioTransmission
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthLanguage
  name: SpeechServiceConnection_SynthLanguage
  nameWithType: PropertyId.SpeechServiceConnection_SynthLanguage
  summary: <p>The spoken language to be synthesized (e.g. en-US) Added in version 1.7.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthLanguage
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthModelKey
  name: SpeechServiceConnection_SynthModelKey
  nameWithType: PropertyId.SpeechServiceConnection_SynthModelKey
  summary: <p>The decryption key of the model to be used for speech synthesis. Under normal circumstances, you shouldn't use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig.setSpeechSynthesisVoice(String,String)" data-throw-if-not-resolved="false" data-raw-source="EmbeddedSpeechConfig.setSpeechSynthesisVoice"></xref>. Added in version 1.19.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthModelKey
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOfflineDataPath
  name: SpeechServiceConnection_SynthOfflineDataPath
  nameWithType: PropertyId.SpeechServiceConnection_SynthOfflineDataPath
  summary: <p>The data file path(s) for offline synthesis engine; only valid when synthesis backend is offline. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig.fromPath(String)" data-throw-if-not-resolved="false" data-raw-source="EmbeddedSpeechConfig.fromPath"></xref> or <xref uid="com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig.fromPaths(List&lt;String&gt;)" data-throw-if-not-resolved="false" data-raw-source="EmbeddedSpeechConfig.fromPaths"></xref>. Added in version 1.19.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOfflineDataPath
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOfflineVoice
  name: SpeechServiceConnection_SynthOfflineVoice
  nameWithType: PropertyId.SpeechServiceConnection_SynthOfflineVoice
  summary: <p>The name of the offline TTS voice to be used for speech synthesis. Under normal circumstances, you shouldn't use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig.setSpeechSynthesisVoice(String,String)" data-throw-if-not-resolved="false" data-raw-source="EmbeddedSpeechConfig.setSpeechSynthesisVoice"></xref>. Added in version 1.19.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOfflineVoice
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOutputFormat
  name: SpeechServiceConnection_SynthOutputFormat
  nameWithType: PropertyId.SpeechServiceConnection_SynthOutputFormat
  summary: <p>The string to specify TTS output audio format (e.g. riff-16khz-16bit-mono-pcm) Added in version 1.7.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOutputFormat
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthVoice
  name: SpeechServiceConnection_SynthVoice
  nameWithType: PropertyId.SpeechServiceConnection_SynthVoice
  summary: <p>The name of the TTS voice to be used for speech synthesis Added in version 1.7.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthVoice
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationFeatures
  name: SpeechServiceConnection_TranslationFeatures
  nameWithType: PropertyId.SpeechServiceConnection_TranslationFeatures
  summary: <p>Translation features. For internal use. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationFeatures
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationToLanguages
  name: SpeechServiceConnection_TranslationToLanguages
  nameWithType: PropertyId.SpeechServiceConnection_TranslationToLanguages
  summary: <p>The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances, you shouldn't have to use this property directly. Instead, use SpeechTranslationConfig.addTargetLanguage, SpeechTranslationConfig.getTargetLanguages, TranslationRecognizer.getTargetLanguages. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationToLanguages
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationVoice
  name: SpeechServiceConnection_TranslationVoice
  nameWithType: PropertyId.SpeechServiceConnection_TranslationVoice
  summary: "<p>The name of the Cognitive Service Text to Speech Service voice. Under normal circumstances, you shouldn't have to use this property directly. Instead use SpeechTranslationConfig.setVoiceName. NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>. </p>"
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationVoice
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Url
  name: SpeechServiceConnection_Url
  nameWithType: PropertyId.SpeechServiceConnection_Url
  summary: '<p>The URL string built from speech configuration. This property is intended to be read-only. The SDK is using it internally. NOTE: Added in version 1.5.0. </p>'
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Url
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_VoicesListEndpoint
  name: SpeechServiceConnection_VoicesListEndpoint
  nameWithType: PropertyId.SpeechServiceConnection_VoicesListEndpoint
  summary: <p>The Cognitive Services Speech Service voices list api endpoint (url). Under normal circumstances, you don't need to specify this property, SDK will construct it based on the region/host/endpoint of <xref uid="com.microsoft.cognitiveservices.speech.SpeechConfig" data-throw-if-not-resolved="false" data-raw-source="SpeechConfig"></xref>. Added in version 1.16.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_VoicesListEndpoint
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonErrorDetails
  name: SpeechServiceResponse_JsonErrorDetails
  nameWithType: PropertyId.SpeechServiceResponse_JsonErrorDetails
  summary: <p>The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid="com.microsoft.cognitiveservices.speech.CancellationDetails.getErrorDetails()" data-throw-if-not-resolved="false" data-raw-source="CancellationDetails.getErrorDetails"></xref>. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonErrorDetails
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonResult
  name: SpeechServiceResponse_JsonResult
  nameWithType: PropertyId.SpeechServiceResponse_JsonResult
  summary: <p>The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonResult
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_OutputFormatOption
  name: SpeechServiceResponse_OutputFormatOption
  nameWithType: PropertyId.SpeechServiceResponse_OutputFormatOption
  summary: <p>A string value specifying the output format option in the response result. Internal use only. Added in version 1.5.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_OutputFormatOption
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_PostProcessingOption
  name: SpeechServiceResponse_PostProcessingOption
  nameWithType: PropertyId.SpeechServiceResponse_PostProcessingOption
  summary: <p>A string value specifying which post processing option should be used by service. Allowed values are "TrueText". Added in version 1.5.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_PostProcessingOption
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_ProfanityOption
  name: SpeechServiceResponse_ProfanityOption
  nameWithType: PropertyId.SpeechServiceResponse_ProfanityOption
  summary: <p>The requested Cognitive Services Speech Service response output profanity setting. Allowed values are "masked", "removed", and "raw". Added in version 1.5.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_ProfanityOption
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs
  name: SpeechServiceResponse_RecognitionLatencyMs
  nameWithType: PropertyId.SpeechServiceResponse_RecognitionLatencyMs
  summary: <p>The recognition latency in milliseconds. Read-only, available on final speech/translation/intent results. This measures the latency between when an audio input is received by the SDK, and the moment the final result is received from the service. The SDK computes the time difference between the last audio fragment from the audio input that is contributing to the final result, and the time the final result is received from the speech service. Added in version 1.3.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
  name: SpeechServiceResponse_RequestDetailedResultTrueFalse
  nameWithType: PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
  summary: <p>The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have to use this property directly. Instead use <xref uid="com.microsoft.cognitiveservices.speech.SpeechConfig.setOutputFormat(OutputFormat)" data-throw-if-not-resolved="false" data-raw-source="SpeechConfig.setOutputFormat"></xref>. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
  name: SpeechServiceResponse_RequestProfanityFilterTrueFalse
  nameWithType: PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
  summary: <p>The requested Cognitive Services Speech Service response output profanity level. Currently unused. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestSnr
  name: SpeechServiceResponse_RequestSnr
  nameWithType: PropertyId.SpeechServiceResponse_RequestSnr
  summary: <p>A boolean value specifying whether to include SNR (signal to noise ratio) in the response result. Added in version 1.18.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestSnr
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps
  name: SpeechServiceResponse_RequestWordLevelTimestamps
  nameWithType: PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps
  summary: <p>A boolean value specifying whether to include word-level timestamps in the response result. Added in version 1.5.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_StablePartialResultThreshold
  name: SpeechServiceResponse_StablePartialResultThreshold
  nameWithType: PropertyId.SpeechServiceResponse_StablePartialResultThreshold
  summary: <p>The number of times a word has to be in partial results to be returned. Added in version 1.5.0 </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_StablePartialResultThreshold
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisBackend
  name: SpeechServiceResponse_SynthesisBackend
  nameWithType: PropertyId.SpeechServiceResponse_SynthesisBackend
  summary: <p>Indicates which backend the synthesis is finished by. Read-only, available on speech synthesis results, except for the result in SynthesisStarted event. Added in version 1.17.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisBackend
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisFinishLatencyMs
  name: SpeechServiceResponse_SynthesisFinishLatencyMs
  nameWithType: PropertyId.SpeechServiceResponse_SynthesisFinishLatencyMs
  summary: <p>The speech synthesis all bytes latency in milliseconds. Read-only, available on final speech synthesis results. This measures the latency between when the synthesis is started to be processed, and the moment the whole audio is synthesized. Added in version 1.17.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisFinishLatencyMs
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisFirstByteLatencyMs
  name: SpeechServiceResponse_SynthesisFirstByteLatencyMs
  nameWithType: PropertyId.SpeechServiceResponse_SynthesisFirstByteLatencyMs
  summary: <p>The speech synthesis first byte latency in milliseconds. Read-only, available on final speech synthesis results. This measures the latency between when the synthesis is started to be processed, and the moment the first byte audio is available. Added in version 1.17.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisFirstByteLatencyMs
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisUnderrunTimeMs
  name: SpeechServiceResponse_SynthesisUnderrunTimeMs
  nameWithType: PropertyId.SpeechServiceResponse_SynthesisUnderrunTimeMs
  summary: <p>The underrun time for speech synthesis in milliseconds. Read-only, available on results in SynthesisCompleted events. This measures the total underrun time from <xref uid="com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_PlaybackBufferLengthInMs" data-throw-if-not-resolved="false" data-raw-source="PropertyId.AudioConfig_PlaybackBufferLengthInMs"></xref> is filled to synthesis completed. Added in version 1.17.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisUnderrunTimeMs
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult
  name: SpeechServiceResponse_TranslationRequestStablePartialResult
  nameWithType: PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult
  summary: <p>A boolean value to request for stabilizing translation partial results by omitting words in the end. Added in version 1.5.0. </p>
  uid: com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult
inheritances:
- <xref href="java.lang.Object" data-throw-if-not-resolved="False"/>
- <xref href="java.lang.Enum&lt;PropertyId&gt;" data-throw-if-not-resolved="False"/>
methods:
- fullName: com.microsoft.cognitiveservices.speech.PropertyId.getValue()
  name: getValue()
  nameWithType: PropertyId.getValue()
  returns:
    description: <p>the speech property id </p>
    type: <xref href="int?alt=int&text=int" data-throw-if-not-resolved="False"/>
  summary: >-
    <p>Returns the internal value property id</p>

    <p></p>
  syntax: public int getValue()
  uid: com.microsoft.cognitiveservices.speech.PropertyId.getValue()
nameWithType: PropertyId
syntax: public enum PropertyId
uid: com.microsoft.cognitiveservices.speech.PropertyId
fullName: com.microsoft.cognitiveservices.speech.PropertyId
name: PropertyId
package: com.microsoft.cognitiveservices.speech
summary: <p>Defines property ids. Changed in version 1.8.0. </p>
metadata: {}
