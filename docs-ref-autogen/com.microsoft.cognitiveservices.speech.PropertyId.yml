### YamlMime:JavaEnum
uid: "com.microsoft.cognitiveservices.speech.PropertyId"
fullName: "com.microsoft.cognitiveservices.speech.PropertyId"
name: "PropertyId"
nameWithType: "PropertyId"
summary: "Defines property ids."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
- "<xref href=\"java.lang.Enum?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedClassMethods:
- classRef: "<xref href=\"java.lang.Enum?alt=java.lang.Enum&text=Enum\" data-throw-if-not-resolved=\"False\" />"
  methodsRef:
  - "<xref href=\"java.lang.Enum.<T>valueOf(java.lang.Class<T>,java.lang.String)?alt=java.lang.Enum.<T>valueOf&text=<T>valueOf\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Enum.clone()?alt=java.lang.Enum.clone&text=clone\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Enum.compareTo(E)?alt=java.lang.Enum.compareTo&text=compareTo\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Enum.describeConstable()?alt=java.lang.Enum.describeConstable&text=describeConstable\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Enum.equals(java.lang.Object)?alt=java.lang.Enum.equals&text=equals\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Enum.finalize()?alt=java.lang.Enum.finalize&text=finalize\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Enum.getDeclaringClass()?alt=java.lang.Enum.getDeclaringClass&text=getDeclaringClass\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Enum.hashCode()?alt=java.lang.Enum.hashCode&text=hashCode\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Enum.name()?alt=java.lang.Enum.name&text=name\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Enum.ordinal()?alt=java.lang.Enum.ordinal&text=ordinal\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Enum.toString()?alt=java.lang.Enum.toString&text=toString\" data-throw-if-not-resolved=\"False\" />"
- classRef: "<xref href=\"java.lang.Object?alt=java.lang.Object&text=Object\" data-throw-if-not-resolved=\"False\" />"
  methodsRef:
  - "<xref href=\"java.lang.Object.getClass()?alt=java.lang.Object.getClass&text=getClass\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Object.notify()?alt=java.lang.Object.notify&text=notify\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Object.notifyAll()?alt=java.lang.Object.notifyAll&text=notifyAll\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Object.wait()?alt=java.lang.Object.wait&text=wait\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Object.wait(long)?alt=java.lang.Object.wait&text=wait\" data-throw-if-not-resolved=\"False\" />"
  - "<xref href=\"java.lang.Object.wait(long,int)?alt=java.lang.Object.wait&text=wait\" data-throw-if-not-resolved=\"False\" />"
syntax: "public enum **PropertyId**</br> extends <xref href=\"java.lang.Enum?alt=java.lang.Enum&text=Enum\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.microsoft.cognitiveservices.speech.PropertyId?alt=com.microsoft.cognitiveservices.speech.PropertyId&text=PropertyId\" data-throw-if-not-resolved=\"False\" />&gt;"
fields:
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_AudioProcessingOptions"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_AudioProcessingOptions"
  name: "AudioConfig_AudioProcessingOptions"
  nameWithType: "PropertyId.AudioConfig_AudioProcessingOptions"
  summary: "Audio processing options in JSON format."
  desc: "Audio processing options in JSON format."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForRender"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForRender"
  name: "AudioConfig_DeviceNameForRender"
  nameWithType: "PropertyId.AudioConfig_DeviceNameForRender"
  summary: "The device name for audio render."
  desc: "The device name for audio render. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.audio.AudioConfig.fromSpeakerOutput\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.audio.AudioConfig#fromSpeakerOutput\"></xref>. Added in version 1.17.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_PlaybackBufferLengthInMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_PlaybackBufferLengthInMs"
  name: "AudioConfig_PlaybackBufferLengthInMs"
  nameWithType: "PropertyId.AudioConfig_PlaybackBufferLengthInMs"
  summary: "Playback buffer length in milliseconds, default is 50 milliseconds."
  desc: "Playback buffer length in milliseconds, default is 50 milliseconds."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_Reason"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_Reason"
  name: "CancellationDetails_Reason"
  nameWithType: "PropertyId.CancellationDetails_Reason"
  summary: "The cancellation reason."
  desc: "The cancellation reason. Currently unused."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonDetailedText"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonDetailedText"
  name: "CancellationDetails_ReasonDetailedText"
  nameWithType: "PropertyId.CancellationDetails_ReasonDetailedText"
  summary: "The cancellation detailed text."
  desc: "The cancellation detailed text. Currently unused."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonText"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonText"
  name: "CancellationDetails_ReasonText"
  nameWithType: "PropertyId.CancellationDetails_ReasonText"
  summary: "The cancellation text."
  desc: "The cancellation text. Currently unused."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_ApplicationId"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_ApplicationId"
  name: "Conversation_ApplicationId"
  nameWithType: "PropertyId.Conversation_ApplicationId"
  summary: "Identifier used to connect to the backend service."
  desc: "Identifier used to connect to the backend service. Added in version 1.5.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Connection_Id"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Connection_Id"
  name: "Conversation_Connection_Id"
  nameWithType: "PropertyId.Conversation_Connection_Id"
  summary: "Additional identifying information, such as a Direct Line token, used to authenticate with the backend service."
  desc: "Additional identifying information, such as a Direct Line token, used to authenticate with the backend service. Added in version 1.16.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Conversation_Id"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Conversation_Id"
  name: "Conversation_Conversation_Id"
  nameWithType: "PropertyId.Conversation_Conversation_Id"
  summary: "Conversation<wbr>Id for the session."
  desc: "ConversationId for the session. Added in version 1.8.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Custom_Voice_Deployment_Ids"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Custom_Voice_Deployment_Ids"
  name: "Conversation_Custom_Voice_Deployment_Ids"
  nameWithType: "PropertyId.Conversation_Custom_Voice_Deployment_Ids"
  summary: "Comma separated list of custom voice deployment ids."
  desc: "Comma separated list of custom voice deployment ids. Added in version 1.8.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_DialogType"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_DialogType"
  name: "Conversation_DialogType"
  nameWithType: "PropertyId.Conversation_DialogType"
  summary: "Type of dialog backend to connect to."
  desc: "Type of dialog backend to connect to. Added in version 1.7.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_From_Id"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_From_Id"
  name: "Conversation_From_Id"
  nameWithType: "PropertyId.Conversation_From_Id"
  summary: "From id to be used on speech recognition activities Added in version 1.5.0."
  desc: "From id to be used on speech recognition activities Added in version 1.5.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Initial_Silence_Timeout"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Initial_Silence_Timeout"
  name: "Conversation_Initial_Silence_Timeout"
  nameWithType: "PropertyId.Conversation_Initial_Silence_Timeout"
  summary: "Silence timeout for listening Added in version 1.5.0."
  desc: "Silence timeout for listening Added in version 1.5.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Request_Bot_Status_Messages"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Request_Bot_Status_Messages"
  name: "Conversation_Request_Bot_Status_Messages"
  nameWithType: "PropertyId.Conversation_Request_Bot_Status_Messages"
  summary: "A boolean value that specifies whether the client should receive status messages and generate corresponding turn<wbr>Status<wbr>Received events."
  desc: "A boolean value that specifies whether the client should receive status messages and generate corresponding turnStatusReceived events. Defaults to true. Added in version 1.15.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Speech_Activity_Template"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Conversation_Speech_Activity_Template"
  name: "Conversation_Speech_Activity_Template"
  nameWithType: "PropertyId.Conversation_Speech_Activity_Template"
  summary: "Speech activity template, stamp properties in the template on the activity generated by the service for speech."
  desc: "Speech activity template, stamp properties in the template on the activity generated by the service for speech. Added in version 1.10.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.DataBuffer_TimeStamp"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.DataBuffer_TimeStamp"
  name: "DataBuffer_TimeStamp"
  nameWithType: "PropertyId.DataBuffer_TimeStamp"
  summary: "The time stamp associated to data buffer written by client when using Pull/Push audio mode streams."
  desc: "The time stamp associated to data buffer written by client when using Pull/Push audio mode streams. The time stamp is a 64-bit value with a resolution of 90 kHz. The same as the presentation timestamp in an MPEG transport stream. See https://en.wikipedia.org/wiki/Presentation\\_timestamp. Added in version 1.5.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.DataBuffer_UserId"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.DataBuffer_UserId"
  name: "DataBuffer_UserId"
  nameWithType: "PropertyId.DataBuffer_UserId"
  summary: "The user id associated to data buffer written by client when using Pull/Push audio mode streams."
  desc: "The user id associated to data buffer written by client when using Pull/Push audio mode streams. Added in version 1.5.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.EmbeddedSpeech_EnablePerformanceMetrics"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.EmbeddedSpeech_EnablePerformanceMetrics"
  name: "EmbeddedSpeech_EnablePerformanceMetrics"
  nameWithType: "PropertyId.EmbeddedSpeech_EnablePerformanceMetrics"
  summary: "Enable the collection of embedded speech performance metrics which can be used to evaluate the capability of a device to use embedded speech."
  desc: "Enable the collection of embedded speech performance metrics which can be used to evaluate the capability of a device to use embedded speech. The collected data is included in results from specific scenarios like speech recognition. The default setting is \"false\". Note that metrics may not be available from all embedded speech scenarios."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.KeywordRecognition_ModelKey"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.KeywordRecognition_ModelKey"
  name: "KeywordRecognition_ModelKey"
  nameWithType: "PropertyId.KeywordRecognition_ModelKey"
  summary: "This property is deprecated."
  desc: "This property is deprecated."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.KeywordRecognition_ModelName"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.KeywordRecognition_ModelName"
  name: "KeywordRecognition_ModelName"
  nameWithType: "PropertyId.KeywordRecognition_ModelName"
  summary: "The name of a model to be used for keyword recognition."
  desc: "The name of a model to be used for keyword recognition. Do not use this property directly. Currently this is only valid when EmbeddedSpeechConfig is used."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult"
  name: "LanguageUnderstandingServiceResponse_JsonResult"
  nameWithType: "PropertyId.LanguageUnderstandingServiceResponse_JsonResult"
  summary: "The Language Understanding Service response output (in JSON format)."
  desc: "The Language Understanding Service response output (in JSON format). Available via <xref uid=\"com.microsoft.cognitiveservices.speech.intent.IntentRecognitionResult.toString\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.intent.IntentRecognitionResult#toString\"></xref>."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_ContentTopic"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_ContentTopic"
  name: "PronunciationAssessment_ContentTopic"
  nameWithType: "PropertyId.PronunciationAssessment_ContentTopic"
  summary: "The content type of the pronunciation assessment."
  desc: "The content type of the pronunciation assessment. Under normal circumstances, you shouldn't have to use this property directly. instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.PronunciationAssessmentConfig.enableContentAssessmentWithTopic\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.PronunciationAssessmentConfig#enableContentAssessmentWithTopic\"></xref>. Added in version 1.33.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_EnableMiscue"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_EnableMiscue"
  name: "PronunciationAssessment_EnableMiscue"
  nameWithType: "PropertyId.PronunciationAssessment_EnableMiscue"
  summary: "Defines if enable miscue calculation."
  desc: "Defines if enable miscue calculation. With this enabled, the pronounced words will be compared to the reference text, and will be marked with omission/insertion based on the comparison. The default setting is False. Under normal circumstances, you shouldn't have to use this property directly. Added in version 1.14.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_EnableProsodyAssessment"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_EnableProsodyAssessment"
  name: "PronunciationAssessment_EnableProsodyAssessment"
  nameWithType: "PropertyId.PronunciationAssessment_EnableProsodyAssessment"
  summary: "Whether to enable prosody assessment."
  desc: "Whether to enable prosody assessment. Under normal circumstances, you shouldn't have to use this property directly. instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.PronunciationAssessmentConfig.enableProsodyAssessment\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.PronunciationAssessmentConfig#enableProsodyAssessment\"></xref>. Added in version 1.33.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_GradingSystem"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_GradingSystem"
  name: "PronunciationAssessment_GradingSystem"
  nameWithType: "PropertyId.PronunciationAssessment_GradingSystem"
  summary: "The point system for pronunciation score calibration (Five<wbr>Point or Hundred<wbr>Mark)."
  desc: "The point system for pronunciation score calibration (FivePoint or HundredMark). Under normal circumstances, you shouldn't have to use this property directly. Added in version 1.14.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Granularity"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Granularity"
  name: "PronunciationAssessment_Granularity"
  nameWithType: "PropertyId.PronunciationAssessment_Granularity"
  summary: "The pronunciation evaluation granularity (Phoneme, Word, or Full<wbr>Text)."
  desc: "The pronunciation evaluation granularity (Phoneme, Word, or FullText). Under normal circumstances, you shouldn't have to use this property directly. Added in version 1.14.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Json"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Json"
  name: "PronunciationAssessment_Json"
  nameWithType: "PropertyId.PronunciationAssessment_Json"
  summary: "The json string of pronunciation assessment parameters Under normal circumstances, you shouldn't have to use this property directly."
  desc: "The json string of pronunciation assessment parameters Under normal circumstances, you shouldn't have to use this property directly. Added in version 1.14.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_NBestPhonemeCount"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_NBestPhonemeCount"
  name: "PronunciationAssessment_NBestPhonemeCount"
  nameWithType: "PropertyId.PronunciationAssessment_NBestPhonemeCount"
  summary: "The pronunciation evaluation nbest phoneme count."
  desc: "The pronunciation evaluation nbest phoneme count. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.PronunciationAssessmentConfig.setNBestPhonemeCount\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.PronunciationAssessmentConfig#setNBestPhonemeCount\"></xref>. Added in version 1.20.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Params"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_Params"
  name: "PronunciationAssessment_Params"
  nameWithType: "PropertyId.PronunciationAssessment_Params"
  summary: "Pronunciation assessment parameters."
  desc: "Pronunciation assessment parameters. This property is intended to be read-only. The SDK is using it internally. Added in version 1.14.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_PhonemeAlphabet"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_PhonemeAlphabet"
  name: "PronunciationAssessment_PhonemeAlphabet"
  nameWithType: "PropertyId.PronunciationAssessment_PhonemeAlphabet"
  summary: "The pronunciation evaluation phoneme alphabet."
  desc: "The pronunciation evaluation phoneme alphabet. The valid values are \"SAPI\" (default) and \"IPA\" Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.PronunciationAssessmentConfig.setPhonemeAlphabet\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.PronunciationAssessmentConfig#setPhonemeAlphabet\"></xref>. Added in version 1.20.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_ReferenceText"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.PronunciationAssessment_ReferenceText"
  name: "PronunciationAssessment_ReferenceText"
  nameWithType: "PropertyId.PronunciationAssessment_ReferenceText"
  summary: "The reference text of the audio for pronunciation evaluation."
  desc: "The reference text of the audio for pronunciation evaluation. For this and the following pronunciation assessment parameters, see https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text\\#pronunciation-assessment-parameters for details. Under normal circumstances, you shouldn't have to use this property directly. Added in version 1.14.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeakerRecognition_Api_Version"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeakerRecognition_Api_Version"
  name: "SpeakerRecognition_Api_Version"
  nameWithType: "PropertyId.SpeakerRecognition_Api_Version"
  summary: "Version of Speaker Recognition to use."
  desc: "Version of Speaker Recognition to use. Added in version 1.18.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Token"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Token"
  name: "SpeechServiceAuthorization_Token"
  nameWithType: "PropertyId.SpeechServiceAuthorization_Token"
  summary: "The Cognitive Services Speech Service authorization token (aka access token)."
  desc: "The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances, you shouldn't have to use this property directly.\n\n```java\nInstead, use\n      ,\n      ,\n      ,\n      .\n```"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Type"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Type"
  name: "SpeechServiceAuthorization_Type"
  nameWithType: "PropertyId.SpeechServiceAuthorization_Type"
  summary: "The Cognitive Services Speech Service authorization type."
  desc: "The Cognitive Services Speech Service authorization type. Currently unused."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult"
  name: "SpeechServiceConnection_AutoDetectSourceLanguageResult"
  nameWithType: "PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult"
  summary: "The auto detect source language result Added in version 1.8.0."
  desc: "The auto detect source language result Added in version 1.8.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages"
  name: "SpeechServiceConnection_AutoDetectSourceLanguages"
  nameWithType: "PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages"
  summary: "The auto detect source languages Added in version 1.8.0."
  desc: "The auto detect source languages Added in version 1.8.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EnableAudioLogging"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EnableAudioLogging"
  name: "SpeechServiceConnection_EnableAudioLogging"
  nameWithType: "PropertyId.SpeechServiceConnection_EnableAudioLogging"
  summary: "A boolean value specifying whether audio logging is enabled in the service or not."
  desc: "A boolean value specifying whether audio logging is enabled in the service or not. Audio and content logs are stored either in Microsoft-owned storage, or in your own storage account linked to your Cognitive Services subscription (Bring Your Own Storage (BYOS) enabled Speech resource). Added in version 1.5.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs"
  name: "SpeechServiceConnection_EndSilenceTimeoutMs"
  nameWithType: "PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs"
  summary: "The end silence timeout value (in milliseconds) used by the service."
  desc: "The end silence timeout value (in milliseconds) used by the service. Added in version 1.5.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Endpoint"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Endpoint"
  name: "SpeechServiceConnection_Endpoint"
  nameWithType: "PropertyId.SpeechServiceConnection_Endpoint"
  summary: "The Cognitive Services Speech Service endpoint (url)."
  desc: "The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.fromEndpoint\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.SpeechConfig#fromEndpoint\"></xref>"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndpointId"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndpointId"
  name: "SpeechServiceConnection_EndpointId"
  nameWithType: "PropertyId.SpeechServiceConnection_EndpointId"
  summary: "The Cognitive Services Custom Speech or Custom Voice Service endpoint id."
  desc: "The Cognitive Services Custom Speech or Custom Voice Service endpoint id. Under normal circumstances, you shouldn't have to use this property directly. Instead use\n\n```java\n.\n\n NOTE: The endpoint id is available in the Custom Speech Portal, listed under Endpoint Details.\n```"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Host"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Host"
  name: "SpeechServiceConnection_Host"
  nameWithType: "PropertyId.SpeechServiceConnection_Host"
  summary: "The Cognitive Services Speech Service host (url)."
  desc: "The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\n\n```java\nInstead, use\n      .\n```"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs"
  name: "SpeechServiceConnection_InitialSilenceTimeoutMs"
  nameWithType: "PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs"
  summary: "The initial silence timeout value (in milliseconds) used by the service."
  desc: "The initial silence timeout value (in milliseconds) used by the service. Added in version 1.5.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_IntentRegion"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_IntentRegion"
  name: "SpeechServiceConnection_IntentRegion"
  nameWithType: "PropertyId.SpeechServiceConnection_IntentRegion"
  summary: "The Language Understanding Service region."
  desc: "The Language Understanding Service region. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.intent.LanguageUnderstandingModel\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.intent.LanguageUnderstandingModel\"></xref>."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Key"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Key"
  name: "SpeechServiceConnection_Key"
  nameWithType: "PropertyId.SpeechServiceConnection_Key"
  summary: "The Cognitive Services Speech Service subscription key."
  desc: "The Cognitive Services Speech Service subscription key. If you are using an intent recognizer, you need to specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.fromSubscription\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.SpeechConfig#fromSubscription\"></xref>"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_LanguageIdMode"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_LanguageIdMode"
  name: "SpeechServiceConnection_LanguageIdMode"
  nameWithType: "PropertyId.SpeechServiceConnection_LanguageIdMode"
  summary: "The speech service connection language identifier mode."
  desc: "The speech service connection language identifier mode. Can be \"AtStart\" (the default), or \"Continuous\". See [Language Identification][] document. Added in 1.25.0\n\n\n[Language Identification]: https://aka.ms/speech/lid?pivots=programming-language-java"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostBypass"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostBypass"
  name: "SpeechServiceConnection_ProxyHostBypass"
  nameWithType: "PropertyId.SpeechServiceConnection_ProxyHostBypass"
  summary: "Specifies the list of hosts for which proxies should not be used."
  desc: "Specifies the list of hosts for which proxies should not be used. This setting overrides all other configurations. Hostnames are separated by commas and are matched in a case-insensitive manner. Wildcards are not supported."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostName"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostName"
  name: "SpeechServiceConnection_ProxyHostName"
  nameWithType: "PropertyId.SpeechServiceConnection_ProxyHostName"
  summary: "The host name of the proxy server used to connect to the Cognitive Services Speech Service."
  desc: "The host name of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances, you shouldn't have to use this property directly.\n\n```java\nInstead, use\n      .\n\n NOTE: This property id was added in version 1.1.0.\n```"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPassword"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPassword"
  name: "SpeechServiceConnection_ProxyPassword"
  nameWithType: "PropertyId.SpeechServiceConnection_ProxyPassword"
  summary: "The password of the proxy server used to connect to the Cognitive Services Speech Service."
  desc: "The password of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances, you shouldn't have to use this property directly.\n\n```java\nInstead, use\n      .\n\n NOTE: This property id was added in version 1.1.0.\n```"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPort"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPort"
  name: "SpeechServiceConnection_ProxyPort"
  nameWithType: "PropertyId.SpeechServiceConnection_ProxyPort"
  summary: "The port of the proxy server used to connect to the Cognitive Services Speech Service."
  desc: "The port of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances, you shouldn't have to use this property directly.\n\n```java\nInstead, use\n      .\n\n NOTE: This property id was added in version 1.1.0.\n```"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyUserName"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyUserName"
  name: "SpeechServiceConnection_ProxyUserName"
  nameWithType: "PropertyId.SpeechServiceConnection_ProxyUserName"
  summary: "The user name of the proxy server used to connect to the Cognitive Services Speech Service."
  desc: "The user name of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances, you shouldn't have to use this property directly.\n\n```java\nInstead, use\n      .\n\n NOTE: This property id was added in version 1.1.0.\n```"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoBackend"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoBackend"
  name: "SpeechServiceConnection_RecoBackend"
  nameWithType: "PropertyId.SpeechServiceConnection_RecoBackend"
  summary: "The string to specify the backend to be used for speech recognition; allowed options are online and offline."
  desc: "The string to specify the backend to be used for speech recognition; allowed options are online and offline. Under normal circumstances, you shouldn't use this property directly. Currently the offline option is only valid when EmbeddedSpeechConfig is used. Added in version 1.19.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoLanguage"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoLanguage"
  name: "SpeechServiceConnection_RecoLanguage"
  nameWithType: "PropertyId.SpeechServiceConnection_RecoLanguage"
  summary: "The spoken language to be recognized (in BCP-47 format)."
  desc: "The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.setSpeechRecognitionLanguage\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.SpeechConfig#setSpeechRecognitionLanguage\"></xref>."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoMode"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoMode"
  name: "SpeechServiceConnection_RecoMode"
  nameWithType: "PropertyId.SpeechServiceConnection_RecoMode"
  summary: "The Cognitive Services Speech Service recognition mode."
  desc: "The Cognitive Services Speech Service recognition mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\". This property is intended to be read-only. The SDK is using it internally."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoModelKey"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoModelKey"
  name: "SpeechServiceConnection_RecoModelKey"
  nameWithType: "PropertyId.SpeechServiceConnection_RecoModelKey"
  summary: "This property is deprecated."
  desc: "This property is deprecated."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoModelName"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoModelName"
  name: "SpeechServiceConnection_RecoModelName"
  nameWithType: "PropertyId.SpeechServiceConnection_RecoModelName"
  summary: "The name of the model to be used for speech recognition."
  desc: "The name of the model to be used for speech recognition. Under normal circumstances, you shouldn't use this property directly. Currently this is only valid when EmbeddedSpeechConfig is used. Added in version 1.19.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Region"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Region"
  name: "SpeechServiceConnection_Region"
  nameWithType: "PropertyId.SpeechServiceConnection_Region"
  summary: "The Cognitive Services Speech Service region."
  desc: "The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.fromSubscription\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.SpeechConfig#fromSubscription\"></xref>, <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.fromEndpoint\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.SpeechConfig#fromEndpoint\"></xref>, <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.fromHost\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.SpeechConfig#fromHost\"></xref>, <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.fromAuthorizationToken\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.SpeechConfig#fromAuthorizationToken\"></xref>."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthBackend"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthBackend"
  name: "SpeechServiceConnection_SynthBackend"
  nameWithType: "PropertyId.SpeechServiceConnection_SynthBackend"
  summary: "The string to specify TTS backend; valid options are online and offline."
  desc: "The string to specify TTS backend; valid options are online and offline. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig.fromPath\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig#fromPath\"></xref> or <xref uid=\"com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig.fromPaths\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig#fromPaths\"></xref> to set the synthesis backend to offline. Added in version 1.19.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthEnableCompressedAudioTransmission"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthEnableCompressedAudioTransmission"
  name: "SpeechServiceConnection_SynthEnableCompressedAudioTransmission"
  nameWithType: "PropertyId.SpeechServiceConnection_SynthEnableCompressedAudioTransmission"
  summary: "Indicates if use compressed audio format for speech synthesis audio transmission."
  desc: "Indicates if use compressed audio format for speech synthesis audio transmission. This property only affects when SpeechServiceConnection\\_SynthOutputFormat is set to a pcm format. If this property is not set and GStreamer is available, SDK will use compressed format for synthesized audio transmission, and decode it. You can set this property to \"false\" to use raw pcm format for transmission on wire. Added in version 1.16.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthLanguage"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthLanguage"
  name: "SpeechServiceConnection_SynthLanguage"
  nameWithType: "PropertyId.SpeechServiceConnection_SynthLanguage"
  summary: "The spoken language to be synthesized (e.<wbr>g."
  desc: "The spoken language to be synthesized (e.g. en-US) Added in version 1.7.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthModelKey"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthModelKey"
  name: "SpeechServiceConnection_SynthModelKey"
  nameWithType: "PropertyId.SpeechServiceConnection_SynthModelKey"
  summary: "This property is deprecated."
  desc: "This property is deprecated."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOfflineDataPath"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOfflineDataPath"
  name: "SpeechServiceConnection_SynthOfflineDataPath"
  nameWithType: "PropertyId.SpeechServiceConnection_SynthOfflineDataPath"
  summary: "The data file path(s) for offline synthesis engine; only valid when synthesis backend is offline."
  desc: "The data file path(s) for offline synthesis engine; only valid when synthesis backend is offline. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig.fromPath\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig#fromPath\"></xref> or <xref uid=\"com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig.fromPaths\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig#fromPaths\"></xref>. Added in version 1.19.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOfflineVoice"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOfflineVoice"
  name: "SpeechServiceConnection_SynthOfflineVoice"
  nameWithType: "PropertyId.SpeechServiceConnection_SynthOfflineVoice"
  summary: "The name of the offline TTS voice to be used for speech synthesis."
  desc: "The name of the offline TTS voice to be used for speech synthesis. Under normal circumstances, you shouldn't use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig.setSpeechSynthesisVoice\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.EmbeddedSpeechConfig#setSpeechSynthesisVoice\"></xref>. Added in version 1.19.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOutputFormat"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOutputFormat"
  name: "SpeechServiceConnection_SynthOutputFormat"
  nameWithType: "PropertyId.SpeechServiceConnection_SynthOutputFormat"
  summary: "The string to specify TTS output audio format (e.<wbr>g."
  desc: "The string to specify TTS output audio format (e.g. riff-16khz-16bit-mono-pcm) Added in version 1.7.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthVoice"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthVoice"
  name: "SpeechServiceConnection_SynthVoice"
  nameWithType: "PropertyId.SpeechServiceConnection_SynthVoice"
  summary: "The name of the TTS voice to be used for speech synthesis Added in version 1.7.0"
  desc: "The name of the TTS voice to be used for speech synthesis Added in version 1.7.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationCategoryId"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationCategoryId"
  name: "SpeechServiceConnection_TranslationCategoryId"
  nameWithType: "PropertyId.SpeechServiceConnection_TranslationCategoryId"
  summary: "The speech service connection translation category<wbr>Id."
  desc: "The speech service connection translation categoryId."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationFeatures"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationFeatures"
  name: "SpeechServiceConnection_TranslationFeatures"
  nameWithType: "PropertyId.SpeechServiceConnection_TranslationFeatures"
  summary: "Translation features."
  desc: "Translation features. For internal use."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationToLanguages"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationToLanguages"
  name: "SpeechServiceConnection_TranslationToLanguages"
  nameWithType: "PropertyId.SpeechServiceConnection_TranslationToLanguages"
  summary: "The list of comma separated languages (BCP-47 format) used as target translation languages."
  desc: "The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.translation.SpeechTranslationConfig.addTargetLanguage\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.translation.SpeechTranslationConfig#addTargetLanguage\"></xref>, <xref uid=\"com.microsoft.cognitiveservices.speech.translation.SpeechTranslationConfig.getTargetLanguages\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.translation.SpeechTranslationConfig#getTargetLanguages\"></xref>, <xref uid=\"com.microsoft.cognitiveservices.speech.translation.TranslationRecognizer.getTargetLanguages\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.translation.TranslationRecognizer#getTargetLanguages\"></xref>."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationVoice"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationVoice"
  name: "SpeechServiceConnection_TranslationVoice"
  nameWithType: "PropertyId.SpeechServiceConnection_TranslationVoice"
  summary: "The name of the Cognitive Service Text to Speech Service voice."
  desc: "The name of the Cognitive Service Text to Speech Service voice. Under normal circumstances, you shouldn't have to use this property directly. Instead use <xref uid=\"com.microsoft.cognitiveservices.speech.translation.SpeechTranslationConfig.setVoiceName\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.translation.SpeechTranslationConfig#setVoiceName\"></xref>. NOTE: Valid voice names can be found [here][].\n\n\n[here]: https://aka.ms/csspeech/voicenames"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Url"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Url"
  name: "SpeechServiceConnection_Url"
  nameWithType: "PropertyId.SpeechServiceConnection_Url"
  summary: "The URL string built from speech configuration."
  desc: "The URL string built from speech configuration. This property is intended to be read-only. The SDK is using it internally. NOTE: Added in version 1.5.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_VoicesListEndpoint"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceConnection_VoicesListEndpoint"
  name: "SpeechServiceConnection_VoicesListEndpoint"
  nameWithType: "PropertyId.SpeechServiceConnection_VoicesListEndpoint"
  summary: "The Cognitive Services Speech Service voices list api endpoint (url)."
  desc: "The Cognitive Services Speech Service voices list api endpoint (url). Under normal circumstances, you don't need to specify this property, SDK will construct it based on the region/host/endpoint of <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.SpeechConfig\"></xref>. Added in version 1.16.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_DiarizeIntermediateResults"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_DiarizeIntermediateResults"
  name: "SpeechServiceResponse_DiarizeIntermediateResults"
  nameWithType: "PropertyId.SpeechServiceResponse_DiarizeIntermediateResults"
  summary: "Determines if intermediate results contain speaker identification."
  desc: "Determines if intermediate results contain speaker identification. Allowed values are \"true\" or \"false\". If set to \"true\", the intermediate results will contain speaker identification. The default value if unset or set to an invalid value is \"false\". This is currently only supported for scenarios using the ConversationTranscriber\". Adding in version 1.40."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonErrorDetails"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonErrorDetails"
  name: "SpeechServiceResponse_JsonErrorDetails"
  nameWithType: "PropertyId.SpeechServiceResponse_JsonErrorDetails"
  summary: "The Cognitive Services Speech Service error details (in JSON format)."
  desc: "The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to use this property directly. Instead, use <xref uid=\"com.microsoft.cognitiveservices.speech.CancellationDetails.getErrorDetails\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.CancellationDetails#getErrorDetails\"></xref>."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonResult"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonResult"
  name: "SpeechServiceResponse_JsonResult"
  nameWithType: "PropertyId.SpeechServiceResponse_JsonResult"
  summary: "The Cognitive Services Speech Service response output (in JSON format)."
  desc: "The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_OutputFormatOption"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_OutputFormatOption"
  name: "SpeechServiceResponse_OutputFormatOption"
  nameWithType: "PropertyId.SpeechServiceResponse_OutputFormatOption"
  summary: "A string value specifying the output format option in the response result."
  desc: "A string value specifying the output format option in the response result. Internal use only. Added in version 1.5.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_PostProcessingOption"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_PostProcessingOption"
  name: "SpeechServiceResponse_PostProcessingOption"
  nameWithType: "PropertyId.SpeechServiceResponse_PostProcessingOption"
  summary: "A string value specifying which post processing option should be used by service."
  desc: "A string value specifying which post processing option should be used by service. Allowed values are \"TrueText\". Added in version 1.5.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_ProfanityOption"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_ProfanityOption"
  name: "SpeechServiceResponse_ProfanityOption"
  nameWithType: "PropertyId.SpeechServiceResponse_ProfanityOption"
  summary: "The requested Cognitive Services Speech Service response output profanity setting."
  desc: "The requested Cognitive Services Speech Service response output profanity setting. Allowed values are \"masked\", \"removed\", and \"raw\". Added in version 1.5.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionBackend"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionBackend"
  name: "SpeechServiceResponse_RecognitionBackend"
  nameWithType: "PropertyId.SpeechServiceResponse_RecognitionBackend"
  summary: "The recognition backend."
  desc: "The recognition backend. Read-only, available on speech recognition results. This indicates whether cloud (online) or embedded (offline) recognition was used to produce the result."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs"
  name: "SpeechServiceResponse_RecognitionLatencyMs"
  nameWithType: "PropertyId.SpeechServiceResponse_RecognitionLatencyMs"
  summary: "The recognition latency in milliseconds."
  desc: "The recognition latency in milliseconds. Read-only, available on final speech/translation/intent results. This measures the latency between when an audio input is received by the SDK, and the moment the final result is received from the service. The SDK computes the time difference between the last audio fragment from the audio input that is contributing to the final result, and the time the final result is received from the speech service. Added in version 1.3.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse"
  name: "SpeechServiceResponse_RequestDetailedResultTrueFalse"
  nameWithType: "PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse"
  summary: "The requested Cognitive Services Speech Service response output format (simple or detailed)."
  desc: "The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have to use this property directly. Instead use <xref uid=\"com.microsoft.cognitiveservices.speech.SpeechConfig.setOutputFormat\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.SpeechConfig#setOutputFormat\"></xref>."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse"
  name: "SpeechServiceResponse_RequestProfanityFilterTrueFalse"
  nameWithType: "PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse"
  summary: "The requested Cognitive Services Speech Service response output profanity level."
  desc: "The requested Cognitive Services Speech Service response output profanity level. Currently unused."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestPunctuationBoundary"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestPunctuationBoundary"
  name: "SpeechServiceResponse_RequestPunctuationBoundary"
  nameWithType: "PropertyId.SpeechServiceResponse_RequestPunctuationBoundary"
  summary: "A boolean value specifying whether to request punctuation boundary in Word<wbr>Boundary Events."
  desc: "A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true. Added in version 1.21.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestSentenceBoundary"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestSentenceBoundary"
  name: "SpeechServiceResponse_RequestSentenceBoundary"
  nameWithType: "PropertyId.SpeechServiceResponse_RequestSentenceBoundary"
  summary: "A boolean value specifying whether to request sentence boundary in Word<wbr>Boundary Events."
  desc: "A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false. Added in version 1.21.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestSnr"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestSnr"
  name: "SpeechServiceResponse_RequestSnr"
  nameWithType: "PropertyId.SpeechServiceResponse_RequestSnr"
  summary: "A boolean value specifying whether to include SNR (signal to noise ratio) in the response result."
  desc: "A boolean value specifying whether to include SNR (signal to noise ratio) in the response result. Added in version 1.18.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestWordBoundary"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestWordBoundary"
  name: "SpeechServiceResponse_RequestWordBoundary"
  nameWithType: "PropertyId.SpeechServiceResponse_RequestWordBoundary"
  summary: "A boolean value specifying whether to request Word<wbr>Boundary events."
  desc: "A boolean value specifying whether to request WordBoundary events. Added in version 1.21.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps"
  name: "SpeechServiceResponse_RequestWordLevelTimestamps"
  nameWithType: "PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps"
  summary: "A boolean value specifying whether to include word-level timestamps in the response result."
  desc: "A boolean value specifying whether to include word-level timestamps in the response result. Added in version 1.5.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_StablePartialResultThreshold"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_StablePartialResultThreshold"
  name: "SpeechServiceResponse_StablePartialResultThreshold"
  nameWithType: "PropertyId.SpeechServiceResponse_StablePartialResultThreshold"
  summary: "The number of times a word has to be in partial results to be returned."
  desc: "The number of times a word has to be in partial results to be returned. Added in version 1.5.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisBackend"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisBackend"
  name: "SpeechServiceResponse_SynthesisBackend"
  nameWithType: "PropertyId.SpeechServiceResponse_SynthesisBackend"
  summary: "Indicates which backend the synthesis is finished by."
  desc: "Indicates which backend the synthesis is finished by. Read-only, available on speech synthesis results, except for the result in SynthesisStarted event. Added in version 1.17.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisConnectionLatencyMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisConnectionLatencyMs"
  name: "SpeechServiceResponse_SynthesisConnectionLatencyMs"
  nameWithType: "PropertyId.SpeechServiceResponse_SynthesisConnectionLatencyMs"
  summary: "The speech synthesis connection latency in milliseconds."
  desc: "The speech synthesis connection latency in milliseconds. Read-only, available on final speech synthesis results. This measures the latency between when the synthesis is started to be processed, and the moment the HTTP/WebSocket connection is established. Added in version 1.26.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisEventsSyncToAudio"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisEventsSyncToAudio"
  name: "SpeechServiceResponse_SynthesisEventsSyncToAudio"
  nameWithType: "PropertyId.SpeechServiceResponse_SynthesisEventsSyncToAudio"
  summary: "A boolean value specifying whether the SDK should synchronize synthesis metadata events, (e.<wbr>g."
  desc: "A boolean value specifying whether the SDK should synchronize synthesis metadata events, (e.g. word boundary, viseme, etc.) to the audio playback. This only takes effect when the audio is played through the SDK. Default is true. If set to false, the SDK will fire the events as they come from the service, which may be out of sync with the audio playback. Added in version 1.31.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisFinishLatencyMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisFinishLatencyMs"
  name: "SpeechServiceResponse_SynthesisFinishLatencyMs"
  nameWithType: "PropertyId.SpeechServiceResponse_SynthesisFinishLatencyMs"
  summary: "The speech synthesis all bytes latency in milliseconds."
  desc: "The speech synthesis all bytes latency in milliseconds. Read-only, available on final speech synthesis results. This measures the latency between when the synthesis is started to be processed, and the moment the whole audio is synthesized. Added in version 1.17.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisFirstByteLatencyMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisFirstByteLatencyMs"
  name: "SpeechServiceResponse_SynthesisFirstByteLatencyMs"
  nameWithType: "PropertyId.SpeechServiceResponse_SynthesisFirstByteLatencyMs"
  summary: "The speech synthesis first byte latency in milliseconds."
  desc: "The speech synthesis first byte latency in milliseconds. Read-only, available on final speech synthesis results. This measures the latency between when the synthesis is started to be processed, and the moment the first byte audio is available. Added in version 1.17.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisNetworkLatencyMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisNetworkLatencyMs"
  name: "SpeechServiceResponse_SynthesisNetworkLatencyMs"
  nameWithType: "PropertyId.SpeechServiceResponse_SynthesisNetworkLatencyMs"
  summary: "The speech synthesis network latency in milliseconds."
  desc: "The speech synthesis network latency in milliseconds. Read-only, available on final speech synthesis results. This measures the network round trip time. Added in version 1.26.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisServiceLatencyMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisServiceLatencyMs"
  name: "SpeechServiceResponse_SynthesisServiceLatencyMs"
  nameWithType: "PropertyId.SpeechServiceResponse_SynthesisServiceLatencyMs"
  summary: "The speech synthesis service latency in milliseconds."
  desc: "The speech synthesis service latency in milliseconds. Read-only, available on final speech synthesis results. This measures the service processing time to synthesize the first byte of audio. Added in version 1.26.0"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisUnderrunTimeMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisUnderrunTimeMs"
  name: "SpeechServiceResponse_SynthesisUnderrunTimeMs"
  nameWithType: "PropertyId.SpeechServiceResponse_SynthesisUnderrunTimeMs"
  summary: "The underrun time for speech synthesis in milliseconds."
  desc: "The underrun time for speech synthesis in milliseconds. Read-only, available on results in SynthesisCompleted events. This measures the total underrun time from <xref uid=\"com.microsoft.cognitiveservices.speech.PropertyId.AudioConfig_PlaybackBufferLengthInMs\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.PropertyId#AudioConfig_PlaybackBufferLengthInMs\"></xref> is filled to synthesis completed. Added in version 1.17.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult"
  name: "SpeechServiceResponse_TranslationRequestStablePartialResult"
  nameWithType: "PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult"
  summary: "A boolean value to request for stabilizing translation partial results by omitting words in the end."
  desc: "A boolean value to request for stabilizing translation partial results by omitting words in the end. Added in version 1.5.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechSynthesis_FrameTimeoutInterval"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechSynthesis_FrameTimeoutInterval"
  name: "SpeechSynthesis_FrameTimeoutInterval"
  nameWithType: "PropertyId.SpeechSynthesis_FrameTimeoutInterval"
  summary: "The timeout interval in milliseconds between synthesized speech audio frames."
  desc: "The timeout interval in milliseconds between synthesized speech audio frames. The greater of this and 10 seconds is used as a hard frame timeout. A speech synthesis timeout occurs if a) the time passed since the latest frame exceeds this timeout interval and the Real-Time Factor (RTF) exceeds its maximum value, or b) the time passed since the latest frame exceeds the hard frame timeout."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechSynthesis_RtfTimeoutThreshold"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechSynthesis_RtfTimeoutThreshold"
  name: "SpeechSynthesis_RtfTimeoutThreshold"
  nameWithType: "PropertyId.SpeechSynthesis_RtfTimeoutThreshold"
  summary: "The maximum Real-Time Factor (RTF) for speech synthesis."
  desc: "The maximum Real-Time Factor (RTF) for speech synthesis. The RTF is calculated as RTF = f(d)/d where f(d) is the time taken to synthesize speech audio of duration d."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechTranslation_ModelKey"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechTranslation_ModelKey"
  name: "SpeechTranslation_ModelKey"
  nameWithType: "PropertyId.SpeechTranslation_ModelKey"
  summary: "This property is deprecated."
  desc: "This property is deprecated."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechTranslation_ModelName"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.SpeechTranslation_ModelName"
  name: "SpeechTranslation_ModelName"
  nameWithType: "PropertyId.SpeechTranslation_ModelName"
  summary: "The name of a model to be used for speech translation."
  desc: "The name of a model to be used for speech translation. Do not use this property directly. Currently this is only valid when EmbeddedSpeechConfig is used."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Speech_LogFilename"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Speech_LogFilename"
  name: "Speech_LogFilename"
  nameWithType: "PropertyId.Speech_LogFilename"
  summary: "The file name to write logs."
  desc: "The file name to write logs. Added in version 1.4.0."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Speech_SegmentationMaximumTimeMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Speech_SegmentationMaximumTimeMs"
  name: "Speech_SegmentationMaximumTimeMs"
  nameWithType: "PropertyId.Speech_SegmentationMaximumTimeMs"
  summary: "The maximum length of a spoken phrase when using the Time segmentation strategy."
  desc: "The maximum length of a spoken phrase when using the Time segmentation strategy. As the length of a spoken phrase approaches this value, the  will begin being reduced until either the phrase silence timeout is hit or the phrase reaches the maximum length. The value must be in the range \\*\\*\\[20000, 70000\\]\\*\\* milliseconds."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Speech_SegmentationSilenceTimeoutMs"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Speech_SegmentationSilenceTimeoutMs"
  name: "Speech_SegmentationSilenceTimeoutMs"
  nameWithType: "PropertyId.Speech_SegmentationSilenceTimeoutMs"
  summary: "A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken phrase has ended and generate a final Recognized result."
  desc: "A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations where spoken input is significantly faster or slower than usual and default segmentation behavior consistently yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting behavior should be thoroughly validated as intended. The value must be in the range \\*\\*\\[100, 5000\\]\\*\\* milliseconds. For more information about timeout configuration that includes discussion of default behaviors, please visit https://aka.ms/csspeech/timeouts."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Speech_SegmentationStrategy"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Speech_SegmentationStrategy"
  name: "Speech_SegmentationStrategy"
  nameWithType: "PropertyId.Speech_SegmentationStrategy"
  summary: "The strategy used to determine when a spoken phrase has ended and a final Recognized result should be generated."
  desc: "The strategy used to determine when a spoken phrase has ended and a final Recognized result should be generated. Allowed values are \"Default\", \"Time\", and \"Semantic\".\n\nValid values are:\n\n *  **Default** \\- Use the default strategy and settings as determined by the Speech Service. Use in most situations.\n *  **Time** \\- Uses a time-based strategy where the amount of silence between speech is used to determine when to generate a final result.\n *  **Semantic** \\- Uses an AI model to determine the end of a spoken phrase based on the content of the phrase.\n\nWhen using the time strategy, the <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Speech_SegmentationSilenceTimeoutMs\"></xref> property can be used to adjust the amount of silence needed to determine the end of a spoken phrase, and the <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Speech_SegmentationMaximumTimeMs\"></xref> property can be used to adjust the maximum length of a spoken phrase.\n\nThe semantic strategy has no control properties available."
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.Speech_SessionId"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.Speech_SessionId"
  name: "Speech_SessionId"
  nameWithType: "PropertyId.Speech_SessionId"
  summary: "The session id."
  desc: "The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream and the underlying speech recognition instance to which its bound. Under normal circumstances, you shouldn't have to use this property directly. Instead use <xref uid=\"com.microsoft.cognitiveservices.speech.SessionEventArgs.getSessionId\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.microsoft.cognitiveservices.speech.SessionEventArgs#getSessionId\"></xref>."
methods:
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.getValue()"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.getValue()"
  name: "getValue()"
  nameWithType: "PropertyId.getValue()"
  summary: "Returns the internal value property id"
  syntax: "public int getValue()"
  desc: "Returns the internal value property id"
  returns:
    description: "the speech property id"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.valueOf(java.lang.String)"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.valueOf(String name)"
  name: "valueOf(String name)"
  nameWithType: "PropertyId.valueOf(String name)"
  modifiers:
  - "static"
  parameters:
  - name: "name"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public static PropertyId valueOf(String name)"
  returns:
    type: "<xref href=\"com.microsoft.cognitiveservices.speech.PropertyId?alt=com.microsoft.cognitiveservices.speech.PropertyId&text=PropertyId\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.microsoft.cognitiveservices.speech.PropertyId.values()"
  fullName: "com.microsoft.cognitiveservices.speech.PropertyId.values()"
  name: "values()"
  nameWithType: "PropertyId.values()"
  modifiers:
  - "static"
  syntax: "public static PropertyId[] values()"
  returns:
    type: "<xref href=\"com.microsoft.cognitiveservices.speech.PropertyId?alt=com.microsoft.cognitiveservices.speech.PropertyId&text=PropertyId\" data-throw-if-not-resolved=\"False\" />[]"
desc: "Defines property ids. Changed in version 1.8.0."
metadata: {}
package: "com.microsoft.cognitiveservices.speech"
artifact: com.microsoft.cognitiveservices.speech:client-sdk:1.43.0
