### YamlMime:ManagedReference
items:
- uid: "com.azure.storage.file.datalake.DataLakeFileClient"
  id: "DataLakeFileClient"
  parent: "com.azure.storage.file.datalake"
  children:
  - "com.azure.storage.file.datalake.DataLakeFileClient.DataLakeFileClient(com.azure.storage.file.datalake.DataLakeFileAsyncClient,com.azure.storage.blob.specialized.BlockBlobClient)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.append(java.io.InputStream,long,long)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.appendWithResponse(java.io.InputStream,long,long,byte[],java.lang.String,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.delete()"
  - "com.azure.storage.file.datalake.DataLakeFileClient.deleteWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.flush(long)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.flush(long,boolean)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.flushWithResponse(long,boolean,boolean,com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.getFileName()"
  - "com.azure.storage.file.datalake.DataLakeFileClient.getFilePath()"
  - "com.azure.storage.file.datalake.DataLakeFileClient.getFileUrl()"
  - "com.azure.storage.file.datalake.DataLakeFileClient.read(java.io.OutputStream)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.readToFile(java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.readToFile(java.lang.String,boolean)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.readToFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.FileRange,com.azure.storage.common.ParallelTransferOptions,com.azure.storage.file.datalake.models.DownloadRetryOptions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,boolean,java.util.Set<java.nio.file.OpenOption>,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.readWithResponse(java.io.OutputStream,com.azure.storage.file.datalake.models.FileRange,com.azure.storage.file.datalake.models.DownloadRetryOptions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,boolean,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.rename(java.lang.String,java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile(java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile(java.lang.String,boolean)"
  - "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile(java.lang.String,com.azure.storage.common.ParallelTransferOptions,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration)"
  langs:
  - "java"
  name: "DataLakeFileClient"
  nameWithType: "DataLakeFileClient"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient"
  type: "Class"
  package: "com.azure.storage.file.datalake"
  summary: "This class provides a client that contains file operations for Azure Storage Data Lake. Operations provided by this client include creating a file, deleting a file, renaming a file, setting metadata and http headers, setting and retrieving access control, getting properties, reading a file, and appending and flushing data to write to a file.\n\nThis client is instantiated through <xref uid=\"com.azure.storage.file.datalake.DataLakePathClientBuilder\" data-throw-if-not-resolved=\"false\">DataLakePathClientBuilder</xref> or retrieved via <xref uid=\"com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient(java.lang.String)\" data-throw-if-not-resolved=\"false\">getFileClient</xref>.\n\nPlease refer to the [Azure Docs][] for more information.\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction?toc=%2fazure%2fstorage%2fblobs%2ftoc.json"
  syntax:
    content: "public class DataLakeFileClient extends DataLakePathClient"
  inheritance:
  - "java.lang.Object"
  - "com.azure.storage.file.datalake.DataLakePathClient"
  inheritedMembers:
  - "com.azure.storage.file.datalake.DataLakePathClient.create()"
  - "com.azure.storage.file.datalake.DataLakePathClient.create(boolean)"
  - "com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.exists()"
  - "com.azure.storage.file.datalake.DataLakePathClient.existsWithResponse(java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)"
  - "com.azure.storage.file.datalake.DataLakePathClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)"
  - "com.azure.storage.file.datalake.DataLakePathClient.getAccessControl()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getAccessControlWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.getAccountName()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getBlockBlobClient()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getFileSystemName()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getHttpPipeline()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getObjectName()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getObjectPath()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getPathUrl()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getProperties()"
  - "com.azure.storage.file.datalake.DataLakePathClient.getPropertiesWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.getServiceVersion()"
  - "com.azure.storage.file.datalake.DataLakePathClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeaders(com.azure.storage.file.datalake.models.PathHttpHeaders)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeadersWithResponse(com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setPermissions(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String)"
  - "com.azure.storage.file.datalake.DataLakePathClient.setPermissionsWithResponse(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  - "java.lang.Object.clone()"
  - "java.lang.Object.equals(java.lang.Object)"
  - "java.lang.Object.finalize()"
  - "java.lang.Object.getClass()"
  - "java.lang.Object.hashCode()"
  - "java.lang.Object.notify()"
  - "java.lang.Object.notifyAll()"
  - "java.lang.Object.toString()"
  - "java.lang.Object.wait()"
  - "java.lang.Object.wait(long)"
  - "java.lang.Object.wait(long,int)"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.DataLakeFileClient(com.azure.storage.file.datalake.DataLakeFileAsyncClient,com.azure.storage.blob.specialized.BlockBlobClient)"
  id: "DataLakeFileClient(com.azure.storage.file.datalake.DataLakeFileAsyncClient,com.azure.storage.blob.specialized.BlockBlobClient)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "DataLakeFileClient(DataLakeFileAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)"
  nameWithType: "DataLakeFileClient.DataLakeFileClient(DataLakeFileAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.DataLakeFileClient(DataLakeFileAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.DataLakeFileClient*"
  type: "Constructor"
  package: "com.azure.storage.file.datalake"
  syntax:
    content: " DataLakeFileClient(DataLakeFileAsyncClient pathAsyncClient, BlockBlobClient blockBlobClient)"
    parameters:
    - id: "pathAsyncClient"
      type: "com.azure.storage.file.datalake.DataLakeFileAsyncClient"
    - id: "blockBlobClient"
      type: "com.azure.storage.blob.specialized.BlockBlobClient"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.DataLakeFileClient(com.azure.storage.file.datalake.DataLakePathClient)"
  id: "DataLakeFileClient(com.azure.storage.file.datalake.DataLakePathClient)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "DataLakeFileClient(DataLakePathClient dataLakePathClient)"
  nameWithType: "DataLakeFileClient.DataLakeFileClient(DataLakePathClient dataLakePathClient)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.DataLakeFileClient(DataLakePathClient dataLakePathClient)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.DataLakeFileClient*"
  type: "Constructor"
  package: "com.azure.storage.file.datalake"
  syntax:
    content: "private DataLakeFileClient(DataLakePathClient dataLakePathClient)"
    parameters:
    - id: "dataLakePathClient"
      type: "com.azure.storage.file.datalake.DataLakePathClient"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.append(java.io.InputStream,long,long)"
  id: "append(java.io.InputStream,long,long)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "append(InputStream data, long fileOffset, long length)"
  nameWithType: "DataLakeFileClient.append(InputStream data, long fileOffset, long length)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.append(InputStream data, long fileOffset, long length)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.append*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Appends data to the specified resource to later be flushed (written) by a call to flush\n\n**Code Samples>Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.append\\#InputStream-long-long\\}\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update"
  syntax:
    content: "public void append(InputStream data, long fileOffset, long length)"
    parameters:
    - id: "data"
      type: "java.io.InputStream"
      description: "The data to write to the file."
    - id: "fileOffset"
      type: "long"
      description: "The position where the data is to be appended."
    - id: "length"
      type: "long"
      description: "The exact length of the data."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.appendWithResponse(java.io.InputStream,long,long,byte[],java.lang.String,java.time.Duration,com.azure.core.util.Context)"
  id: "appendWithResponse(java.io.InputStream,long,long,byte[],java.lang.String,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "appendWithResponse(InputStream data, long fileOffset, long length, byte[] contentMd5, String leaseId, Duration timeout, Context context)"
  nameWithType: "DataLakeFileClient.appendWithResponse(InputStream data, long fileOffset, long length, byte[] contentMd5, String leaseId, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.appendWithResponse(InputStream data, long fileOffset, long length, byte[] contentMd5, String leaseId, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.appendWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Appends data to the specified resource to later be flushed (written) by a call to flush\n\n**Code Samples>Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.appendWithResponse\\#InputStream-long-long-byte-String-Duration-Context\\}\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update"
  syntax:
    content: "public Response<Void> appendWithResponse(InputStream data, long fileOffset, long length, byte[] contentMd5, String leaseId, Duration timeout, Context context)"
    parameters:
    - id: "data"
      type: "java.io.InputStream"
      description: "The data to write to the file."
    - id: "fileOffset"
      type: "long"
      description: "The position where the data is to be appended."
    - id: "length"
      type: "long"
      description: "The exact length of the data."
    - id: "contentMd5"
      type: "byte[]"
      description: "An MD5 hash of the content of the data. If specified, the service will calculate the MD5 of the\n received data and fail the request if it does not match the provided MD5."
    - id: "leaseId"
      type: "java.lang.String"
      description: "By setting lease id, requests will fail if the provided lease does not match the active lease on\n the file."
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.core.http.rest.Response<java.lang.Void>"
      description: "A response signalling completion."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.delete()"
  id: "delete()"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "delete()"
  nameWithType: "DataLakeFileClient.delete()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.delete()"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.delete*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Deletes a file.\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.delete\\}\n\nFor more information see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: "public void delete()"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.deleteWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  id: "deleteWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeFileClient.deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.deleteWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Deletes a file.\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.deleteWithResponse\\#DataLakeRequestConditions-Duration-Context\\}\n\nFor more information see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: "public Response<Void> deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
    parameters:
    - id: "requestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref>"
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.core.http.rest.Response<java.lang.Void>"
      description: "A response containing status code and HTTP headers."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.flush(long)"
  id: "flush(long)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "flush(long position)"
  nameWithType: "DataLakeFileClient.flush(long position)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.flush(long position)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.flush*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Flushes (writes) data previously appended to the file through a call to append. The previously uploaded data must be contiguous.\n\nBy default this method will not overwrite existing data.\n\n**Code Samples>Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.flush\\#long\\}\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update"
  syntax:
    content: "public PathInfo flush(long position)"
    parameters:
    - id: "position"
      type: "long"
      description: "The length of the file after all data has been written."
    return:
      type: "com.azure.storage.file.datalake.models.PathInfo"
      description: "Information about the created resource."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.flush(long,boolean)"
  id: "flush(long,boolean)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "flush(long position, boolean overwrite)"
  nameWithType: "DataLakeFileClient.flush(long position, boolean overwrite)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.flush(long position, boolean overwrite)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.flush*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Flushes (writes) data previously appended to the file through a call to append. The previously uploaded data must be contiguous.\n\n**Code Samples>Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.flush\\#long-boolean\\}\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update"
  syntax:
    content: "public PathInfo flush(long position, boolean overwrite)"
    parameters:
    - id: "position"
      type: "long"
      description: "The length of the file after all data has been written."
    - id: "overwrite"
      type: "boolean"
      description: "Whether or not to overwrite, should data exist on the file."
    return:
      type: "com.azure.storage.file.datalake.models.PathInfo"
      description: "Information about the created resource."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.flushWithResponse(long,boolean,boolean,com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  id: "flushWithResponse(long,boolean,boolean,com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "flushWithResponse(long position, boolean retainUncommittedData, boolean close, PathHttpHeaders httpHeaders, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeFileClient.flushWithResponse(long position, boolean retainUncommittedData, boolean close, PathHttpHeaders httpHeaders, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.flushWithResponse(long position, boolean retainUncommittedData, boolean close, PathHttpHeaders httpHeaders, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.flushWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Flushes (writes) data previously appended to the file through a call to append. The previously uploaded data must be contiguous.\n\n**Code Samples>Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.flushWithResponse\\#long-boolean-boolean-PathHttpHeaders-DataLakeRequestConditions-Duration-Context\\}\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update"
  syntax:
    content: "public Response<PathInfo> flushWithResponse(long position, boolean retainUncommittedData, boolean close, PathHttpHeaders httpHeaders, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
    parameters:
    - id: "position"
      type: "long"
      description: "The length of the file after all data has been written."
    - id: "retainUncommittedData"
      type: "boolean"
      description: "Whether or not uncommitted data is to be retained after the operation."
    - id: "close"
      type: "boolean"
      description: "Whether or not a file changed event raised indicates completion (true) or modification (false)."
    - id: "httpHeaders"
      type: "com.azure.storage.file.datalake.models.PathHttpHeaders"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.PathHttpHeaders\" data-throw-if-not-resolved=\"false\">httpHeaders</xref>"
    - id: "requestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">requestConditions</xref>"
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.core.http.rest.Response<com.azure.storage.file.datalake.models.PathInfo>"
      description: "A response containing the information of the created resource."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.getFileName()"
  id: "getFileName()"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "getFileName()"
  nameWithType: "DataLakeFileClient.getFileName()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.getFileName()"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.getFileName*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Gets the name of this file, not including its full path."
  syntax:
    content: "public String getFileName()"
    return:
      type: "java.lang.String"
      description: "The name of the file."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.getFilePath()"
  id: "getFilePath()"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "getFilePath()"
  nameWithType: "DataLakeFileClient.getFilePath()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.getFilePath()"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.getFilePath*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Gets the path of this file, not including the name of the resource itself."
  syntax:
    content: "public String getFilePath()"
    return:
      type: "java.lang.String"
      description: "The path of the file."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.getFileUrl()"
  id: "getFileUrl()"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "getFileUrl()"
  nameWithType: "DataLakeFileClient.getFileUrl()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.getFileUrl()"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.getFileUrl*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Gets the URL of the file represented by this client on the Data Lake service."
  syntax:
    content: "public String getFileUrl()"
    return:
      type: "java.lang.String"
      description: "the URL."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.read(java.io.OutputStream)"
  id: "read(java.io.OutputStream)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "read(OutputStream stream)"
  nameWithType: "DataLakeFileClient.read(OutputStream stream)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.read(OutputStream stream)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.read*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Reads the entire file into an output stream.\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.read\\#OutputStream\\}\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob"
  syntax:
    content: "public void read(OutputStream stream)"
    parameters:
    - id: "stream"
      type: "java.io.OutputStream"
      description: "A non-null <xref uid=\"\" data-throw-if-not-resolved=\"false\">OutputStream</xref> instance where the downloaded data will be written."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.readToFile(java.lang.String)"
  id: "readToFile(java.lang.String)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "readToFile(String filePath)"
  nameWithType: "DataLakeFileClient.readToFile(String filePath)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.readToFile(String filePath)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.readToFile*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Reads the entire file into a file specified by the path.\n\nThe file will be created and must not exist, if the file already exists a <xref uid=\"\" data-throw-if-not-resolved=\"false\">FileAlreadyExistsException</xref> will be thrown.\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.readToFile\\#String\\}\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob"
  syntax:
    content: "public PathProperties readToFile(String filePath)"
    parameters:
    - id: "filePath"
      type: "java.lang.String"
      description: "A <xref uid=\"java.lang.String\" data-throw-if-not-resolved=\"false\">String</xref> representing the filePath where the downloaded data will be written."
    return:
      type: "com.azure.storage.file.datalake.models.PathProperties"
      description: "The file properties and metadata."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.readToFile(java.lang.String,boolean)"
  id: "readToFile(java.lang.String,boolean)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "readToFile(String filePath, boolean overwrite)"
  nameWithType: "DataLakeFileClient.readToFile(String filePath, boolean overwrite)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.readToFile(String filePath, boolean overwrite)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.readToFile*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Reads the entire file into a file specified by the path.\n\nIf overwrite is set to false, the file will be created and must not exist, if the file already exists a <xref uid=\"\" data-throw-if-not-resolved=\"false\">FileAlreadyExistsException</xref> will be thrown.\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.readToFile\\#String-boolean\\}\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob"
  syntax:
    content: "public PathProperties readToFile(String filePath, boolean overwrite)"
    parameters:
    - id: "filePath"
      type: "java.lang.String"
      description: "A <xref uid=\"java.lang.String\" data-throw-if-not-resolved=\"false\">String</xref> representing the filePath where the downloaded data will be written."
    - id: "overwrite"
      type: "boolean"
      description: "Whether or not to overwrite the file, should the file exist."
    return:
      type: "com.azure.storage.file.datalake.models.PathProperties"
      description: "The file properties and metadata."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.readToFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.FileRange,com.azure.storage.common.ParallelTransferOptions,com.azure.storage.file.datalake.models.DownloadRetryOptions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,boolean,java.util.Set<java.nio.file.OpenOption>,java.time.Duration,com.azure.core.util.Context)"
  id: "readToFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.FileRange,com.azure.storage.common.ParallelTransferOptions,com.azure.storage.file.datalake.models.DownloadRetryOptions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,boolean,java.util.Set<java.nio.file.OpenOption>,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "readToFileWithResponse(String filePath, FileRange range, ParallelTransferOptions parallelTransferOptions, DownloadRetryOptions downloadRetryOptions, DataLakeRequestConditions requestConditions, boolean rangeGetContentMd5, Set<OpenOption> openOptions, Duration timeout, Context context)"
  nameWithType: "DataLakeFileClient.readToFileWithResponse(String filePath, FileRange range, ParallelTransferOptions parallelTransferOptions, DownloadRetryOptions downloadRetryOptions, DataLakeRequestConditions requestConditions, boolean rangeGetContentMd5, Set<OpenOption> openOptions, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.readToFileWithResponse(String filePath, FileRange range, ParallelTransferOptions parallelTransferOptions, DownloadRetryOptions downloadRetryOptions, DataLakeRequestConditions requestConditions, boolean rangeGetContentMd5, Set<OpenOption> openOptions, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.readToFileWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Reads the entire file into a file specified by the path.\n\nBy default the file will be created and must not exist, if the file already exists a <xref uid=\"\" data-throw-if-not-resolved=\"false\">FileAlreadyExistsException</xref> will be thrown. To override this behavior, provide appropriate <xref uid=\"java.nio.file.OpenOption\" data-throw-if-not-resolved=\"false\">OpenOptions</xref>\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.readToFileWithResponse\\#String-FileRange-ParallelTransferOptions-DownloadRetryOptions-DataLakeRequestConditions-boolean-Set-Duration-Context\\}\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob"
  syntax:
    content: "public Response<PathProperties> readToFileWithResponse(String filePath, FileRange range, ParallelTransferOptions parallelTransferOptions, DownloadRetryOptions downloadRetryOptions, DataLakeRequestConditions requestConditions, boolean rangeGetContentMd5, Set<OpenOption> openOptions, Duration timeout, Context context)"
    parameters:
    - id: "filePath"
      type: "java.lang.String"
      description: "A <xref uid=\"java.lang.String\" data-throw-if-not-resolved=\"false\">String</xref> representing the filePath where the downloaded data will be written."
    - id: "range"
      type: "com.azure.storage.file.datalake.models.FileRange"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.FileRange\" data-throw-if-not-resolved=\"false\">FileRange</xref>"
    - id: "parallelTransferOptions"
      type: "com.azure.storage.common.ParallelTransferOptions"
      description: "<xref uid=\"\" data-throw-if-not-resolved=\"false\">ParallelTransferOptions</xref> to use to download to file. Number of parallel\n transfers parameter is ignored."
    - id: "downloadRetryOptions"
      type: "com.azure.storage.file.datalake.models.DownloadRetryOptions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DownloadRetryOptions\" data-throw-if-not-resolved=\"false\">DownloadRetryOptions</xref>"
    - id: "requestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref>"
    - id: "rangeGetContentMd5"
      type: "boolean"
      description: "Whether the contentMD5 for the specified file range should be returned."
    - id: "openOptions"
      type: "java.util.Set<java.nio.file.OpenOption>"
      description: "<xref uid=\"java.nio.file.OpenOption\" data-throw-if-not-resolved=\"false\">OpenOptions</xref> to use to configure how to open or create the file."
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.core.http.rest.Response<com.azure.storage.file.datalake.models.PathProperties>"
      description: "A response containing the file properties and metadata."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.readWithResponse(java.io.OutputStream,com.azure.storage.file.datalake.models.FileRange,com.azure.storage.file.datalake.models.DownloadRetryOptions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,boolean,java.time.Duration,com.azure.core.util.Context)"
  id: "readWithResponse(java.io.OutputStream,com.azure.storage.file.datalake.models.FileRange,com.azure.storage.file.datalake.models.DownloadRetryOptions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,boolean,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "readWithResponse(OutputStream stream, FileRange range, DownloadRetryOptions options, DataLakeRequestConditions requestConditions, boolean getRangeContentMd5, Duration timeout, Context context)"
  nameWithType: "DataLakeFileClient.readWithResponse(OutputStream stream, FileRange range, DownloadRetryOptions options, DataLakeRequestConditions requestConditions, boolean getRangeContentMd5, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.readWithResponse(OutputStream stream, FileRange range, DownloadRetryOptions options, DataLakeRequestConditions requestConditions, boolean getRangeContentMd5, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.readWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Reads a range of bytes from a file into an output stream.\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.readWithResponse\\#OutputStream-FileRange-DownloadRetryOptions-DataLakeRequestConditions-boolean-Duration-Context\\}\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob"
  syntax:
    content: "public FileReadResponse readWithResponse(OutputStream stream, FileRange range, DownloadRetryOptions options, DataLakeRequestConditions requestConditions, boolean getRangeContentMd5, Duration timeout, Context context)"
    parameters:
    - id: "stream"
      type: "java.io.OutputStream"
      description: "A non-null <xref uid=\"\" data-throw-if-not-resolved=\"false\">OutputStream</xref> instance where the downloaded data will be written."
    - id: "range"
      type: "com.azure.storage.file.datalake.models.FileRange"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.FileRange\" data-throw-if-not-resolved=\"false\">FileRange</xref>"
    - id: "options"
      type: "com.azure.storage.file.datalake.models.DownloadRetryOptions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DownloadRetryOptions\" data-throw-if-not-resolved=\"false\">DownloadRetryOptions</xref>"
    - id: "requestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref>"
    - id: "getRangeContentMd5"
      type: "boolean"
      description: "Whether the contentMD5 for the specified file range should be returned."
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.storage.file.datalake.models.FileReadResponse"
      description: "A response containing status code and HTTP headers."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.rename(java.lang.String,java.lang.String)"
  id: "rename(java.lang.String,java.lang.String)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "rename(String destinationFileSystem, String destinationPath)"
  nameWithType: "DataLakeFileClient.rename(String destinationFileSystem, String destinationPath)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.rename(String destinationFileSystem, String destinationPath)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.rename*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Moves the file to another location within the file system. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeDirectoryAsyncClient.rename\\#String-String\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create"
  syntax:
    content: "public DataLakeFileClient rename(String destinationFileSystem, String destinationPath)"
    parameters:
    - id: "destinationFileSystem"
      type: "java.lang.String"
      description: "The file system of the destination within the account.\n <code>null</code> for the current file system."
    - id: "destinationPath"
      type: "java.lang.String"
      description: "Relative path from the file system to rename the file to, excludes the file system name.\n For example if you want to move a file with fileSystem = \"myfilesystem\", path = \"mydir/hello.txt\" to another path\n in myfilesystem (ex: newdir/hi.txt) then set the destinationPath = \"newdir/hi.txt\""
    return:
      type: "com.azure.storage.file.datalake.DataLakeFileClient"
      description: "A <xref uid=\"com.azure.storage.file.datalake.DataLakeFileClient\" data-throw-if-not-resolved=\"false\">DataLakeFileClient</xref> used to interact with the new file created."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  id: "renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeFileClient.renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.renameWithResponse*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Moves the file to another location within the file system. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.renameWithResponse\\#String-String-DataLakeRequestConditions-DataLakeRequestConditions-Duration-Context\\}\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create"
  syntax:
    content: "public Response<DataLakeFileClient> renameWithResponse(String destinationFileSystem, String destinationPath, DataLakeRequestConditions sourceRequestConditions, DataLakeRequestConditions destinationRequestConditions, Duration timeout, Context context)"
    parameters:
    - id: "destinationFileSystem"
      type: "java.lang.String"
      description: "The file system of the destination within the account.\n <code>null</code> for the current file system."
    - id: "destinationPath"
      type: "java.lang.String"
      description: "Relative path from the file system to rename the file to, excludes the file system name.\n For example if you want to move a file with fileSystem = \"myfilesystem\", path = \"mydir/hello.txt\" to another path\n in myfilesystem (ex: newdir/hi.txt) then set the destinationPath = \"newdir/hi.txt\""
    - id: "sourceRequestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref> against the source."
    - id: "destinationRequestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref> against the destination."
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
    - id: "context"
      type: "com.azure.core.util.Context"
      description: "Additional context that is passed through the Http pipeline during the service call."
    return:
      type: "com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeFileClient>"
      description: "A <xref uid=\"com.azure.core.http.rest.Response\" data-throw-if-not-resolved=\"false\">Response</xref> whose <xref uid=\"\" data-throw-if-not-resolved=\"false\">value</xref> that contains a <xref uid=\"com.azure.storage.file.datalake.DataLakeFileClient\" data-throw-if-not-resolved=\"false\">DataLakeFileClient</xref>\n used to interact with the file created."
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile(java.lang.String)"
  id: "uploadFromFile(java.lang.String)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "uploadFromFile(String filePath)"
  nameWithType: "DataLakeFileClient.uploadFromFile(String filePath)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile(String filePath)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Creates a file, with the content of the specified file. By default this method will not overwrite an existing file.\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile\\#String\\}"
  syntax:
    content: "public void uploadFromFile(String filePath)"
    parameters:
    - id: "filePath"
      type: "java.lang.String"
      description: "Path of the file to upload"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile(java.lang.String,boolean)"
  id: "uploadFromFile(java.lang.String,boolean)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "uploadFromFile(String filePath, boolean overwrite)"
  nameWithType: "DataLakeFileClient.uploadFromFile(String filePath, boolean overwrite)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile(String filePath, boolean overwrite)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Creates a file, with the content of the specified file.\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile\\#String-boolean\\}"
  syntax:
    content: "public void uploadFromFile(String filePath, boolean overwrite)"
    parameters:
    - id: "filePath"
      type: "java.lang.String"
      description: "Path of the file to upload"
    - id: "overwrite"
      type: "boolean"
      description: "Whether or not to overwrite, should the file already exist"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile(java.lang.String,com.azure.storage.common.ParallelTransferOptions,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration)"
  id: "uploadFromFile(java.lang.String,com.azure.storage.common.ParallelTransferOptions,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration)"
  parent: "com.azure.storage.file.datalake.DataLakeFileClient"
  langs:
  - "java"
  name: "uploadFromFile(String filePath, ParallelTransferOptions parallelTransferOptions, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout)"
  nameWithType: "DataLakeFileClient.uploadFromFile(String filePath, ParallelTransferOptions parallelTransferOptions, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile(String filePath, ParallelTransferOptions parallelTransferOptions, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout)"
  overload: "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile*"
  type: "Method"
  package: "com.azure.storage.file.datalake"
  summary: "Creates a file, with the content of the specified file.\n\nTo avoid overwriting, pass \"\\*\" to <xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions.setIfNoneMatch(java.lang.String)\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions#setIfNoneMatch(String)</xref>.\n\n**Code Samples**\n\n\\{@codesnippet com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile\\#String-ParallelTransferOptions-PathHttpHeaders-Map-DataLakeRequestConditions-Duration\\}"
  syntax:
    content: "public void uploadFromFile(String filePath, ParallelTransferOptions parallelTransferOptions, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout)"
    parameters:
    - id: "filePath"
      type: "java.lang.String"
      description: "Path of the file to upload"
    - id: "parallelTransferOptions"
      type: "com.azure.storage.common.ParallelTransferOptions"
      description: "<xref uid=\"\" data-throw-if-not-resolved=\"false\">ParallelTransferOptions</xref> used to configure buffered uploading."
    - id: "headers"
      type: "com.azure.storage.file.datalake.models.PathHttpHeaders"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.PathHttpHeaders\" data-throw-if-not-resolved=\"false\">PathHttpHeaders</xref>"
    - id: "metadata"
      type: "java.util.Map<java.lang.String,java.lang.String>"
      description: "Metadata to associate with the resource."
    - id: "requestConditions"
      type: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
      description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\">DataLakeRequestConditions</xref>"
    - id: "timeout"
      type: "java.time.Duration"
      description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\">RuntimeException</xref> will be raised."
references:
- uid: "com.azure.storage.file.datalake.DataLakeFileAsyncClient"
  name: "DataLakeFileAsyncClient"
  nameWithType: "DataLakeFileAsyncClient"
  fullName: "com.azure.storage.file.datalake.DataLakeFileAsyncClient"
- uid: "com.azure.storage.blob.specialized.BlockBlobClient"
  spec.java:
  - uid: "com.azure.storage.blob.specialized.BlockBlobClient"
    name: "BlockBlobClient"
    fullName: "com.azure.storage.blob.specialized.BlockBlobClient"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.DataLakeFileClient*"
  name: "DataLakeFileClient"
  nameWithType: "DataLakeFileClient.DataLakeFileClient"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.DataLakeFileClient"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakePathClient"
  name: "DataLakePathClient"
  nameWithType: "DataLakePathClient"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient"
- uid: "java.lang.String"
  spec.java:
  - uid: "java.lang.String"
    name: "String"
    fullName: "java.lang.String"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.getFileUrl*"
  name: "getFileUrl"
  nameWithType: "DataLakeFileClient.getFileUrl"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.getFileUrl"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.getFilePath*"
  name: "getFilePath"
  nameWithType: "DataLakeFileClient.getFilePath"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.getFilePath"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.getFileName*"
  name: "getFileName"
  nameWithType: "DataLakeFileClient.getFileName"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.getFileName"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.delete*"
  name: "delete"
  nameWithType: "DataLakeFileClient.delete"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.delete"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
  name: "DataLakeRequestConditions"
  nameWithType: "DataLakeRequestConditions"
  fullName: "com.azure.storage.file.datalake.models.DataLakeRequestConditions"
- uid: "java.time.Duration"
  spec.java:
  - uid: "java.time.Duration"
    name: "Duration"
    fullName: "java.time.Duration"
- uid: "com.azure.core.util.Context"
  spec.java:
  - uid: "com.azure.core.util.Context"
    name: "Context"
    fullName: "com.azure.core.util.Context"
- uid: "com.azure.core.http.rest.Response<java.lang.Void>"
  spec.java:
  - uid: "com.azure.core.http.rest.Response"
    name: "Response"
    fullName: "com.azure.core.http.rest.Response"
  - name: "<"
    fullName: "<"
  - uid: "java.lang.Void"
    name: "Void"
    fullName: "java.lang.Void"
  - name: ">"
    fullName: ">"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.deleteWithResponse*"
  name: "deleteWithResponse"
  nameWithType: "DataLakeFileClient.deleteWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.deleteWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile*"
  name: "uploadFromFile"
  nameWithType: "DataLakeFileClient.uploadFromFile"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.uploadFromFile"
  package: "com.azure.storage.file.datalake"
- uid: "boolean"
  spec.java:
  - uid: "boolean"
    name: "boolean"
    fullName: "boolean"
- uid: "com.azure.storage.common.ParallelTransferOptions"
  spec.java:
  - uid: "com.azure.storage.common.ParallelTransferOptions"
    name: "ParallelTransferOptions"
    fullName: "com.azure.storage.common.ParallelTransferOptions"
- uid: "com.azure.storage.file.datalake.models.PathHttpHeaders"
  name: "PathHttpHeaders"
  nameWithType: "PathHttpHeaders"
  fullName: "com.azure.storage.file.datalake.models.PathHttpHeaders"
- uid: "java.util.Map<java.lang.String,java.lang.String>"
  spec.java:
  - uid: "java.util.Map"
    name: "Map"
    fullName: "java.util.Map"
  - name: "<"
    fullName: "<"
  - uid: "java.lang.String"
    name: "String"
    fullName: "java.lang.String"
  - name: ","
    fullName: ","
  - uid: "java.lang.String"
    name: "String"
    fullName: "java.lang.String"
  - name: ">"
    fullName: ">"
- uid: "java.io.InputStream"
  spec.java:
  - uid: "java.io.InputStream"
    name: "InputStream"
    fullName: "java.io.InputStream"
- uid: "long"
  spec.java:
  - uid: "long"
    name: "long"
    fullName: "long"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.append*"
  name: "append"
  nameWithType: "DataLakeFileClient.append"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.append"
  package: "com.azure.storage.file.datalake"
- uid: "byte[]"
  spec.java:
  - uid: "byte"
    name: "byte"
    fullName: "byte"
  - name: "[]"
    fullName: "[]"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.appendWithResponse*"
  name: "appendWithResponse"
  nameWithType: "DataLakeFileClient.appendWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.appendWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.models.PathInfo"
  name: "PathInfo"
  nameWithType: "PathInfo"
  fullName: "com.azure.storage.file.datalake.models.PathInfo"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.flush*"
  name: "flush"
  nameWithType: "DataLakeFileClient.flush"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.flush"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.core.http.rest.Response<com.azure.storage.file.datalake.models.PathInfo>"
  spec.java:
  - uid: "com.azure.core.http.rest.Response"
    name: "Response"
    fullName: "com.azure.core.http.rest.Response"
  - name: "<"
    fullName: "<"
  - uid: "com.azure.storage.file.datalake.models.PathInfo"
    name: "PathInfo"
    fullName: "com.azure.storage.file.datalake.models.PathInfo"
  - name: ">"
    fullName: ">"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.flushWithResponse*"
  name: "flushWithResponse"
  nameWithType: "DataLakeFileClient.flushWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.flushWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "java.io.OutputStream"
  spec.java:
  - uid: "java.io.OutputStream"
    name: "OutputStream"
    fullName: "java.io.OutputStream"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.read*"
  name: "read"
  nameWithType: "DataLakeFileClient.read"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.read"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.models.FileRange"
  name: "FileRange"
  nameWithType: "FileRange"
  fullName: "com.azure.storage.file.datalake.models.FileRange"
- uid: "com.azure.storage.file.datalake.models.DownloadRetryOptions"
  name: "DownloadRetryOptions"
  nameWithType: "DownloadRetryOptions"
  fullName: "com.azure.storage.file.datalake.models.DownloadRetryOptions"
- uid: "com.azure.storage.file.datalake.models.FileReadResponse"
  name: "FileReadResponse"
  nameWithType: "FileReadResponse"
  fullName: "com.azure.storage.file.datalake.models.FileReadResponse"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.readWithResponse*"
  name: "readWithResponse"
  nameWithType: "DataLakeFileClient.readWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.readWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.models.PathProperties"
  name: "PathProperties"
  nameWithType: "PathProperties"
  fullName: "com.azure.storage.file.datalake.models.PathProperties"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.readToFile*"
  name: "readToFile"
  nameWithType: "DataLakeFileClient.readToFile"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.readToFile"
  package: "com.azure.storage.file.datalake"
- uid: "java.util.Set<java.nio.file.OpenOption>"
  spec.java:
  - uid: "java.util.Set"
    name: "Set"
    fullName: "java.util.Set"
  - name: "<"
    fullName: "<"
  - uid: "java.nio.file.OpenOption"
    name: "OpenOption"
    fullName: "java.nio.file.OpenOption"
  - name: ">"
    fullName: ">"
- uid: "com.azure.core.http.rest.Response<com.azure.storage.file.datalake.models.PathProperties>"
  spec.java:
  - uid: "com.azure.core.http.rest.Response"
    name: "Response"
    fullName: "com.azure.core.http.rest.Response"
  - name: "<"
    fullName: "<"
  - uid: "com.azure.storage.file.datalake.models.PathProperties"
    name: "PathProperties"
    fullName: "com.azure.storage.file.datalake.models.PathProperties"
  - name: ">"
    fullName: ">"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.readToFileWithResponse*"
  name: "readToFileWithResponse"
  nameWithType: "DataLakeFileClient.readToFileWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.readToFileWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.rename*"
  name: "rename"
  nameWithType: "DataLakeFileClient.rename"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.rename"
  package: "com.azure.storage.file.datalake"
- uid: "com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeFileClient>"
  spec.java:
  - uid: "com.azure.core.http.rest.Response"
    name: "Response"
    fullName: "com.azure.core.http.rest.Response"
  - name: "<"
    fullName: "<"
  - uid: "com.azure.storage.file.datalake.DataLakeFileClient"
    name: "DataLakeFileClient"
    fullName: "com.azure.storage.file.datalake.DataLakeFileClient"
  - name: ">"
    fullName: ">"
- uid: "com.azure.storage.file.datalake.DataLakeFileClient.renameWithResponse*"
  name: "renameWithResponse"
  nameWithType: "DataLakeFileClient.renameWithResponse"
  fullName: "com.azure.storage.file.datalake.DataLakeFileClient.renameWithResponse"
  package: "com.azure.storage.file.datalake"
- uid: "java.lang.Object.wait()"
  name: "Object.wait()"
  nameWithType: "Object.wait()"
  fullName: "java.lang.Object.wait()"
- uid: "java.lang.Object.finalize()"
  name: "Object.finalize()"
  nameWithType: "Object.finalize()"
  fullName: "java.lang.Object.finalize()"
- uid: "java.lang.Object.clone()"
  name: "Object.clone()"
  nameWithType: "Object.clone()"
  fullName: "java.lang.Object.clone()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getProperties()"
  name: "DataLakePathClient.getProperties()"
  nameWithType: "DataLakePathClient.getProperties()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getProperties()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getObjectName()"
  name: "DataLakePathClient.getObjectName()"
  nameWithType: "DataLakePathClient.getObjectName()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getObjectName()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.existsWithResponse(java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.existsWithResponse(Duration,Context)"
  nameWithType: "DataLakePathClient.existsWithResponse(Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.existsWithResponse(java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)"
  name: "DataLakePathClient.setAccessControlList(List<PathAccessControlEntry>,String,String)"
  nameWithType: "DataLakePathClient.setAccessControlList(List<PathAccessControlEntry>,String,String)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.create()"
  name: "DataLakePathClient.create()"
  nameWithType: "DataLakePathClient.create()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.create()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.core.util.Context)"
  name: "DataLakePathClient.renameWithResponse(String,String,DataLakeRequestConditions,DataLakeRequestConditions,Context)"
  nameWithType: "DataLakePathClient.renameWithResponse(String,String,DataLakeRequestConditions,DataLakeRequestConditions,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.renameWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.storage.file.datalake.models.DataLakeRequestConditions,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getPathUrl()"
  name: "DataLakePathClient.getPathUrl()"
  nameWithType: "DataLakePathClient.getPathUrl()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getPathUrl()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map<String,String>,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map<String,String>,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getAccessControl()"
  name: "DataLakePathClient.getAccessControl()"
  nameWithType: "DataLakePathClient.getAccessControl()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getAccessControl()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.setMetadataWithResponse(Map<String,String>,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.setMetadataWithResponse(Map<String,String>,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "java.lang.Object.wait(long)"
  name: "Object.wait(long)"
  nameWithType: "Object.wait(long)"
  fullName: "java.lang.Object.wait(long)"
- uid: "java.lang.Object.getClass()"
  name: "Object.getClass()"
  nameWithType: "Object.getClass()"
  fullName: "java.lang.Object.getClass()"
- uid: "java.lang.Object.hashCode()"
  name: "Object.hashCode()"
  nameWithType: "Object.hashCode()"
  fullName: "java.lang.Object.hashCode()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getServiceVersion()"
  name: "DataLakePathClient.getServiceVersion()"
  nameWithType: "DataLakePathClient.getServiceVersion()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getServiceVersion()"
- uid: "java.lang.Object.wait(long,int)"
  name: "Object.wait(long,int)"
  nameWithType: "Object.wait(long,int)"
  fullName: "java.lang.Object.wait(long,int)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getAccountName()"
  name: "DataLakePathClient.getAccountName()"
  nameWithType: "DataLakePathClient.getAccountName()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getAccountName()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getBlockBlobClient()"
  name: "DataLakePathClient.getBlockBlobClient()"
  nameWithType: "DataLakePathClient.getBlockBlobClient()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getBlockBlobClient()"
- uid: "java.lang.Object.notify()"
  name: "Object.notify()"
  nameWithType: "Object.notify()"
  fullName: "java.lang.Object.notify()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getAccessControlWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.getAccessControlWithResponse(boolean,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.getAccessControlWithResponse(boolean,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getAccessControlWithResponse(boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "java.lang.Object.notifyAll()"
  name: "Object.notifyAll()"
  nameWithType: "Object.notifyAll()"
  fullName: "java.lang.Object.notifyAll()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)"
  name: "DataLakePathClient.generateSas(DataLakeServiceSasSignatureValues)"
  nameWithType: "DataLakePathClient.generateSas(DataLakeServiceSasSignatureValues)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)"
- uid: "java.lang.Object.equals(java.lang.Object)"
  name: "Object.equals(Object)"
  nameWithType: "Object.equals(Object)"
  fullName: "java.lang.Object.equals(java.lang.Object)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)"
  name: "DataLakePathClient.setMetadata(Map<String,String>)"
  nameWithType: "DataLakePathClient.setMetadata(Map<String,String>)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeadersWithResponse(com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.setHttpHeadersWithResponse(PathHttpHeaders,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.setHttpHeadersWithResponse(PathHttpHeaders,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeadersWithResponse(com.azure.storage.file.datalake.models.PathHttpHeaders,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.exists()"
  name: "DataLakePathClient.exists()"
  nameWithType: "DataLakePathClient.exists()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.exists()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)"
  name: "DataLakePathClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues,UserDelegationKey)"
  nameWithType: "DataLakePathClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues,UserDelegationKey)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setPermissions(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String)"
  name: "DataLakePathClient.setPermissions(PathPermissions,String,String)"
  nameWithType: "DataLakePathClient.setPermissions(PathPermissions,String,String)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setPermissions(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String)"
- uid: "java.lang.Object.toString()"
  name: "Object.toString()"
  nameWithType: "Object.toString()"
  fullName: "java.lang.Object.toString()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getFileSystemName()"
  name: "DataLakePathClient.getFileSystemName()"
  nameWithType: "DataLakePathClient.getFileSystemName()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getFileSystemName()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.create(boolean)"
  name: "DataLakePathClient.create(boolean)"
  nameWithType: "DataLakePathClient.create(boolean)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.create(boolean)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setPermissionsWithResponse(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.setPermissionsWithResponse(PathPermissions,String,String,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.setPermissionsWithResponse(PathPermissions,String,String,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setPermissionsWithResponse(com.azure.storage.file.datalake.models.PathPermissions,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeaders(com.azure.storage.file.datalake.models.PathHttpHeaders)"
  name: "DataLakePathClient.setHttpHeaders(PathHttpHeaders)"
  nameWithType: "DataLakePathClient.setHttpHeaders(PathHttpHeaders)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setHttpHeaders(com.azure.storage.file.datalake.models.PathHttpHeaders)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getHttpPipeline()"
  name: "DataLakePathClient.getHttpPipeline()"
  nameWithType: "DataLakePathClient.getHttpPipeline()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getHttpPipeline()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.setAccessControlListWithResponse(List<PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.setAccessControlListWithResponse(List<PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List<com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getObjectPath()"
  name: "DataLakePathClient.getObjectPath()"
  nameWithType: "DataLakePathClient.getObjectPath()"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getObjectPath()"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.getPropertiesWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "DataLakePathClient.getPropertiesWithResponse(DataLakeRequestConditions,Duration,Context)"
  nameWithType: "DataLakePathClient.getPropertiesWithResponse(DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.getPropertiesWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "java.lang.Void"
  name: "Void"
  nameWithType: "Void"
  fullName: "java.lang.Void"
- uid: "com.azure.core.http.rest.Response"
  name: "Response"
  nameWithType: "Response"
  fullName: "com.azure.core.http.rest.Response"
- uid: "java.util.Map"
  name: "Map"
  nameWithType: "Map"
  fullName: "java.util.Map"
- uid: "java.lang.String,java.lang.String"
  name: "String,String"
  nameWithType: "String,String"
  fullName: "java.lang.String,java.lang.String"
- uid: "java.nio.file.OpenOption"
  name: "OpenOption"
  nameWithType: "OpenOption"
  fullName: "java.nio.file.OpenOption"
- uid: "java.util.Set"
  name: "Set"
  nameWithType: "Set"
  fullName: "java.util.Set"
- uid: "com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)"
  name: "PathAccessControlEntry>,String,String)"
  nameWithType: "PathAccessControlEntry>,String,String)"
  fullName: "com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List"
  name: "DataLakePathClient.setAccessControlList(List"
  nameWithType: "DataLakePathClient.setAccessControlList(List"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlList(java.util.List"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map"
  name: "DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map"
  nameWithType: "DataLakePathClient.createWithResponse(String,String,PathHttpHeaders,Map"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.createWithResponse(java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map"
- uid: "java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "String,String>,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "String,String>,DataLakeRequestConditions,Duration,Context)"
  fullName: "java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map"
  name: "DataLakePathClient.setMetadataWithResponse(Map"
  nameWithType: "DataLakePathClient.setMetadataWithResponse(Map"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setMetadataWithResponse(java.util.Map"
- uid: "java.lang.String,java.lang.String>)"
  name: "String,String>)"
  nameWithType: "String,String>)"
  fullName: "java.lang.String,java.lang.String>)"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map"
  name: "DataLakePathClient.setMetadata(Map"
  nameWithType: "DataLakePathClient.setMetadata(Map"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setMetadata(java.util.Map"
- uid: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List"
  name: "DataLakePathClient.setAccessControlListWithResponse(List"
  nameWithType: "DataLakePathClient.setAccessControlListWithResponse(List"
  fullName: "com.azure.storage.file.datalake.DataLakePathClient.setAccessControlListWithResponse(java.util.List"
- uid: "com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  name: "PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)"
  nameWithType: "PathAccessControlEntry>,String,String,DataLakeRequestConditions,Duration,Context)"
  fullName: "com.azure.storage.file.datalake.models.PathAccessControlEntry>,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
