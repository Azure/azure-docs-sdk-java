### YamlMime:JavaMember
uid: "com.azure.storage.blob.BlobAsyncClient.uploadWithResponse*"
fullName: "com.azure.storage.blob.BlobAsyncClient.uploadWithResponse"
name: "uploadWithResponse"
nameWithType: "BlobAsyncClient.uploadWithResponse"
members:
- uid: "com.azure.storage.blob.BlobAsyncClient.uploadWithResponse(com.azure.storage.blob.options.BlobParallelUploadOptions)"
  fullName: "com.azure.storage.blob.BlobAsyncClient.uploadWithResponse(BlobParallelUploadOptions options)"
  name: "uploadWithResponse(BlobParallelUploadOptions options)"
  nameWithType: "BlobAsyncClient.uploadWithResponse(BlobParallelUploadOptions options)"
  summary: "Creates a new block blob, or updates the content of an existing block blob.\n\nUpdating an existing block blob overwrites any existing metadata on the blob. Partial updates are not supported with this method; the content of the existing blob is overwritten with the new content. To perform a partial update of a block blob's, use <xref uid=\"com.azure.storage.blob.specialized.BlockBlobAsyncClient.stageBlock(java.lang.String,reactor.core.publisher.Flux&lt;java.nio.ByteBuffer&gt;,long)\" data-throw-if-not-resolved=\"false\">stageBlock</xref> and <xref uid=\"com.azure.storage.blob.specialized.BlockBlobAsyncClient.commitBlockList(java.util.List&lt;java.lang.String&gt;)\" data-throw-if-not-resolved=\"false\">commitBlockList</xref>. For more information, see the [Azure Docs for Put Block][] and the [Azure Docs for Put Block List][].\n\nThe data passed need not support multiple subscriptions/be replayable as is required in other upload methods when retries are enabled, and the length of the data need not be known in advance. Therefore, this method does support uploading any arbitrary data source, including network streams. This behavior is possible because this method will perform some internal buffering as configured by the blockSize and numBuffers parameters, so while this method may offer additional convenience, it will not be as performant as other options, which should be preferred when possible.\n\nTypically, the greater the number of buffers used, the greater the possible parallelism when transferring the data. Larger buffers means we will have to stage fewer blocks and therefore require fewer IO operations. The trade-offs between these values are context-dependent, so some experimentation may be required to optimize inputs for a given scenario.\n\nTo avoid overwriting, pass \"\\*\" to <xref uid=\"com.azure.storage.blob.models.BlobRequestConditions.setIfNoneMatch(java.lang.String)\" data-throw-if-not-resolved=\"false\">BlobRequestConditions#setIfNoneMatch(String)</xref>.\n\n**Code Samples**\n\n```java\nBlobHttpHeaders headers = new BlobHttpHeaders()\n     .setContentMd5(\"data\".getBytes(StandardCharsets.UTF_8))\n     .setContentLanguage(\"en-US\")\n     .setContentType(\"binary\");\n \n Map<String, String> metadata = Collections.singletonMap(\"metadata\", \"value\");\n Map<String, String> tags = Collections.singletonMap(\"tag\", \"value\");\n BlobRequestConditions requestConditions = new BlobRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n \n ParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions().setBlockSizeLong(blockSize)\n     .setMaxConcurrency(maxConcurrency).setProgressReceiver(bytesTransferred ->\n         System.out.printf(\"Upload progress: %s bytes sent\", bytesTransferred));\n \n client.uploadWithResponse(new BlobParallelUploadOptions(data)\n     .setParallelTransferOptions(parallelTransferOptions).setHeaders(headers).setMetadata(metadata).setTags(tags)\n     .setTier(AccessTier.HOT).setRequestConditions(requestConditions))\n     .subscribe(response -> System.out.printf(\"Uploaded BlockBlob MD5 is %s%n\",\n         Base64.getEncoder().encodeToString(response.getValue().getContentMd5())));\n```\n\n**Using Progress Reporting**\n\n```java\nBlobHttpHeaders headers = new BlobHttpHeaders()\n     .setContentMd5(\"data\".getBytes(StandardCharsets.UTF_8))\n     .setContentLanguage(\"en-US\")\n     .setContentType(\"binary\");\n \n Map<String, String> metadata = Collections.singletonMap(\"metadata\", \"value\");\n Map<String, String> tags = Collections.singletonMap(\"tag\", \"value\");\n BlobRequestConditions requestConditions = new BlobRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n \n ParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions().setBlockSizeLong(blockSize)\n     .setMaxConcurrency(maxConcurrency).setProgressReceiver(bytesTransferred ->\n         System.out.printf(\"Upload progress: %s bytes sent\", bytesTransferred));\n \n client.uploadWithResponse(new BlobParallelUploadOptions(data)\n     .setParallelTransferOptions(parallelTransferOptions).setHeaders(headers).setMetadata(metadata).setTags(tags)\n     .setTier(AccessTier.HOT).setRequestConditions(requestConditions))\n     .subscribe(response -> System.out.printf(\"Uploaded BlockBlob MD5 is %s%n\",\n         Base64.getEncoder().encodeToString(response.getValue().getContentMd5())));\n```\n\n\n[Azure Docs for Put Block]: https://docs.microsoft.com/rest/api/storageservices/put-block\n[Azure Docs for Put Block List]: https://docs.microsoft.com/rest/api/storageservices/put-block-list"
  parameters:
  - description: "<xref uid=\"com.azure.storage.blob.options.BlobParallelUploadOptions\" data-throw-if-not-resolved=\"false\">BlobParallelUploadOptions</xref>. Unlike other upload methods, this method does not require that\n the <code>Flux</code> be replayable. In other words, it does not have to support multiple subscribers and is not\n expected to produce the same values across subscriptions."
    name: "options"
    type: "<xref href=\"com.azure.storage.blob.options.BlobParallelUploadOptions?alt=com.azure.storage.blob.options.BlobParallelUploadOptions&text=BlobParallelUploadOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<BlockBlobItem>> uploadWithResponse(BlobParallelUploadOptions options)"
  returns:
    description: "A reactive response containing the information of the uploaded block blob."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.blob.models.BlockBlobItem?alt=com.azure.storage.blob.models.BlockBlobItem&text=BlockBlobItem\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.storage.blob.BlobAsyncClient.uploadWithResponse(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.blob.models.ParallelTransferOptions,com.azure.storage.blob.models.BlobHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.blob.models.AccessTier,com.azure.storage.blob.models.BlobRequestConditions)"
  fullName: "com.azure.storage.blob.BlobAsyncClient.uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, BlobHttpHeaders headers, Map<String,String> metadata, AccessTier tier, BlobRequestConditions requestConditions)"
  name: "uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, BlobHttpHeaders headers, Map<String,String> metadata, AccessTier tier, BlobRequestConditions requestConditions)"
  nameWithType: "BlobAsyncClient.uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, BlobHttpHeaders headers, Map<String,String> metadata, AccessTier tier, BlobRequestConditions requestConditions)"
  summary: "Creates a new block blob, or updates the content of an existing block blob.\n\nUpdating an existing block blob overwrites any existing metadata on the blob. Partial updates are not supported with this method; the content of the existing blob is overwritten with the new content. To perform a partial update of a block blob's, use <xref uid=\"com.azure.storage.blob.specialized.BlockBlobAsyncClient.stageBlock(java.lang.String,reactor.core.publisher.Flux&lt;java.nio.ByteBuffer&gt;,long)\" data-throw-if-not-resolved=\"false\">stageBlock</xref> and <xref uid=\"com.azure.storage.blob.specialized.BlockBlobAsyncClient.commitBlockList(java.util.List&lt;java.lang.String&gt;)\" data-throw-if-not-resolved=\"false\">commitBlockList</xref>. For more information, see the [Azure Docs for Put Block][] and the [Azure Docs for Put Block List][].\n\nThe data passed need not support multiple subscriptions/be replayable as is required in other upload methods when retries are enabled, and the length of the data need not be known in advance. Therefore, this method does support uploading any arbitrary data source, including network streams. This behavior is possible because this method will perform some internal buffering as configured by the blockSize and numBuffers parameters, so while this method may offer additional convenience, it will not be as performant as other options, which should be preferred when possible.\n\nTypically, the greater the number of buffers used, the greater the possible parallelism when transferring the data. Larger buffers means we will have to stage fewer blocks and therefore require fewer IO operations. The trade-offs between these values are context-dependent, so some experimentation may be required to optimize inputs for a given scenario.\n\nTo avoid overwriting, pass \"\\*\" to <xref uid=\"com.azure.storage.blob.models.BlobRequestConditions.setIfNoneMatch(java.lang.String)\" data-throw-if-not-resolved=\"false\">BlobRequestConditions#setIfNoneMatch(String)</xref>.\n\n**Code Samples**\n\n```java\nBlobHttpHeaders headers = new BlobHttpHeaders()\n     .setContentMd5(\"data\".getBytes(StandardCharsets.UTF_8))\n     .setContentLanguage(\"en-US\")\n     .setContentType(\"binary\");\n \n Map<String, String> metadata = Collections.singletonMap(\"metadata\", \"value\");\n BlobRequestConditions requestConditions = new BlobRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n \n ParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions()\n     .setBlockSizeLong(blockSize)\n     .setMaxConcurrency(maxConcurrency);\n \n client.uploadWithResponse(data, parallelTransferOptions, headers, metadata, AccessTier.HOT, requestConditions)\n     .subscribe(response -> System.out.printf(\"Uploaded BlockBlob MD5 is %s%n\",\n         Base64.getEncoder().encodeToString(response.getValue().getContentMd5())));\n```\n\n**Using Progress Reporting**\n\n```java\nBlobHttpHeaders headers = new BlobHttpHeaders()\n     .setContentMd5(\"data\".getBytes(StandardCharsets.UTF_8))\n     .setContentLanguage(\"en-US\")\n     .setContentType(\"binary\");\n \n Map<String, String> metadata = Collections.singletonMap(\"metadata\", \"value\");\n BlobRequestConditions requestConditions = new BlobRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n \n ParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions()\n     .setBlockSizeLong(blockSize)\n     .setMaxConcurrency(maxConcurrency)\n     .setProgressReceiver(bytesTransferred -> System.out.printf(\"Upload progress: %s bytes sent\", bytesTransferred));\n \n client.uploadWithResponse(data, parallelTransferOptions, headers, metadata, AccessTier.HOT, requestConditions)\n     .subscribe(response -> System.out.printf(\"Uploaded BlockBlob MD5 is %s%n\",\n         Base64.getEncoder().encodeToString(response.getValue().getContentMd5())));\n```\n\n\n[Azure Docs for Put Block]: https://docs.microsoft.com/rest/api/storageservices/put-block\n[Azure Docs for Put Block List]: https://docs.microsoft.com/rest/api/storageservices/put-block-list"
  parameters:
  - description: "The data to write to the blob. Unlike other upload methods, this method does not require that the\n <code>Flux</code> be replayable. In other words, it does not have to support multiple subscribers and is not expected\n to produce the same values across subscriptions."
    name: "data"
    type: "<xref href=\"reactor.core.publisher.Flux?alt=reactor.core.publisher.Flux&text=Flux\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.nio.ByteBuffer?alt=java.nio.ByteBuffer&text=ByteBuffer\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "<xref uid=\"com.azure.storage.blob.models.ParallelTransferOptions\" data-throw-if-not-resolved=\"false\">ParallelTransferOptions</xref> used to configure buffered uploading."
    name: "parallelTransferOptions"
    type: "<xref href=\"com.azure.storage.blob.models.ParallelTransferOptions?alt=com.azure.storage.blob.models.ParallelTransferOptions&text=ParallelTransferOptions\" data-throw-if-not-resolved=\"False\" />"
  - description: "<xref uid=\"com.azure.storage.blob.models.BlobHttpHeaders\" data-throw-if-not-resolved=\"false\">BlobHttpHeaders</xref>"
    name: "headers"
    type: "<xref href=\"com.azure.storage.blob.models.BlobHttpHeaders?alt=com.azure.storage.blob.models.BlobHttpHeaders&text=BlobHttpHeaders\" data-throw-if-not-resolved=\"False\" />"
  - description: "Metadata to associate with the blob."
    name: "metadata"
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "<xref uid=\"com.azure.storage.blob.models.AccessTier\" data-throw-if-not-resolved=\"false\">AccessTier</xref> for the destination blob."
    name: "tier"
    type: "<xref href=\"com.azure.storage.blob.models.AccessTier?alt=com.azure.storage.blob.models.AccessTier&text=AccessTier\" data-throw-if-not-resolved=\"False\" />"
  - description: "<xref uid=\"com.azure.storage.blob.models.BlobRequestConditions\" data-throw-if-not-resolved=\"false\">BlobRequestConditions</xref>"
    name: "requestConditions"
    type: "<xref href=\"com.azure.storage.blob.models.BlobRequestConditions?alt=com.azure.storage.blob.models.BlobRequestConditions&text=BlobRequestConditions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<BlockBlobItem>> uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, BlobHttpHeaders headers, Map<String,String> metadata, AccessTier tier, BlobRequestConditions requestConditions)"
  returns:
    description: "A reactive response containing the information of the uploaded block blob."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.blob.models.BlockBlobItem?alt=com.azure.storage.blob.models.BlockBlobItem&text=BlockBlobItem\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
type: "method"
metadata: {}
package: "com.azure.storage.blob"
artifact: com.azure:azure-storage-blob:12.8.0
