### YamlMime:JavaType
uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient"
fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient"
name: "DataLakeFileSystemClient"
nameWithType: "DataLakeFileSystemClient"
summary: "Client to a file system. It may only be instantiated through a <xref uid=\"com.azure.storage.file.datalake.DataLakeFileSystemClientBuilder\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeFileSystemClientBuilder\"></xref> or via the method <xref uid=\"com.azure.storage.file.datalake.DataLakeServiceClient.getFileSystemClient(java.lang.String)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceClient#getFileSystemClient(String)\"></xref>. This class does not hold any state about a particular file system but is instead a convenient way of sending off appropriate requests to the resource on the service. It may also be used to construct URLs to files/directories.\n\nThis client contains operations on a file system. Operations on a path are available on <xref uid=\"com.azure.storage.file.datalake.DataLakeFileClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeFileClient\"></xref> and <xref uid=\"com.azure.storage.file.datalake.DataLakeDirectoryClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeDirectoryClient\"></xref> through <xref uid=\"com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient(java.lang.String)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"#getFileClient(String)\"></xref> and <xref uid=\"com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient(java.lang.String)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"#getDirectoryClient(String)\"></xref> respectively, and operations on the service are available on <xref uid=\"com.azure.storage.file.datalake.DataLakeServiceClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceClient\"></xref>.\n\nPlease refer to the [ Azure Docs][Azure Docs] for more information on file systems.\n\n\n[Azure Docs]: https://docs.microsoft.com/azure/storage/blobs/data-lake-storage-introduction"
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public class DataLakeFileSystemClient"
fields:
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.ROOT_FILESYSTEM_NAME"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.ROOT_FILESYSTEM_NAME"
  name: "ROOT_FILESYSTEM_NAME"
  nameWithType: "DataLakeFileSystemClient.ROOT_FILESYSTEM_NAME"
  summary: "Special file system name for the root file system in the Storage account."
  modifiers:
  - "static"
  - "final"
  field:
    value: "$root"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public static final String ROOT_FILESYSTEM_NAME"
methods:
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.create()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.create()"
  name: "create()"
  nameWithType: "DataLakeFileSystemClient.create()"
  summary: "Creates a new file system within a storage account. If a file system with the same name already exists, the operation fails. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\ntry {\n     client.create();\n     System.out.printf(\"Create completed%n\");\n } catch (BlobStorageException error) {\n     if (error.getErrorCode().equals(BlobErrorCode.CONTAINER_ALREADY_EXISTS)) {\n         System.out.printf(\"Can't create file system. It already exists %n\");\n     }\n }\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/create-container"
  syntax: "public void create()"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory(java.lang.String)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory(String directoryName)"
  name: "createDirectory(String directoryName)"
  nameWithType: "DataLakeFileSystemClient.createDirectory(String directoryName)"
  summary: "Creates a new directory within a file system. By default, this method will not overwrite an existing directory. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeDirectoryClient directoryClient = client.createDirectory(directoryName);\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/create"
  parameters:
  - description: "Name of the directory to create. If the path name contains special characters, pass in the\n url encoded version of the path name."
    name: "directoryName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DataLakeDirectoryClient createDirectory(String directoryName)"
  returns:
    description: "A <xref uid=\"com.azure.storage.file.datalake.DataLakeDirectoryClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeDirectoryClient\"></xref> used to interact with the directory created."
    type: "<xref href=\"com.azure.storage.file.datalake.DataLakeDirectoryClient?alt=com.azure.storage.file.datalake.DataLakeDirectoryClient&text=DataLakeDirectoryClient\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory(java.lang.String,boolean)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory(String directoryName, boolean overwrite)"
  name: "createDirectory(String directoryName, boolean overwrite)"
  nameWithType: "DataLakeFileSystemClient.createDirectory(String directoryName, boolean overwrite)"
  summary: "Creates a new directory within a file system. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nboolean overwrite = false; /* Default value. */\n DataLakeDirectoryClient dClient = client.createDirectory(fileName, overwrite);\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/create"
  parameters:
  - description: "Name of the directory to create. If the path name contains special characters, pass in the\n url encoded version of the path name."
    name: "directoryName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "Whether to overwrite, should a directory exist."
    name: "overwrite"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DataLakeDirectoryClient createDirectory(String directoryName, boolean overwrite)"
  returns:
    description: "A <xref uid=\"com.azure.storage.file.datalake.DataLakeDirectoryClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeDirectoryClient\"></xref> used to interact with the directory created."
    type: "<xref href=\"com.azure.storage.file.datalake.DataLakeDirectoryClient?alt=com.azure.storage.file.datalake.DataLakeDirectoryClient&text=DataLakeDirectoryClient\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectoryWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectoryWithResponse(String directoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  name: "createDirectoryWithResponse(String directoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.createDirectoryWithResponse(String directoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  summary: "Creates a new directory within a file system. If a directory with the same name already exists, the directory will be overwritten. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nPathHttpHeaders httpHeaders = new PathHttpHeaders()\n     .setContentLanguage(\"en-US\")\n     .setContentType(\"binary\");\n DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId);\n String permissions = \"permissions\";\n String umask = \"umask\";\n Response<DataLakeDirectoryClient> newDirectoryClient = client.createDirectoryWithResponse(directoryName,\n     permissions, umask, httpHeaders, Collections.singletonMap(\"metadata\", \"value\"), requestConditions,\n     timeout, new Context(key1, value1));\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/create"
  parameters:
  - description: "Name of the directory to create.  If the path name contains special characters, pass in the\n url encoded version of the path name."
    name: "directoryName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "POSIX access permissions for the directory owner, the directory owning group, and others."
    name: "permissions"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "Restricts permissions of the directory to be created."
    name: "umask"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.PathHttpHeaders\" data-throw-if-not-resolved=\"false\" data-raw-source=\"PathHttpHeaders\"></xref>"
    name: "headers"
    type: "<xref href=\"com.azure.storage.file.datalake.models.PathHttpHeaders?alt=com.azure.storage.file.datalake.models.PathHttpHeaders&text=PathHttpHeaders\" data-throw-if-not-resolved=\"False\" />"
  - description: "Metadata to associate with the resource. If there is leading or trailing whitespace in any\n metadata key or value, it must be removed or encoded."
    name: "metadata"
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions\"></xref>"
    name: "requestConditions"
    type: "<xref href=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions?alt=com.azure.storage.file.datalake.models.DataLakeRequestConditions&text=DataLakeRequestConditions\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<DataLakeDirectoryClient> createDirectoryWithResponse(String directoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  returns:
    description: "A <xref uid=\"com.azure.core.http.rest.Response\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Response\"></xref> whose <xref uid=\"com.azure.core.http.rest.Response.getValue*\" data-throw-if-not-resolved=\"false\" data-raw-source=\"value\"></xref> contains a <xref uid=\"com.azure.storage.file.datalake.DataLakeDirectoryClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeDirectoryClient\"></xref>\n used to interact with the directory created."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.DataLakeDirectoryClient?alt=com.azure.storage.file.datalake.DataLakeDirectoryClient&text=DataLakeDirectoryClient\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile(java.lang.String)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile(String fileName)"
  name: "createFile(String fileName)"
  nameWithType: "DataLakeFileSystemClient.createFile(String fileName)"
  summary: "Creates a new file within a file system. By default, this method will not overwrite an existing file. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeFileClient fileClient = client.createFile(fileName);\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/create"
  parameters:
  - description: "Name of the file to create. If the path name contains special characters, pass in the url encoded\n  version of the path name."
    name: "fileName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DataLakeFileClient createFile(String fileName)"
  returns:
    description: "A <xref uid=\"com.azure.storage.file.datalake.DataLakeFileClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeFileClient\"></xref> used to interact with the file created."
    type: "<xref href=\"com.azure.storage.file.datalake.DataLakeFileClient?alt=com.azure.storage.file.datalake.DataLakeFileClient&text=DataLakeFileClient\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile(java.lang.String,boolean)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile(String fileName, boolean overwrite)"
  name: "createFile(String fileName, boolean overwrite)"
  nameWithType: "DataLakeFileSystemClient.createFile(String fileName, boolean overwrite)"
  summary: "Creates a new file within a file system. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nboolean overwrite = false; /* Default value. */\n DataLakeFileClient fClient = client.createFile(fileName, overwrite);\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/create"
  parameters:
  - description: "Name of the file to create. If the path name contains special characters, pass in the url encoded\n version of the path name."
    name: "fileName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "Whether to overwrite, should a file exist."
    name: "overwrite"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DataLakeFileClient createFile(String fileName, boolean overwrite)"
  returns:
    description: "A <xref uid=\"com.azure.storage.file.datalake.DataLakeFileClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeFileClient\"></xref> used to interact with the file created."
    type: "<xref href=\"com.azure.storage.file.datalake.DataLakeFileClient?alt=com.azure.storage.file.datalake.DataLakeFileClient&text=DataLakeFileClient\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createFileWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  name: "createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  summary: "Creates a new file within a file system. If a file with the same name already exists, the file will be overwritten. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nPathHttpHeaders httpHeaders = new PathHttpHeaders()\n     .setContentLanguage(\"en-US\")\n     .setContentType(\"binary\");\n DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId);\n String permissions = \"permissions\";\n String umask = \"umask\";\n Response<DataLakeFileClient> newFileClient = client.createFileWithResponse(fileName, permissions, umask, httpHeaders,\n     Collections.singletonMap(\"metadata\", \"value\"), requestConditions,\n     timeout, new Context(key1, value1));\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/create"
  parameters:
  - description: "Name of the file to create. If the path name contains special characters, pass in the url encoded\n version of the path name."
    name: "fileName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "POSIX access permissions for the file owner, the file owning group, and others."
    name: "permissions"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "Restricts permissions of the file to be created."
    name: "umask"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.PathHttpHeaders\" data-throw-if-not-resolved=\"false\" data-raw-source=\"PathHttpHeaders\"></xref>"
    name: "headers"
    type: "<xref href=\"com.azure.storage.file.datalake.models.PathHttpHeaders?alt=com.azure.storage.file.datalake.models.PathHttpHeaders&text=PathHttpHeaders\" data-throw-if-not-resolved=\"False\" />"
  - description: "Metadata to associate with the file. If there is leading or trailing whitespace in any\n metadata key or value, it must be removed or encoded."
    name: "metadata"
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions\"></xref>"
    name: "requestConditions"
    type: "<xref href=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions?alt=com.azure.storage.file.datalake.models.DataLakeRequestConditions&text=DataLakeRequestConditions\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<DataLakeFileClient> createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  returns:
    description: "A <xref uid=\"com.azure.core.http.rest.Response\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Response\"></xref> whose <xref uid=\"com.azure.core.http.rest.Response.getValue*\" data-throw-if-not-resolved=\"false\" data-raw-source=\"value\"></xref> contains the <xref uid=\"com.azure.storage.file.datalake.DataLakeFileClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeFileClient\"></xref> used\n to interact with the file created."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.DataLakeFileClient?alt=com.azure.storage.file.datalake.DataLakeFileClient&text=DataLakeFileClient\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.PublicAccessType,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.createWithResponse(Map<String,String> metadata, PublicAccessType accessType, Duration timeout, Context context)"
  name: "createWithResponse(Map<String,String> metadata, PublicAccessType accessType, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.createWithResponse(Map<String,String> metadata, PublicAccessType accessType, Duration timeout, Context context)"
  summary: "Creates a new file system within a storage account. If a file system with the same name already exists, the operation fails. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nMap<String, String> metadata = Collections.singletonMap(\"metadata\", \"value\");\n Context context = new Context(\"Key\", \"Value\");\n\n System.out.printf(\"Create completed with status %d%n\",\n     client.createWithResponse(metadata, PublicAccessType.CONTAINER, timeout, context).getStatusCode());\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/create-container"
  parameters:
  - description: "Metadata to associate with the file system. If there is leading or trailing whitespace in any\n metadata key or value, it must be removed or encoded."
    name: "metadata"
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "Specifies how the data in this file system is available to the public. See the\n x-ms-blob-public-access header in the Azure Docs for more information. Pass null for no public access."
    name: "accessType"
    type: "<xref href=\"com.azure.storage.file.datalake.models.PublicAccessType?alt=com.azure.storage.file.datalake.models.PublicAccessType&text=PublicAccessType\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<Void> createWithResponse(Map<String,String> metadata, PublicAccessType accessType, Duration timeout, Context context)"
  returns:
    description: "A response containing status code and HTTP headers"
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.delete()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.delete()"
  name: "delete()"
  nameWithType: "DataLakeFileSystemClient.delete()"
  summary: "Marks the specified file system for deletion. The file system and any files/directories contained within it are later deleted during garbage collection. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\ntry {\n     client.delete();\n     System.out.printf(\"Delete completed%n\");\n } catch (BlobStorageException error) {\n     if (error.getErrorCode().equals(BlobErrorCode.CONTAINER_NOT_FOUND)) {\n         System.out.printf(\"Delete failed. File System was not found %n\");\n     }\n }\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/delete-container"
  syntax: "public void delete()"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectory(java.lang.String)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectory(String directoryName)"
  name: "deleteDirectory(String directoryName)"
  nameWithType: "DataLakeFileSystemClient.deleteDirectory(String directoryName)"
  summary: "Deletes the specified directory in the file system. If the directory doesn't exist the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nclient.deleteDirectory(directoryName);\n System.out.println(\"Delete request completed\");\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/delete"
  parameters:
  - description: "Name of the directory to delete.  If the path name contains special characters, pass in the\n url encoded version of the path name."
    name: "directoryName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public void deleteDirectory(String directoryName)"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectoryWithResponse(java.lang.String,boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectoryWithResponse(String directoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  name: "deleteDirectoryWithResponse(String directoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.deleteDirectoryWithResponse(String directoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  summary: "Deletes the specified directory in the file system. If the directory doesn't exist the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId);\n boolean recursive = false; // Default value\n\n client.deleteDirectoryWithResponse(directoryName, recursive, requestConditions, timeout,\n     new Context(key1, value1));\n System.out.println(\"Delete request completed\");\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/delete"
  parameters:
  - description: "Name of the directory to delete. If the path name contains special characters, pass in the\n url encoded version of the path name."
    name: "directoryName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "Whether to delete all paths beneath the directory."
    name: "recursive"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions\"></xref>"
    name: "requestConditions"
    type: "<xref href=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions?alt=com.azure.storage.file.datalake.models.DataLakeRequestConditions&text=DataLakeRequestConditions\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<Void> deleteDirectoryWithResponse(String directoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  returns:
    description: "A response containing status code and HTTP headers"
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFile(java.lang.String)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFile(String fileName)"
  name: "deleteFile(String fileName)"
  nameWithType: "DataLakeFileSystemClient.deleteFile(String fileName)"
  summary: "Deletes the specified file in the file system. If the file doesn't exist the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nclient.deleteFile(fileName);\n System.out.println(\"Delete request completed\");\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/delete"
  parameters:
  - description: "Name of the file to delete. If the path name contains special characters, pass in the url encoded\n version of the path name."
    name: "fileName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public void deleteFile(String fileName)"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  name: "deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  summary: "Deletes the specified file in the file system. If the file doesn't exist the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId);\n\n client.deleteFileWithResponse(fileName, requestConditions, timeout, new Context(key1, value1));\n System.out.println(\"Delete request completed\");\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/delete"
  parameters:
  - description: "Name of the file to delete. If the path name contains special characters, pass in the url encoded\n version of the path name."
    name: "fileName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions\"></xref>"
    name: "requestConditions"
    type: "<xref href=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions?alt=com.azure.storage.file.datalake.models.DataLakeRequestConditions&text=DataLakeRequestConditions\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<Void> deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  returns:
    description: "A response containing status code and HTTP headers"
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  name: "deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  summary: "Marks the specified file system for deletion. The file system and any files/directories contained within it are later deleted during garbage collection. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n Context context = new Context(\"Key\", \"Value\");\n\n System.out.printf(\"Delete completed with status %d%n\", client.deleteWithResponse(\n     requestConditions, timeout, context).getStatusCode());\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/delete-container"
  parameters:
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions\"></xref>"
    name: "requestConditions"
    type: "<xref href=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions?alt=com.azure.storage.file.datalake.models.DataLakeRequestConditions&text=DataLakeRequestConditions\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<Void> deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  returns:
    description: "A response containing status code and HTTP headers"
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues)"
  name: "generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues)"
  nameWithType: "DataLakeFileSystemClient.generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues)"
  summary: "Generates a service SAS for the file system using the specified <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref>\n\nNote : The client must be authenticated via <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"StorageSharedKeyCredential\"></xref>\n\nSee <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref> for more information on how to construct a service SAS.\n\n**Code Samples**\n\n```java\nOffsetDateTime expiryTime = OffsetDateTime.now().plusDays(1);\n FileSystemSasPermission permission = new FileSystemSasPermission().setReadPermission(true);\n\n DataLakeServiceSasSignatureValues values = new DataLakeServiceSasSignatureValues(expiryTime, permission)\n     .setStartTime(OffsetDateTime.now());\n\n client.generateSas(values); // Client must be authenticated via StorageSharedKeyCredential\n```"
  parameters:
  - description: "<xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref>"
    name: "dataLakeServiceSasSignatureValues"
    type: "<xref href=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues?alt=com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues&text=DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public String generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues)"
  returns:
    description: "A <code>String</code> representing the SAS query parameters."
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, Context context)"
  name: "generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, Context context)"
  nameWithType: "DataLakeFileSystemClient.generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, Context context)"
  summary: "Generates a service SAS for the file system using the specified <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref>\n\nNote : The client must be authenticated via <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"StorageSharedKeyCredential\"></xref>\n\nSee <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref> for more information on how to construct a service SAS.\n\n**Code Samples**\n\n```java\nOffsetDateTime expiryTime = OffsetDateTime.now().plusDays(1);\n FileSystemSasPermission permission = new FileSystemSasPermission().setReadPermission(true);\n\n DataLakeServiceSasSignatureValues values = new DataLakeServiceSasSignatureValues(expiryTime, permission)\n     .setStartTime(OffsetDateTime.now());\n\n // Client must be authenticated via StorageSharedKeyCredential\n client.generateSas(values, new Context(\"key\", \"value\"));\n```"
  parameters:
  - description: "<xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref>"
    name: "dataLakeServiceSasSignatureValues"
    type: "<xref href=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues?alt=com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues&text=DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the code when generating a SAS."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public String generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, Context context)"
  returns:
    description: "A <code>String</code> representing the SAS query parameters."
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey)"
  name: "generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey)"
  nameWithType: "DataLakeFileSystemClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey)"
  summary: "Generates a user delegation SAS for the file system using the specified <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref>.\n\nSee <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref> for more information on how to construct a user delegation SAS.\n\n**Code Samples**\n\n```java\nOffsetDateTime myExpiryTime = OffsetDateTime.now().plusDays(1);\n FileSystemSasPermission myPermission = new FileSystemSasPermission().setReadPermission(true);\n\n DataLakeServiceSasSignatureValues myValues = new DataLakeServiceSasSignatureValues(expiryTime, permission)\n     .setStartTime(OffsetDateTime.now());\n\n client.generateUserDelegationSas(values, userDelegationKey);\n```"
  parameters:
  - description: "<xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref>"
    name: "dataLakeServiceSasSignatureValues"
    type: "<xref href=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues?alt=com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues&text=DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"False\" />"
  - description: "A <xref uid=\"com.azure.storage.file.datalake.models.UserDelegationKey\" data-throw-if-not-resolved=\"false\" data-raw-source=\"UserDelegationKey\"></xref> object used to sign the SAS values.\n See <xref uid=\"com.azure.storage.file.datalake.DataLakeServiceClient.getUserDelegationKey(java.time.OffsetDateTime,java.time.OffsetDateTime)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceClient#getUserDelegationKey(OffsetDateTime, OffsetDateTime)\"></xref> for more information\n on how to get a user delegation key."
    name: "userDelegationKey"
    type: "<xref href=\"com.azure.storage.file.datalake.models.UserDelegationKey?alt=com.azure.storage.file.datalake.models.UserDelegationKey&text=UserDelegationKey\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public String generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey)"
  returns:
    description: "A <code>String</code> representing the SAS query parameters."
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey,java.lang.String,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey, String accountName, Context context)"
  name: "generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey, String accountName, Context context)"
  nameWithType: "DataLakeFileSystemClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey, String accountName, Context context)"
  summary: "Generates a user delegation SAS for the file system using the specified <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref>.\n\nSee <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref> for more information on how to construct a user delegation SAS.\n\n**Code Samples**\n\n```java\nOffsetDateTime myExpiryTime = OffsetDateTime.now().plusDays(1);\n FileSystemSasPermission myPermission = new FileSystemSasPermission().setReadPermission(true);\n\n DataLakeServiceSasSignatureValues myValues = new DataLakeServiceSasSignatureValues(expiryTime, permission)\n     .setStartTime(OffsetDateTime.now());\n\n client.generateUserDelegationSas(values, userDelegationKey, accountName, new Context(\"key\", \"value\"));\n```"
  parameters:
  - description: "<xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceSasSignatureValues\"></xref>"
    name: "dataLakeServiceSasSignatureValues"
    type: "<xref href=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues?alt=com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues&text=DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"False\" />"
  - description: "A <xref uid=\"com.azure.storage.file.datalake.models.UserDelegationKey\" data-throw-if-not-resolved=\"false\" data-raw-source=\"UserDelegationKey\"></xref> object used to sign the SAS values.\n See <xref uid=\"com.azure.storage.file.datalake.DataLakeServiceClient.getUserDelegationKey(java.time.OffsetDateTime,java.time.OffsetDateTime)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeServiceClient#getUserDelegationKey(OffsetDateTime, OffsetDateTime)\"></xref> for more information\n on how to get a user delegation key."
    name: "userDelegationKey"
    type: "<xref href=\"com.azure.storage.file.datalake.models.UserDelegationKey?alt=com.azure.storage.file.datalake.models.UserDelegationKey&text=UserDelegationKey\" data-throw-if-not-resolved=\"False\" />"
  - description: "The account name."
    name: "accountName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the code when generating a SAS."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public String generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey, String accountName, Context context)"
  returns:
    description: "A <code>String</code> representing the SAS query parameters."
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicy()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicy()"
  name: "getAccessPolicy()"
  nameWithType: "DataLakeFileSystemClient.getAccessPolicy()"
  summary: "Returns the file system's permissions. The permissions indicate whether file system's paths may be accessed publicly. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nFileSystemAccessPolicies accessPolicies = client.getAccessPolicy();\n System.out.printf(\"Data Lake Access Type: %s%n\", accessPolicies.getDataLakeAccessType());\n\n for (DataLakeSignedIdentifier identifier : accessPolicies.getIdentifiers()) {\n     System.out.printf(\"Identifier Name: %s, Permissions %s%n\",\n         identifier.getId(),\n         identifier.getAccessPolicy().getPermissions());\n }\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/get-container-acl"
  syntax: "public FileSystemAccessPolicies getAccessPolicy()"
  returns:
    description: "The file system access policy."
    type: "<xref href=\"com.azure.storage.file.datalake.models.FileSystemAccessPolicies?alt=com.azure.storage.file.datalake.models.FileSystemAccessPolicies&text=FileSystemAccessPolicies\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicyWithResponse(java.lang.String,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicyWithResponse(String leaseId, Duration timeout, Context context)"
  name: "getAccessPolicyWithResponse(String leaseId, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.getAccessPolicyWithResponse(String leaseId, Duration timeout, Context context)"
  summary: "Returns the file system's permissions. The permissions indicate whether file system's paths may be accessed publicly. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nContext context = new Context(\"Key\", \"Value\");\n FileSystemAccessPolicies accessPolicies = client.getAccessPolicyWithResponse(leaseId, timeout, context)\n     .getValue();\n System.out.printf(\"Data Lake Access Type: %s%n\", accessPolicies.getDataLakeAccessType());\n\n for (DataLakeSignedIdentifier identifier : accessPolicies.getIdentifiers()) {\n     System.out.printf(\"Identifier Name: %s, Permissions %s%n\",\n         identifier.getId(),\n         identifier.getAccessPolicy().getPermissions());\n }\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/get-container-acl"
  parameters:
  - description: "The lease ID the active lease on the file system must match."
    name: "leaseId"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<FileSystemAccessPolicies> getAccessPolicyWithResponse(String leaseId, Duration timeout, Context context)"
  returns:
    description: "The file system access policy."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.FileSystemAccessPolicies?alt=com.azure.storage.file.datalake.models.FileSystemAccessPolicies&text=FileSystemAccessPolicies\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccountName()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccountName()"
  name: "getAccountName()"
  nameWithType: "DataLakeFileSystemClient.getAccountName()"
  summary: "Get associated account name."
  syntax: "public String getAccountName()"
  returns:
    description: "account name associated with this storage resource."
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccountUrl()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccountUrl()"
  name: "getAccountUrl()"
  nameWithType: "DataLakeFileSystemClient.getAccountUrl()"
  summary: "Get the url of the storage account."
  syntax: "public String getAccountUrl()"
  returns:
    description: "the URL of the storage account"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient(java.lang.String)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient(String directoryName)"
  name: "getDirectoryClient(String directoryName)"
  nameWithType: "DataLakeFileSystemClient.getDirectoryClient(String directoryName)"
  summary: "Initializes a new DataLakeDirectoryClient object by concatenating directoryName to the end of DataLakeFileSystemClient's URL. The new DataLakeDirectoryClient uses the same request policy pipeline as the DataLakeFileSystemClient."
  parameters:
  - description: "A <code>String</code> representing the name of the directory. If the path name contains special\n characters, pass in the url encoded version of the path name.\n\n <p><strong>Code Samples</strong></p>\n\n <!-- src_embed com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient#String -->\n <pre>\n DataLakeDirectoryClient dataLakeDirectoryClient = client.getDirectoryClient&#40;directoryName&#41;;\n </pre>\n <!-- end com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient#String -->"
    name: "directoryName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DataLakeDirectoryClient getDirectoryClient(String directoryName)"
  returns:
    description: "A new <xref uid=\"com.azure.storage.file.datalake.DataLakeDirectoryClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeDirectoryClient\"></xref> object which references the directory with the specified name in\n this file system."
    type: "<xref href=\"com.azure.storage.file.datalake.DataLakeDirectoryClient?alt=com.azure.storage.file.datalake.DataLakeDirectoryClient&text=DataLakeDirectoryClient\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient(java.lang.String)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient(String fileName)"
  name: "getFileClient(String fileName)"
  nameWithType: "DataLakeFileSystemClient.getFileClient(String fileName)"
  summary: "Initializes a new DataLakeFileClient object by concatenating fileName to the end of DataLakeFileSystemClient's URL. The new DataLakeFileClient uses the same request policy pipeline as the DataLakeFileSystemClient."
  parameters:
  - description: "A <code>String</code> representing the name of the file. If the path name contains special characters,\n pass in the url encoded version of the path name.\n\n <p><strong>Code Samples</strong></p>\n\n <!-- src_embed com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient#String -->\n <pre>\n DataLakeFileClient dataLakeFileClient = client.getFileClient&#40;fileName&#41;;\n </pre>\n <!-- end com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient#String -->"
    name: "fileName"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DataLakeFileClient getFileClient(String fileName)"
  returns:
    description: "A new <xref uid=\"com.azure.storage.file.datalake.DataLakeFileClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeFileClient\"></xref> object which references the file with the specified name in this file\n system."
    type: "<xref href=\"com.azure.storage.file.datalake.DataLakeFileClient?alt=com.azure.storage.file.datalake.DataLakeFileClient&text=DataLakeFileClient\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemName()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemName()"
  name: "getFileSystemName()"
  nameWithType: "DataLakeFileSystemClient.getFileSystemName()"
  summary: "Get the file system name.\n\n**Code Samples**\n\n```java\nString fileSystemName = client.getFileSystemName();\n System.out.println(\"The name of the file system is \" + fileSystemName);\n```"
  syntax: "public String getFileSystemName()"
  returns:
    description: "The name of file system."
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemUrl()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemUrl()"
  name: "getFileSystemUrl()"
  nameWithType: "DataLakeFileSystemClient.getFileSystemUrl()"
  summary: "Gets the URL of the file system represented by this client."
  syntax: "public String getFileSystemUrl()"
  returns:
    description: "the URL."
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getHttpPipeline()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getHttpPipeline()"
  name: "getHttpPipeline()"
  nameWithType: "DataLakeFileSystemClient.getHttpPipeline()"
  summary: "Gets the <xref uid=\"com.azure.core.http.HttpPipeline\" data-throw-if-not-resolved=\"false\" data-raw-source=\"HttpPipeline\"></xref> powering this client."
  syntax: "public HttpPipeline getHttpPipeline()"
  returns:
    description: "The pipeline."
    type: "<xref href=\"com.azure.core.http.HttpPipeline?alt=com.azure.core.http.HttpPipeline&text=HttpPipeline\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getProperties()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getProperties()"
  name: "getProperties()"
  nameWithType: "DataLakeFileSystemClient.getProperties()"
  summary: "Returns the file system's metadata and system properties. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nFileSystemProperties properties = client.getProperties();\n System.out.printf(\"Public Access Type: %s, Legal Hold? %b, Immutable? %b%n\",\n     properties.getDataLakePublicAccess(),\n     properties.hasLegalHold(),\n     properties.hasImmutabilityPolicy());\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/get-container-metadata"
  syntax: "public FileSystemProperties getProperties()"
  returns:
    description: "The file system properties."
    type: "<xref href=\"com.azure.storage.file.datalake.models.FileSystemProperties?alt=com.azure.storage.file.datalake.models.FileSystemProperties&text=FileSystemProperties\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getPropertiesWithResponse(java.lang.String,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getPropertiesWithResponse(String leaseId, Duration timeout, Context context)"
  name: "getPropertiesWithResponse(String leaseId, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.getPropertiesWithResponse(String leaseId, Duration timeout, Context context)"
  summary: "Returns the file system's metadata and system properties. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nContext context = new Context(\"Key\", \"Value\");\n\n FileSystemProperties properties = client.getPropertiesWithResponse(leaseId, timeout, context)\n     .getValue();\n System.out.printf(\"Public Access Type: %s, Legal Hold? %b, Immutable? %b%n\",\n     properties.getDataLakePublicAccess(),\n     properties.hasLegalHold(),\n     properties.hasImmutabilityPolicy());\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/get-container-metadata"
  parameters:
  - description: "The lease ID the active lease on the file system must match."
    name: "leaseId"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<FileSystemProperties> getPropertiesWithResponse(String leaseId, Duration timeout, Context context)"
  returns:
    description: "A response containing the file system properties."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.FileSystemProperties?alt=com.azure.storage.file.datalake.models.FileSystemProperties&text=FileSystemProperties\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getServiceVersion()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.getServiceVersion()"
  name: "getServiceVersion()"
  nameWithType: "DataLakeFileSystemClient.getServiceVersion()"
  summary: "Gets the service version the client is using."
  syntax: "public DataLakeServiceVersion getServiceVersion()"
  returns:
    description: "the service version the client is using."
    type: "<xref href=\"com.azure.storage.file.datalake.DataLakeServiceVersion?alt=com.azure.storage.file.datalake.DataLakeServiceVersion&text=DataLakeServiceVersion\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.listDeletedPaths()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.listDeletedPaths()"
  name: "listDeletedPaths()"
  nameWithType: "DataLakeFileSystemClient.listDeletedPaths()"
  summary: "Returns a lazy loaded list of files/directories recently soft deleted in this file system. The returned <xref uid=\"com.azure.core.http.rest.PagedIterable\" data-throw-if-not-resolved=\"false\" data-raw-source=\"PagedIterable\"></xref> can be consumed while new items are automatically retrieved as needed. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nclient.listDeletedPaths().forEach(path -> System.out.printf(\"Name: %s%n\", path.getPath()));\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/filesystem/list#filesystem"
  syntax: "public PagedIterable<PathDeletedItem> listDeletedPaths()"
  returns:
    description: "The list of files/directories."
    type: "<xref href=\"com.azure.core.http.rest.PagedIterable?alt=com.azure.core.http.rest.PagedIterable&text=PagedIterable\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.PathDeletedItem?alt=com.azure.storage.file.datalake.models.PathDeletedItem&text=PathDeletedItem\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.listDeletedPaths(java.lang.String,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.listDeletedPaths(String prefix, Duration timeout, Context context)"
  name: "listDeletedPaths(String prefix, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.listDeletedPaths(String prefix, Duration timeout, Context context)"
  summary: "Returns a lazy loaded list of files/directories recently soft deleted in this account. The returned <xref uid=\"com.azure.core.http.rest.PagedIterable\" data-throw-if-not-resolved=\"false\" data-raw-source=\"PagedIterable\"></xref> can be consumed while new items are automatically retrieved as needed. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nContext context = new Context(\"Key\", \"Value\");\n int pageSize = 10;\n\n client.listDeletedPaths(\"PathPrefixToMatch\", timeout, context)\n     .iterableByPage(pageSize)\n     .forEach(page ->\n         page.getValue().forEach(path ->\n             System.out.printf(\"Name: %s%n\", path.getPath())));\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/filesystem/list#filesystem"
  parameters:
  - description: "Specifies the path to filter the results to."
    name: "prefix"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public PagedIterable<PathDeletedItem> listDeletedPaths(String prefix, Duration timeout, Context context)"
  returns:
    description: "The list of files/directories."
    type: "<xref href=\"com.azure.core.http.rest.PagedIterable?alt=com.azure.core.http.rest.PagedIterable&text=PagedIterable\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.PathDeletedItem?alt=com.azure.storage.file.datalake.models.PathDeletedItem&text=PathDeletedItem\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths()"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths()"
  name: "listPaths()"
  nameWithType: "DataLakeFileSystemClient.listPaths()"
  summary: "Returns a lazy loaded list of files/directories in this account. The returned <xref uid=\"com.azure.core.http.rest.PagedIterable\" data-throw-if-not-resolved=\"false\" data-raw-source=\"PagedIterable\"></xref> can be consumed while new items are automatically retrieved as needed. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nclient.listPaths().forEach(path -> System.out.printf(\"Name: %s%n\", path.getName()));\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/filesystem/list#filesystem"
  syntax: "public PagedIterable<PathItem> listPaths()"
  returns:
    description: "The list of files/directories."
    type: "<xref href=\"com.azure.core.http.rest.PagedIterable?alt=com.azure.core.http.rest.PagedIterable&text=PagedIterable\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.PathItem?alt=com.azure.storage.file.datalake.models.PathItem&text=PathItem\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths(com.azure.storage.file.datalake.models.ListPathsOptions,java.time.Duration)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths(ListPathsOptions options, Duration timeout)"
  name: "listPaths(ListPathsOptions options, Duration timeout)"
  nameWithType: "DataLakeFileSystemClient.listPaths(ListPathsOptions options, Duration timeout)"
  summary: "Returns a lazy loaded list of files/directories in this account. The returned <xref uid=\"com.azure.core.http.rest.PagedIterable\" data-throw-if-not-resolved=\"false\" data-raw-source=\"PagedIterable\"></xref> can be consumed while new items are automatically retrieved as needed. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nListPathsOptions options = new ListPathsOptions()\n     .setPath(\"pathPrefixToMatch\")\n     .setMaxResults(10);\n\n client.listPaths(options, timeout).forEach(path -> System.out.printf(\"Name: %s%n\", path.getName()));\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/filesystem/list#filesystem"
  parameters:
  - description: "A <xref uid=\"com.azure.storage.file.datalake.models.ListPathsOptions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"ListPathsOptions\"></xref> which specifies what data should be returned by the service. If\n iterating by page, the page size passed to byPage methods such as\n <xref uid=\"com.azure.core.http.rest.PagedIterable.iterableByPage*\" data-throw-if-not-resolved=\"false\" data-raw-source=\"PagedIterable#iterableByPage(int)\"></xref> will be preferred over the value set on these options."
    name: "options"
    type: "<xref href=\"com.azure.storage.file.datalake.models.ListPathsOptions?alt=com.azure.storage.file.datalake.models.ListPathsOptions&text=ListPathsOptions\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public PagedIterable<PathItem> listPaths(ListPathsOptions options, Duration timeout)"
  returns:
    description: "The list of files/directories."
    type: "<xref href=\"com.azure.core.http.rest.PagedIterable?alt=com.azure.core.http.rest.PagedIterable&text=PagedIterable\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.PathItem?alt=com.azure.storage.file.datalake.models.PathItem&text=PathItem\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicy(com.azure.storage.file.datalake.models.PublicAccessType,java.util.List<com.azure.storage.file.datalake.models.DataLakeSignedIdentifier>)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicy(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers)"
  name: "setAccessPolicy(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers)"
  nameWithType: "DataLakeFileSystemClient.setAccessPolicy(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers)"
  summary: "Sets the file system's permissions. The permissions indicate whether paths in a file system may be accessed publicly. Note that, for each signed identifier, we will truncate the start and expiry times to the nearest second to ensure the time formatting is compatible with the service. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeSignedIdentifier identifier = new DataLakeSignedIdentifier()\n     .setId(\"name\")\n     .setAccessPolicy(new DataLakeAccessPolicy()\n         .setStartsOn(OffsetDateTime.now())\n         .setExpiresOn(OffsetDateTime.now().plusDays(7))\n         .setPermissions(\"permissionString\"));\n\n try {\n     client.setAccessPolicy(PublicAccessType.CONTAINER, Collections.singletonList(identifier));\n     System.out.printf(\"Set Access Policy completed %n\");\n } catch (UnsupportedOperationException error) {\n     System.out.printf(\"Set Access Policy completed %s%n\", error);\n }\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/set-container-acl"
  parameters:
  - description: "Specifies how the data in this file system is available to the public. See the\n x-ms-blob-public-access header in the Azure Docs for more information. Pass null for no public access."
    name: "accessType"
    type: "<xref href=\"com.azure.storage.file.datalake.models.PublicAccessType?alt=com.azure.storage.file.datalake.models.PublicAccessType&text=PublicAccessType\" data-throw-if-not-resolved=\"False\" />"
  - description: "A list of <xref uid=\"com.azure.storage.file.datalake.models.DataLakeSignedIdentifier\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeSignedIdentifier\"></xref> objects that specify the permissions for the file\n system.\n Please see\n <a href=\"https://docs.microsoft.com/rest/api/storageservices/establishing-a-stored-access-policy\">here</a>\n for more information. Passing null will clear all access policies."
    name: "identifiers"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.DataLakeSignedIdentifier?alt=com.azure.storage.file.datalake.models.DataLakeSignedIdentifier&text=DataLakeSignedIdentifier\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public void setAccessPolicy(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers)"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicyWithResponse(com.azure.storage.file.datalake.models.PublicAccessType,java.util.List<com.azure.storage.file.datalake.models.DataLakeSignedIdentifier>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicyWithResponse(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  name: "setAccessPolicyWithResponse(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.setAccessPolicyWithResponse(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  summary: "Sets the file system's permissions. The permissions indicate whether paths in a file system may be accessed publicly. Note that, for each signed identifier, we will truncate the start and expiry times to the nearest second to ensure the time formatting is compatible with the service. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeSignedIdentifier identifier = new DataLakeSignedIdentifier()\n     .setId(\"name\")\n     .setAccessPolicy(new DataLakeAccessPolicy()\n         .setStartsOn(OffsetDateTime.now())\n         .setExpiresOn(OffsetDateTime.now().plusDays(7))\n         .setPermissions(\"permissionString\"));\n\n DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n\n Context context = new Context(\"Key\", \"Value\");\n\n System.out.printf(\"Set access policy completed with status %d%n\",\n     client.setAccessPolicyWithResponse(PublicAccessType.CONTAINER,\n         Collections.singletonList(identifier),\n         requestConditions,\n         timeout,\n         context).getStatusCode());\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/set-container-acl"
  parameters:
  - description: "Specifies how the data in this file system is available to the public. See the\n x-ms-blob-public-access header in the Azure Docs for more information. Pass null for no public access."
    name: "accessType"
    type: "<xref href=\"com.azure.storage.file.datalake.models.PublicAccessType?alt=com.azure.storage.file.datalake.models.PublicAccessType&text=PublicAccessType\" data-throw-if-not-resolved=\"False\" />"
  - description: "A list of <xref uid=\"com.azure.storage.file.datalake.models.DataLakeSignedIdentifier\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeSignedIdentifier\"></xref> objects that specify the permissions for the file\n system.\n Please see\n <a href=\"https://docs.microsoft.com/rest/api/storageservices/establishing-a-stored-access-policy\">here</a>\n for more information. Passing null will clear all access policies."
    name: "identifiers"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.DataLakeSignedIdentifier?alt=com.azure.storage.file.datalake.models.DataLakeSignedIdentifier&text=DataLakeSignedIdentifier\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions\"></xref>"
    name: "requestConditions"
    type: "<xref href=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions?alt=com.azure.storage.file.datalake.models.DataLakeRequestConditions&text=DataLakeRequestConditions\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<Void> setAccessPolicyWithResponse(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  returns:
    description: "A response containing status code and HTTP headers"
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadata(Map<String,String> metadata)"
  name: "setMetadata(Map<String,String> metadata)"
  nameWithType: "DataLakeFileSystemClient.setMetadata(Map<String,String> metadata)"
  summary: "Sets the file system's metadata. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nMap<String, String> metadata = Collections.singletonMap(\"metadata\", \"value\");\n try {\n     client.setMetadata(metadata);\n     System.out.printf(\"Set metadata completed with status %n\");\n } catch (UnsupportedOperationException error) {\n     System.out.printf(\"Fail while setting metadata %n\");\n }\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/set-container-metadata"
  parameters:
  - description: "Metadata to associate with the file system. If there is leading or trailing whitespace in any\n metadata key or value, it must be removed or encoded."
    name: "metadata"
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public void setMetadata(Map<String,String> metadata)"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadataWithResponse(Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  name: "setMetadataWithResponse(Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.setMetadataWithResponse(Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  summary: "Sets the file system's metadata. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nMap<String, String> metadata = Collections.singletonMap(\"metadata\", \"value\");\n DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n Context context = new Context(\"Key\", \"Value\");\n\n System.out.printf(\"Set metadata completed with status %d%n\",\n     client.setMetadataWithResponse(metadata, requestConditions, timeout, context).getStatusCode());\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/set-container-metadata"
  parameters:
  - description: "Metadata to associate with the file system. If there is leading or trailing whitespace in any\n metadata key or value, it must be removed or encoded."
    name: "metadata"
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions\"></xref>"
    name: "requestConditions"
    type: "<xref href=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions?alt=com.azure.storage.file.datalake.models.DataLakeRequestConditions&text=DataLakeRequestConditions\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<Void> setMetadataWithResponse(Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)"
  returns:
    description: "A response containing status code and HTTP headers"
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.Void?alt=java.lang.Void&text=Void\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.undeletePath(java.lang.String,java.lang.String)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.undeletePath(String deletedPath, String deletionId)"
  name: "undeletePath(String deletedPath, String deletionId)"
  nameWithType: "DataLakeFileSystemClient.undeletePath(String deletedPath, String deletionId)"
  summary: "Restores a soft deleted path in the file system. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nclient.undeletePath(deletedPath, deletionId);\n System.out.println(\"Delete request completed\");\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/delete"
  parameters:
  - description: "The deleted path"
    name: "deletedPath"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "deletion ID associated with the soft deleted path that uniquely identifies a resource if\n multiple have been soft deleted at this location.\n You can get soft deleted paths and their associated deletion IDs with <xref uid=\"com.azure.storage.file.datalake.DataLakeFileSystemClient.listDeletedPaths()\" data-throw-if-not-resolved=\"false\" data-raw-source=\"#listDeletedPaths()\"></xref>."
    name: "deletionId"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DataLakePathClient undeletePath(String deletedPath, String deletionId)"
  returns:
    description: "A client pointing to the restored resource."
    type: "<xref href=\"com.azure.storage.file.datalake.DataLakePathClient?alt=com.azure.storage.file.datalake.DataLakePathClient&text=DataLakePathClient\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.DataLakeFileSystemClient.undeletePathWithResponse(java.lang.String,java.lang.String,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileSystemClient.undeletePathWithResponse(String deletedPath, String deletionId, Duration timeout, Context context)"
  name: "undeletePathWithResponse(String deletedPath, String deletionId, Duration timeout, Context context)"
  nameWithType: "DataLakeFileSystemClient.undeletePathWithResponse(String deletedPath, String deletionId, Duration timeout, Context context)"
  summary: "Restores a soft deleted path in the file system. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nclient.undeletePathWithResponse(deletedPath, deletionId, timeout, new Context(key1, value1));\n System.out.println(\"Delete request completed\");\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/datalakestoragegen2/path/delete"
  parameters:
  - description: "The deleted path"
    name: "deletedPath"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "deletion ID associated with the soft deleted path that uniquely identifies a resource if\n multiple have been soft deleted at this location.\n You can get soft deleted paths and their associated deletion IDs with <xref uid=\"com.azure.storage.file.datalake.DataLakeFileSystemClient.listDeletedPaths()\" data-throw-if-not-resolved=\"false\" data-raw-source=\"#listDeletedPaths()\"></xref>."
    name: "deletionId"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<DataLakePathClient> undeletePathWithResponse(String deletedPath, String deletionId, Duration timeout, Context context)"
  returns:
    description: "A response containing a client pointing to the restored resource."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.DataLakePathClient?alt=com.azure.storage.file.datalake.DataLakePathClient&text=DataLakePathClient\" data-throw-if-not-resolved=\"False\" />&gt;"
type: "class"
metadata: {}
package: "com.azure.storage.file.datalake"
artifact: com.azure:azure-storage-file-datalake:12.9.0
