### YamlMime:ManagedReference
items:
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient
  id: DataLakeFileSystemClient
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake
  children:
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.DataLakeFileSystemClient(com.azure.storage.file.datalake.DataLakeFileSystemAsyncClient,com.azure.storage.blob.BlobContainerClient)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.ROOT_FILESYSTEM_NAME
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.create()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory(java.lang.String,boolean)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectoryWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile(java.lang.String,boolean)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.createFileWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.createWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.PublicAccessType,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.delete()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectory(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectoryWithResponse(java.lang.String,boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFile(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicy()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicyWithResponse(java.lang.String,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccountName()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getBlobContainerClient()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient(java.lang.String)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemName()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemUrl()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getHttpPipeline()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getProperties()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getPropertiesWithResponse(java.lang.String,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getRootDirectoryClient()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.getServiceVersion()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths()
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths(com.azure.storage.file.datalake.models.ListPathsOptions,java.time.Duration)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicy(com.azure.storage.file.datalake.models.PublicAccessType,java.util.List<com.azure.storage.file.datalake.models.DataLakeSignedIdentifier>)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicyWithResponse(com.azure.storage.file.datalake.models.PublicAccessType,java.util.List<com.azure.storage.file.datalake.models.DataLakeSignedIdentifier>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)
  - com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  langs:
  - java
  name: DataLakeFileSystemClient
  nameWithType: DataLakeFileSystemClient
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient
  type: Class
  package: com.azure.storage.file.datalake
  summary: >-
    Client to a file system. It may only be instantiated through a <xref uid="com.azure.storage.file.datalake.DataLakeFileSystemClientBuilder" data-throw-if-not-resolved="false">DataLakeFileSystemClientBuilder</xref> or via the method <xref uid="com.azure.storage.file.datalake.DataLakeServiceClient.getFileSystemClient(java.lang.String)" data-throw-if-not-resolved="false">DataLakeServiceClient#getFileSystemClient(String)</xref>. This class does not hold any state about a particular file system but is instead a convenient way of sending off appropriate requests to the resource on the service. It may also be used to construct URLs to files/directories.


    This client contains operations on a file system. Operations on a path are available on <xref uid="com.azure.storage.file.datalake.DataLakeFileClient" data-throw-if-not-resolved="false">DataLakeFileClient</xref> and <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref> through <xref uid="com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient(java.lang.String)" data-throw-if-not-resolved="false">#getFileClient(String)</xref> and <xref uid="com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient(java.lang.String)" data-throw-if-not-resolved="false">#getDirectoryClient(String)</xref> respectively, and operations on the service are available on <xref uid="com.azure.storage.file.datalake.DataLakeServiceClient" data-throw-if-not-resolved="false">DataLakeServiceClient</xref>.


    Please refer to the [ Azure Docs][Azure Docs] for more information on file systems.



    [Azure Docs]: https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction?toc=%2fazure%2fstorage%2fblobs%2ftoc.json
  syntax:
    content: public class DataLakeFileSystemClient
  inheritance:
  - java.lang.Object
  inheritedMembers:
  - java.lang.Object.clone()
  - java.lang.Object.equals(java.lang.Object)
  - java.lang.Object.finalize()
  - java.lang.Object.getClass()
  - java.lang.Object.hashCode()
  - java.lang.Object.notify()
  - java.lang.Object.notifyAll()
  - java.lang.Object.toString()
  - java.lang.Object.wait()
  - java.lang.Object.wait(long)
  - java.lang.Object.wait(long,int)
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.DataLakeFileSystemClient(com.azure.storage.file.datalake.DataLakeFileSystemAsyncClient,com.azure.storage.blob.BlobContainerClient)
  id: DataLakeFileSystemClient(com.azure.storage.file.datalake.DataLakeFileSystemAsyncClient,com.azure.storage.blob.BlobContainerClient)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: DataLakeFileSystemClient(DataLakeFileSystemAsyncClient dataLakeFileSystemAsyncClient, BlobContainerClient blobContainerClient)
  nameWithType: DataLakeFileSystemClient.DataLakeFileSystemClient(DataLakeFileSystemAsyncClient dataLakeFileSystemAsyncClient, BlobContainerClient blobContainerClient)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.DataLakeFileSystemClient(DataLakeFileSystemAsyncClient dataLakeFileSystemAsyncClient, BlobContainerClient blobContainerClient)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.DataLakeFileSystemClient*
  type: Constructor
  package: com.azure.storage.file.datalake
  summary: Package-private constructor for use by <xref uid="com.azure.storage.file.datalake.DataLakeFileSystemClientBuilder" data-throw-if-not-resolved="false">DataLakeFileSystemClientBuilder</xref>.
  syntax:
    content: " DataLakeFileSystemClient(DataLakeFileSystemAsyncClient dataLakeFileSystemAsyncClient, BlobContainerClient blobContainerClient)"
    parameters:
    - id: dataLakeFileSystemAsyncClient
      type: com.azure.storage.file.datalake.DataLakeFileSystemAsyncClient
      description: the async file system client.
    - id: blobContainerClient
      type: com.azure.storage.blob.BlobContainerClient
      description: the sync blob container client.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.ROOT_FILESYSTEM_NAME
  id: ROOT_FILESYSTEM_NAME
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: ROOT_FILESYSTEM_NAME
  nameWithType: DataLakeFileSystemClient.ROOT_FILESYSTEM_NAME
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.ROOT_FILESYSTEM_NAME
  type: Field
  package: com.azure.storage.file.datalake
  syntax:
    content: public static final String ROOT_FILESYSTEM_NAME
    return:
      type: java.lang.String
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.create()
  id: create()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: create()
  nameWithType: DataLakeFileSystemClient.create()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.create()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.create*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new file system within a storage account. If a file system with the same name already exists, the operation fails. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    try {
         client.create();
         System.out.printf("Create completed%n");
     } catch (BlobStorageException error) {
         if (error.getErrorCode().equals(BlobErrorCode.CONTAINER_ALREADY_EXISTS)) {
             System.out.printf("Can't create file system. It already exists %n");
         }
     }
    ```



    [Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/create-container
  syntax:
    content: public void create()
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory(java.lang.String)
  id: createDirectory(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: createDirectory(String directoryName)
  nameWithType: DataLakeFileSystemClient.createDirectory(String directoryName)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory(String directoryName)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new directory within a file system. By default, this method will not overwrite an existing directory. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    DataLakeDirectoryClient directoryClient = client.createDirectory(directoryName);

    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public DataLakeDirectoryClient createDirectory(String directoryName)
    parameters:
    - id: directoryName
      type: java.lang.String
      description: Name of the directory to create.
    return:
      type: com.azure.storage.file.datalake.DataLakeDirectoryClient
      description: A <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref> used to interact with the directory created.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory(java.lang.String,boolean)
  id: createDirectory(java.lang.String,boolean)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: createDirectory(String directoryName, boolean overwrite)
  nameWithType: DataLakeFileSystemClient.createDirectory(String directoryName, boolean overwrite)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory(String directoryName, boolean overwrite)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new directory within a file system. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    boolean overwrite = false; /* Default value. */
     DataLakeDirectoryClient dClient = client.createDirectory(fileName, overwrite);
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public DataLakeDirectoryClient createDirectory(String directoryName, boolean overwrite)
    parameters:
    - id: directoryName
      type: java.lang.String
      description: Name of the directory to create.
    - id: overwrite
      type: boolean
      description: Whether or not to overwrite, should a directory exist.
    return:
      type: com.azure.storage.file.datalake.DataLakeDirectoryClient
      description: A <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref> used to interact with the directory created.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectoryWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: createDirectoryWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: createDirectoryWithResponse(String directoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeFileSystemClient.createDirectoryWithResponse(String directoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectoryWithResponse(String directoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectoryWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new directory within a file system. If a directory with the same name already exists, the directory will be overwritten. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    PathHttpHeaders httpHeaders = new PathHttpHeaders()
         .setContentLanguage("en-US")
         .setContentType("binary");
     DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()
         .setLeaseId(leaseId);
     String permissions = "permissions";
     String umask = "umask";
     Response<DataLakeDirectoryClient> newDirectoryClient = client.createDirectoryWithResponse(directoryName,
         permissions, umask, httpHeaders, Collections.singletonMap("metadata", "value"), requestConditions,
         timeout, new Context(key1, value1));
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public Response<DataLakeDirectoryClient> createDirectoryWithResponse(String directoryName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: directoryName
      type: java.lang.String
      description: Name of the directory to create.
    - id: permissions
      type: java.lang.String
      description: POSIX access permissions for the directory owner, the directory owning group, and others.
    - id: umask
      type: java.lang.String
      description: Restricts permissions of the directory to be created.
    - id: headers
      type: com.azure.storage.file.datalake.models.PathHttpHeaders
      description: <xref uid="com.azure.storage.file.datalake.models.PathHttpHeaders" data-throw-if-not-resolved="false">PathHttpHeaders</xref>
    - id: metadata
      type: java.util.Map<java.lang.String,java.lang.String>
      description: Metadata to associate with the directory.
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeDirectoryClient>
      description: >-
        A <xref uid="com.azure.core.http.rest.Response" data-throw-if-not-resolved="false">Response</xref> whose <xref uid="" data-throw-if-not-resolved="false">value</xref> contains a <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref>
         used to interact with the directory created.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile(java.lang.String)
  id: createFile(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: createFile(String fileName)
  nameWithType: DataLakeFileSystemClient.createFile(String fileName)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile(String fileName)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new file within a file system. By default, this method will not overwrite an existing file. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    DataLakeFileClient fileClient = client.createFile(fileName);

    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public DataLakeFileClient createFile(String fileName)
    parameters:
    - id: fileName
      type: java.lang.String
      description: Name of the file to create.
    return:
      type: com.azure.storage.file.datalake.DataLakeFileClient
      description: A <xref uid="com.azure.storage.file.datalake.DataLakeFileClient" data-throw-if-not-resolved="false">DataLakeFileClient</xref> used to interact with the file created.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile(java.lang.String,boolean)
  id: createFile(java.lang.String,boolean)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: createFile(String fileName, boolean overwrite)
  nameWithType: DataLakeFileSystemClient.createFile(String fileName, boolean overwrite)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile(String fileName, boolean overwrite)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new file within a file system. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    boolean overwrite = false; /* Default value. */
     DataLakeFileClient fClient = client.createFile(fileName, overwrite);
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public DataLakeFileClient createFile(String fileName, boolean overwrite)
    parameters:
    - id: fileName
      type: java.lang.String
      description: Name of the file to create.
    - id: overwrite
      type: boolean
      description: Whether or not to overwrite, should a file exist.
    return:
      type: com.azure.storage.file.datalake.DataLakeFileClient
      description: A <xref uid="com.azure.storage.file.datalake.DataLakeFileClient" data-throw-if-not-resolved="false">DataLakeFileClient</xref> used to interact with the file created.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFileWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: createFileWithResponse(java.lang.String,java.lang.String,java.lang.String,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeFileSystemClient.createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFileWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Creates a new file within a file system. If a file with the same name already exists, the file will be overwritten. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    PathHttpHeaders httpHeaders = new PathHttpHeaders()
         .setContentLanguage("en-US")
         .setContentType("binary");
     DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()
         .setLeaseId(leaseId);
     String permissions = "permissions";
     String umask = "umask";
     Response<DataLakeFileClient> newFileClient = client.createFileWithResponse(fileName, permissions, umask, httpHeaders,
         Collections.singletonMap("metadata", "value"), requestConditions,
         timeout, new Context(key1, value1));
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
  syntax:
    content: public Response<DataLakeFileClient> createFileWithResponse(String fileName, String permissions, String umask, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: fileName
      type: java.lang.String
      description: Name of the file to create.
    - id: permissions
      type: java.lang.String
      description: POSIX access permissions for the file owner, the file owning group, and others.
    - id: umask
      type: java.lang.String
      description: Restricts permissions of the file to be created.
    - id: headers
      type: com.azure.storage.file.datalake.models.PathHttpHeaders
      description: <xref uid="com.azure.storage.file.datalake.models.PathHttpHeaders" data-throw-if-not-resolved="false">PathHttpHeaders</xref>
    - id: metadata
      type: java.util.Map<java.lang.String,java.lang.String>
      description: Metadata to associate with the file.
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeFileClient>
      description: >-
        A <xref uid="com.azure.core.http.rest.Response" data-throw-if-not-resolved="false">Response</xref> whose <xref uid="" data-throw-if-not-resolved="false">value</xref> contains the <xref uid="com.azure.storage.file.datalake.DataLakeFileClient" data-throw-if-not-resolved="false">DataLakeFileClient</xref> used
         to interact with the file created.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.PublicAccessType,java.time.Duration,com.azure.core.util.Context)
  id: createWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.PublicAccessType,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: createWithResponse(Map<String,String> metadata, PublicAccessType accessType, Duration timeout, Context context)
  nameWithType: DataLakeFileSystemClient.createWithResponse(Map<String,String> metadata, PublicAccessType accessType, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createWithResponse(Map<String,String> metadata, PublicAccessType accessType, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.createWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Creates a new file system within a storage account. If a file system with the same name already exists, the operation fails. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nMap<String, String> metadata = Collections.singletonMap(\"metadata\", \"value\");\n Context context = new Context(\"Key\", \"Value\");\n \n System.out.printf(\"Create completed with status %d%n\",\n     client.createWithResponse(metadata, PublicAccessType.CONTAINER, timeout, context).getStatusCode());\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/create-container"
  syntax:
    content: public Response<Void> createWithResponse(Map<String,String> metadata, PublicAccessType accessType, Duration timeout, Context context)
    parameters:
    - id: metadata
      type: java.util.Map<java.lang.String,java.lang.String>
      description: Metadata to associate with the file system.
    - id: accessType
      type: com.azure.storage.file.datalake.models.PublicAccessType
      description: >-
        Specifies how the data in this file system is available to the public. See the
         x-ms-blob-public-access header in the Azure Docs for more information. Pass null for no public access.
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<java.lang.Void>
      description: A response containing status code and HTTP headers
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.delete()
  id: delete()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: delete()
  nameWithType: DataLakeFileSystemClient.delete()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.delete()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.delete*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Marks the specified file system for deletion. The file system and any files/directories contained within it are later deleted during garbage collection. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    try {
         client.delete();
         System.out.printf("Delete completed%n");
     } catch (BlobStorageException error) {
         if (error.getErrorCode().equals(BlobErrorCode.CONTAINER_NOT_FOUND)) {
             System.out.printf("Delete failed. File System was not found %n");
         }
     }
    ```



    [Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/delete-container
  syntax:
    content: public void delete()
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectory(java.lang.String)
  id: deleteDirectory(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: deleteDirectory(String directoryName)
  nameWithType: DataLakeFileSystemClient.deleteDirectory(String directoryName)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectory(String directoryName)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectory*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Deletes the specified directory in the file system. If the directory doesn't exist the operation fails. For more information see the [Azure Docs][].


    **Code Samples**


    ```java

    client.deleteDirectory(directoryName);
     System.out.println("Delete request completed");
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete
  syntax:
    content: public void deleteDirectory(String directoryName)
    parameters:
    - id: directoryName
      type: java.lang.String
      description: Name of the directory to delete.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectoryWithResponse(java.lang.String,boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: deleteDirectoryWithResponse(java.lang.String,boolean,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: deleteDirectoryWithResponse(String directoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeFileSystemClient.deleteDirectoryWithResponse(String directoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectoryWithResponse(String directoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectoryWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Deletes the specified directory in the file system. If the directory doesn't exist the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId);\n boolean recursive = false; // Default value\n \n client.deleteDirectoryWithResponse(directoryName, recursive, requestConditions, timeout,\n     new Context(key1, value1));\n System.out.println(\"Delete request completed\");\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: public Response<Void> deleteDirectoryWithResponse(String directoryName, boolean recursive, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: directoryName
      type: java.lang.String
      description: Name of the directory to delete.
    - id: recursive
      type: boolean
      description: Whether or not to delete all paths beneath the directory.
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<java.lang.Void>
      description: A response containing status code and HTTP headers
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFile(java.lang.String)
  id: deleteFile(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: deleteFile(String fileName)
  nameWithType: DataLakeFileSystemClient.deleteFile(String fileName)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFile(String fileName)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFile*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Deletes the specified file in the file system. If the file doesn't exist the operation fails. For more information see the [Azure Docs][].


    **Code Samples**


    ```java

    client.deleteFile(fileName);
     System.out.println("Delete request completed");
    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete
  syntax:
    content: public void deleteFile(String fileName)
    parameters:
    - id: fileName
      type: java.lang.String
      description: Name of the file to delete.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: deleteFileWithResponse(java.lang.String,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeFileSystemClient.deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFileWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Deletes the specified file in the file system. If the file doesn't exist the operation fails. For more information see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId);\n \n client.deleteFileWithResponse(fileName, requestConditions, timeout, new Context(key1, value1));\n System.out.println(\"Delete request completed\");\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete"
  syntax:
    content: public Response<Void> deleteFileWithResponse(String fileName, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: fileName
      type: java.lang.String
      description: Name of the file to delete.
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<java.lang.Void>
      description: A response containing status code and HTTP headers
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: deleteWithResponse(com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeFileSystemClient.deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Marks the specified file system for deletion. The file system and any files/directories contained within it are later deleted during garbage collection. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n Context context = new Context(\"Key\", \"Value\");\n \n System.out.printf(\"Delete completed with status %d%n\", client.deleteWithResponse(\n     requestConditions, timeout, context).getStatusCode());\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/delete-container"
  syntax:
    content: public Response<Void> deleteWithResponse(DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<java.lang.Void>
      description: A response containing status code and HTTP headers
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)
  id: generateSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues)
  nameWithType: DataLakeFileSystemClient.generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.generateSas*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Generates a service SAS for the file system using the specified <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\">DataLakeServiceSasSignatureValues</xref> Note : The client must be authenticated via <xref uid=\"\" data-throw-if-not-resolved=\"false\">StorageSharedKeyCredential</xref>\n\nSee <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\">DataLakeServiceSasSignatureValues</xref> for more information on how to construct a service SAS.\n\n**Code Samples**\n\n```java\nOffsetDateTime expiryTime = OffsetDateTime.now().plusDays(1);\n FileSystemSasPermission permission = new FileSystemSasPermission().setReadPermission(true);\n \n DataLakeServiceSasSignatureValues values = new DataLakeServiceSasSignatureValues(expiryTime, permission)\n     .setStartTime(OffsetDateTime.now());\n \n client.generateSas(values); // Client must be authenticated via StorageSharedKeyCredential\n```"
  syntax:
    content: public String generateSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues)
    parameters:
    - id: dataLakeServiceSasSignatureValues
      type: com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues
      description: <xref uid="com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues" data-throw-if-not-resolved="false">DataLakeServiceSasSignatureValues</xref>
    return:
      type: java.lang.String
      description: A <code>String</code> representing all SAS query parameters.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)
  id: generateUserDelegationSas(com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues,com.azure.storage.file.datalake.models.UserDelegationKey)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey)
  nameWithType: DataLakeFileSystemClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.generateUserDelegationSas*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Generates a user delegation SAS for the file system using the specified <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\">DataLakeServiceSasSignatureValues</xref>.\n\nSee <xref uid=\"com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues\" data-throw-if-not-resolved=\"false\">DataLakeServiceSasSignatureValues</xref> for more information on how to construct a user delegation SAS.\n\n**Code Samples**\n\n```java\nOffsetDateTime myExpiryTime = OffsetDateTime.now().plusDays(1);\n FileSystemSasPermission myPermission = new FileSystemSasPermission().setReadPermission(true);\n \n DataLakeServiceSasSignatureValues myValues = new DataLakeServiceSasSignatureValues(expiryTime, permission)\n     .setStartTime(OffsetDateTime.now());\n \n client.generateUserDelegationSas(values, userDelegationKey);\n```"
  syntax:
    content: public String generateUserDelegationSas(DataLakeServiceSasSignatureValues dataLakeServiceSasSignatureValues, UserDelegationKey userDelegationKey)
    parameters:
    - id: dataLakeServiceSasSignatureValues
      type: com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues
      description: <xref uid="com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues" data-throw-if-not-resolved="false">DataLakeServiceSasSignatureValues</xref>
    - id: userDelegationKey
      type: com.azure.storage.file.datalake.models.UserDelegationKey
      description: A <xref uid="com.azure.storage.file.datalake.models.UserDelegationKey" data-throw-if-not-resolved="false">UserDelegationKey</xref> object used to sign the SAS values.
    return:
      type: java.lang.String
      description: A <code>String</code> representing all SAS query parameters.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicy()
  id: getAccessPolicy()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getAccessPolicy()
  nameWithType: DataLakeFileSystemClient.getAccessPolicy()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicy()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicy*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Returns the file system's permissions. The permissions indicate whether file system's paths may be accessed publicly. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nFileSystemAccessPolicies accessPolicies = client.getAccessPolicy();\n System.out.printf(\"Data Lake Access Type: %s%n\", accessPolicies.getDataLakeAccessType());\n \n for (DataLakeSignedIdentifier identifier : accessPolicies.getIdentifiers()) {\n     System.out.printf(\"Identifier Name: %s, Permissions %s%n\",\n         identifier.getId(),\n         identifier.getAccessPolicy().getPermissions());\n }\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/get-container-acl"
  syntax:
    content: public FileSystemAccessPolicies getAccessPolicy()
    return:
      type: com.azure.storage.file.datalake.models.FileSystemAccessPolicies
      description: The file system access policy.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicyWithResponse(java.lang.String,java.time.Duration,com.azure.core.util.Context)
  id: getAccessPolicyWithResponse(java.lang.String,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getAccessPolicyWithResponse(String leaseId, Duration timeout, Context context)
  nameWithType: DataLakeFileSystemClient.getAccessPolicyWithResponse(String leaseId, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicyWithResponse(String leaseId, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicyWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Returns the file system's permissions. The permissions indicate whether file system's paths may be accessed publicly. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nContext context = new Context(\"Key\", \"Value\");\n FileSystemAccessPolicies accessPolicies = client.getAccessPolicyWithResponse(leaseId, timeout, context)\n     .getValue();\n System.out.printf(\"Data Lake Access Type: %s%n\", accessPolicies.getDataLakeAccessType());\n \n for (DataLakeSignedIdentifier identifier : accessPolicies.getIdentifiers()) {\n     System.out.printf(\"Identifier Name: %s, Permissions %s%n\",\n         identifier.getId(),\n         identifier.getAccessPolicy().getPermissions());\n }\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/get-container-acl"
  syntax:
    content: public Response<FileSystemAccessPolicies> getAccessPolicyWithResponse(String leaseId, Duration timeout, Context context)
    parameters:
    - id: leaseId
      type: java.lang.String
      description: The lease ID the active lease on the file system must match.
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.models.FileSystemAccessPolicies>
      description: The file system access policy.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccountName()
  id: getAccountName()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getAccountName()
  nameWithType: DataLakeFileSystemClient.getAccountName()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccountName()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccountName*
  type: Method
  package: com.azure.storage.file.datalake
  summary: Get associated account name.
  syntax:
    content: public String getAccountName()
    return:
      type: java.lang.String
      description: account name associated with this storage resource.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getBlobContainerClient()
  id: getBlobContainerClient()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getBlobContainerClient()
  nameWithType: DataLakeFileSystemClient.getBlobContainerClient()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getBlobContainerClient()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getBlobContainerClient*
  type: Method
  package: com.azure.storage.file.datalake
  syntax:
    content: " BlobContainerClient getBlobContainerClient()"
    return:
      type: com.azure.storage.blob.BlobContainerClient
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient(java.lang.String)
  id: getDirectoryClient(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getDirectoryClient(String directoryName)
  nameWithType: DataLakeFileSystemClient.getDirectoryClient(String directoryName)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient(String directoryName)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient*
  type: Method
  package: com.azure.storage.file.datalake
  summary: Initializes a new DataLakeDirectoryClient object by concatenating directoryName to the end of DataLakeFileSystemClient's URL. The new DataLakeDirectoryClient uses the same request policy pipeline as the DataLakeFileSystemClient.
  syntax:
    content: public DataLakeDirectoryClient getDirectoryClient(String directoryName)
    parameters:
    - id: directoryName
      type: java.lang.String
      description: >-
        A <code>String</code> representing the name of the directory.

         <p><strong>Code Samples</strong></p>

         <pre>
         DataLakeDirectoryClient dataLakeDirectoryClient = client.getDirectoryClient&#40;directoryName&#41;;
         </pre>
    return:
      type: com.azure.storage.file.datalake.DataLakeDirectoryClient
      description: >-
        A new <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref> object which references the directory with the specified name in
         this file system.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient(java.lang.String)
  id: getFileClient(java.lang.String)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getFileClient(String fileName)
  nameWithType: DataLakeFileSystemClient.getFileClient(String fileName)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient(String fileName)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient*
  type: Method
  package: com.azure.storage.file.datalake
  summary: Initializes a new DataLakeFileClient object by concatenating fileName to the end of DataLakeFileSystemClient's URL. The new DataLakeFileClient uses the same request policy pipeline as the DataLakeFileSystemClient.
  syntax:
    content: public DataLakeFileClient getFileClient(String fileName)
    parameters:
    - id: fileName
      type: java.lang.String
      description: >-
        A <code>String</code> representing the name of the file.

         <p><strong>Code Samples</strong></p>

         <pre>
         DataLakeFileClient dataLakeFileClient = client.getFileClient&#40;fileName&#41;;
         </pre>
    return:
      type: com.azure.storage.file.datalake.DataLakeFileClient
      description: >-
        A new <xref uid="com.azure.storage.file.datalake.DataLakeFileClient" data-throw-if-not-resolved="false">DataLakeFileClient</xref> object which references the file with the specified name in this file
         system.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemName()
  id: getFileSystemName()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getFileSystemName()
  nameWithType: DataLakeFileSystemClient.getFileSystemName()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemName()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemName*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Get the file system name.


    **Code Samples**


    ```java

    String fileSystemName = client.getFileSystemName();
     System.out.println("The name of the file system is " + fileSystemName);
    ```
  syntax:
    content: public String getFileSystemName()
    return:
      type: java.lang.String
      description: The name of file system.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemUrl()
  id: getFileSystemUrl()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getFileSystemUrl()
  nameWithType: DataLakeFileSystemClient.getFileSystemUrl()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemUrl()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemUrl*
  type: Method
  package: com.azure.storage.file.datalake
  summary: Gets the URL of the file system represented by this client.
  syntax:
    content: public String getFileSystemUrl()
    return:
      type: java.lang.String
      description: the URL.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getHttpPipeline()
  id: getHttpPipeline()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getHttpPipeline()
  nameWithType: DataLakeFileSystemClient.getHttpPipeline()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getHttpPipeline()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getHttpPipeline*
  type: Method
  package: com.azure.storage.file.datalake
  summary: Gets the <xref uid="" data-throw-if-not-resolved="false">HttpPipeline</xref> powering this client.
  syntax:
    content: public HttpPipeline getHttpPipeline()
    return:
      type: com.azure.core.http.HttpPipeline
      description: The pipeline.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getProperties()
  id: getProperties()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getProperties()
  nameWithType: DataLakeFileSystemClient.getProperties()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getProperties()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getProperties*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Returns the file system's metadata and system properties. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    FileSystemProperties properties = client.getProperties();
     System.out.printf("Public Access Type: %s, Legal Hold? %b, Immutable? %b%n",
         properties.getDataLakePublicAccess(),
         properties.hasLegalHold(),
         properties.hasImmutabilityPolicy());
    ```



    [Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/get-container-metadata
  syntax:
    content: public FileSystemProperties getProperties()
    return:
      type: com.azure.storage.file.datalake.models.FileSystemProperties
      description: The file system properties.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getPropertiesWithResponse(java.lang.String,java.time.Duration,com.azure.core.util.Context)
  id: getPropertiesWithResponse(java.lang.String,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getPropertiesWithResponse(String leaseId, Duration timeout, Context context)
  nameWithType: DataLakeFileSystemClient.getPropertiesWithResponse(String leaseId, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getPropertiesWithResponse(String leaseId, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getPropertiesWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Returns the file system's metadata and system properties. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nContext context = new Context(\"Key\", \"Value\");\n \n FileSystemProperties properties = client.getPropertiesWithResponse(leaseId, timeout, context)\n     .getValue();\n System.out.printf(\"Public Access Type: %s, Legal Hold? %b, Immutable? %b%n\",\n     properties.getDataLakePublicAccess(),\n     properties.hasLegalHold(),\n     properties.hasImmutabilityPolicy());\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/get-container-metadata"
  syntax:
    content: public Response<FileSystemProperties> getPropertiesWithResponse(String leaseId, Duration timeout, Context context)
    parameters:
    - id: leaseId
      type: java.lang.String
      description: The lease ID the active lease on the file system must match.
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.models.FileSystemProperties>
      description: A response containing the file system properties.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getRootDirectoryClient()
  id: getRootDirectoryClient()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getRootDirectoryClient()
  nameWithType: DataLakeFileSystemClient.getRootDirectoryClient()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getRootDirectoryClient()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getRootDirectoryClient*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Initializes a new DataLakeDirectoryClient object by concatenating `""` to the end of DataLakeFileSystemClient's URL. The new DataLakeDirectoryClient uses the same request policy pipeline as the DataLakeFileSystemClient.


    **Code Samples**


    ```java

    DataLakeDirectoryClient dataLakeDirectoryClient = client.getRootDirectoryClient();

    ```
  syntax:
    content: " DataLakeDirectoryClient getRootDirectoryClient()"
    return:
      type: com.azure.storage.file.datalake.DataLakeDirectoryClient
      description: A new <xref uid="com.azure.storage.file.datalake.DataLakeDirectoryClient" data-throw-if-not-resolved="false">DataLakeDirectoryClient</xref> object which references the root directory in this file system.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getServiceVersion()
  id: getServiceVersion()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: getServiceVersion()
  nameWithType: DataLakeFileSystemClient.getServiceVersion()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getServiceVersion()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.getServiceVersion*
  type: Method
  package: com.azure.storage.file.datalake
  summary: Gets the service version the client is using.
  syntax:
    content: public DataLakeServiceVersion getServiceVersion()
    return:
      type: com.azure.storage.file.datalake.DataLakeServiceVersion
      description: the service version the client is using.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths()
  id: listPaths()
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: listPaths()
  nameWithType: DataLakeFileSystemClient.listPaths()
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths()
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Returns a lazy loaded list of files/directories in this account. The returned <xref uid="com.azure.core.http.rest.PagedIterable" data-throw-if-not-resolved="false">PagedIterable</xref> can be consumed while new items are automatically retrieved as needed. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    client.listPaths().forEach(path -> System.out.printf("Name: %s%n", path.getName()));

    ```



    [Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/filesystem/list#filesystem
  syntax:
    content: public PagedIterable<PathItem> listPaths()
    return:
      type: com.azure.core.http.rest.PagedIterable<com.azure.storage.file.datalake.models.PathItem>
      description: The list of files/directories.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths(com.azure.storage.file.datalake.models.ListPathsOptions,java.time.Duration)
  id: listPaths(com.azure.storage.file.datalake.models.ListPathsOptions,java.time.Duration)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: listPaths(ListPathsOptions options, Duration timeout)
  nameWithType: DataLakeFileSystemClient.listPaths(ListPathsOptions options, Duration timeout)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths(ListPathsOptions options, Duration timeout)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Returns a lazy loaded list of files/directories in this account. The returned <xref uid=\"com.azure.core.http.rest.PagedIterable\" data-throw-if-not-resolved=\"false\">PagedIterable</xref> can be consumed while new items are automatically retrieved as needed. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nListPathsOptions options = new ListPathsOptions()\n     .setPath(\"pathPrefixToMatch\")\n     .setMaxResults(10);\n \n client.listPaths(options, timeout).forEach(path -> System.out.printf(\"Name: %s%n\", path.getName()));\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/filesystem/list#filesystem"
  syntax:
    content: public PagedIterable<PathItem> listPaths(ListPathsOptions options, Duration timeout)
    parameters:
    - id: options
      type: com.azure.storage.file.datalake.models.ListPathsOptions
      description: A <xref uid="com.azure.storage.file.datalake.models.ListPathsOptions" data-throw-if-not-resolved="false">ListPathsOptions</xref> which specifies what data should be returned by the service.
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    return:
      type: com.azure.core.http.rest.PagedIterable<com.azure.storage.file.datalake.models.PathItem>
      description: The list of files/directories.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicy(com.azure.storage.file.datalake.models.PublicAccessType,java.util.List<com.azure.storage.file.datalake.models.DataLakeSignedIdentifier>)
  id: setAccessPolicy(com.azure.storage.file.datalake.models.PublicAccessType,java.util.List<com.azure.storage.file.datalake.models.DataLakeSignedIdentifier>)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: setAccessPolicy(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers)
  nameWithType: DataLakeFileSystemClient.setAccessPolicy(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicy(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicy*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Sets the file system's permissions. The permissions indicate whether paths in a file system may be accessed publicly. Note that, for each signed identifier, we will truncate the start and expiry times to the nearest second to ensure the time formatting is compatible with the service. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeSignedIdentifier identifier = new DataLakeSignedIdentifier()\n     .setId(\"name\")\n     .setAccessPolicy(new DataLakeAccessPolicy()\n         .setStartsOn(OffsetDateTime.now())\n         .setExpiresOn(OffsetDateTime.now().plusDays(7))\n         .setPermissions(\"permissionString\"));\n \n try {\n     client.setAccessPolicy(PublicAccessType.CONTAINER, Collections.singletonList(identifier));\n     System.out.printf(\"Set Access Policy completed %n\");\n } catch (UnsupportedOperationException error) {\n     System.out.printf(\"Set Access Policy completed %s%n\", error);\n }\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/set-container-acl"
  syntax:
    content: public void setAccessPolicy(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers)
    parameters:
    - id: accessType
      type: com.azure.storage.file.datalake.models.PublicAccessType
      description: >-
        Specifies how the data in this file system is available to the public. See the
         x-ms-blob-public-access header in the Azure Docs for more information. Pass null for no public access.
    - id: identifiers
      type: java.util.List<com.azure.storage.file.datalake.models.DataLakeSignedIdentifier>
      description: >-
        A list of <xref uid="com.azure.storage.file.datalake.models.DataLakeSignedIdentifier" data-throw-if-not-resolved="false">DataLakeSignedIdentifier</xref> objects that specify the permissions for the file
         system.
         Please see
         <a href="https://docs.microsoft.com/en-us/rest/api/storageservices/establishing-a-stored-access-policy">here</a>
         for more information. Passing null will clear all access policies.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicyWithResponse(com.azure.storage.file.datalake.models.PublicAccessType,java.util.List<com.azure.storage.file.datalake.models.DataLakeSignedIdentifier>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: setAccessPolicyWithResponse(com.azure.storage.file.datalake.models.PublicAccessType,java.util.List<com.azure.storage.file.datalake.models.DataLakeSignedIdentifier>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: setAccessPolicyWithResponse(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeFileSystemClient.setAccessPolicyWithResponse(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicyWithResponse(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicyWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Sets the file system's permissions. The permissions indicate whether paths in a file system may be accessed publicly. Note that, for each signed identifier, we will truncate the start and expiry times to the nearest second to ensure the time formatting is compatible with the service. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nDataLakeSignedIdentifier identifier = new DataLakeSignedIdentifier()\n     .setId(\"name\")\n     .setAccessPolicy(new DataLakeAccessPolicy()\n         .setStartsOn(OffsetDateTime.now())\n         .setExpiresOn(OffsetDateTime.now().plusDays(7))\n         .setPermissions(\"permissionString\"));\n \n DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n \n Context context = new Context(\"Key\", \"Value\");\n \n System.out.printf(\"Set access policy completed with status %d%n\",\n     client.setAccessPolicyWithResponse(PublicAccessType.CONTAINER,\n         Collections.singletonList(identifier),\n         requestConditions,\n         timeout,\n         context).getStatusCode());\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/set-container-acl"
  syntax:
    content: public Response<Void> setAccessPolicyWithResponse(PublicAccessType accessType, List<DataLakeSignedIdentifier> identifiers, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: accessType
      type: com.azure.storage.file.datalake.models.PublicAccessType
      description: >-
        Specifies how the data in this file system is available to the public. See the
         x-ms-blob-public-access header in the Azure Docs for more information. Pass null for no public access.
    - id: identifiers
      type: java.util.List<com.azure.storage.file.datalake.models.DataLakeSignedIdentifier>
      description: >-
        A list of <xref uid="com.azure.storage.file.datalake.models.DataLakeSignedIdentifier" data-throw-if-not-resolved="false">DataLakeSignedIdentifier</xref> objects that specify the permissions for the file
         system.
         Please see
         <a href="https://docs.microsoft.com/en-us/rest/api/storageservices/establishing-a-stored-access-policy">here</a>
         for more information. Passing null will clear all access policies.
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<java.lang.Void>
      description: A response containing status code and HTTP headers
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadata(java.util.Map<java.lang.String,java.lang.String>)
  id: setMetadata(java.util.Map<java.lang.String,java.lang.String>)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: setMetadata(Map<String,String> metadata)
  nameWithType: DataLakeFileSystemClient.setMetadata(Map<String,String> metadata)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadata(Map<String,String> metadata)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadata*
  type: Method
  package: com.azure.storage.file.datalake
  summary: >-
    Sets the file system's metadata. For more information, see the [Azure Docs][].


    **Code Samples**


    ```java

    Map<String, String> metadata = Collections.singletonMap("metadata", "value");
     try {
         client.setMetadata(metadata);
         System.out.printf("Set metadata completed with status %n");
     } catch (UnsupportedOperationException error) {
         System.out.printf("Fail while setting metadata %n");
     }
    ```



    [Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/set-container-metadata
  syntax:
    content: public void setMetadata(Map<String,String> metadata)
    parameters:
    - id: metadata
      type: java.util.Map<java.lang.String,java.lang.String>
      description: Metadata to associate with the file system.
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  id: setMetadataWithResponse(java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions,java.time.Duration,com.azure.core.util.Context)
  artifact: com.azure:azure-storage-file-datalake:12.1.0
  parent: com.azure.storage.file.datalake.DataLakeFileSystemClient
  langs:
  - java
  name: setMetadataWithResponse(Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  nameWithType: DataLakeFileSystemClient.setMetadataWithResponse(Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadataWithResponse(Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
  overload: com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadataWithResponse*
  type: Method
  package: com.azure.storage.file.datalake
  summary: "Sets the file system's metadata. For more information, see the [Azure Docs][].\n\n**Code Samples**\n\n```java\nMap<String, String> metadata = Collections.singletonMap(\"metadata\", \"value\");\n DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n Context context = new Context(\"Key\", \"Value\");\n \n System.out.printf(\"Set metadata completed with status %d%n\",\n     client.setMetadataWithResponse(metadata, requestConditions, timeout, context).getStatusCode());\n```\n\n\n[Azure Docs]: https://docs.microsoft.com/rest/api/storageservices/set-container-metadata"
  syntax:
    content: public Response<Void> setMetadataWithResponse(Map<String,String> metadata, DataLakeRequestConditions requestConditions, Duration timeout, Context context)
    parameters:
    - id: metadata
      type: java.util.Map<java.lang.String,java.lang.String>
      description: Metadata to associate with the file system.
    - id: requestConditions
      type: com.azure.storage.file.datalake.models.DataLakeRequestConditions
      description: <xref uid="com.azure.storage.file.datalake.models.DataLakeRequestConditions" data-throw-if-not-resolved="false">DataLakeRequestConditions</xref>
    - id: timeout
      type: java.time.Duration
      description: An optional timeout value beyond which a <xref uid="" data-throw-if-not-resolved="false">RuntimeException</xref> will be raised.
    - id: context
      type: com.azure.core.util.Context
      description: Additional context that is passed through the Http pipeline during the service call.
    return:
      type: com.azure.core.http.rest.Response<java.lang.Void>
      description: A response containing status code and HTTP headers
references:
- uid: com.azure.storage.file.datalake.DataLakeFileSystemAsyncClient
  name: DataLakeFileSystemAsyncClient
  nameWithType: DataLakeFileSystemAsyncClient
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemAsyncClient
- uid: com.azure.storage.blob.BlobContainerClient
  spec.java:
  - uid: com.azure.storage.blob.BlobContainerClient
    name: BlobContainerClient
    fullName: com.azure.storage.blob.BlobContainerClient
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.DataLakeFileSystemClient*
  name: DataLakeFileSystemClient
  nameWithType: DataLakeFileSystemClient.DataLakeFileSystemClient
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.DataLakeFileSystemClient
  package: com.azure.storage.file.datalake
- uid: java.lang.String
  spec.java:
  - uid: java.lang.String
    name: String
    fullName: java.lang.String
- uid: com.azure.storage.file.datalake.DataLakeFileClient
  name: DataLakeFileClient
  nameWithType: DataLakeFileClient
  fullName: com.azure.storage.file.datalake.DataLakeFileClient
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient*
  name: getFileClient
  nameWithType: DataLakeFileSystemClient.getFileClient
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileClient
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeDirectoryClient
  name: DataLakeDirectoryClient
  nameWithType: DataLakeDirectoryClient
  fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient*
  name: getDirectoryClient
  nameWithType: DataLakeFileSystemClient.getDirectoryClient
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getDirectoryClient
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getRootDirectoryClient*
  name: getRootDirectoryClient
  nameWithType: DataLakeFileSystemClient.getRootDirectoryClient
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getRootDirectoryClient
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemName*
  name: getFileSystemName
  nameWithType: DataLakeFileSystemClient.getFileSystemName
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemName
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemUrl*
  name: getFileSystemUrl
  nameWithType: DataLakeFileSystemClient.getFileSystemUrl
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getFileSystemUrl
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccountName*
  name: getAccountName
  nameWithType: DataLakeFileSystemClient.getAccountName
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccountName
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeServiceVersion
  name: DataLakeServiceVersion
  nameWithType: DataLakeServiceVersion
  fullName: com.azure.storage.file.datalake.DataLakeServiceVersion
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getServiceVersion*
  name: getServiceVersion
  nameWithType: DataLakeFileSystemClient.getServiceVersion
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getServiceVersion
  package: com.azure.storage.file.datalake
- uid: com.azure.core.http.HttpPipeline
  spec.java:
  - uid: com.azure.core.http.HttpPipeline
    name: HttpPipeline
    fullName: com.azure.core.http.HttpPipeline
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getHttpPipeline*
  name: getHttpPipeline
  nameWithType: DataLakeFileSystemClient.getHttpPipeline
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getHttpPipeline
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.create*
  name: create
  nameWithType: DataLakeFileSystemClient.create
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.create
  package: com.azure.storage.file.datalake
- uid: java.util.Map<java.lang.String,java.lang.String>
  spec.java:
  - uid: java.util.Map
    name: Map
    fullName: java.util.Map
  - name: <
    fullName: <
  - uid: java.lang.String
    name: String
    fullName: java.lang.String
  - name: ','
    fullName: ','
  - uid: java.lang.String
    name: String
    fullName: java.lang.String
  - name: '>'
    fullName: '>'
- uid: com.azure.storage.file.datalake.models.PublicAccessType
  name: PublicAccessType
  nameWithType: PublicAccessType
  fullName: com.azure.storage.file.datalake.models.PublicAccessType
- uid: java.time.Duration
  spec.java:
  - uid: java.time.Duration
    name: Duration
    fullName: java.time.Duration
- uid: com.azure.core.util.Context
  spec.java:
  - uid: com.azure.core.util.Context
    name: Context
    fullName: com.azure.core.util.Context
- uid: com.azure.core.http.rest.Response<java.lang.Void>
  spec.java:
  - uid: com.azure.core.http.rest.Response
    name: Response
    fullName: com.azure.core.http.rest.Response
  - name: <
    fullName: <
  - uid: java.lang.Void
    name: Void
    fullName: java.lang.Void
  - name: '>'
    fullName: '>'
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createWithResponse*
  name: createWithResponse
  nameWithType: DataLakeFileSystemClient.createWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.delete*
  name: delete
  nameWithType: DataLakeFileSystemClient.delete
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.delete
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.models.DataLakeRequestConditions
  name: DataLakeRequestConditions
  nameWithType: DataLakeRequestConditions
  fullName: com.azure.storage.file.datalake.models.DataLakeRequestConditions
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteWithResponse*
  name: deleteWithResponse
  nameWithType: DataLakeFileSystemClient.deleteWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.models.FileSystemProperties
  name: FileSystemProperties
  nameWithType: FileSystemProperties
  fullName: com.azure.storage.file.datalake.models.FileSystemProperties
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getProperties*
  name: getProperties
  nameWithType: DataLakeFileSystemClient.getProperties
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getProperties
  package: com.azure.storage.file.datalake
- uid: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.models.FileSystemProperties>
  spec.java:
  - uid: com.azure.core.http.rest.Response
    name: Response
    fullName: com.azure.core.http.rest.Response
  - name: <
    fullName: <
  - uid: com.azure.storage.file.datalake.models.FileSystemProperties
    name: FileSystemProperties
    fullName: com.azure.storage.file.datalake.models.FileSystemProperties
  - name: '>'
    fullName: '>'
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getPropertiesWithResponse*
  name: getPropertiesWithResponse
  nameWithType: DataLakeFileSystemClient.getPropertiesWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getPropertiesWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadata*
  name: setMetadata
  nameWithType: DataLakeFileSystemClient.setMetadata
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadata
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadataWithResponse*
  name: setMetadataWithResponse
  nameWithType: DataLakeFileSystemClient.setMetadataWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.setMetadataWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.core.http.rest.PagedIterable<com.azure.storage.file.datalake.models.PathItem>
  spec.java:
  - uid: com.azure.core.http.rest.PagedIterable
    name: PagedIterable
    fullName: com.azure.core.http.rest.PagedIterable
  - name: <
    fullName: <
  - uid: com.azure.storage.file.datalake.models.PathItem
    name: PathItem
    fullName: com.azure.storage.file.datalake.models.PathItem
  - name: '>'
    fullName: '>'
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths*
  name: listPaths
  nameWithType: DataLakeFileSystemClient.listPaths
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.listPaths
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.models.ListPathsOptions
  name: ListPathsOptions
  nameWithType: ListPathsOptions
  fullName: com.azure.storage.file.datalake.models.ListPathsOptions
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile*
  name: createFile
  nameWithType: DataLakeFileSystemClient.createFile
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFile
  package: com.azure.storage.file.datalake
- uid: boolean
  spec.java:
  - uid: boolean
    name: boolean
    fullName: boolean
- uid: com.azure.storage.file.datalake.models.PathHttpHeaders
  name: PathHttpHeaders
  nameWithType: PathHttpHeaders
  fullName: com.azure.storage.file.datalake.models.PathHttpHeaders
- uid: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeFileClient>
  spec.java:
  - uid: com.azure.core.http.rest.Response
    name: Response
    fullName: com.azure.core.http.rest.Response
  - name: <
    fullName: <
  - uid: com.azure.storage.file.datalake.DataLakeFileClient
    name: DataLakeFileClient
    fullName: com.azure.storage.file.datalake.DataLakeFileClient
  - name: '>'
    fullName: '>'
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFileWithResponse*
  name: createFileWithResponse
  nameWithType: DataLakeFileSystemClient.createFileWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createFileWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFile*
  name: deleteFile
  nameWithType: DataLakeFileSystemClient.deleteFile
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFile
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFileWithResponse*
  name: deleteFileWithResponse
  nameWithType: DataLakeFileSystemClient.deleteFileWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteFileWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory*
  name: createDirectory
  nameWithType: DataLakeFileSystemClient.createDirectory
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectory
  package: com.azure.storage.file.datalake
- uid: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.DataLakeDirectoryClient>
  spec.java:
  - uid: com.azure.core.http.rest.Response
    name: Response
    fullName: com.azure.core.http.rest.Response
  - name: <
    fullName: <
  - uid: com.azure.storage.file.datalake.DataLakeDirectoryClient
    name: DataLakeDirectoryClient
    fullName: com.azure.storage.file.datalake.DataLakeDirectoryClient
  - name: '>'
    fullName: '>'
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectoryWithResponse*
  name: createDirectoryWithResponse
  nameWithType: DataLakeFileSystemClient.createDirectoryWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.createDirectoryWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectory*
  name: deleteDirectory
  nameWithType: DataLakeFileSystemClient.deleteDirectory
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectory
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectoryWithResponse*
  name: deleteDirectoryWithResponse
  nameWithType: DataLakeFileSystemClient.deleteDirectoryWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.deleteDirectoryWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.models.FileSystemAccessPolicies
  name: FileSystemAccessPolicies
  nameWithType: FileSystemAccessPolicies
  fullName: com.azure.storage.file.datalake.models.FileSystemAccessPolicies
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicy*
  name: getAccessPolicy
  nameWithType: DataLakeFileSystemClient.getAccessPolicy
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicy
  package: com.azure.storage.file.datalake
- uid: com.azure.core.http.rest.Response<com.azure.storage.file.datalake.models.FileSystemAccessPolicies>
  spec.java:
  - uid: com.azure.core.http.rest.Response
    name: Response
    fullName: com.azure.core.http.rest.Response
  - name: <
    fullName: <
  - uid: com.azure.storage.file.datalake.models.FileSystemAccessPolicies
    name: FileSystemAccessPolicies
    fullName: com.azure.storage.file.datalake.models.FileSystemAccessPolicies
  - name: '>'
    fullName: '>'
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicyWithResponse*
  name: getAccessPolicyWithResponse
  nameWithType: DataLakeFileSystemClient.getAccessPolicyWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getAccessPolicyWithResponse
  package: com.azure.storage.file.datalake
- uid: java.util.List<com.azure.storage.file.datalake.models.DataLakeSignedIdentifier>
  spec.java:
  - uid: java.util.List
    name: List
    fullName: java.util.List
  - name: <
    fullName: <
  - uid: com.azure.storage.file.datalake.models.DataLakeSignedIdentifier
    name: DataLakeSignedIdentifier
    fullName: com.azure.storage.file.datalake.models.DataLakeSignedIdentifier
  - name: '>'
    fullName: '>'
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicy*
  name: setAccessPolicy
  nameWithType: DataLakeFileSystemClient.setAccessPolicy
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicy
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicyWithResponse*
  name: setAccessPolicyWithResponse
  nameWithType: DataLakeFileSystemClient.setAccessPolicyWithResponse
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.setAccessPolicyWithResponse
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.getBlobContainerClient*
  name: getBlobContainerClient
  nameWithType: DataLakeFileSystemClient.getBlobContainerClient
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.getBlobContainerClient
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues
  name: DataLakeServiceSasSignatureValues
  nameWithType: DataLakeServiceSasSignatureValues
  fullName: com.azure.storage.file.datalake.sas.DataLakeServiceSasSignatureValues
- uid: com.azure.storage.file.datalake.models.UserDelegationKey
  name: UserDelegationKey
  nameWithType: UserDelegationKey
  fullName: com.azure.storage.file.datalake.models.UserDelegationKey
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.generateUserDelegationSas*
  name: generateUserDelegationSas
  nameWithType: DataLakeFileSystemClient.generateUserDelegationSas
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.generateUserDelegationSas
  package: com.azure.storage.file.datalake
- uid: com.azure.storage.file.datalake.DataLakeFileSystemClient.generateSas*
  name: generateSas
  nameWithType: DataLakeFileSystemClient.generateSas
  fullName: com.azure.storage.file.datalake.DataLakeFileSystemClient.generateSas
  package: com.azure.storage.file.datalake
- uid: java.lang.Object.notify()
  name: Object.notify()
  nameWithType: Object.notify()
  fullName: java.lang.Object.notify()
- uid: java.lang.Object.wait()
  name: Object.wait()
  nameWithType: Object.wait()
  fullName: java.lang.Object.wait()
- uid: java.lang.Object.finalize()
  name: Object.finalize()
  nameWithType: Object.finalize()
  fullName: java.lang.Object.finalize()
- uid: java.lang.Object.clone()
  name: Object.clone()
  nameWithType: Object.clone()
  fullName: java.lang.Object.clone()
- uid: java.lang.Object.notifyAll()
  name: Object.notifyAll()
  nameWithType: Object.notifyAll()
  fullName: java.lang.Object.notifyAll()
- uid: java.lang.Object.equals(java.lang.Object)
  name: Object.equals(Object)
  nameWithType: Object.equals(Object)
  fullName: java.lang.Object.equals(java.lang.Object)
- uid: java.lang.Object.getClass()
  name: Object.getClass()
  nameWithType: Object.getClass()
  fullName: java.lang.Object.getClass()
- uid: java.lang.Object.wait(long)
  name: Object.wait(long)
  nameWithType: Object.wait(long)
  fullName: java.lang.Object.wait(long)
- uid: java.lang.Object.hashCode()
  name: Object.hashCode()
  nameWithType: Object.hashCode()
  fullName: java.lang.Object.hashCode()
- uid: java.lang.Object.wait(long,int)
  name: Object.wait(long,int)
  nameWithType: Object.wait(long,int)
  fullName: java.lang.Object.wait(long,int)
- uid: java.lang.Object.toString()
  name: Object.toString()
  nameWithType: Object.toString()
  fullName: java.lang.Object.toString()
- uid: java.util.Map
  name: Map
  nameWithType: Map
  fullName: java.util.Map
- uid: java.lang.String,java.lang.String
  name: String,String
  nameWithType: String,String
  fullName: java.lang.String,java.lang.String
- uid: java.lang.Void
  name: Void
  nameWithType: Void
  fullName: java.lang.Void
- uid: com.azure.core.http.rest.Response
  name: Response
  nameWithType: Response
  fullName: com.azure.core.http.rest.Response
- uid: com.azure.core.http.rest.PagedIterable
  name: PagedIterable
  nameWithType: PagedIterable
  fullName: com.azure.core.http.rest.PagedIterable
- uid: com.azure.storage.file.datalake.models.PathItem
  name: PathItem
  nameWithType: PathItem
  fullName: com.azure.storage.file.datalake.models.PathItem
- uid: java.util.List
  name: List
  nameWithType: List
  fullName: java.util.List
- uid: com.azure.storage.file.datalake.models.DataLakeSignedIdentifier
  name: DataLakeSignedIdentifier
  nameWithType: DataLakeSignedIdentifier
  fullName: com.azure.storage.file.datalake.models.DataLakeSignedIdentifier
