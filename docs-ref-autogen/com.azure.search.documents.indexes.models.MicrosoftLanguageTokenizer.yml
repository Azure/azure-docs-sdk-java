### YamlMime:JavaType
uid: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer"
fullName: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer"
name: "MicrosoftLanguageTokenizer"
nameWithType: "MicrosoftLanguageTokenizer"
summary: "Divides text using language-specific rules."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
- "<xref href=\"com.azure.search.documents.indexes.models.LexicalTokenizer?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "com.azure.search.documents.indexes.models.LexicalTokenizer.getName()"
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class MicrosoftLanguageTokenizer extends LexicalTokenizer"
constructors:
- uid: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.MicrosoftLanguageTokenizer(java.lang.String)"
  fullName: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.MicrosoftLanguageTokenizer(String name)"
  name: "MicrosoftLanguageTokenizer(String name)"
  nameWithType: "MicrosoftLanguageTokenizer.MicrosoftLanguageTokenizer(String name)"
  summary: "Constructor of <xref uid=\"com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer\" data-throw-if-not-resolved=\"false\" data-raw-source=\"MicrosoftLanguageTokenizer\"></xref>."
  parameters:
  - description: "The name of the tokenizer. It must only contain letters, digits, spaces,\n dashes or underscores, can only start and end with alphanumeric\n characters, and is limited to 128 characters."
    name: "name"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public MicrosoftLanguageTokenizer(String name)"
  desc: "Constructor of <xref uid=\"com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer\" data-throw-if-not-resolved=\"false\" data-raw-source=\"MicrosoftLanguageTokenizer\"></xref>."
methods:
- uid: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.getLanguage()"
  fullName: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.getLanguage()"
  name: "getLanguage()"
  nameWithType: "MicrosoftLanguageTokenizer.getLanguage()"
  summary: "Get the language property: The language to use."
  syntax: "public MicrosoftTokenizerLanguage getLanguage()"
  desc: "Get the language property: The language to use. The default is English. Possible values include: 'Bangla', 'Bulgarian', 'Catalan', 'ChineseSimplified', 'ChineseTraditional', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'French', 'German', 'Greek', 'Gujarati', 'Hindi', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Kannada', 'Korean', 'Malay', 'Malayalam', 'Marathi', 'NorwegianBokmaal', 'Polish', 'Portuguese', 'PortugueseBrazilian', 'Punjabi', 'Romanian', 'Russian', 'SerbianCyrillic', 'SerbianLatin', 'Slovenian', 'Spanish', 'Swedish', 'Tamil', 'Telugu', 'Thai', 'Ukrainian', 'Urdu', 'Vietnamese'."
  returns:
    description: "the language value."
    type: "<xref href=\"com.azure.search.documents.indexes.models.MicrosoftTokenizerLanguage?alt=com.azure.search.documents.indexes.models.MicrosoftTokenizerLanguage&text=MicrosoftTokenizerLanguage\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.getMaxTokenLength()"
  fullName: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.getMaxTokenLength()"
  name: "getMaxTokenLength()"
  nameWithType: "MicrosoftLanguageTokenizer.getMaxTokenLength()"
  summary: "Get the max<wbr>Token<wbr>Length property: The maximum token length."
  syntax: "public Integer getMaxTokenLength()"
  desc: "Get the maxTokenLength property: The maximum token length. Tokens longer than the maximum length are split. Maximum token length that can be used is 300 characters. Tokens longer than 300 characters are first split into tokens of length 300 and then each of those tokens is split based on the max token length set. Default is 255."
  returns:
    description: "the maxTokenLength value."
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.isSearchTokenizer()"
  fullName: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.isSearchTokenizer()"
  name: "isSearchTokenizer()"
  nameWithType: "MicrosoftLanguageTokenizer.isSearchTokenizer()"
  summary: "Get the is<wbr>Search<wbr>Tokenizer property: A value indicating how the tokenizer is used."
  syntax: "public Boolean isSearchTokenizer()"
  desc: "Get the isSearchTokenizer property: A value indicating how the tokenizer is used. Set to true if used as the search tokenizer, set to false if used as the indexing tokenizer. Default is false."
  returns:
    description: "the isSearchTokenizer value."
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.setIsSearchTokenizer(java.lang.Boolean)"
  fullName: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.setIsSearchTokenizer(Boolean isSearchTokenizer)"
  name: "setIsSearchTokenizer(Boolean isSearchTokenizer)"
  nameWithType: "MicrosoftLanguageTokenizer.setIsSearchTokenizer(Boolean isSearchTokenizer)"
  summary: "Set the is<wbr>Search<wbr>Tokenizer property: A value indicating how the tokenizer is used."
  parameters:
  - description: "the isSearchTokenizer value to set."
    name: "isSearchTokenizer"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public MicrosoftLanguageTokenizer setIsSearchTokenizer(Boolean isSearchTokenizer)"
  desc: "Set the isSearchTokenizer property: A value indicating how the tokenizer is used. Set to true if used as the search tokenizer, set to false if used as the indexing tokenizer. Default is false."
  returns:
    description: "the MicrosoftLanguageTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer?alt=com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer&text=MicrosoftLanguageTokenizer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.setLanguage(com.azure.search.documents.indexes.models.MicrosoftTokenizerLanguage)"
  fullName: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.setLanguage(MicrosoftTokenizerLanguage language)"
  name: "setLanguage(MicrosoftTokenizerLanguage language)"
  nameWithType: "MicrosoftLanguageTokenizer.setLanguage(MicrosoftTokenizerLanguage language)"
  summary: "Set the language property: The language to use."
  parameters:
  - description: "the language value to set."
    name: "language"
    type: "<xref href=\"com.azure.search.documents.indexes.models.MicrosoftTokenizerLanguage?alt=com.azure.search.documents.indexes.models.MicrosoftTokenizerLanguage&text=MicrosoftTokenizerLanguage\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public MicrosoftLanguageTokenizer setLanguage(MicrosoftTokenizerLanguage language)"
  desc: "Set the language property: The language to use. The default is English. Possible values include: 'Bangla', 'Bulgarian', 'Catalan', 'ChineseSimplified', 'ChineseTraditional', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'French', 'German', 'Greek', 'Gujarati', 'Hindi', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Kannada', 'Korean', 'Malay', 'Malayalam', 'Marathi', 'NorwegianBokmaal', 'Polish', 'Portuguese', 'PortugueseBrazilian', 'Punjabi', 'Romanian', 'Russian', 'SerbianCyrillic', 'SerbianLatin', 'Slovenian', 'Spanish', 'Swedish', 'Tamil', 'Telugu', 'Thai', 'Ukrainian', 'Urdu', 'Vietnamese'."
  returns:
    description: "the MicrosoftLanguageTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer?alt=com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer&text=MicrosoftLanguageTokenizer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.setMaxTokenLength(java.lang.Integer)"
  fullName: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.setMaxTokenLength(Integer maxTokenLength)"
  name: "setMaxTokenLength(Integer maxTokenLength)"
  nameWithType: "MicrosoftLanguageTokenizer.setMaxTokenLength(Integer maxTokenLength)"
  summary: "Set the max<wbr>Token<wbr>Length property: The maximum token length."
  parameters:
  - description: "the maxTokenLength value to set."
    name: "maxTokenLength"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public MicrosoftLanguageTokenizer setMaxTokenLength(Integer maxTokenLength)"
  desc: "Set the maxTokenLength property: The maximum token length. Tokens longer than the maximum length are split. Maximum token length that can be used is 300 characters. Tokens longer than 300 characters are first split into tokens of length 300 and then each of those tokens is split based on the max token length set. Default is 255."
  returns:
    description: "the MicrosoftLanguageTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer?alt=com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer&text=MicrosoftLanguageTokenizer\" data-throw-if-not-resolved=\"False\" />"
type: "class"
desc: "Divides text using language-specific rules."
metadata: {}
package: "com.azure.search.documents.indexes.models"
artifact: com.azure:azure-search-documents:11.4.13
