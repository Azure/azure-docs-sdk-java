### YamlMime:ManagedReference
items:
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd
  id: _faces1f3220f531b183633f100aae482e50cd
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  children:
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd.execute()
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd.executeAsync()
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd.yml
  langs:
  - java
  name: Faces.FacesDetectWithUrlDefinitionStages.WithExecute
  nameWithType: Faces.FacesDetectWithUrlDefinitionStages.WithExecute
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithUrlDefinitionStages.WithExecute
  type: Interface
  source:
    remote: &o0
      path: cognitiveservices/data-plane/vision/faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
      branch: master
      repo: https://github.com/Azure/azure-sdk-for-java
    path: cognitiveservices/data-plane/vision/faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
    startLine: 389
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
  summary: "<p>The last stage of the definition which will make the operation call. </p>"
  syntax:
    content: public interface WithExecute extends Faces.FacesDetectWithUrlDefinitionStages.WithAllOptions
  inheritedMembers:
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63.withReturnFaceAttributes(List<FaceAttributeType>)
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63.withReturnFaceId(Boolean)
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63.withReturnFaceLandmarks(Boolean)
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd.execute()
  id: execute()
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd.yml
  langs:
  - java
  name: execute()
  nameWithType: Faces.FacesDetectWithUrlDefinitionStages.WithExecute.execute()
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithUrlDefinitionStages.WithExecute.execute()
  overload: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd.execute*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/data-plane/vision/faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
    startLine: 395
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
  summary: "<p>Execute the request.</p>\r\n<p></p>"
  syntax:
    content: public List<DetectedFace> execute()
    return:
      type: 5618da2dcom.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_facea08ddfce
      description: <p>the List&lt;DetectedFace&gt; object if successful. </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd.executeAsync()
  id: executeAsync()
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd.yml
  langs:
  - java
  name: executeAsync()
  nameWithType: Faces.FacesDetectWithUrlDefinitionStages.WithExecute.executeAsync()
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithUrlDefinitionStages.WithExecute.executeAsync()
  overload: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd.executeAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/data-plane/vision/faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
    startLine: 402
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
  summary: "<p>Execute the request asynchronously.</p>\r\n<p></p>"
  syntax:
    content: public Observable<List<DetectedFace>> executeAsync()
    return:
      type: 39a50407com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_facee7daa122
      description: <p>the observable to the List&lt;DetectedFace&gt; object </p>
references:
- uid: 5618da2dcom.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_facea08ddfce
  spec.java:
  - name: List<
    fullName: List<
  - uid: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face
    name: DetectedFace
    fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.models.DetectedFace
    href: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face.yml
  - name: '>'
    fullName: '>'
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd.execute*
  name: execute
  nameWithType: Faces.FacesDetectWithUrlDefinitionStages.WithExecute.execute
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithUrlDefinitionStages.WithExecute.execute
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
- uid: 39a50407com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_facee7daa122
  spec.java:
  - name: Observable<List<
    fullName: Observable<List<
  - uid: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face
    name: DetectedFace
    fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.models.DetectedFace
    href: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face.yml
  - name: '>>'
    fullName: '>>'
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces1f3220f531b183633f100aae482e50cd.executeAsync*
  name: executeAsync
  nameWithType: Faces.FacesDetectWithUrlDefinitionStages.WithExecute.executeAsync
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithUrlDefinitionStages.WithExecute.executeAsync
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63.withReturnFaceAttributes(List<FaceAttributeType>)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63.yml
  name: withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  nameWithType: Faces.FacesDetectWithUrlDefinitionStages.WithAllOptions.withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithUrlDefinitionStages.WithAllOptions.withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  type: Method
  summary: >-
    <p>Analyze and return the one or more specified face attributes in the comma-separated string like "returnFaceAttributes=age,gender". Supported face attributes include age, gender, headPose, smile, facialHair, glasses and emotion. Note that each face attribute analysis has additional computational and time cost.</p>

    <p></p>
  syntax:
    content: public FacesDetectWithUrlDefinitionStages.WithExecute withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
    parameters:
    - id: returnFaceAttributes
      type: 5618da2dcom.microsoft.azure.cognitiveservices.vision.faceapi.models._face_attribute_typea08ddfce
    return:
      type: 0d8e130f
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63.withReturnFaceId(Boolean)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63.yml
  name: withReturnFaceId(Boolean returnFaceId)
  nameWithType: Faces.FacesDetectWithUrlDefinitionStages.WithAllOptions.withReturnFaceId(Boolean returnFaceId)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithUrlDefinitionStages.WithAllOptions.withReturnFaceId(Boolean returnFaceId)
  type: Method
  summary: >-
    <p>A value indicating whether the operation should return faceIds of detected faces.</p>

    <p></p>
  syntax:
    content: public FacesDetectWithUrlDefinitionStages.WithExecute withReturnFaceId(Boolean returnFaceId)
    parameters:
    - id: returnFaceId
      type: 866c2227
    return:
      type: 0d8e130f
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63.withReturnFaceLandmarks(Boolean)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63.yml
  name: withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  nameWithType: Faces.FacesDetectWithUrlDefinitionStages.WithAllOptions.withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithUrlDefinitionStages.WithAllOptions.withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  type: Method
  summary: >-
    <p>A value indicating whether the operation should return landmarks of the detected faces.</p>

    <p></p>
  syntax:
    content: public FacesDetectWithUrlDefinitionStages.WithExecute withReturnFaceLandmarks(Boolean returnFaceLandmarks)
    parameters:
    - id: returnFaceLandmarks
      type: 866c2227
    return:
      type: 0d8e130f
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces5adc4878a6268e4b994b6b4b95337d63.yml
  name: Faces.FacesDetectWithUrlDefinitionStages.WithAllOptions
  nameWithType: Faces.FacesDetectWithUrlDefinitionStages.WithAllOptions
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithUrlDefinitionStages.WithAllOptions
  type: Interface
  summary: <p>The stage of the definition which allows for any other optional settings to be specified. </p>
  syntax:
    content: public interface WithAllOptions
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces_detect_with_url_definition
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces_detect_with_url_definition.yml
  name: Faces.FacesDetectWithUrlDefinition
  nameWithType: Faces.FacesDetectWithUrlDefinition
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithUrlDefinition
  type: Interface
  summary: <p>The entirety of detectWithUrl definition. </p>
  syntax:
    content: public interface FacesDetectWithUrlDefinition extends Faces.FacesDetectWithUrlDefinitionStages.WithUrl,Faces.FacesDetectWithUrlDefinitionStages.WithExecute
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi.models
  href: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face.yml
  name: DetectedFace
  nameWithType: DetectedFace
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.models.DetectedFace
  type: Class
  summary: <p>Detected Face object. </p>
  syntax:
    content: public class DetectedFace
