### YamlMime:JavaMember
uid: "com.azure.storage.blob.specialized.AppendBlobClient.appendBlockWithResponse*"
fullName: "com.azure.storage.blob.specialized.AppendBlobClient.appendBlockWithResponse"
name: "appendBlockWithResponse"
nameWithType: "AppendBlobClient.appendBlockWithResponse"
members:
- uid: "com.azure.storage.blob.specialized.AppendBlobClient.appendBlockWithResponse(java.io.InputStream,long,byte[],com.azure.storage.blob.models.AppendBlobRequestConditions,java.time.Duration,com.azure.core.util.Context)"
  fullName: "com.azure.storage.blob.specialized.AppendBlobClient.appendBlockWithResponse(InputStream data, long length, byte[] contentMd5, AppendBlobRequestConditions appendBlobRequestConditions, Duration timeout, Context context)"
  name: "appendBlockWithResponse(InputStream data, long length, byte[] contentMd5, AppendBlobRequestConditions appendBlobRequestConditions, Duration timeout, Context context)"
  nameWithType: "AppendBlobClient.appendBlockWithResponse(InputStream data, long length, byte[] contentMd5, AppendBlobRequestConditions appendBlobRequestConditions, Duration timeout, Context context)"
  summary: "Commits a new block of data to the end of the existing append blob.\n\nNote that the data passed must be replayable if retries are enabled (the default). In other words, the `Flux` must produce the same data each time it is subscribed to.\n\n**Code Samples**\n\n```java\nbyte[] md5 = MessageDigest.getInstance(\"MD5\").digest(\"data\".getBytes(StandardCharsets.UTF_8));\n AppendBlobRequestConditions requestConditions = new AppendBlobRequestConditions()\n     .setAppendPosition(POSITION)\n     .setMaxSize(maxSize);\n Context context = new Context(\"key\", \"value\");\n \n System.out.printf(\"AppendBlob has %d committed blocks%n\",\n     client.appendBlockWithResponse(data, length, md5, requestConditions, timeout, context)\n         .getValue().getBlobCommittedBlockCount());\n```"
  parameters:
  - description: "The data to write to the blob. The data must be markable. This is in order to support retries. If\n the data is not markable, consider using <xref uid=\"com.azure.storage.blob.specialized.AppendBlobClient.getBlobOutputStream()\" data-throw-if-not-resolved=\"false\" data-raw-source=\"#getBlobOutputStream()\"></xref> and writing to the returned OutputStream.\n Alternatively, consider wrapping your data source in a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"java.io.BufferedInputStream\"></xref> to add mark support."
    name: "data"
    type: "<xref href=\"java.io.InputStream?alt=java.io.InputStream&text=InputStream\" data-throw-if-not-resolved=\"False\" />"
  - description: "The exact length of the data. It is important that this value match precisely the length of the\n data emitted by the <code>Flux</code>."
    name: "length"
    type: "<xref href=\"long?alt=long&text=long\" data-throw-if-not-resolved=\"False\" />"
  - description: "An MD5 hash of the block content. This hash is used to verify the integrity of the block during\n transport. When this header is specified, the storage service compares the hash of the content that has arrived\n with this header value. Note that this MD5 hash is not stored with the blob. If the two hashes do not match, the\n operation will fail."
    name: "contentMd5"
    type: "<xref href=\"byte?alt=byte&text=byte\" data-throw-if-not-resolved=\"False\" />[]"
  - description: "<xref uid=\"com.azure.storage.blob.models.AppendBlobRequestConditions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"AppendBlobRequestConditions\"></xref>"
    name: "appendBlobRequestConditions"
    type: "<xref href=\"com.azure.storage.blob.models.AppendBlobRequestConditions?alt=com.azure.storage.blob.models.AppendBlobRequestConditions&text=AppendBlobRequestConditions\" data-throw-if-not-resolved=\"False\" />"
  - description: "An optional timeout value beyond which a <xref uid=\"\" data-throw-if-not-resolved=\"false\" data-raw-source=\"RuntimeException\"></xref> will be raised."
    name: "timeout"
    type: "<xref href=\"java.time.Duration?alt=java.time.Duration&text=Duration\" data-throw-if-not-resolved=\"False\" />"
  - description: "Additional context that is passed through the Http pipeline during the service call."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Response<AppendBlobItem> appendBlockWithResponse(InputStream data, long length, byte[] contentMd5, AppendBlobRequestConditions appendBlobRequestConditions, Duration timeout, Context context)"
  returns:
    description: "A <xref uid=\"com.azure.core.http.rest.Response\" data-throw-if-not-resolved=\"false\" data-raw-source=\"Response\"></xref> whose <xref uid=\"com.azure.core.http.rest.Response.getValue*\" data-throw-if-not-resolved=\"false\" data-raw-source=\"value\"></xref> contains the append blob operation."
    type: "<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.blob.models.AppendBlobItem?alt=com.azure.storage.blob.models.AppendBlobItem&text=AppendBlobItem\" data-throw-if-not-resolved=\"False\" />&gt;"
type: "method"
metadata: {}
package: "com.azure.storage.blob.specialized"
artifact: com.azure:azure-storage-blob:12.8.0
