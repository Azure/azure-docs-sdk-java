### YamlMime:ManagedReference
items:
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e
  id: _facese55a9be762e5757882dfbc975d1b7e5e
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  children:
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.execute()
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.executeAsync()
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.yml
  langs:
  - java
  name: Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  type: Interface
  source:
    remote: &o0
      path: cognitiveservices/data-plane/vision/faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
      branch: master
      repo: https://github.com/Azure/azure-sdk-for-java
    path: cognitiveservices/data-plane/vision/faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
    startLine: 525
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
  summary: "<p>The last stage of the definition which will make the operation call. </p>"
  syntax:
    content: public interface WithExecute extends Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions
  inheritedMembers:
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceAttributes(List<FaceAttributeType>)
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceId(Boolean)
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceLandmarks(Boolean)
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.execute()
  id: execute()
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.yml
  langs:
  - java
  name: execute()
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithExecute.execute()
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.execute()
  overload: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.execute*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/data-plane/vision/faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
    startLine: 531
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
  summary: "<p>Execute the request.</p>\r\n<p></p>"
  syntax:
    content: public List<DetectedFace> execute()
    return:
      type: 5618da2dcom.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_facea08ddfce
      description: <p>the List&lt;DetectedFace&gt; object if successful. </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.executeAsync()
  id: executeAsync()
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.yml
  langs:
  - java
  name: executeAsync()
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithExecute.executeAsync()
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.executeAsync()
  overload: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.executeAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/data-plane/vision/faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
    startLine: 538
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
  summary: "<p>Execute the request asynchronously.</p>\r\n<p></p>"
  syntax:
    content: public Observable<List<DetectedFace>> executeAsync()
    return:
      type: 39a50407com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_facee7daa122
      description: <p>the observable to the List&lt;DetectedFace&gt; object </p>
references:
- uid: 5618da2dcom.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_facea08ddfce
  spec.java:
  - name: List<
    fullName: List<
  - uid: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face
    name: DetectedFace
    fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.models.DetectedFace
    href: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face.yml
  - name: '>'
    fullName: '>'
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.execute*
  name: execute
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithExecute.execute
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.execute
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
- uid: 39a50407com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_facee7daa122
  spec.java:
  - name: Observable<List<
    fullName: Observable<List<
  - uid: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face
    name: DetectedFace
    fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.models.DetectedFace
    href: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face.yml
  - name: '>>'
    fullName: '>>'
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.executeAsync*
  name: executeAsync
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithExecute.executeAsync
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.executeAsync
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceAttributes(List<FaceAttributeType>)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.yml
  name: withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  type: Method
  summary: >-
    <p>Analyze and return the one or more specified face attributes in the comma-separated string like "returnFaceAttributes=age,gender". Supported face attributes include age, gender, headPose, smile, facialHair, glasses and emotion. Note that each face attribute analysis has additional computational and time cost.</p>

    <p></p>
  syntax:
    content: public FacesDetectWithStreamDefinitionStages.WithExecute withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
    parameters:
    - id: returnFaceAttributes
      type: 5618da2dcom.microsoft.azure.cognitiveservices.vision.faceapi.models._face_attribute_typea08ddfce
    return:
      type: 1f48b658
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceId(Boolean)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.yml
  name: withReturnFaceId(Boolean returnFaceId)
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceId(Boolean returnFaceId)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceId(Boolean returnFaceId)
  type: Method
  summary: >-
    <p>A value indicating whether the operation should return faceIds of detected faces.</p>

    <p></p>
  syntax:
    content: public FacesDetectWithStreamDefinitionStages.WithExecute withReturnFaceId(Boolean returnFaceId)
    parameters:
    - id: returnFaceId
      type: 866c2227
    return:
      type: 1f48b658
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceLandmarks(Boolean)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.yml
  name: withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  type: Method
  summary: >-
    <p>A value indicating whether the operation should return landmarks of the detected faces.</p>

    <p></p>
  syntax:
    content: public FacesDetectWithStreamDefinitionStages.WithExecute withReturnFaceLandmarks(Boolean returnFaceLandmarks)
    parameters:
    - id: returnFaceLandmarks
      type: 866c2227
    return:
      type: 1f48b658
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.yml
  name: Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions
  type: Interface
  summary: <p>The stage of the definition which allows for any other optional settings to be specified. </p>
  syntax:
    content: public interface WithAllOptions
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces_detect_with_stream_definition
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces_detect_with_stream_definition.yml
  name: Faces.FacesDetectWithStreamDefinition
  nameWithType: Faces.FacesDetectWithStreamDefinition
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinition
  type: Interface
  summary: <p>The entirety of detectWithStream definition. </p>
  syntax:
    content: public interface FacesDetectWithStreamDefinition extends Faces.FacesDetectWithStreamDefinitionStages.WithImage,Faces.FacesDetectWithStreamDefinitionStages.WithExecute
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi.models
  href: com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_face.yml
  name: DetectedFace
  nameWithType: DetectedFace
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.models.DetectedFace
  type: Class
  summary: <p>Detected Face object. </p>
  syntax:
    content: public class DetectedFace
