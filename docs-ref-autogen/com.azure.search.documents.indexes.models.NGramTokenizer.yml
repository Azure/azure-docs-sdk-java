### YamlMime:JavaType
uid: "com.azure.search.documents.indexes.models.NGramTokenizer"
fullName: "com.azure.search.documents.indexes.models.NGramTokenizer"
name: "NGramTokenizer"
nameWithType: "NGramTokenizer"
summary: "Tokenizes the input into n-grams of the given size(s)."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
- "<xref href=\"com.azure.search.documents.indexes.models.LexicalTokenizer?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "com.azure.search.documents.indexes.models.LexicalTokenizer.getName()"
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class NGramTokenizer extends LexicalTokenizer"
constructors:
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.NGramTokenizer(java.lang.String)"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.NGramTokenizer(String name)"
  name: "NGramTokenizer(String name)"
  nameWithType: "NGramTokenizer.NGramTokenizer(String name)"
  summary: "Constructor of <xref uid=\"com.azure.search.documents.indexes.models.NGramTokenizer\" data-throw-if-not-resolved=\"false\" data-raw-source=\"NGramTokenizer\"></xref>."
  parameters:
  - description: "The name of the tokenizer. It must only contain letters, digits, spaces,\n dashes or underscores, can only start and end with alphanumeric\n characters, and is limited to 128 characters."
    name: "name"
    type: "<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public NGramTokenizer(String name)"
  desc: "Constructor of <xref uid=\"com.azure.search.documents.indexes.models.NGramTokenizer\" data-throw-if-not-resolved=\"false\" data-raw-source=\"NGramTokenizer\"></xref>."
methods:
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.getMaxGram()"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.getMaxGram()"
  name: "getMaxGram()"
  nameWithType: "NGramTokenizer.getMaxGram()"
  summary: "Get the max<wbr>Gram property: The maximum n-gram length."
  syntax: "public Integer getMaxGram()"
  desc: "Get the maxGram property: The maximum n-gram length. Default is 2. Maximum is 300."
  returns:
    description: "the maxGram value."
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.getMinGram()"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.getMinGram()"
  name: "getMinGram()"
  nameWithType: "NGramTokenizer.getMinGram()"
  summary: "Get the min<wbr>Gram property: The minimum n-gram length."
  syntax: "public Integer getMinGram()"
  desc: "Get the minGram property: The minimum n-gram length. Default is 1. Maximum is 300. Must be less than the value of maxGram."
  returns:
    description: "the minGram value."
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.getTokenChars()"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.getTokenChars()"
  name: "getTokenChars()"
  nameWithType: "NGramTokenizer.getTokenChars()"
  summary: "Get the token<wbr>Chars property: Character classes to keep in the tokens."
  syntax: "public List<TokenCharacterKind> getTokenChars()"
  desc: "Get the tokenChars property: Character classes to keep in the tokens."
  returns:
    description: "the tokenChars value."
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.search.documents.indexes.models.TokenCharacterKind?alt=com.azure.search.documents.indexes.models.TokenCharacterKind&text=TokenCharacterKind\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.setMaxGram(java.lang.Integer)"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.setMaxGram(Integer maxGram)"
  name: "setMaxGram(Integer maxGram)"
  nameWithType: "NGramTokenizer.setMaxGram(Integer maxGram)"
  summary: "Set the max<wbr>Gram property: The maximum n-gram length."
  parameters:
  - description: "the maxGram value to set."
    name: "maxGram"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public NGramTokenizer setMaxGram(Integer maxGram)"
  desc: "Set the maxGram property: The maximum n-gram length. Default is 2. Maximum is 300."
  returns:
    description: "the NGramTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.NGramTokenizer?alt=com.azure.search.documents.indexes.models.NGramTokenizer&text=NGramTokenizer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.setMinGram(java.lang.Integer)"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.setMinGram(Integer minGram)"
  name: "setMinGram(Integer minGram)"
  nameWithType: "NGramTokenizer.setMinGram(Integer minGram)"
  summary: "Set the min<wbr>Gram property: The minimum n-gram length."
  parameters:
  - description: "the minGram value to set."
    name: "minGram"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public NGramTokenizer setMinGram(Integer minGram)"
  desc: "Set the minGram property: The minimum n-gram length. Default is 1. Maximum is 300. Must be less than the value of maxGram."
  returns:
    description: "the NGramTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.NGramTokenizer?alt=com.azure.search.documents.indexes.models.NGramTokenizer&text=NGramTokenizer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.setTokenChars(com.azure.search.documents.indexes.models.TokenCharacterKind...)"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.setTokenChars(TokenCharacterKind[] tokenChars)"
  name: "setTokenChars(TokenCharacterKind[] tokenChars)"
  nameWithType: "NGramTokenizer.setTokenChars(TokenCharacterKind[] tokenChars)"
  summary: "Set the token<wbr>Chars property: Character classes to keep in the tokens."
  parameters:
  - description: "the tokenChars value to set."
    name: "tokenChars"
    type: "<xref href=\"com.azure.search.documents.indexes.models.TokenCharacterKind?alt=com.azure.search.documents.indexes.models.TokenCharacterKind&text=TokenCharacterKind\" data-throw-if-not-resolved=\"False\" />[]"
  syntax: "public NGramTokenizer setTokenChars(TokenCharacterKind[] tokenChars)"
  desc: "Set the tokenChars property: Character classes to keep in the tokens."
  returns:
    description: "the NGramTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.NGramTokenizer?alt=com.azure.search.documents.indexes.models.NGramTokenizer&text=NGramTokenizer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.setTokenChars(java.util.List<com.azure.search.documents.indexes.models.TokenCharacterKind>)"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.setTokenChars(List<TokenCharacterKind> tokenChars)"
  name: "setTokenChars(List<TokenCharacterKind> tokenChars)"
  nameWithType: "NGramTokenizer.setTokenChars(List<TokenCharacterKind> tokenChars)"
  summary: "Set the token<wbr>Chars property: Character classes to keep in the tokens."
  parameters:
  - description: "the tokenChars value to set."
    name: "tokenChars"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.search.documents.indexes.models.TokenCharacterKind?alt=com.azure.search.documents.indexes.models.TokenCharacterKind&text=TokenCharacterKind\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public NGramTokenizer setTokenChars(List<TokenCharacterKind> tokenChars)"
  desc: "Set the tokenChars property: Character classes to keep in the tokens."
  returns:
    description: "the NGramTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.NGramTokenizer?alt=com.azure.search.documents.indexes.models.NGramTokenizer&text=NGramTokenizer\" data-throw-if-not-resolved=\"False\" />"
type: "class"
desc: "Tokenizes the input into n-grams of the given size(s). This tokenizer is implemented using Apache Lucene."
metadata: {}
package: "com.azure.search.documents.indexes.models"
artifact: com.azure:azure-search-documents:11.4.13
