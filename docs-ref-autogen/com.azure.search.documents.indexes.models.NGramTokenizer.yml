### YamlMime:JavaType
uid: "com.azure.search.documents.indexes.models.NGramTokenizer"
fullName: "com.azure.search.documents.indexes.models.NGramTokenizer"
name: "NGramTokenizer"
nameWithType: "NGramTokenizer"
summary: "Tokenizes the input into n-grams of the given size(s)."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
- "<xref href=\"com.azure.search.documents.indexes.models.LexicalTokenizer?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedClassMethods:
- classRef: "<xref href=\"com.azure.search.documents.indexes.models.LexicalTokenizer?alt=com.azure.search.documents.indexes.models.LexicalTokenizer&text=LexicalTokenizer\" data-throw-if-not-resolved=\"False\" />"
  methodsRef:
  - "<xref href=\"com.azure.search.documents.indexes.models.LexicalTokenizer.getName()?alt=com.azure.search.documents.indexes.models.LexicalTokenizer.getName&text=getName\" data-throw-if-not-resolved=\"False\" />"
- classRef: "java.lang.<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html\">Object</a>"
  methodsRef:
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#clone--\">clone</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#equals-java.lang.Object-\">equals</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#finalize--\">finalize</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#getClass--\">getClass</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#hashCode--\">hashCode</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#notify--\">notify</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#notifyAll--\">notifyAll</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#toString--\">toString</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#wait--\">wait</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#wait-long-\">wait</a>"
  - "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#wait-long-int-\">wait</a>"
syntax: "public final class **NGramTokenizer**</br> extends <xref href=\"com.azure.search.documents.indexes.models.LexicalTokenizer?alt=com.azure.search.documents.indexes.models.LexicalTokenizer&text=LexicalTokenizer\" data-throw-if-not-resolved=\"False\" />"
constructors:
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.NGramTokenizer(java.lang.String)"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.NGramTokenizer(String name)"
  name: "NGramTokenizer(String name)"
  nameWithType: "NGramTokenizer.NGramTokenizer(String name)"
  summary: "Constructor of <xref uid=\"com.azure.search.documents.indexes.models.NGramTokenizer\" data-throw-if-not-resolved=\"false\" data-raw-source=\"NGramTokenizer\"></xref>."
  parameters:
  - description: "The name of the tokenizer. It must only contain letters, digits, spaces,\n dashes or underscores, can only start and end with alphanumeric\n characters, and is limited to 128 characters."
    name: "name"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/String.html\">String</a>"
  syntax: "public NGramTokenizer(String name)"
  desc: "Constructor of <xref uid=\"com.azure.search.documents.indexes.models.NGramTokenizer\" data-throw-if-not-resolved=\"false\" data-raw-source=\"NGramTokenizer\"></xref>."
methods:
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.getMaxGram()"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.getMaxGram()"
  name: "getMaxGram()"
  nameWithType: "NGramTokenizer.getMaxGram()"
  summary: "Get the max<wbr>Gram property: The maximum n-gram length."
  syntax: "public Integer getMaxGram()"
  desc: "Get the maxGram property: The maximum n-gram length. Default is 2. Maximum is 300."
  returns:
    description: "the maxGram value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Integer.html\">Integer</a>"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.getMinGram()"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.getMinGram()"
  name: "getMinGram()"
  nameWithType: "NGramTokenizer.getMinGram()"
  summary: "Get the min<wbr>Gram property: The minimum n-gram length."
  syntax: "public Integer getMinGram()"
  desc: "Get the minGram property: The minimum n-gram length. Default is 1. Maximum is 300. Must be less than the value of maxGram."
  returns:
    description: "the minGram value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Integer.html\">Integer</a>"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.getTokenChars()"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.getTokenChars()"
  name: "getTokenChars()"
  nameWithType: "NGramTokenizer.getTokenChars()"
  summary: "Get the token<wbr>Chars property: Character classes to keep in the tokens."
  syntax: "public List<TokenCharacterKind> getTokenChars()"
  desc: "Get the tokenChars property: Character classes to keep in the tokens."
  returns:
    description: "the tokenChars value."
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.search.documents.indexes.models.TokenCharacterKind?alt=com.azure.search.documents.indexes.models.TokenCharacterKind&text=TokenCharacterKind\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.setMaxGram(java.lang.Integer)"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.setMaxGram(Integer maxGram)"
  name: "setMaxGram(Integer maxGram)"
  nameWithType: "NGramTokenizer.setMaxGram(Integer maxGram)"
  summary: "Set the max<wbr>Gram property: The maximum n-gram length."
  parameters:
  - description: "the maxGram value to set."
    name: "maxGram"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Integer.html\">Integer</a>"
  syntax: "public NGramTokenizer setMaxGram(Integer maxGram)"
  desc: "Set the maxGram property: The maximum n-gram length. Default is 2. Maximum is 300."
  returns:
    description: "the NGramTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.NGramTokenizer?alt=com.azure.search.documents.indexes.models.NGramTokenizer&text=NGramTokenizer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.setMinGram(java.lang.Integer)"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.setMinGram(Integer minGram)"
  name: "setMinGram(Integer minGram)"
  nameWithType: "NGramTokenizer.setMinGram(Integer minGram)"
  summary: "Set the min<wbr>Gram property: The minimum n-gram length."
  parameters:
  - description: "the minGram value to set."
    name: "minGram"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Integer.html\">Integer</a>"
  syntax: "public NGramTokenizer setMinGram(Integer minGram)"
  desc: "Set the minGram property: The minimum n-gram length. Default is 1. Maximum is 300. Must be less than the value of maxGram."
  returns:
    description: "the NGramTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.NGramTokenizer?alt=com.azure.search.documents.indexes.models.NGramTokenizer&text=NGramTokenizer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.setTokenChars(com.azure.search.documents.indexes.models.TokenCharacterKind...)"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.setTokenChars(TokenCharacterKind[] tokenChars)"
  name: "setTokenChars(TokenCharacterKind[] tokenChars)"
  nameWithType: "NGramTokenizer.setTokenChars(TokenCharacterKind[] tokenChars)"
  summary: "Set the token<wbr>Chars property: Character classes to keep in the tokens."
  parameters:
  - description: "the tokenChars value to set."
    name: "tokenChars"
    type: "<xref href=\"com.azure.search.documents.indexes.models.TokenCharacterKind?alt=com.azure.search.documents.indexes.models.TokenCharacterKind&text=TokenCharacterKind\" data-throw-if-not-resolved=\"False\" />[]"
  syntax: "public NGramTokenizer setTokenChars(TokenCharacterKind[] tokenChars)"
  desc: "Set the tokenChars property: Character classes to keep in the tokens."
  returns:
    description: "the NGramTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.NGramTokenizer?alt=com.azure.search.documents.indexes.models.NGramTokenizer&text=NGramTokenizer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.search.documents.indexes.models.NGramTokenizer.setTokenChars(java.util.List<com.azure.search.documents.indexes.models.TokenCharacterKind>)"
  fullName: "com.azure.search.documents.indexes.models.NGramTokenizer.setTokenChars(List<TokenCharacterKind> tokenChars)"
  name: "setTokenChars(List<TokenCharacterKind> tokenChars)"
  nameWithType: "NGramTokenizer.setTokenChars(List<TokenCharacterKind> tokenChars)"
  summary: "Set the token<wbr>Chars property: Character classes to keep in the tokens."
  parameters:
  - description: "the tokenChars value to set."
    name: "tokenChars"
    type: "<a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/List.html\">List</a>&lt;<xref href=\"com.azure.search.documents.indexes.models.TokenCharacterKind?alt=com.azure.search.documents.indexes.models.TokenCharacterKind&text=TokenCharacterKind\" data-throw-if-not-resolved=\"False\" />&gt;"
  syntax: "public NGramTokenizer setTokenChars(List<TokenCharacterKind> tokenChars)"
  desc: "Set the tokenChars property: Character classes to keep in the tokens."
  returns:
    description: "the NGramTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.NGramTokenizer?alt=com.azure.search.documents.indexes.models.NGramTokenizer&text=NGramTokenizer\" data-throw-if-not-resolved=\"False\" />"
type: "class"
desc: "Tokenizes the input into n-grams of the given size(s). This tokenizer is implemented using Apache Lucene."
metadata: {}
package: "com.azure.search.documents.indexes.models"
artifact: com.azure:azure-search-documents:11.5.6
