### YamlMime:JavaType
inheritances:
- <xref href="java.lang.Object" data-throw-if-not-resolved="False"/>
- <xref href="AutoCloseable" data-throw-if-not-resolved="False"/>
methods:
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.close()
  name: close()
  nameWithType: AudioProcessingOptions.close()
  summary: <p>Explicitly frees any external resource attached to the object. </p>
  syntax: public void close()
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.close()
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.create(int audioProcessingFlags)
  name: create(int audioProcessingFlags)
  nameWithType: AudioProcessingOptions.create(int audioProcessingFlags)
  parameters:
  - description: <p>Specifies flags to control the audio processing performed by Speech SDK. It is bitwise OR of constants from AudioProcessingConstants class. </p>
    name: audioProcessingFlags
    type: <xref href="int?alt=int&text=int" data-throw-if-not-resolved="False"/>
  returns:
    description: <p>The audio processing options object being created. </p>
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions?alt=com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions&text=AudioProcessingOptions" data-throw-if-not-resolved="False"/>
  summary: <p>Creates an AudioProcessingOptions object with audio processing flags. </p>
  syntax: public static AudioProcessingOptions create(int audioProcessingFlags)
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.create(int)
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.create(int audioProcessingFlags, MicrophoneArrayGeometry microphoneArrayGeometry)
  name: create(int audioProcessingFlags, MicrophoneArrayGeometry microphoneArrayGeometry)
  nameWithType: AudioProcessingOptions.create(int audioProcessingFlags, MicrophoneArrayGeometry microphoneArrayGeometry)
  parameters:
  - description: <p>Specifies flags to control the audio processing performed by Speech SDK. It is bitwise OR of constants from AudioProcessingConstants class. </p>
    name: audioProcessingFlags
    type: <xref href="int?alt=int&text=int" data-throw-if-not-resolved="False"/>
  - description: <p>Specifies the microphone array geometry. </p>
    name: microphoneArrayGeometry
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.MicrophoneArrayGeometry?alt=com.microsoft.cognitiveservices.speech.audio.MicrophoneArrayGeometry&text=MicrophoneArrayGeometry" data-throw-if-not-resolved="False"/>
  returns:
    description: <p>The audio processing options object being created. </p>
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions?alt=com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions&text=AudioProcessingOptions" data-throw-if-not-resolved="False"/>
  summary: <p>Creates an AudioProcessingOptions object with audio processing flags and custom microphone array geometry. </p>
  syntax: public static AudioProcessingOptions create(int audioProcessingFlags, MicrophoneArrayGeometry microphoneArrayGeometry)
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.create(int,MicrophoneArrayGeometry)
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.create(int audioProcessingFlags, MicrophoneArrayGeometry microphoneArrayGeometry, SpeakerReferenceChannel speakerReferenceChannel)
  name: create(int audioProcessingFlags, MicrophoneArrayGeometry microphoneArrayGeometry, SpeakerReferenceChannel speakerReferenceChannel)
  nameWithType: AudioProcessingOptions.create(int audioProcessingFlags, MicrophoneArrayGeometry microphoneArrayGeometry, SpeakerReferenceChannel speakerReferenceChannel)
  parameters:
  - description: <p>Specifies flags to control the audio processing performed by Speech SDK. It is bitwise OR of constants from AudioProcessingConstants class. </p>
    name: audioProcessingFlags
    type: <xref href="int?alt=int&text=int" data-throw-if-not-resolved="False"/>
  - description: <p>Specifies the microphone array geometry. </p>
    name: microphoneArrayGeometry
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.MicrophoneArrayGeometry?alt=com.microsoft.cognitiveservices.speech.audio.MicrophoneArrayGeometry&text=MicrophoneArrayGeometry" data-throw-if-not-resolved="False"/>
  - description: <p>Specifies the speaker reference channel position in the input audio. </p>
    name: speakerReferenceChannel
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.SpeakerReferenceChannel?alt=com.microsoft.cognitiveservices.speech.audio.SpeakerReferenceChannel&text=SpeakerReferenceChannel" data-throw-if-not-resolved="False"/>
  returns:
    description: <p>The audio processing options object being created. </p>
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions?alt=com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions&text=AudioProcessingOptions" data-throw-if-not-resolved="False"/>
  summary: <p>Creates an AudioProcessingOptions object with audio processing flags, custom microphone array geometry and speaker reference channel position. </p>
  syntax: public static AudioProcessingOptions create(int audioProcessingFlags, MicrophoneArrayGeometry microphoneArrayGeometry, SpeakerReferenceChannel speakerReferenceChannel)
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.create(int,MicrophoneArrayGeometry,SpeakerReferenceChannel)
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.create(int audioProcessingFlags, PresetMicrophoneArrayGeometry microphoneArrayGeometry)
  name: create(int audioProcessingFlags, PresetMicrophoneArrayGeometry microphoneArrayGeometry)
  nameWithType: AudioProcessingOptions.create(int audioProcessingFlags, PresetMicrophoneArrayGeometry microphoneArrayGeometry)
  parameters:
  - description: <p>Specifies flags to control the audio processing performed by Speech SDK. It is bitwise OR of constants from AudioProcessingConstants class. </p>
    name: audioProcessingFlags
    type: <xref href="int?alt=int&text=int" data-throw-if-not-resolved="False"/>
  - description: <p>Specifies the type of microphone array geometry. </p>
    name: microphoneArrayGeometry
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.PresetMicrophoneArrayGeometry?alt=com.microsoft.cognitiveservices.speech.audio.PresetMicrophoneArrayGeometry&text=PresetMicrophoneArrayGeometry" data-throw-if-not-resolved="False"/>
  returns:
    description: <p>The audio processing options object being created. </p>
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions?alt=com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions&text=AudioProcessingOptions" data-throw-if-not-resolved="False"/>
  summary: <p>Creates an AudioProcessingOptions object with audio processing flags and preset microphone array geometry. </p>
  syntax: public static AudioProcessingOptions create(int audioProcessingFlags, PresetMicrophoneArrayGeometry microphoneArrayGeometry)
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.create(int,PresetMicrophoneArrayGeometry)
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.create(int audioProcessingFlags, PresetMicrophoneArrayGeometry microphoneArrayGeometry, SpeakerReferenceChannel speakerReferenceChannel)
  name: create(int audioProcessingFlags, PresetMicrophoneArrayGeometry microphoneArrayGeometry, SpeakerReferenceChannel speakerReferenceChannel)
  nameWithType: AudioProcessingOptions.create(int audioProcessingFlags, PresetMicrophoneArrayGeometry microphoneArrayGeometry, SpeakerReferenceChannel speakerReferenceChannel)
  parameters:
  - description: <p>Specifies flags to control the audio processing performed by Speech SDK. It is bitwise OR of constants from AudioProcessingConstants class. </p>
    name: audioProcessingFlags
    type: <xref href="int?alt=int&text=int" data-throw-if-not-resolved="False"/>
  - description: <p>Specifies the type of microphone array geometry. </p>
    name: microphoneArrayGeometry
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.PresetMicrophoneArrayGeometry?alt=com.microsoft.cognitiveservices.speech.audio.PresetMicrophoneArrayGeometry&text=PresetMicrophoneArrayGeometry" data-throw-if-not-resolved="False"/>
  - description: <p>Specifies the speaker reference channel position in the input audio. </p>
    name: speakerReferenceChannel
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.SpeakerReferenceChannel?alt=com.microsoft.cognitiveservices.speech.audio.SpeakerReferenceChannel&text=SpeakerReferenceChannel" data-throw-if-not-resolved="False"/>
  returns:
    description: <p>The audio processing options object being created. </p>
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions?alt=com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions&text=AudioProcessingOptions" data-throw-if-not-resolved="False"/>
  summary: <p>Creates an AudioProcessingOptions object with audio processing flags, preset microphone array geometry and speaker reference channel position. </p>
  syntax: public static AudioProcessingOptions create(int audioProcessingFlags, PresetMicrophoneArrayGeometry microphoneArrayGeometry, SpeakerReferenceChannel speakerReferenceChannel)
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.create(int,PresetMicrophoneArrayGeometry,SpeakerReferenceChannel)
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getAudioProcessingFlags()
  name: getAudioProcessingFlags()
  nameWithType: AudioProcessingOptions.getAudioProcessingFlags()
  returns:
    description: <p>Bitwise OR of flags from AudioProcessingConstants class indicating the audio processing performed by Speech SDK. </p>
    type: <xref href="int?alt=int&text=int" data-throw-if-not-resolved="False"/>
  summary: <p>Returns the type of audio processing performed by Speech SDK. </p>
  syntax: public int getAudioProcessingFlags()
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getAudioProcessingFlags()
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getBeamformingEndAngle()
  name: getBeamformingEndAngle()
  nameWithType: AudioProcessingOptions.getBeamformingEndAngle()
  returns:
    description: <p>Beamforming end angle. </p>
    type: <xref href="int?alt=int&text=int" data-throw-if-not-resolved="False"/>
  summary: <p>Returns the end angle used for beamforming. </p>
  syntax: public int getBeamformingEndAngle()
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getBeamformingEndAngle()
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getBeamformingStartAngle()
  name: getBeamformingStartAngle()
  nameWithType: AudioProcessingOptions.getBeamformingStartAngle()
  returns:
    description: <p>Beamforming start angle. </p>
    type: <xref href="int?alt=int&text=int" data-throw-if-not-resolved="False"/>
  summary: <p>Returns the start angle used for beamforming. </p>
  syntax: public int getBeamformingStartAngle()
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getBeamformingStartAngle()
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getMicrophoneArrayType()
  name: getMicrophoneArrayType()
  nameWithType: AudioProcessingOptions.getMicrophoneArrayType()
  returns:
    description: <p>Type of microphone array used for audio input. </p>
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.MicrophoneArrayType?alt=com.microsoft.cognitiveservices.speech.audio.MicrophoneArrayType&text=MicrophoneArrayType" data-throw-if-not-resolved="False"/>
  summary: <p>Returns the microphone array type of the microphone used for audio input. </p>
  syntax: public MicrophoneArrayType getMicrophoneArrayType()
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getMicrophoneArrayType()
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getMicrophoneCoordinates()
  name: getMicrophoneCoordinates()
  nameWithType: AudioProcessingOptions.getMicrophoneCoordinates()
  returns:
    description: <p>An array of MicrophoneCoordinates objects. </p>
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.MicrophoneCoordinates?alt=com.microsoft.cognitiveservices.speech.audio.MicrophoneCoordinates&text=MicrophoneCoordinates" data-throw-if-not-resolved="False"/> []
  summary: <p>Returns the coordinates of microphones in the microphone array used for audio input. </p>
  syntax: public MicrophoneCoordinates [] getMicrophoneCoordinates()
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getMicrophoneCoordinates()
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getPresetMicrophoneArrayGeometry()
  name: getPresetMicrophoneArrayGeometry()
  nameWithType: AudioProcessingOptions.getPresetMicrophoneArrayGeometry()
  returns:
    description: <p>Microphone array geometry of the microphone used for audio input. </p>
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.PresetMicrophoneArrayGeometry?alt=com.microsoft.cognitiveservices.speech.audio.PresetMicrophoneArrayGeometry&text=PresetMicrophoneArrayGeometry" data-throw-if-not-resolved="False"/>
  summary: <p>Returns the microphone array geometry of the microphone used for audio input. </p>
  syntax: public PresetMicrophoneArrayGeometry getPresetMicrophoneArrayGeometry()
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getPresetMicrophoneArrayGeometry()
- fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getSpeakerReferenceChannel()
  name: getSpeakerReferenceChannel()
  nameWithType: AudioProcessingOptions.getSpeakerReferenceChannel()
  returns:
    description: <p>Speaker reference channel position in the audio input. </p>
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.SpeakerReferenceChannel?alt=com.microsoft.cognitiveservices.speech.audio.SpeakerReferenceChannel&text=SpeakerReferenceChannel" data-throw-if-not-resolved="False"/>
  summary: <p>Returns the speaker reference channel position in the audio input. </p>
  syntax: public SpeakerReferenceChannel getSpeakerReferenceChannel()
  uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions.getSpeakerReferenceChannel()
nameWithType: AudioProcessingOptions
syntax: public class AudioProcessingOptions
type: class
uid: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions
fullName: com.microsoft.cognitiveservices.speech.audio.AudioProcessingOptions
name: AudioProcessingOptions
package: com.microsoft.cognitiveservices.speech.audio
summary: '<p>Represents audio processing options used with audio config class. Note: close() must be called in order to release underlying resources held by the object. </p>'
metadata: {}
