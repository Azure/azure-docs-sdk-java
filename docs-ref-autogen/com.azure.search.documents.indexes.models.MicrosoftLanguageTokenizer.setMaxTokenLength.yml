### YamlMime:JavaMember
uid: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.setMaxTokenLength*"
fullName: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.setMaxTokenLength"
name: "setMaxTokenLength"
nameWithType: "MicrosoftLanguageTokenizer.setMaxTokenLength"
members:
- uid: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.setMaxTokenLength(java.lang.Integer)"
  fullName: "com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer.setMaxTokenLength(Integer maxTokenLength)"
  name: "setMaxTokenLength(Integer maxTokenLength)"
  nameWithType: "MicrosoftLanguageTokenizer.setMaxTokenLength(Integer maxTokenLength)"
  summary: "Set the maxTokenLength property: The maximum token length. Tokens longer than the maximum length are split. Maximum token length that can be used is 300 characters. Tokens longer than 300 characters are first split into tokens of length 300 and then each of those tokens is split based on the max token length set. Default is 255."
  parameters:
  - description: "the maxTokenLength value to set."
    name: "maxTokenLength"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public MicrosoftLanguageTokenizer setMaxTokenLength(Integer maxTokenLength)"
  returns:
    description: "the MicrosoftLanguageTokenizer object itself."
    type: "<xref href=\"com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer?alt=com.azure.search.documents.indexes.models.MicrosoftLanguageTokenizer&text=MicrosoftLanguageTokenizer\" data-throw-if-not-resolved=\"False\" />"
type: "method"
metadata: {}
package: "com.azure.search.documents.indexes.models"
artifact: com.azure:azure-search-documents:11.1.3
