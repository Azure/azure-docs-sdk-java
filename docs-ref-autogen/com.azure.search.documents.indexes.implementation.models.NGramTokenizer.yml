### YamlMime:ManagedReference
items:
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
  id: NGramTokenizer
  artifact: com.azure:azure-search-documents:11.0.0
  parent: com.azure.search.documents.indexes.implementation.models
  children:
  - com.azure.search.documents.indexes.implementation.models.NGramTokenizer.NGramTokenizer(java.lang.String)
  - com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMaxGram()
  - com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMinGram()
  - com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getTokenChars()
  - com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMaxGram(java.lang.Integer)
  - com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMinGram(java.lang.Integer)
  - com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setTokenChars(java.util.List<com.azure.search.documents.indexes.implementation.models.TokenCharacterKind>)
  - com.azure.search.documents.indexes.implementation.models.NGramTokenizer.validate()
  langs:
  - java
  name: NGramTokenizer
  nameWithType: NGramTokenizer
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
  type: Class
  package: com.azure.search.documents.indexes.implementation.models
  summary: The NGramTokenizer model.
  syntax:
    content: public class NGramTokenizer extends LexicalTokenizer
  inheritance:
  - java.lang.Object
  - com.azure.search.documents.indexes.implementation.models.LexicalTokenizer
  inheritedMembers:
  - com.azure.search.documents.indexes.implementation.models.LexicalTokenizer.getName()
  - com.azure.search.documents.indexes.implementation.models.LexicalTokenizer.validate()
  - java.lang.Object.clone()
  - java.lang.Object.equals(java.lang.Object)
  - java.lang.Object.finalize()
  - java.lang.Object.getClass()
  - java.lang.Object.hashCode()
  - java.lang.Object.notify()
  - java.lang.Object.notifyAll()
  - java.lang.Object.toString()
  - java.lang.Object.wait()
  - java.lang.Object.wait(long)
  - java.lang.Object.wait(long,int)
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.NGramTokenizer(java.lang.String)
  id: NGramTokenizer(java.lang.String)
  artifact: com.azure:azure-search-documents:11.0.0
  parent: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
  langs:
  - java
  name: NGramTokenizer(String name)
  nameWithType: NGramTokenizer.NGramTokenizer(String name)
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.NGramTokenizer(String name)
  overload: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.NGramTokenizer*
  type: Constructor
  package: com.azure.search.documents.indexes.implementation.models
  summary: Creates an instance of NGramTokenizer class.
  syntax:
    content: public NGramTokenizer(String name)
    parameters:
    - id: name
      type: java.lang.String
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMaxGram()
  id: getMaxGram()
  artifact: com.azure:azure-search-documents:11.0.0
  parent: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
  langs:
  - java
  name: getMaxGram()
  nameWithType: NGramTokenizer.getMaxGram()
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMaxGram()
  overload: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMaxGram*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Get the maxGram property: The maximum n-gram length. Default is 2. Maximum is 300.'
  syntax:
    content: public Integer getMaxGram()
    return:
      type: java.lang.Integer
      description: the maxGram value.
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMinGram()
  id: getMinGram()
  artifact: com.azure:azure-search-documents:11.0.0
  parent: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
  langs:
  - java
  name: getMinGram()
  nameWithType: NGramTokenizer.getMinGram()
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMinGram()
  overload: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMinGram*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Get the minGram property: The minimum n-gram length. Default is 1. Maximum is 300. Must be less than the value of maxGram.'
  syntax:
    content: public Integer getMinGram()
    return:
      type: java.lang.Integer
      description: the minGram value.
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getTokenChars()
  id: getTokenChars()
  artifact: com.azure:azure-search-documents:11.0.0
  parent: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
  langs:
  - java
  name: getTokenChars()
  nameWithType: NGramTokenizer.getTokenChars()
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getTokenChars()
  overload: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getTokenChars*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Get the tokenChars property: Character classes to keep in the tokens.'
  syntax:
    content: public List<TokenCharacterKind> getTokenChars()
    return:
      type: java.util.List<com.azure.search.documents.indexes.implementation.models.TokenCharacterKind>
      description: the tokenChars value.
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMaxGram(java.lang.Integer)
  id: setMaxGram(java.lang.Integer)
  artifact: com.azure:azure-search-documents:11.0.0
  parent: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
  langs:
  - java
  name: setMaxGram(Integer maxGram)
  nameWithType: NGramTokenizer.setMaxGram(Integer maxGram)
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMaxGram(Integer maxGram)
  overload: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMaxGram*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Set the maxGram property: The maximum n-gram length. Default is 2. Maximum is 300.'
  syntax:
    content: public NGramTokenizer setMaxGram(Integer maxGram)
    parameters:
    - id: maxGram
      type: java.lang.Integer
      description: the maxGram value to set.
    return:
      type: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
      description: the NGramTokenizer object itself.
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMinGram(java.lang.Integer)
  id: setMinGram(java.lang.Integer)
  artifact: com.azure:azure-search-documents:11.0.0
  parent: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
  langs:
  - java
  name: setMinGram(Integer minGram)
  nameWithType: NGramTokenizer.setMinGram(Integer minGram)
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMinGram(Integer minGram)
  overload: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMinGram*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Set the minGram property: The minimum n-gram length. Default is 1. Maximum is 300. Must be less than the value of maxGram.'
  syntax:
    content: public NGramTokenizer setMinGram(Integer minGram)
    parameters:
    - id: minGram
      type: java.lang.Integer
      description: the minGram value to set.
    return:
      type: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
      description: the NGramTokenizer object itself.
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setTokenChars(java.util.List<com.azure.search.documents.indexes.implementation.models.TokenCharacterKind>)
  id: setTokenChars(java.util.List<com.azure.search.documents.indexes.implementation.models.TokenCharacterKind>)
  artifact: com.azure:azure-search-documents:11.0.0
  parent: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
  langs:
  - java
  name: setTokenChars(List<TokenCharacterKind> tokenChars)
  nameWithType: NGramTokenizer.setTokenChars(List<TokenCharacterKind> tokenChars)
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setTokenChars(List<TokenCharacterKind> tokenChars)
  overload: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setTokenChars*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: 'Set the tokenChars property: Character classes to keep in the tokens.'
  syntax:
    content: public NGramTokenizer setTokenChars(List<TokenCharacterKind> tokenChars)
    parameters:
    - id: tokenChars
      type: java.util.List<com.azure.search.documents.indexes.implementation.models.TokenCharacterKind>
      description: the tokenChars value to set.
    return:
      type: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
      description: the NGramTokenizer object itself.
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.validate()
  id: validate()
  artifact: com.azure:azure-search-documents:11.0.0
  parent: com.azure.search.documents.indexes.implementation.models.NGramTokenizer
  langs:
  - java
  name: validate()
  nameWithType: NGramTokenizer.validate()
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.validate()
  overload: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.validate*
  type: Method
  package: com.azure.search.documents.indexes.implementation.models
  summary: Validates the instance.
  syntax:
    content: public void validate()
references:
- uid: java.lang.String
  spec.java:
  - uid: java.lang.String
    name: String
    fullName: java.lang.String
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.NGramTokenizer*
  name: NGramTokenizer
  nameWithType: NGramTokenizer.NGramTokenizer
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.NGramTokenizer
  package: com.azure.search.documents.indexes.implementation.models
- uid: java.lang.Integer
  spec.java:
  - uid: java.lang.Integer
    name: Integer
    fullName: java.lang.Integer
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMinGram*
  name: getMinGram
  nameWithType: NGramTokenizer.getMinGram
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMinGram
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMinGram*
  name: setMinGram
  nameWithType: NGramTokenizer.setMinGram
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMinGram
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMaxGram*
  name: getMaxGram
  nameWithType: NGramTokenizer.getMaxGram
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getMaxGram
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMaxGram*
  name: setMaxGram
  nameWithType: NGramTokenizer.setMaxGram
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setMaxGram
  package: com.azure.search.documents.indexes.implementation.models
- uid: java.util.List<com.azure.search.documents.indexes.implementation.models.TokenCharacterKind>
  spec.java:
  - uid: java.util.List
    name: List
    fullName: java.util.List
  - name: <
    fullName: <
  - uid: com.azure.search.documents.indexes.implementation.models.TokenCharacterKind
    name: TokenCharacterKind
    fullName: com.azure.search.documents.indexes.implementation.models.TokenCharacterKind
  - name: '>'
    fullName: '>'
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getTokenChars*
  name: getTokenChars
  nameWithType: NGramTokenizer.getTokenChars
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.getTokenChars
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setTokenChars*
  name: setTokenChars
  nameWithType: NGramTokenizer.setTokenChars
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.setTokenChars
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.validate*
  name: validate
  nameWithType: NGramTokenizer.validate
  fullName: com.azure.search.documents.indexes.implementation.models.NGramTokenizer.validate
  package: com.azure.search.documents.indexes.implementation.models
- uid: com.azure.search.documents.indexes.implementation.models.LexicalTokenizer
  name: LexicalTokenizer
  nameWithType: LexicalTokenizer
  fullName: com.azure.search.documents.indexes.implementation.models.LexicalTokenizer
- uid: java.lang.Object.notify()
  name: Object.notify()
  nameWithType: Object.notify()
  fullName: java.lang.Object.notify()
- uid: java.lang.Object.wait()
  name: Object.wait()
  nameWithType: Object.wait()
  fullName: java.lang.Object.wait()
- uid: java.lang.Object.finalize()
  name: Object.finalize()
  nameWithType: Object.finalize()
  fullName: java.lang.Object.finalize()
- uid: com.azure.search.documents.indexes.implementation.models.LexicalTokenizer.validate()
  name: LexicalTokenizer.validate()
  nameWithType: LexicalTokenizer.validate()
  fullName: com.azure.search.documents.indexes.implementation.models.LexicalTokenizer.validate()
- uid: java.lang.Object.notifyAll()
  name: Object.notifyAll()
  nameWithType: Object.notifyAll()
  fullName: java.lang.Object.notifyAll()
- uid: java.lang.Object.clone()
  name: Object.clone()
  nameWithType: Object.clone()
  fullName: java.lang.Object.clone()
- uid: java.lang.Object.equals(java.lang.Object)
  name: Object.equals(Object)
  nameWithType: Object.equals(Object)
  fullName: java.lang.Object.equals(java.lang.Object)
- uid: java.lang.Object.toString()
  name: Object.toString()
  nameWithType: Object.toString()
  fullName: java.lang.Object.toString()
- uid: java.lang.Object.getClass()
  name: Object.getClass()
  nameWithType: Object.getClass()
  fullName: java.lang.Object.getClass()
- uid: java.lang.Object.wait(long)
  name: Object.wait(long)
  nameWithType: Object.wait(long)
  fullName: java.lang.Object.wait(long)
- uid: java.lang.Object.hashCode()
  name: Object.hashCode()
  nameWithType: Object.hashCode()
  fullName: java.lang.Object.hashCode()
- uid: java.lang.Object.wait(long,int)
  name: Object.wait(long,int)
  nameWithType: Object.wait(long,int)
  fullName: java.lang.Object.wait(long,int)
- uid: com.azure.search.documents.indexes.implementation.models.LexicalTokenizer.getName()
  name: LexicalTokenizer.getName()
  nameWithType: LexicalTokenizer.getName()
  fullName: com.azure.search.documents.indexes.implementation.models.LexicalTokenizer.getName()
- uid: java.util.List
  name: List
  nameWithType: List
  fullName: java.util.List
- uid: com.azure.search.documents.indexes.implementation.models.TokenCharacterKind
  name: TokenCharacterKind
  nameWithType: TokenCharacterKind
  fullName: com.azure.search.documents.indexes.implementation.models.TokenCharacterKind
