### YamlMime:JavaMember
uid: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.uploadWithResponse*"
fullName: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.uploadWithResponse"
name: "uploadWithResponse"
nameWithType: "DataLakeFileAsyncClient.uploadWithResponse"
members:
- uid: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.uploadWithResponse(com.azure.storage.file.datalake.options.FileParallelUploadOptions)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.uploadWithResponse(FileParallelUploadOptions options)"
  name: "uploadWithResponse(FileParallelUploadOptions options)"
  nameWithType: "DataLakeFileAsyncClient.uploadWithResponse(FileParallelUploadOptions options)"
  summary: "Creates a new file.\n\nTo avoid overwriting, pass \"\\*\" to <xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions.setIfNoneMatch(java.lang.String)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions#setIfNoneMatch(String)\"></xref>.\n\n**Code Samples**\n\n```java\nPathHttpHeaders headers = new PathHttpHeaders()\n     .setContentMd5(\"data\".getBytes(StandardCharsets.UTF_8))\n     .setContentLanguage(\"en-US\")\n     .setContentType(\"binary\");\n \n Map<String, String> metadata = Collections.singletonMap(\"metadata\", \"value\");\n DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n Long blockSize = 100L * 1024L * 1024L; // 100 MB;\n ParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions().setBlockSizeLong(blockSize);\n \n client.uploadWithResponse(new FileParallelUploadOptions(data)\n     .setParallelTransferOptions(parallelTransferOptions).setHeaders(headers)\n     .setMetadata(metadata).setRequestConditions(requestConditions)\n     .setPermissions(\"permissions\").setUmask(\"umask\"))\n     .subscribe(response -> System.out.println(\"Uploaded file %n\"));\n```\n\n**Using Progress Reporting**\n\n```java\nPathHttpHeaders httpHeaders = new PathHttpHeaders()\n     .setContentMd5(\"data\".getBytes(StandardCharsets.UTF_8))\n     .setContentLanguage(\"en-US\")\n     .setContentType(\"binary\");\n \n Map<String, String> metadataMap = Collections.singletonMap(\"metadata\", \"value\");\n DataLakeRequestConditions conditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n ParallelTransferOptions pto = new ParallelTransferOptions()\n     .setBlockSizeLong(blockSize)\n     .setProgressReceiver(bytesTransferred -> System.out.printf(\"Upload progress: %s bytes sent\", bytesTransferred));\n \n client.uploadWithResponse(new FileParallelUploadOptions(data)\n     .setParallelTransferOptions(parallelTransferOptions).setHeaders(headers)\n     .setMetadata(metadata).setRequestConditions(requestConditions)\n     .setPermissions(\"permissions\").setUmask(\"umask\"))\n     .subscribe(response -> System.out.println(\"Uploaded file %n\"));\n```"
  parameters:
  - description: "<xref uid=\"com.azure.storage.file.datalake.options.FileParallelUploadOptions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"FileParallelUploadOptions\"></xref>"
    name: "options"
    type: "<xref href=\"com.azure.storage.file.datalake.options.FileParallelUploadOptions?alt=com.azure.storage.file.datalake.options.FileParallelUploadOptions&text=FileParallelUploadOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<PathInfo>> uploadWithResponse(FileParallelUploadOptions options)"
  returns:
    description: "A reactive response containing the information of the uploaded file."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.PathInfo?alt=com.azure.storage.file.datalake.models.PathInfo&text=PathInfo\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.uploadWithResponse(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.common.ParallelTransferOptions,com.azure.storage.file.datalake.models.PathHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.file.datalake.models.DataLakeRequestConditions)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions)"
  name: "uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions)"
  nameWithType: "DataLakeFileAsyncClient.uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions)"
  summary: "Creates a new file.\n\nTo avoid overwriting, pass \"\\*\" to <xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions.setIfNoneMatch(java.lang.String)\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions#setIfNoneMatch(String)\"></xref>.\n\n**Code Samples**\n\n```java\nPathHttpHeaders headers = new PathHttpHeaders()\n     .setContentMd5(\"data\".getBytes(StandardCharsets.UTF_8))\n     .setContentLanguage(\"en-US\")\n     .setContentType(\"binary\");\n \n Map<String, String> metadata = Collections.singletonMap(\"metadata\", \"value\");\n DataLakeRequestConditions requestConditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n Long blockSize = 100L * 1024L * 1024L; // 100 MB;\n ParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions().setBlockSizeLong(blockSize);\n \n client.uploadWithResponse(data, parallelTransferOptions, headers, metadata, requestConditions)\n     .subscribe(response -> System.out.println(\"Uploaded file %n\"));\n```\n\n**Using Progress Reporting**\n\n```java\nPathHttpHeaders httpHeaders = new PathHttpHeaders()\n     .setContentMd5(\"data\".getBytes(StandardCharsets.UTF_8))\n     .setContentLanguage(\"en-US\")\n     .setContentType(\"binary\");\n \n Map<String, String> metadataMap = Collections.singletonMap(\"metadata\", \"value\");\n DataLakeRequestConditions conditions = new DataLakeRequestConditions()\n     .setLeaseId(leaseId)\n     .setIfUnmodifiedSince(OffsetDateTime.now().minusDays(3));\n ParallelTransferOptions pto = new ParallelTransferOptions()\n     .setBlockSizeLong(blockSize)\n     .setProgressReceiver(bytesTransferred -> System.out.printf(\"Upload progress: %s bytes sent\", bytesTransferred));\n \n client.uploadWithResponse(data, pto, httpHeaders, metadataMap, conditions)\n     .subscribe(response -> System.out.println(\"Uploaded file %n\"));\n```"
  parameters:
  - description: "The data to write to the file. Unlike other upload methods, this method does not require that the\n <code>Flux</code> be replayable. In other words, it does not have to support multiple subscribers and is not expected\n to produce the same values across subscriptions."
    name: "data"
    type: "<xref href=\"reactor.core.publisher.Flux?alt=reactor.core.publisher.Flux&text=Flux\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.nio.ByteBuffer?alt=java.nio.ByteBuffer&text=ByteBuffer\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "<xref uid=\"com.azure.storage.common.ParallelTransferOptions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"ParallelTransferOptions\"></xref> used to configure buffered uploading."
    name: "parallelTransferOptions"
    type: "<xref href=\"com.azure.storage.common.ParallelTransferOptions?alt=com.azure.storage.common.ParallelTransferOptions&text=ParallelTransferOptions\" data-throw-if-not-resolved=\"False\" />"
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.PathHttpHeaders\" data-throw-if-not-resolved=\"false\" data-raw-source=\"PathHttpHeaders\"></xref>"
    name: "headers"
    type: "<xref href=\"com.azure.storage.file.datalake.models.PathHttpHeaders?alt=com.azure.storage.file.datalake.models.PathHttpHeaders&text=PathHttpHeaders\" data-throw-if-not-resolved=\"False\" />"
  - description: "Metadata to associate with the resource. If there is leading or trailing whitespace in any\n metadata key or value, it must be removed or encoded."
    name: "metadata"
    type: "<xref href=\"java.util.Map?alt=java.util.Map&text=Map\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />,<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions\"></xref>"
    name: "requestConditions"
    type: "<xref href=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions?alt=com.azure.storage.file.datalake.models.DataLakeRequestConditions&text=DataLakeRequestConditions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<Response<PathInfo>> uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, PathHttpHeaders headers, Map<String,String> metadata, DataLakeRequestConditions requestConditions)"
  returns:
    description: "A reactive response containing the information of the uploaded file."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.PathInfo?alt=com.azure.storage.file.datalake.models.PathInfo&text=PathInfo\" data-throw-if-not-resolved=\"False\" />&gt;&gt;"
type: "method"
metadata: {}
package: "com.azure.storage.file.datalake"
artifact: com.azure:azure-storage-file-datalake:12.4.0
