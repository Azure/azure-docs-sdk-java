### YamlMime:ManagedReference
items:
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinition
  id: FacesDetectWithStreamDefinition
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  href: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinition.yml
  langs:
  - java
  name: Faces.FacesDetectWithStreamDefinition
  nameWithType: Faces.FacesDetectWithStreamDefinition
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinition
  type: Interface
  source:
    remote:
      path: sdk/cognitiveservices/ms-azure-cs-faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
      branch: master
      repo: https://github.com/Azure/azure-sdk-for-java
    path: sdk/cognitiveservices/ms-azure-cs-faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
    startLine: 545
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
  summary: "<p>The entirety of detectWithStream definition. </p>"
  syntax:
    content: public interface FacesDetectWithStreamDefinition extends Faces.FacesDetectWithStreamDefinitionStages.WithImage,Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  inheritedMembers:
  - com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.execute()
  - com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.executeAsync()
  - com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithImage.withImage(byte [])
  - com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceAttributes(List<FaceAttributeType>)
  - com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceId(Boolean)
  - com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceLandmarks(Boolean)
references:
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.execute()
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  href: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.yml
  name: execute()
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithExecute.execute()
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.execute()
  type: Method
  summary: "<p>Execute the request.</p>\r\n<p></p>"
  syntax:
    content: public List<DetectedFace> execute()
    return:
      type: 5618da2dcom.microsoft.azure.cognitiveservices.vision.faceapi.models.DetectedFacea08ddfce
      description: <p>the List&lt;DetectedFace&gt; object if successful. </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.executeAsync()
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  href: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.yml
  name: executeAsync()
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithExecute.executeAsync()
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.executeAsync()
  type: Method
  summary: "<p>Execute the request asynchronously.</p>\r\n<p></p>"
  syntax:
    content: public Observable<List<DetectedFace>> executeAsync()
    return:
      type: 39a50407com.microsoft.azure.cognitiveservices.vision.faceapi.models.DetectedFacee7daa122
      description: <p>the observable to the List&lt;DetectedFace&gt; object </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithImage.withImage(byte [])
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithImage
  href: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithImage.yml
  name: withImage(byte[] image)
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithImage.withImage(byte[] image)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithImage.withImage(byte[] image)
  type: Method
  summary: "<p>An image stream.</p>\r\n<p></p>"
  syntax:
    content: public FacesDetectWithStreamDefinitionStages.WithExecute withImage(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
    return:
      type: 1f48b658
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceAttributes(List<FaceAttributeType>)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions
  href: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.yml
  name: withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  type: Method
  summary: "<p>Analyze and return the one or more specified face attributes in the comma-separated string like \"returnFaceAttributes=age,gender\". Supported face attributes include age, gender, headPose, smile, facialHair, glasses and emotion. Note that each face attribute analysis has additional computational and time cost.</p>\r\n<p></p>"
  syntax:
    content: public FacesDetectWithStreamDefinitionStages.WithExecute withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
    parameters:
    - id: returnFaceAttributes
      type: 5618da2dcom.microsoft.azure.cognitiveservices.vision.faceapi.models.FaceAttributeTypea08ddfce
    return:
      type: 1f48b658
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceId(Boolean)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions
  href: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.yml
  name: withReturnFaceId(Boolean returnFaceId)
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceId(Boolean returnFaceId)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceId(Boolean returnFaceId)
  type: Method
  summary: "<p>A value indicating whether the operation should return faceIds of detected faces.</p>\r\n<p></p>"
  syntax:
    content: public FacesDetectWithStreamDefinitionStages.WithExecute withReturnFaceId(Boolean returnFaceId)
    parameters:
    - id: returnFaceId
      type: 866c2227
    return:
      type: 1f48b658
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceLandmarks(Boolean)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions
  href: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.yml
  name: withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  type: Method
  summary: "<p>A value indicating whether the operation should return landmarks of the detected faces.</p>\r\n<p></p>"
  syntax:
    content: public FacesDetectWithStreamDefinitionStages.WithExecute withReturnFaceLandmarks(Boolean returnFaceLandmarks)
    parameters:
    - id: returnFaceLandmarks
      type: 866c2227
    return:
      type: 1f48b658
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithImage
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  href: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithImage.yml
  name: Faces.FacesDetectWithStreamDefinitionStages.WithImage
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithImage
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithImage
  type: Interface
  summary: "<p>The stage of the definition to be specify image. </p>"
  syntax:
    content: public interface WithImage
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  href: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.yml
  name: Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  type: Interface
  summary: "<p>The last stage of the definition which will make the operation call. </p>"
  syntax:
    content: public interface WithExecute
