### YamlMime:JavaPackage
uid: "com.azure.ai.formrecognizer.documentanalysis"
fullName: "com.azure.ai.formrecognizer.documentanalysis"
name: "com.azure.ai.formrecognizer.documentanalysis"
summary: "[ Azure Form Recognizer][Azure Form Recognizer] is a cloud-based service provided by Microsoft Azure that utilizes machine learning to extract information from various types of documents.\n\n\n[Azure Form Recognizer]: https://aka.ms/form-recognizer-3.0.0"
classes:
- "com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisAsyncClient"
- "com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisClient"
- "com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisClientBuilder"
enums:
- "com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisServiceVersion"
desc: "[ Azure Form Recognizer][Azure Form Recognizer] is a cloud-based service provided by Microsoft Azure that utilizes machine learning to extract information from various types of documents. Form Recognizer applies machine-learning-based optical character recognition (OCR) and document understanding technologies to classify documents, extract text, tables, structure, and key-value pairs from documents. You can also label and train custom models to automate data extraction from structured, semi-structured, and unstructured documents.\n\nThe service uses advanced optical character recognition (OCR) technology to extract text and key-value pairs from documents, enabling organizations to automate data entry tasks that would otherwise require manual effort. It can recognize and extract information like dates, addresses, invoice numbers, line items, and other relevant data points from documents.\n\nThe Azure Form Recognizer client library allows Java developers to interact with the Azure Form Recognizer service. It provides a set of classes and methods that abstract the underlying RESTful API of Azure Form Recognizer, making it easier to integrate the service into Java applications.\n\nThe Azure Form Recognizer client library provides the following capabilities:\n\n1.  Document Analysis: It allows you to submit documents for analysis to detect and extract information like text, key-value pairs, tables, language, and fields. You can analyze both structured and unstructured documents.\n2.  Model Management: It enables you to manage models created in your account by building, listing, deleting, and see the limit of custom models your account.\n3.  Analysis Results: It provides methods to retrieve and interpret analysis results, including extracted text and field values, confidence scores, and document layout information.\n4.  Polling and Callbacks: It includes mechanisms for polling the service to check the status of an analysis operation or registering callbacks to receive notifications when the analysis is complete.\n\n## Getting Started ##\n\nThe Azure Form Recognizer library provides analysis clients like <xref uid=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisAsyncClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisAsyncClient\"></xref> and <xref uid=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisClient\"></xref> to connect to the Form Recognizer Azure Cognitive Service to analyze information from documents and extract it into structured data. It also provides administration clients like <xref uid=\"com.azure.ai.formrecognizer.documentanalysis.administration.DocumentModelAdministrationClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.azure.ai.formrecognizer.documentanalysis.administration.DocumentModelAdministrationClient\"></xref> and <xref uid=\"com.azure.ai.formrecognizer.documentanalysis.administration.DocumentModelAdministrationAsyncClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.azure.ai.formrecognizer.documentanalysis.administration.DocumentModelAdministrationAsyncClient\"></xref> to build and manage models from custom documents.\n\n**Note:**This client only supports <xref uid=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisServiceVersion.V2022_08_31\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisServiceVersion#V2022_08_31\"></xref> and newer. To use an older service version, <xref uid=\"com.azure.ai.formrecognizer.FormRecognizerClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.azure.ai.formrecognizer.FormRecognizerClient\"></xref> and <xref uid=\"com.azure.ai.formrecognizer.training.FormTrainingClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.azure.ai.formrecognizer.training.FormTrainingClient\"></xref>.\n\nService clients are the point of interaction for developers to use Azure Form Recognizer. <xref uid=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisClient\"></xref> is the synchronous service client and <xref uid=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisAsyncClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisAsyncClient\"></xref> is the asynchronous service client. The examples shown in this document use a credential object named DefaultAzureCredential for authentication, which is appropriate for most scenarios, including local development and production environments. Additionally, we recommend using [managed identity][] for authentication in production environments. You can find more information on different ways of authenticating and their corresponding credential types in the [Azure Identity documentation\"][Azure Identity documentation].\n\n**Sample: Construct a DocumentAnalysisClient with DefaultAzureCredential**\n\nThe following code sample demonstrates the creation of a <xref uid=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisClient\"></xref>, using the \\`DefaultAzureCredentialBuilder\\` to configure it.\n\n```java\nDocumentAnalysisClient documentAnalysisClient = new DocumentAnalysisClientBuilder()\n     .endpoint(\"{endpoint}\")\n     .credential(new DefaultAzureCredentialBuilder().build())\n     .buildClient();\n```\n\nFurther, see the code sample below to use <xref uid=\"com.azure.core.credential.AzureKeyCredential\" data-throw-if-not-resolved=\"false\" data-raw-source=\"AzureKeyCredential\"></xref> for client creation.\n\n```java\nDocumentAnalysisClient documentAnalysisClient = new DocumentAnalysisClientBuilder()\n     .credential(new AzureKeyCredential(\"{key}\"))\n     .endpoint(\"{endpoint}\")\n     .buildClient();\n```\n\nLet's take a look at the analysis client scenarios and their respective usage below.\n\n\n--------------------\n\n## Analyzing documents with prebuilt models ##\n\n[Form Recognizer models][] and their associated output to help you choose the best model to address your document scenario needs.\n\nYou can use a prebuilt document analysis or domain specific model or build a custom model tailored to your specific business needs and use cases.\n\n**Sample: Analyze with the prebuilt read model from url source**\n\nThe following code sample demonstrates how to analyze textual elements, such as words, lines, styles, and text language information from documents using the prebuilt read model.\n\n```java\nString documentUrl = \"documentUrl\";\n\n SyncPoller<OperationResult, AnalyzeResult> analyzeResultPoller =\n     documentAnalysisClient.beginAnalyzeDocumentFromUrl(\"prebuilt-read\", documentUrl);\n AnalyzeResult analyzeResult = analyzeResultPoller.getFinalResult();\n\n System.out.println(\"Detected Languages: \");\n for (DocumentLanguage language : analyzeResult.getLanguages()) {\n     System.out.printf(\"Found language with locale %s and confidence %.2f\",\n         language.getLocale(),\n         language.getConfidence());\n }\n\n System.out.println(\"Detected Styles: \");\n for (DocumentStyle style: analyzeResult.getStyles()) {\n     if (style.isHandwritten()) {\n         System.out.printf(\"Found handwritten content %s with confidence %.2f\",\n             style.getSpans().stream().map(span -> analyzeResult.getContent()\n                 .substring(span.getOffset(), span.getLength())),\n             style.getConfidence());\n     }\n }\n\n // pages\n analyzeResult.getPages().forEach(documentPage -> {\n     System.out.printf(\"Page has width: %.2f and height: %.2f, measured with unit: %s%n\",\n         documentPage.getWidth(),\n         documentPage.getHeight(),\n         documentPage.getUnit());\n\n     // lines\n     documentPage.getLines().forEach(documentLine ->\n         System.out.printf(\"Line '%s' is within a bounding polygon %s.%n\",\n             documentLine.getContent(),\n             documentLine.getBoundingPolygon().stream().map(point -> String.format(\"[%.2f, %.2f]\", point.getX(),\n                 point.getY())).collect(Collectors.joining(\", \"))));\n });\n```\n\nYou can also analyze a local file with prebuilt models using the <xref uid=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisClient\" data-throw-if-not-resolved=\"false\" data-raw-source=\"com.azure.ai.formrecognizer.documentanalysis.DocumentAnalysisClient\"></xref>.\n\n**Sample: Analyze local file with the prebuilt read model**\n\nThe following code sample demonstrates how to analyze a local file with \"prebuilt-read\" analysis model.\n\n```java\nFile document = new File(\"{local/file_path/fileName.jpg}\");\n SyncPoller<OperationResult, AnalyzeResult> analyzeResultPoller =\n     documentAnalysisClient.beginAnalyzeDocument(\"prebuilt-read\",\n         BinaryData.fromFile(document.toPath(),\n             (int) document.length()));\n AnalyzeResult analyzeResult = analyzeResultPoller.getFinalResult();\n\n System.out.println(\"Detected Languages: \");\n for (DocumentLanguage language : analyzeResult.getLanguages()) {\n     System.out.printf(\"Found language with locale %s and confidence %.2f\",\n         language.getLocale(),\n         language.getConfidence());\n }\n\n System.out.println(\"Detected Styles: \");\n for (DocumentStyle style: analyzeResult.getStyles()) {\n     if (style.isHandwritten()) {\n         System.out.printf(\"Found handwritten content %s with confidence %.2f\",\n             style.getSpans().stream().map(span -> analyzeResult.getContent()\n                 .substring(span.getOffset(), span.getLength())),\n             style.getConfidence());\n     }\n }\n\n // pages\n analyzeResult.getPages().forEach(documentPage -> {\n     System.out.printf(\"Page has width: %.2f and height: %.2f, measured with unit: %s%n\",\n         documentPage.getWidth(),\n         documentPage.getHeight(),\n         documentPage.getUnit());\n\n     // lines\n     documentPage.getLines().forEach(documentLine ->\n         System.out.printf(\"Line '%s' is within a bounding polygon %s.%n\",\n             documentLine.getContent(),\n             documentLine.getBoundingPolygon().stream().map(point -> String.format(\"[%.2f, %.2f]\", point.getX(),\n                 point.getY())).collect(Collectors.joining(\", \"))));\n });\n```\n\nFor more information on which supported model you should use refer to [models usage documentation][].\n\n\n--------------------\n\n## Analyzing documents with custom models ##\n\nCustom models are trained with your own data, so they're tailored to your documents. For more information on how to build your own custom model, see [build a model][].\n\n**Sample: Analyze documents using custom trained model**\n\nThis sample demonstrates how to analyze text, field values, selection marks, and table data from custom documents.\n\n```java\nString blobContainerUrl = \"{SAS_URL_of_your_container_in_blob_storage}\";\n // The shared access signature (SAS) Url of your Azure Blob Storage container with your custom documents.\n String prefix = \"{blob_name_prefix}}\";\n // Build custom document analysis model\n SyncPoller<OperationResult, DocumentModelDetails> buildOperationPoller =\n     documentModelAdminClient.beginBuildDocumentModel(blobContainerUrl,\n         DocumentModelBuildMode.TEMPLATE,\n         prefix,\n         new BuildDocumentModelOptions().setModelId(\"my-custom-built-model\").setDescription(\"model desc\"),\n         Context.NONE);\n\n DocumentModelDetails customBuildModel = buildOperationPoller.getFinalResult();\n\n // analyze using custom-built model\n String modelId = customBuildModel.getModelId();\n String documentUrl = \"documentUrl\";\n SyncPoller<OperationResult, AnalyzeResult> analyzeDocumentPoller =\n     documentAnalysisClient.beginAnalyzeDocumentFromUrl(modelId, documentUrl);\n\n AnalyzeResult analyzeResult = analyzeDocumentPoller.getFinalResult();\n\n for (int i = 0; i < analyzeResult.getDocuments().size(); i++) {\n     final AnalyzedDocument analyzedDocument = analyzeResult.getDocuments().get(i);\n     System.out.printf(\"----------- Analyzing custom document %d -----------%n\", i);\n     System.out.printf(\"Analyzed document has doc type %s with confidence : %.2f%n\",\n         analyzedDocument.getDocType(), analyzedDocument.getConfidence());\n     analyzedDocument.getFields().forEach((key, documentField) -> {\n         System.out.printf(\"Document Field content: %s%n\", documentField.getContent());\n         System.out.printf(\"Document Field confidence: %.2f%n\", documentField.getConfidence());\n         System.out.printf(\"Document Field Type: %s%n\", documentField.getType());\n         System.out.printf(\"Document Field found within bounding region: %s%n\",\n             documentField.getBoundingRegions().toString());\n     });\n }\n\n analyzeResult.getPages().forEach(documentPage -> {\n     System.out.printf(\"Page has width: %.2f and height: %.2f, measured with unit: %s%n\",\n         documentPage.getWidth(),\n         documentPage.getHeight(),\n         documentPage.getUnit());\n\n     // lines\n     documentPage.getLines().forEach(documentLine ->\n         System.out.printf(\"Line '%s' is within a bounding box %s.%n\",\n             documentLine.getContent(),\n             documentLine.getBoundingPolygon().toString()));\n\n     // words\n     documentPage.getWords().forEach(documentWord ->\n         System.out.printf(\"Word '%s' has a confidence score of %.2f.%n\",\n             documentWord.getContent(),\n             documentWord.getConfidence()));\n });\n\n // tables\n List<DocumentTable> tables = analyzeResult.getTables();\n for (int i = 0; i < tables.size(); i++) {\n     DocumentTable documentTable = tables.get(i);\n     System.out.printf(\"Table %d has %d rows and %d columns.%n\", i, documentTable.getRowCount(),\n         documentTable.getColumnCount());\n     documentTable.getCells().forEach(documentTableCell -> {\n         System.out.printf(\"Cell '%s', has row index %d and column index %d.%n\",\n             documentTableCell.getContent(),\n             documentTableCell.getRowIndex(), documentTableCell.getColumnIndex());\n     });\n     System.out.println();\n }\n```\n\n\n[Azure Form Recognizer]: https://aka.ms/form-recognizer-3.0.0\n[managed identity]: https://learn.microsoft.com/azure/active-directory/managed-identities-azure-resources/\n[Azure Identity documentation]: https://learn.microsoft.com/java/api/overview/azure/identity-readme\n[Form Recognizer models]: https://learn.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/concept-model-overview?view=form-recog-3.0.0#model-overview\n[models usage documentation]: https://learn.microsoft.com/azure/applied-ai-services/form-recognizer/overview?view=form-recog-3.0.0#which-form-recognizer-model-should-i-use\n[build a model]: https://github.com/Azure/azure-sdk-for-java/blob/main/sdk/formrecognizer/azure-ai-formrecognizer/src/samples/java/com/azure/ai/formrecognizer/administration/BuildDocumentModel.java"
metadata: {}
package: "com.azure.ai.formrecognizer.documentanalysis"
artifact: com.azure:azure-ai-formrecognizer:4.1.13
