### YamlMime:JavaType
uid: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions"
fullName: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions"
name: "DataLakeFileInputStreamOptions"
nameWithType: "DataLakeFileInputStreamOptions"
summary: "Extended options that may be passed when opening a blob input stream."
inheritances:
- "<xref href=\"java.lang.Object?displayProperty=fullName\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public final class DataLakeFileInputStreamOptions"
constructors:
- uid: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.DataLakeFileInputStreamOptions()"
  fullName: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.DataLakeFileInputStreamOptions()"
  name: "DataLakeFileInputStreamOptions()"
  nameWithType: "DataLakeFileInputStreamOptions.DataLakeFileInputStreamOptions()"
  syntax: "public DataLakeFileInputStreamOptions()"
methods:
- uid: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.getBlockSize()"
  fullName: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.getBlockSize()"
  name: "getBlockSize()"
  nameWithType: "DataLakeFileInputStreamOptions.getBlockSize()"
  syntax: "public Integer getBlockSize()"
  returns:
    description: "The size of each data chunk returned from the service. If block size is large, input stream will make\n fewer network calls, but each individual call will send more data and will therefore take longer.\n The default value is 4 MB."
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.getConsistentReadControl()"
  fullName: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.getConsistentReadControl()"
  name: "getConsistentReadControl()"
  nameWithType: "DataLakeFileInputStreamOptions.getConsistentReadControl()"
  syntax: "public ConsistentReadControl getConsistentReadControl()"
  returns:
    description: "<xref uid=\"com.azure.storage.file.datalake.models.ConsistentReadControl\" data-throw-if-not-resolved=\"false\" data-raw-source=\"ConsistentReadControl\"></xref> Default is E-Tag."
    type: "<xref href=\"com.azure.storage.file.datalake.models.ConsistentReadControl?alt=com.azure.storage.file.datalake.models.ConsistentReadControl&text=ConsistentReadControl\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.getRange()"
  fullName: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.getRange()"
  name: "getRange()"
  nameWithType: "DataLakeFileInputStreamOptions.getRange()"
  syntax: "public FileRange getRange()"
  returns:
    description: "<xref uid=\"com.azure.storage.file.datalake.models.FileRange\" data-throw-if-not-resolved=\"false\" data-raw-source=\"FileRange\"></xref>"
    type: "<xref href=\"com.azure.storage.file.datalake.models.FileRange?alt=com.azure.storage.file.datalake.models.FileRange&text=FileRange\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.getRequestConditions()"
  fullName: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.getRequestConditions()"
  name: "getRequestConditions()"
  nameWithType: "DataLakeFileInputStreamOptions.getRequestConditions()"
  syntax: "public DataLakeRequestConditions getRequestConditions()"
  returns:
    description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions\"></xref>"
    type: "<xref href=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions?alt=com.azure.storage.file.datalake.models.DataLakeRequestConditions&text=DataLakeRequestConditions\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.setBlockSize(java.lang.Integer)"
  fullName: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.setBlockSize(Integer blockSize)"
  name: "setBlockSize(Integer blockSize)"
  nameWithType: "DataLakeFileInputStreamOptions.setBlockSize(Integer blockSize)"
  parameters:
  - description: "The size of each data chunk returned from the service. If block size is large, input stream\n will make fewer network calls, but each individual call will send more data and will therefore take longer.\n The default value is 4 MB."
    name: "blockSize"
    type: "<xref href=\"java.lang.Integer?alt=java.lang.Integer&text=Integer\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DataLakeFileInputStreamOptions setBlockSize(Integer blockSize)"
  returns:
    description: "The updated options."
    type: "<xref href=\"com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions?alt=com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions&text=DataLakeFileInputStreamOptions\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.setConsistentReadControl(com.azure.storage.file.datalake.models.ConsistentReadControl)"
  fullName: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.setConsistentReadControl(ConsistentReadControl consistentReadControl)"
  name: "setConsistentReadControl(ConsistentReadControl consistentReadControl)"
  nameWithType: "DataLakeFileInputStreamOptions.setConsistentReadControl(ConsistentReadControl consistentReadControl)"
  parameters:
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.ConsistentReadControl\" data-throw-if-not-resolved=\"false\" data-raw-source=\"ConsistentReadControl\"></xref> Default is E-Tag."
    name: "consistentReadControl"
    type: "<xref href=\"com.azure.storage.file.datalake.models.ConsistentReadControl?alt=com.azure.storage.file.datalake.models.ConsistentReadControl&text=ConsistentReadControl\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DataLakeFileInputStreamOptions setConsistentReadControl(ConsistentReadControl consistentReadControl)"
  returns:
    description: "The updated options."
    type: "<xref href=\"com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions?alt=com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions&text=DataLakeFileInputStreamOptions\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.setRange(com.azure.storage.file.datalake.models.FileRange)"
  fullName: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.setRange(FileRange range)"
  name: "setRange(FileRange range)"
  nameWithType: "DataLakeFileInputStreamOptions.setRange(FileRange range)"
  parameters:
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.FileRange\" data-throw-if-not-resolved=\"false\" data-raw-source=\"FileRange\"></xref>"
    name: "range"
    type: "<xref href=\"com.azure.storage.file.datalake.models.FileRange?alt=com.azure.storage.file.datalake.models.FileRange&text=FileRange\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DataLakeFileInputStreamOptions setRange(FileRange range)"
  returns:
    description: "The updated options."
    type: "<xref href=\"com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions?alt=com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions&text=DataLakeFileInputStreamOptions\" data-throw-if-not-resolved=\"False\" />"
- uid: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.setRequestConditions(com.azure.storage.file.datalake.models.DataLakeRequestConditions)"
  fullName: "com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions.setRequestConditions(DataLakeRequestConditions requestConditions)"
  name: "setRequestConditions(DataLakeRequestConditions requestConditions)"
  nameWithType: "DataLakeFileInputStreamOptions.setRequestConditions(DataLakeRequestConditions requestConditions)"
  parameters:
  - description: "<xref uid=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions\" data-throw-if-not-resolved=\"false\" data-raw-source=\"DataLakeRequestConditions\"></xref>"
    name: "requestConditions"
    type: "<xref href=\"com.azure.storage.file.datalake.models.DataLakeRequestConditions?alt=com.azure.storage.file.datalake.models.DataLakeRequestConditions&text=DataLakeRequestConditions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public DataLakeFileInputStreamOptions setRequestConditions(DataLakeRequestConditions requestConditions)"
  returns:
    description: "The updated options."
    type: "<xref href=\"com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions?alt=com.azure.storage.file.datalake.options.DataLakeFileInputStreamOptions&text=DataLakeFileInputStreamOptions\" data-throw-if-not-resolved=\"False\" />"
type: "class"
desc: "Extended options that may be passed when opening a blob input stream."
metadata: {}
package: "com.azure.storage.file.datalake.options"
artifact: com.azure:azure-storage-file-datalake:12.12.0
