### YamlMime:JavaMember
uid: "com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload*"
fullName: "com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload"
name: "upload"
nameWithType: "EncryptedBlobAsyncClient.upload"
members:
- uid: "com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.blob.models.ParallelTransferOptions)"
  fullName: "com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions)"
  name: "upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions)"
  nameWithType: "EncryptedBlobAsyncClient.upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions)"
  summary: "Creates a new block blob. By default this method will not overwrite an existing blob.\n\nUpdating an existing block blob overwrites any existing metadata on the blob. Partial updates are not supported with this method; the content of the existing blob is overwritten with the new content. To perform a partial update of block blob's, use <xref uid=\"\" data-throw-if-not-resolved=\"false\">stageBlock</xref> and <xref uid=\"\" data-throw-if-not-resolved=\"false\">BlockBlobAsyncClient#commitBlockList(List)</xref> on a regular blob client. For more information, see the [Azure Docs for Put Block][] and the [Azure Docs for Put Block List][].\n\nThe data passed need not support multiple subscriptions/be replayable as is required in other upload methods when retries are enabled, and the length of the data need not be known in advance. Therefore, this method should support uploading any arbitrary data source, including network streams. This behavior is possible because this method will perform some internal buffering as configured by the blockSize and numBuffers parameters, so while this method may offer additional convenience, it will not be as performant as other options, which should be preferred when possible.\n\nTypically, the greater the number of buffers used, the greater the possible parallelism when transferring the data. Larger buffers means we will have to stage fewer blocks and therefore require fewer IO operations. The trade-offs between these values are context-dependent, so some experimentation may be required to optimize inputs for a given scenario.\n\n**Code Samples**\n\n```java\nParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions(blockSize, numBuffers, null);\n client.upload(data, parallelTransferOptions).subscribe(response ->\n     System.out.printf(\"Uploaded BlockBlob MD5 is %s%n\",\n         Base64.getEncoder().encodeToString(response.getContentMd5())));\n```\n\n\n[Azure Docs for Put Block]: https://docs.microsoft.com/rest/api/storageservices/put-block\n[Azure Docs for Put Block List]: https://docs.microsoft.com/rest/api/storageservices/put-block-list"
  overridden: "com.azure.storage.blob.BlobAsyncClient.upload(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.blob.models.ParallelTransferOptions)"
  parameters:
  - description: "The data to write to the blob. Unlike other upload methods, this method does not require that the\n <code>Flux</code> be replayable. In other words, it does not have to support multiple subscribers and is not expected\n to produce the same values across subscriptions."
    name: "data"
    type: "<xref href=\"reactor.core.publisher.Flux?alt=reactor.core.publisher.Flux&text=Flux\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.nio.ByteBuffer?alt=java.nio.ByteBuffer&text=ByteBuffer\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "<xref uid=\"com.azure.storage.blob.models.ParallelTransferOptions\" data-throw-if-not-resolved=\"false\">ParallelTransferOptions</xref> used to configure buffered uploading."
    name: "parallelTransferOptions"
    type: "<xref href=\"com.azure.storage.blob.models.ParallelTransferOptions?alt=com.azure.storage.blob.models.ParallelTransferOptions&text=ParallelTransferOptions\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<BlockBlobItem> upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions)"
  returns:
    description: "A reactive response containing the information of the uploaded block blob."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.blob.models.BlockBlobItem?alt=com.azure.storage.blob.models.BlockBlobItem&text=BlockBlobItem\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.blob.models.ParallelTransferOptions,boolean)"
  fullName: "com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, boolean overwrite)"
  name: "upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, boolean overwrite)"
  nameWithType: "EncryptedBlobAsyncClient.upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, boolean overwrite)"
  summary: "Creates a new block blob, or updates the content of an existing block blob.\n\nUpdating an existing block blob overwrites any existing metadata on the blob. Partial updates are not supported with this method; the content of the existing blob is overwritten with the new content. To perform a partial update of block blob's, use <xref uid=\"\" data-throw-if-not-resolved=\"false\">stageBlock</xref> and <xref uid=\"\" data-throw-if-not-resolved=\"false\">BlockBlobAsyncClient#commitBlockList(List)</xref> on a regular blob client. For more information, see the [Azure Docs for Put Block][] and the [Azure Docs for Put Block List][].\n\nThe data passed need not support multiple subscriptions/be replayable as is required in other upload methods when retries are enabled, and the length of the data need not be known in advance. Therefore, this method should support uploading any arbitrary data source, including network streams. This behavior is possible because this method will perform some internal buffering as configured by the blockSize and numBuffers parameters, so while this method may offer additional convenience, it will not be as performant as other options, which should be preferred when possible.\n\nTypically, the greater the number of buffers used, the greater the possible parallelism when transferring the data. Larger buffers means we will have to stage fewer blocks and therefore require fewer IO operations. The trade-offs between these values are context-dependent, so some experimentation may be required to optimize inputs for a given scenario.\n\n**Code Samples**\n\n```java\nParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions(blockSize, numBuffers, null);\n boolean overwrite = false; // Default behavior\n client.upload(data, parallelTransferOptions, overwrite).subscribe(response ->\n     System.out.printf(\"Uploaded BlockBlob MD5 is %s%n\",\n         Base64.getEncoder().encodeToString(response.getContentMd5())));\n```\n\n\n[Azure Docs for Put Block]: https://docs.microsoft.com/rest/api/storageservices/put-block\n[Azure Docs for Put Block List]: https://docs.microsoft.com/rest/api/storageservices/put-block-list"
  overridden: "com.azure.storage.blob.BlobAsyncClient.upload(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.blob.models.ParallelTransferOptions,boolean)"
  parameters:
  - description: "The data to write to the blob. Unlike other upload methods, this method does not require that the\n <code>Flux</code> be replayable. In other words, it does not have to support multiple subscribers and is not expected\n to produce the same values across subscriptions."
    name: "data"
    type: "<xref href=\"reactor.core.publisher.Flux?alt=reactor.core.publisher.Flux&text=Flux\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.nio.ByteBuffer?alt=java.nio.ByteBuffer&text=ByteBuffer\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "<xref uid=\"com.azure.storage.blob.models.ParallelTransferOptions\" data-throw-if-not-resolved=\"false\">ParallelTransferOptions</xref> used to configure buffered uploading."
    name: "parallelTransferOptions"
    type: "<xref href=\"com.azure.storage.blob.models.ParallelTransferOptions?alt=com.azure.storage.blob.models.ParallelTransferOptions&text=ParallelTransferOptions\" data-throw-if-not-resolved=\"False\" />"
  - description: "Whether or not to overwrite, should data exist on the blob."
    name: "overwrite"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<BlockBlobItem> upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, boolean overwrite)"
  returns:
    description: "A reactive response containing the information of the uploaded block blob."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.blob.models.BlockBlobItem?alt=com.azure.storage.blob.models.BlockBlobItem&text=BlockBlobItem\" data-throw-if-not-resolved=\"False\" />&gt;"
type: "method"
metadata: {}
package: "com.azure.storage.blob.specialized.cryptography"
artifact: com.azure:azure-storage-blob-cryptography:12.7.0
