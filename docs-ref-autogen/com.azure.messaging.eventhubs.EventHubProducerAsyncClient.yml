### YamlMime:JavaType
uid: "com.azure.messaging.eventhubs.EventHubProducerAsyncClient"
fullName: "com.azure.messaging.eventhubs.EventHubProducerAsyncClient"
name: "EventHubProducerAsyncClient"
nameWithType: "EventHubProducerAsyncClient"
summary: "An **asynchronous** producer responsible for transmitting <xref uid=\"com.azure.messaging.eventhubs.EventData\" data-throw-if-not-resolved=\"false\">EventData</xref> to a specific Event Hub, grouped together in batches. Depending on the <xref uid=\"com.azure.messaging.eventhubs.models.CreateBatchOptions\" data-throw-if-not-resolved=\"false\">options</xref> specified when creating an <xref uid=\"com.azure.messaging.eventhubs.EventDataBatch\" data-throw-if-not-resolved=\"false\">EventDataBatch</xref>, the events may be automatically routed to an available partition or specific to a partition.\n\nAllowing automatic routing of partitions is recommended when:\n\n *  The sending of events needs to be highly available.\n *  The event data should be evenly distributed among all available partitions.\n\nIf no partition id is specified, the following rules are used for automatically selecting one:\n\n1.  Distribute the events equally amongst all available partitions using a round-robin approach.\n2.  If a partition becomes unavailable, the Event Hubs service will automatically detect it and forward the message to another available partition.\n\n**Create a producer and publish events to any partition**\n\n```java\n// The required parameter is a way to authenticate with Event Hubs using credentials.\n // The connectionString provides a way to authenticate with Event Hub.\n EventHubProducerAsyncClient producer = new EventHubClientBuilder()\n     .connectionString(\n         \"Endpoint={fully-qualified-namespace};SharedAccessKeyName={policy-name};SharedAccessKey={key}\",\n         \"event-hub-name\")\n     .buildAsyncProducerClient();\n \n // Creating a batch without options set, will allow for automatic routing of events to any partition.\n producer.createBatch().flatMap(batch -> {\n     batch.tryAdd(new EventData(\"test-event-1\"));\n     batch.tryAdd(new EventData(\"test-event-2\"));\n     return producer.send(batch);\n }).subscribe(unused -> { },\n     error -> System.err.println(\"Error occurred while sending batch:\" + error),\n     () -> System.out.println(\"Send complete.\"));\n```\n\n**Publish events to partition \"foo\"**\n\n```java\n// Creating a batch with partitionId set will route all events in that batch to partition `foo`.\n CreateBatchOptions options = new CreateBatchOptions().setPartitionId(\"foo\");\n producer.createBatch(options).flatMap(batch -> {\n     batch.tryAdd(new EventData(\"test-event-1\"));\n     batch.tryAdd(new EventData(\"test-event-2\"));\n     return producer.send(batch);\n }).subscribe(unused -> { },\n     error -> System.err.println(\"Error occurred while sending batch:\" + error),\n     () -> System.out.println(\"Send complete.\"));\n```\n\n**Publish events to the same partition, grouped together using partition key**\n\n```java\n// Creating a batch with partitionKey set will tell the service to hash the partitionKey and decide which\n // partition to send the events to. Events with the same partitionKey are always routed to the same partition.\n CreateBatchOptions options = new CreateBatchOptions().setPartitionKey(\"bread\");\n producer.createBatch(options).flatMap(batch -> {\n     batch.tryAdd(new EventData(\"sourdough\"));\n     batch.tryAdd(new EventData(\"rye\"));\n     return producer.send(batch);\n }).subscribe(unused -> { },\n     error -> System.err.println(\"Error occurred while sending batch:\" + error),\n     () -> System.out.println(\"Send complete.\"));\n```\n\n**Publish events using a size-limited <xref uid=\"com.azure.messaging.eventhubs.EventDataBatch\" data-throw-if-not-resolved=\"false\">EventDataBatch</xref>**\n\n```java\nfinal Flux<EventData> telemetryEvents = Flux.just(firstEvent, secondEvent);\n \n // Setting `setMaximumSizeInBytes` when creating a batch, limits the size of that batch.\n // In this case, all the batches created with these options are limited to 256 bytes.\n final CreateBatchOptions options = new CreateBatchOptions()\n     .setMaximumSizeInBytes(256);\n final AtomicReference<EventDataBatch> currentBatch = new AtomicReference<>(\n     producer.createBatch(options).block());\n \n // The sample Flux contains two events, but it could be an infinite stream of telemetry events.\n telemetryEvents.flatMap(event -> {\n     final EventDataBatch batch = currentBatch.get();\n     if (batch.tryAdd(event)) {\n         return Mono.empty();\n     }\n \n     return Mono.when(\n         producer.send(batch),\n         producer.createBatch(options).map(newBatch -> {\n             currentBatch.set(newBatch);\n \n             // Add the event that did not fit in the previous batch.\n             if (!newBatch.tryAdd(event)) {\n                 throw Exceptions.propagate(new IllegalArgumentException(\n                     \"Event was too large to fit in an empty batch. Max size: \" + newBatch.getMaxSizeInBytes()));\n             }\n \n             return newBatch;\n         }));\n }).then()\n     .doFinally(signal -> {\n         final EventDataBatch batch = currentBatch.getAndSet(null);\n         if (batch != null && batch.getCount() > 0) {\n             producer.send(batch).block();\n         }\n     });\n```"
inheritances:
- "<xref href=\"java.lang.Object\" data-throw-if-not-resolved=\"False\" />"
inheritedMembers:
- "java.lang.Object.clone()"
- "java.lang.Object.equals(java.lang.Object)"
- "java.lang.Object.finalize()"
- "java.lang.Object.getClass()"
- "java.lang.Object.hashCode()"
- "java.lang.Object.notify()"
- "java.lang.Object.notifyAll()"
- "java.lang.Object.toString()"
- "java.lang.Object.wait()"
- "java.lang.Object.wait(long)"
- "java.lang.Object.wait(long,int)"
syntax: "public class EventHubProducerAsyncClient implements Closeable"
methods:
- "com.azure.messaging.eventhubs.EventHubProducerAsyncClient.close()"
- "com.azure.messaging.eventhubs.EventHubProducerAsyncClient.createBatch()"
- "com.azure.messaging.eventhubs.EventHubProducerAsyncClient.createBatch(com.azure.messaging.eventhubs.models.CreateBatchOptions)"
- "com.azure.messaging.eventhubs.EventHubProducerAsyncClient.getEventHubName()"
- "com.azure.messaging.eventhubs.EventHubProducerAsyncClient.getEventHubProperties()"
- "com.azure.messaging.eventhubs.EventHubProducerAsyncClient.getFullyQualifiedNamespace()"
- "com.azure.messaging.eventhubs.EventHubProducerAsyncClient.getPartitionIds()"
- "com.azure.messaging.eventhubs.EventHubProducerAsyncClient.getPartitionProperties(java.lang.String)"
- "com.azure.messaging.eventhubs.EventHubProducerAsyncClient.send(com.azure.messaging.eventhubs.EventDataBatch)"
- "com.azure.messaging.eventhubs.EventHubProducerAsyncClient.send(java.lang.Iterable<com.azure.messaging.eventhubs.EventData>)"
- "com.azure.messaging.eventhubs.EventHubProducerAsyncClient.send(java.lang.Iterable<com.azure.messaging.eventhubs.EventData>,com.azure.messaging.eventhubs.models.SendOptions)"
type: "class"
implements:
- "<xref href=\"java.io.Closeable?alt=java.io.Closeable&text=Closeable\" data-throw-if-not-resolved=\"False\" />"
metadata: {}
package: "com.azure.messaging.eventhubs"
artifact: com.azure:azure-messaging-eventhubs:5.3.0
