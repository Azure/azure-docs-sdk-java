### YamlMime:JavaMember
uid: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync*"
fullName: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync"
name: "analyzeReceiptAsyncWithResponseAsync"
nameWithType: "FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync"
members:
- uid: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(com.azure.ai.formrecognizer.implementation.models.ContentType,java.lang.Boolean,com.azure.ai.formrecognizer.implementation.models.Locale,java.util.List<java.lang.String>,reactor.core.publisher.Flux<java.nio.ByteBuffer>,java.lang.Long)"
  fullName: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(ContentType contentType, Boolean includeTextDetails, Locale locale, List<String> pages, Flux<ByteBuffer> fileStream, Long contentLength)"
  name: "analyzeReceiptAsyncWithResponseAsync(ContentType contentType, Boolean includeTextDetails, Locale locale, List<String> pages, Flux<ByteBuffer> fileStream, Long contentLength)"
  nameWithType: "FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(ContentType contentType, Boolean includeTextDetails, Locale locale, List<String> pages, Flux<ByteBuffer> fileStream, Long contentLength)"
  summary: "Extract field text and semantic values from a given receipt document. The input document must be of one of the supported content types - 'application/pdf', 'image/jpeg', 'image/png', 'image/tiff' or 'image/bmp'. Alternatively, use 'application/json' type to specify the location (Uri) of the document to be analyzed."
  parameters:
  - description: "Upload file type."
    name: "contentType"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.ContentType?alt=com.azure.ai.formrecognizer.implementation.models.ContentType&text=ContentType\" data-throw-if-not-resolved=\"False\" />"
  - description: "Include text lines and element references in the result."
    name: "includeTextDetails"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "Locale of the input document. Supported locales include: en-AU, en-CA, en-GB, en-IN,\n     en-US(default)."
    name: "locale"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.Locale?alt=com.azure.ai.formrecognizer.implementation.models.Locale&text=Locale\" data-throw-if-not-resolved=\"False\" />"
  - description: "Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to\n     get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma."
    name: "pages"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: ".json, .pdf, .jpg, .png, .tiff or .bmp type file stream."
    name: "fileStream"
    type: "<xref href=\"reactor.core.publisher.Flux?alt=reactor.core.publisher.Flux&text=Flux\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.nio.ByteBuffer?alt=java.nio.ByteBuffer&text=ByteBuffer\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "The contentLength parameter."
    name: "contentLength"
    type: "<xref href=\"java.lang.Long?alt=java.lang.Long&text=Long\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<AnalyzeReceiptAsyncResponse> analyzeReceiptAsyncWithResponseAsync(ContentType contentType, Boolean includeTextDetails, Locale locale, List<String> pages, Flux<ByteBuffer> fileStream, Long contentLength)"
  returns:
    description: "the completion."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.ai.formrecognizer.implementation.models.AnalyzeReceiptAsyncResponse?alt=com.azure.ai.formrecognizer.implementation.models.AnalyzeReceiptAsyncResponse&text=AnalyzeReceiptAsyncResponse\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(com.azure.ai.formrecognizer.implementation.models.ContentType,java.lang.Boolean,com.azure.ai.formrecognizer.implementation.models.Locale,java.util.List<java.lang.String>,reactor.core.publisher.Flux<java.nio.ByteBuffer>,java.lang.Long,com.azure.core.util.Context)"
  fullName: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(ContentType contentType, Boolean includeTextDetails, Locale locale, List<String> pages, Flux<ByteBuffer> fileStream, Long contentLength, Context context)"
  name: "analyzeReceiptAsyncWithResponseAsync(ContentType contentType, Boolean includeTextDetails, Locale locale, List<String> pages, Flux<ByteBuffer> fileStream, Long contentLength, Context context)"
  nameWithType: "FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(ContentType contentType, Boolean includeTextDetails, Locale locale, List<String> pages, Flux<ByteBuffer> fileStream, Long contentLength, Context context)"
  summary: "Extract field text and semantic values from a given receipt document. The input document must be of one of the supported content types - 'application/pdf', 'image/jpeg', 'image/png', 'image/tiff' or 'image/bmp'. Alternatively, use 'application/json' type to specify the location (Uri) of the document to be analyzed."
  parameters:
  - description: "Upload file type."
    name: "contentType"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.ContentType?alt=com.azure.ai.formrecognizer.implementation.models.ContentType&text=ContentType\" data-throw-if-not-resolved=\"False\" />"
  - description: "Include text lines and element references in the result."
    name: "includeTextDetails"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "Locale of the input document. Supported locales include: en-AU, en-CA, en-GB, en-IN,\n     en-US(default)."
    name: "locale"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.Locale?alt=com.azure.ai.formrecognizer.implementation.models.Locale&text=Locale\" data-throw-if-not-resolved=\"False\" />"
  - description: "Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to\n     get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma."
    name: "pages"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: ".json, .pdf, .jpg, .png, .tiff or .bmp type file stream."
    name: "fileStream"
    type: "<xref href=\"reactor.core.publisher.Flux?alt=reactor.core.publisher.Flux&text=Flux\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.nio.ByteBuffer?alt=java.nio.ByteBuffer&text=ByteBuffer\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: "The contentLength parameter."
    name: "contentLength"
    type: "<xref href=\"java.lang.Long?alt=java.lang.Long&text=Long\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<AnalyzeReceiptAsyncResponse> analyzeReceiptAsyncWithResponseAsync(ContentType contentType, Boolean includeTextDetails, Locale locale, List<String> pages, Flux<ByteBuffer> fileStream, Long contentLength, Context context)"
  returns:
    description: "the completion."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.ai.formrecognizer.implementation.models.AnalyzeReceiptAsyncResponse?alt=com.azure.ai.formrecognizer.implementation.models.AnalyzeReceiptAsyncResponse&text=AnalyzeReceiptAsyncResponse\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(java.lang.Boolean,com.azure.ai.formrecognizer.implementation.models.Locale,java.util.List<java.lang.String>,com.azure.ai.formrecognizer.implementation.models.SourcePath)"
  fullName: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream)"
  name: "analyzeReceiptAsyncWithResponseAsync(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream)"
  nameWithType: "FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream)"
  summary: "Extract field text and semantic values from a given receipt document. The input document must be of one of the supported content types - 'application/pdf', 'image/jpeg', 'image/png', 'image/tiff' or 'image/bmp'. Alternatively, use 'application/json' type to specify the location (Uri) of the document to be analyzed."
  parameters:
  - description: "Include text lines and element references in the result."
    name: "includeTextDetails"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "Locale of the input document. Supported locales include: en-AU, en-CA, en-GB, en-IN,\n     en-US(default)."
    name: "locale"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.Locale?alt=com.azure.ai.formrecognizer.implementation.models.Locale&text=Locale\" data-throw-if-not-resolved=\"False\" />"
  - description: "Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to\n     get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma."
    name: "pages"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: ".json, .pdf, .jpg, .png, .tiff or .bmp type file stream."
    name: "fileStream"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.SourcePath?alt=com.azure.ai.formrecognizer.implementation.models.SourcePath&text=SourcePath\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<AnalyzeReceiptAsyncResponse> analyzeReceiptAsyncWithResponseAsync(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream)"
  returns:
    description: "the completion."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.ai.formrecognizer.implementation.models.AnalyzeReceiptAsyncResponse?alt=com.azure.ai.formrecognizer.implementation.models.AnalyzeReceiptAsyncResponse&text=AnalyzeReceiptAsyncResponse\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(java.lang.Boolean,com.azure.ai.formrecognizer.implementation.models.Locale,java.util.List<java.lang.String>,com.azure.ai.formrecognizer.implementation.models.SourcePath,com.azure.core.util.Context)"
  fullName: "com.azure.ai.formrecognizer.implementation.FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream, Context context)"
  name: "analyzeReceiptAsyncWithResponseAsync(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream, Context context)"
  nameWithType: "FormRecognizerClientImpl.analyzeReceiptAsyncWithResponseAsync(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream, Context context)"
  summary: "Extract field text and semantic values from a given receipt document. The input document must be of one of the supported content types - 'application/pdf', 'image/jpeg', 'image/png', 'image/tiff' or 'image/bmp'. Alternatively, use 'application/json' type to specify the location (Uri) of the document to be analyzed."
  parameters:
  - description: "Include text lines and element references in the result."
    name: "includeTextDetails"
    type: "<xref href=\"java.lang.Boolean?alt=java.lang.Boolean&text=Boolean\" data-throw-if-not-resolved=\"False\" />"
  - description: "Locale of the input document. Supported locales include: en-AU, en-CA, en-GB, en-IN,\n     en-US(default)."
    name: "locale"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.Locale?alt=com.azure.ai.formrecognizer.implementation.models.Locale&text=Locale\" data-throw-if-not-resolved=\"False\" />"
  - description: "Custom page numbers for multi-page documents(PDF/TIFF), input the number of the pages you want to\n     get OCR result. For a range of pages, use a hyphen. Separate each page or range with a comma."
    name: "pages"
    type: "<xref href=\"java.util.List?alt=java.util.List&text=List\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"java.lang.String?alt=java.lang.String&text=String\" data-throw-if-not-resolved=\"False\" />&gt;"
  - description: ".json, .pdf, .jpg, .png, .tiff or .bmp type file stream."
    name: "fileStream"
    type: "<xref href=\"com.azure.ai.formrecognizer.implementation.models.SourcePath?alt=com.azure.ai.formrecognizer.implementation.models.SourcePath&text=SourcePath\" data-throw-if-not-resolved=\"False\" />"
  - description: "The context to associate with this operation."
    name: "context"
    type: "<xref href=\"com.azure.core.util.Context?alt=com.azure.core.util.Context&text=Context\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<AnalyzeReceiptAsyncResponse> analyzeReceiptAsyncWithResponseAsync(Boolean includeTextDetails, Locale locale, List<String> pages, SourcePath fileStream, Context context)"
  returns:
    description: "the completion."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.ai.formrecognizer.implementation.models.AnalyzeReceiptAsyncResponse?alt=com.azure.ai.formrecognizer.implementation.models.AnalyzeReceiptAsyncResponse&text=AnalyzeReceiptAsyncResponse\" data-throw-if-not-resolved=\"False\" />&gt;"
type: "method"
metadata: {}
package: "com.azure.ai.formrecognizer.implementation"
artifact: com.azure:azure-ai-formrecognizer:3.1.6
