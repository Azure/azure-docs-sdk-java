### YamlMime:JavaMember
uid: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.flush*"
fullName: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.flush"
name: "flush"
nameWithType: "DataLakeFileAsyncClient.flush"
members:
- uid: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.flush(long)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.flush(long position)"
  name: "flush(long position)"
  nameWithType: "DataLakeFileAsyncClient.flush(long position)"
  summary: "Flushes (writes) data previously appended to the file through a call to append. The previously uploaded data must be contiguous.\n\nBy default this method will not overwrite existing data.\n\n**Code Samples**\n\n```java\nclient.flush(position).subscribe(response ->\n     System.out.println(\"Flush data completed\"));\n```\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update"
  parameters:
  - description: "The length of the file after all data has been written."
    name: "position"
    type: "<xref href=\"long?alt=long&text=long\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<PathInfo> flush(long position)"
  returns:
    description: "A reactive response containing the information of the created resource."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.PathInfo?alt=com.azure.storage.file.datalake.models.PathInfo&text=PathInfo\" data-throw-if-not-resolved=\"False\" />&gt;"
- uid: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.flush(long,boolean)"
  fullName: "com.azure.storage.file.datalake.DataLakeFileAsyncClient.flush(long position, boolean overwrite)"
  name: "flush(long position, boolean overwrite)"
  nameWithType: "DataLakeFileAsyncClient.flush(long position, boolean overwrite)"
  summary: "Flushes (writes) data previously appended to the file through a call to append. The previously uploaded data must be contiguous.\n\n**Code Samples**\n\n```java\nboolean overwrite = true;\n client.flush(position, overwrite).subscribe(response ->\n     System.out.println(\"Flush data completed\"));\n```\n\nFor more information, see the [Azure Docs][]\n\n\n[Azure Docs]: https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update"
  parameters:
  - description: "The length of the file after all data has been written."
    name: "position"
    type: "<xref href=\"long?alt=long&text=long\" data-throw-if-not-resolved=\"False\" />"
  - description: "Whether or not to overwrite, should data exist on the file."
    name: "overwrite"
    type: "<xref href=\"boolean?alt=boolean&text=boolean\" data-throw-if-not-resolved=\"False\" />"
  syntax: "public Mono<PathInfo> flush(long position, boolean overwrite)"
  returns:
    description: "A reactive response containing the information of the created resource."
    type: "<xref href=\"reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono\" data-throw-if-not-resolved=\"False\" />&lt;<xref href=\"com.azure.storage.file.datalake.models.PathInfo?alt=com.azure.storage.file.datalake.models.PathInfo&text=PathInfo\" data-throw-if-not-resolved=\"False\" />&gt;"
type: "method"
metadata: {}
package: "com.azure.storage.file.datalake"
artifact: com.azure:azure-storage-file-datalake:12.2.0
