### YamlMime:ManagedReference
items:
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces_detect_with_stream_definition
  id: _faces_detect_with_stream_definition
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._faces_detect_with_stream_definition.yml
  langs:
  - java
  name: Faces.FacesDetectWithStreamDefinition
  nameWithType: Faces.FacesDetectWithStreamDefinition
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinition
  type: Interface
  source:
    remote:
      path: cognitiveservices/data-plane/vision/faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
      branch: master
      repo: https://github.com/Azure/azure-sdk-for-java
    path: cognitiveservices/data-plane/vision/faceapi/src/main/java/com/microsoft/azure/cognitiveservices/vision/faceapi/Faces.java
    startLine: 545
  package: com.microsoft.azure.cognitiveservices.vision.faceapi
  summary: "<p>The entirety of detectWithStream definition. </p>"
  syntax:
    content: public interface FacesDetectWithStreamDefinition extends Faces.FacesDetectWithStreamDefinitionStages.WithImage,Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  inheritedMembers:
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.execute()
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.executeAsync()
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesc40995c0f220a6438b2678009a94fa1c.withImage(byte [])
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceAttributes(List<FaceAttributeType>)
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceId(Boolean)
  - com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceLandmarks(Boolean)
references:
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.execute()
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.yml
  name: execute()
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithExecute.execute()
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.execute()
  type: Method
  summary: >-
    <p>Execute the request.</p>

    <p></p>
  syntax:
    content: public List<DetectedFace> execute()
    return:
      type: 5618da2dcom.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_facea08ddfce
      description: <p>the List&lt;DetectedFace&gt; object if successful. </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.executeAsync()
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.yml
  name: executeAsync()
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithExecute.executeAsync()
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute.executeAsync()
  type: Method
  summary: >-
    <p>Execute the request asynchronously.</p>

    <p></p>
  syntax:
    content: public Observable<List<DetectedFace>> executeAsync()
    return:
      type: 39a50407com.microsoft.azure.cognitiveservices.vision.faceapi.models._detected_facee7daa122
      description: <p>the observable to the List&lt;DetectedFace&gt; object </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesc40995c0f220a6438b2678009a94fa1c.withImage(byte [])
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesc40995c0f220a6438b2678009a94fa1c
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesc40995c0f220a6438b2678009a94fa1c.yml
  name: withImage(byte[] image)
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithImage.withImage(byte[] image)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithImage.withImage(byte[] image)
  type: Method
  summary: >-
    <p>An image stream.</p>

    <p></p>
  syntax:
    content: public FacesDetectWithStreamDefinitionStages.WithExecute withImage(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
    return:
      type: 1f48b658
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceAttributes(List<FaceAttributeType>)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.yml
  name: withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
  type: Method
  summary: >-
    <p>Analyze and return the one or more specified face attributes in the comma-separated string like "returnFaceAttributes=age,gender". Supported face attributes include age, gender, headPose, smile, facialHair, glasses and emotion. Note that each face attribute analysis has additional computational and time cost.</p>

    <p></p>
  syntax:
    content: public FacesDetectWithStreamDefinitionStages.WithExecute withReturnFaceAttributes(List<FaceAttributeType> returnFaceAttributes)
    parameters:
    - id: returnFaceAttributes
      type: 5618da2dcom.microsoft.azure.cognitiveservices.vision.faceapi.models._face_attribute_typea08ddfce
    return:
      type: 1f48b658
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceId(Boolean)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.yml
  name: withReturnFaceId(Boolean returnFaceId)
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceId(Boolean returnFaceId)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceId(Boolean returnFaceId)
  type: Method
  summary: >-
    <p>A value indicating whether the operation should return faceIds of detected faces.</p>

    <p></p>
  syntax:
    content: public FacesDetectWithStreamDefinitionStages.WithExecute withReturnFaceId(Boolean returnFaceId)
    parameters:
    - id: returnFaceId
      type: 866c2227
    return:
      type: 1f48b658
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.withReturnFaceLandmarks(Boolean)
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesea6853194b063dd8d8f4e721c06168e2.yml
  name: withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithAllOptions.withReturnFaceLandmarks(Boolean returnFaceLandmarks)
  type: Method
  summary: >-
    <p>A value indicating whether the operation should return landmarks of the detected faces.</p>

    <p></p>
  syntax:
    content: public FacesDetectWithStreamDefinitionStages.WithExecute withReturnFaceLandmarks(Boolean returnFaceLandmarks)
    parameters:
    - id: returnFaceLandmarks
      type: 866c2227
    return:
      type: 1f48b658
      description: <p>next definition stage </p>
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesc40995c0f220a6438b2678009a94fa1c
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facesc40995c0f220a6438b2678009a94fa1c.yml
  name: Faces.FacesDetectWithStreamDefinitionStages.WithImage
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithImage
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithImage
  type: Interface
  summary: <p>The stage of the definition to be specify image. </p>
  syntax:
    content: public interface WithImage
- uid: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e
  parent: com.microsoft.azure.cognitiveservices.vision.faceapi
  href: com.microsoft.azure.cognitiveservices.vision.faceapi._faces._facese55a9be762e5757882dfbc975d1b7e5e.yml
  name: Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  nameWithType: Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  fullName: com.microsoft.azure.cognitiveservices.vision.faceapi.Faces.FacesDetectWithStreamDefinitionStages.WithExecute
  type: Interface
  summary: <p>The last stage of the definition which will make the operation call. </p>
  syntax:
    content: public interface WithExecute
