### YamlMime:JavaMember
uid: "com.azure.cosmos.BulkExecutionOptions.getMaxMicroBatchSize*"
fullName: "com.azure.cosmos.BulkExecutionOptions.getMaxMicroBatchSize"
name: "getMaxMicroBatchSize"
nameWithType: "BulkExecutionOptions.getMaxMicroBatchSize"
members:
- uid: "com.azure.cosmos.BulkExecutionOptions.getMaxMicroBatchSize()"
  fullName: "com.azure.cosmos.BulkExecutionOptions.getMaxMicroBatchSize()"
  name: "getMaxMicroBatchSize()"
  nameWithType: "BulkExecutionOptions.getMaxMicroBatchSize()"
  summary: "The maximum batching size for bulk operations. This value determines number of operations executed in one request. There is an upper limit on both number of operations and sum of size of operations. Any overflow is internally retried. Another instance is: Currently we support a max limit of 200KB, and user select batch size to be 100 and individual documents are of size 20KB, approximately 90 operations will always be retried. So it's better to choose a batch size of 10 here if user is aware of there workload. If sizes are totally unknown and user cannot put a number on it then retries are handled, so no issues as such. If the retry rate exceeds \\`getMaxMicroBatchInterval\\` the micro batch size gets dynamically reduced at runtime"
  syntax: "public int getMaxMicroBatchSize()"
  returns:
    description: "micro batch size"
    type: "<xref href=\"int?alt=int&text=int\" data-throw-if-not-resolved=\"False\" />"
type: "method"
metadata: {}
package: "com.azure.cosmos"
artifact: com.azure:azure-cosmos:4.20.1
