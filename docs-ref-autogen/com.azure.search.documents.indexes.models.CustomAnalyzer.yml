### YamlMime:ManagedReference
items:
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer
  id: CustomAnalyzer
  artifact: com.azure:azure-search-documents:11.1.0
  parent: com.azure.search.documents.indexes.models
  children:
  - com.azure.search.documents.indexes.models.CustomAnalyzer.CustomAnalyzer(java.lang.String,com.azure.search.documents.indexes.models.LexicalTokenizerName)
  - com.azure.search.documents.indexes.models.CustomAnalyzer.getCharFilters()
  - com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenFilters()
  - com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenizer()
  - com.azure.search.documents.indexes.models.CustomAnalyzer.setCharFilters(com.azure.search.documents.indexes.models.CharFilterName...)
  - com.azure.search.documents.indexes.models.CustomAnalyzer.setCharFilters(java.util.List<com.azure.search.documents.indexes.models.CharFilterName>)
  - com.azure.search.documents.indexes.models.CustomAnalyzer.setTokenFilters(com.azure.search.documents.indexes.models.TokenFilterName...)
  - com.azure.search.documents.indexes.models.CustomAnalyzer.setTokenFilters(java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>)
  langs:
  - java
  name: CustomAnalyzer
  nameWithType: CustomAnalyzer
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer
  type: Class
  package: com.azure.search.documents.indexes.models
  summary: Allows you to take control over the process of converting text into indexable/searchable tokens. It's a user-defined configuration consisting of a single predefined tokenizer and one or more filters. The tokenizer is responsible for breaking text into tokens, and the filters for modifying tokens emitted by the tokenizer.
  syntax:
    content: public final class CustomAnalyzer extends LexicalAnalyzer
  inheritance:
  - java.lang.Object
  - com.azure.search.documents.indexes.models.LexicalAnalyzer
  inheritedMembers:
  - com.azure.search.documents.indexes.models.LexicalAnalyzer.getName()
  - java.lang.Object.clone()
  - java.lang.Object.equals(java.lang.Object)
  - java.lang.Object.finalize()
  - java.lang.Object.getClass()
  - java.lang.Object.hashCode()
  - java.lang.Object.notify()
  - java.lang.Object.notifyAll()
  - java.lang.Object.toString()
  - java.lang.Object.wait()
  - java.lang.Object.wait(long)
  - java.lang.Object.wait(long,int)
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.CustomAnalyzer(java.lang.String,com.azure.search.documents.indexes.models.LexicalTokenizerName)
  id: CustomAnalyzer(java.lang.String,com.azure.search.documents.indexes.models.LexicalTokenizerName)
  artifact: com.azure:azure-search-documents:11.1.0
  parent: com.azure.search.documents.indexes.models.CustomAnalyzer
  langs:
  - java
  name: CustomAnalyzer(String name, LexicalTokenizerName tokenizerName)
  nameWithType: CustomAnalyzer.CustomAnalyzer(String name, LexicalTokenizerName tokenizerName)
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.CustomAnalyzer(String name, LexicalTokenizerName tokenizerName)
  overload: com.azure.search.documents.indexes.models.CustomAnalyzer.CustomAnalyzer*
  type: Constructor
  package: com.azure.search.documents.indexes.models
  summary: Constructor of <xref uid="com.azure.search.documents.indexes.models.LexicalAnalyzer" data-throw-if-not-resolved="false">LexicalAnalyzer</xref>.
  syntax:
    content: public CustomAnalyzer(String name, LexicalTokenizerName tokenizerName)
    parameters:
    - id: name
      type: java.lang.String
      description: >-
        The name of the analyzer. It must only contain letters, digits, spaces,
         dashes or underscores, can only start and end with alphanumeric
         characters, and is limited to 128 characters.
    - id: tokenizerName
      type: com.azure.search.documents.indexes.models.LexicalTokenizerName
      description: >-
        The name of the tokenizer to use to divide continuous text into a
         sequence of tokens, such as breaking a sentence into words. Possible
         values include: 'Classic', 'EdgeNGram', 'Keyword', 'Letter',
         'Lowercase', 'MicrosoftLanguageTokenizer',
         'MicrosoftLanguageStemmingTokenizer', 'NGram', 'PathHierarchy',
         'Pattern', 'Standard', 'UaxUrlEmail', 'Whitespace'
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.getCharFilters()
  id: getCharFilters()
  artifact: com.azure:azure-search-documents:11.1.0
  parent: com.azure.search.documents.indexes.models.CustomAnalyzer
  langs:
  - java
  name: getCharFilters()
  nameWithType: CustomAnalyzer.getCharFilters()
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.getCharFilters()
  overload: com.azure.search.documents.indexes.models.CustomAnalyzer.getCharFilters*
  type: Method
  package: com.azure.search.documents.indexes.models
  summary: 'Get the charFilters property: A list of character filters used to prepare input text before it is processed by the tokenizer. For instance, they can replace certain characters or symbols. The filters are run in the order in which they are listed.'
  syntax:
    content: public List<CharFilterName> getCharFilters()
    return:
      type: java.util.List<com.azure.search.documents.indexes.models.CharFilterName>
      description: the charFilters value.
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenFilters()
  id: getTokenFilters()
  artifact: com.azure:azure-search-documents:11.1.0
  parent: com.azure.search.documents.indexes.models.CustomAnalyzer
  langs:
  - java
  name: getTokenFilters()
  nameWithType: CustomAnalyzer.getTokenFilters()
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenFilters()
  overload: com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenFilters*
  type: Method
  package: com.azure.search.documents.indexes.models
  summary: 'Get the tokenFilters property: A list of token filters used to filter out or modify the tokens generated by a tokenizer. For example, you can specify a lowercase filter that converts all characters to lowercase. The filters are run in the order in which they are listed.'
  syntax:
    content: public List<TokenFilterName> getTokenFilters()
    return:
      type: java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>
      description: the tokenFilters value.
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenizer()
  id: getTokenizer()
  artifact: com.azure:azure-search-documents:11.1.0
  parent: com.azure.search.documents.indexes.models.CustomAnalyzer
  langs:
  - java
  name: getTokenizer()
  nameWithType: CustomAnalyzer.getTokenizer()
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenizer()
  overload: com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenizer*
  type: Method
  package: com.azure.search.documents.indexes.models
  summary: "Get the tokenizer property: The name of the tokenizer to use to divide continuous text into a sequence of tokens, such as breaking a sentence into words. Possible values include: 'Classic', 'EdgeNGram', 'Keyword', 'Letter', 'Lowercase', 'MicrosoftLanguageTokenizer', 'MicrosoftLanguageStemmingTokenizer', 'NGram', 'PathHierarchy', 'Pattern', 'Standard', 'UaxUrlEmail', 'Whitespace'."
  syntax:
    content: public LexicalTokenizerName getTokenizer()
    return:
      type: com.azure.search.documents.indexes.models.LexicalTokenizerName
      description: the tokenizer value.
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.setCharFilters(com.azure.search.documents.indexes.models.CharFilterName...)
  id: setCharFilters(com.azure.search.documents.indexes.models.CharFilterName...)
  artifact: com.azure:azure-search-documents:11.1.0
  parent: com.azure.search.documents.indexes.models.CustomAnalyzer
  langs:
  - java
  name: setCharFilters(CharFilterName[] charFilters)
  nameWithType: CustomAnalyzer.setCharFilters(CharFilterName[] charFilters)
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.setCharFilters(CharFilterName[] charFilters)
  overload: com.azure.search.documents.indexes.models.CustomAnalyzer.setCharFilters*
  type: Method
  package: com.azure.search.documents.indexes.models
  summary: 'Set the charFilters property: A list of character filters used to prepare input text before it is processed by the tokenizer. For instance, they can replace certain characters or symbols. The filters are run in the order in which they are listed.'
  syntax:
    content: public CustomAnalyzer setCharFilters(CharFilterName[] charFilters)
    parameters:
    - id: charFilters
      type: com.azure.search.documents.indexes.models.CharFilterName[]
      description: the charFilters value to set.
    return:
      type: com.azure.search.documents.indexes.models.CustomAnalyzer
      description: the CustomAnalyzer object itself.
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.setCharFilters(java.util.List<com.azure.search.documents.indexes.models.CharFilterName>)
  id: setCharFilters(java.util.List<com.azure.search.documents.indexes.models.CharFilterName>)
  artifact: com.azure:azure-search-documents:11.1.0
  parent: com.azure.search.documents.indexes.models.CustomAnalyzer
  langs:
  - java
  name: setCharFilters(List<CharFilterName> charFilters)
  nameWithType: CustomAnalyzer.setCharFilters(List<CharFilterName> charFilters)
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.setCharFilters(List<CharFilterName> charFilters)
  overload: com.azure.search.documents.indexes.models.CustomAnalyzer.setCharFilters*
  type: Method
  package: com.azure.search.documents.indexes.models
  summary: 'Set the charFilters property: A list of character filters used to prepare input text before it is processed by the tokenizer. For instance, they can replace certain characters or symbols. The filters are run in the order in which they are listed.'
  syntax:
    content: public CustomAnalyzer setCharFilters(List<CharFilterName> charFilters)
    parameters:
    - id: charFilters
      type: java.util.List<com.azure.search.documents.indexes.models.CharFilterName>
      description: the charFilters value to set.
    return:
      type: com.azure.search.documents.indexes.models.CustomAnalyzer
      description: the CustomAnalyzer object itself.
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.setTokenFilters(com.azure.search.documents.indexes.models.TokenFilterName...)
  id: setTokenFilters(com.azure.search.documents.indexes.models.TokenFilterName...)
  artifact: com.azure:azure-search-documents:11.1.0
  parent: com.azure.search.documents.indexes.models.CustomAnalyzer
  langs:
  - java
  name: setTokenFilters(TokenFilterName[] tokenFilters)
  nameWithType: CustomAnalyzer.setTokenFilters(TokenFilterName[] tokenFilters)
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.setTokenFilters(TokenFilterName[] tokenFilters)
  overload: com.azure.search.documents.indexes.models.CustomAnalyzer.setTokenFilters*
  type: Method
  package: com.azure.search.documents.indexes.models
  summary: 'Set the tokenFilters property: A list of token filters used to filter out or modify the tokens generated by a tokenizer. For example, you can specify a lowercase filter that converts all characters to lowercase. The filters are run in the order in which they are listed.'
  syntax:
    content: public CustomAnalyzer setTokenFilters(TokenFilterName[] tokenFilters)
    parameters:
    - id: tokenFilters
      type: com.azure.search.documents.indexes.models.TokenFilterName[]
      description: the tokenFilters value to set.
    return:
      type: com.azure.search.documents.indexes.models.CustomAnalyzer
      description: the CustomAnalyzer object itself.
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.setTokenFilters(java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>)
  id: setTokenFilters(java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>)
  artifact: com.azure:azure-search-documents:11.1.0
  parent: com.azure.search.documents.indexes.models.CustomAnalyzer
  langs:
  - java
  name: setTokenFilters(List<TokenFilterName> tokenFilters)
  nameWithType: CustomAnalyzer.setTokenFilters(List<TokenFilterName> tokenFilters)
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.setTokenFilters(List<TokenFilterName> tokenFilters)
  overload: com.azure.search.documents.indexes.models.CustomAnalyzer.setTokenFilters*
  type: Method
  package: com.azure.search.documents.indexes.models
  summary: 'Set the tokenFilters property: A list of token filters used to filter out or modify the tokens generated by a tokenizer. For example, you can specify a lowercase filter that converts all characters to lowercase. The filters are run in the order in which they are listed.'
  syntax:
    content: public CustomAnalyzer setTokenFilters(List<TokenFilterName> tokenFilters)
    parameters:
    - id: tokenFilters
      type: java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>
      description: the tokenFilters value to set.
    return:
      type: com.azure.search.documents.indexes.models.CustomAnalyzer
      description: the CustomAnalyzer object itself.
references:
- uid: java.lang.String
  spec.java:
  - uid: java.lang.String
    name: String
    fullName: java.lang.String
- uid: com.azure.search.documents.indexes.models.LexicalTokenizerName
  name: LexicalTokenizerName
  nameWithType: LexicalTokenizerName
  fullName: com.azure.search.documents.indexes.models.LexicalTokenizerName
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.CustomAnalyzer*
  name: CustomAnalyzer
  nameWithType: CustomAnalyzer.CustomAnalyzer
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.CustomAnalyzer
  package: com.azure.search.documents.indexes.models
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenizer*
  name: getTokenizer
  nameWithType: CustomAnalyzer.getTokenizer
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenizer
  package: com.azure.search.documents.indexes.models
- uid: java.util.List<com.azure.search.documents.indexes.models.TokenFilterName>
  spec.java:
  - uid: java.util.List
    name: List
    fullName: java.util.List
  - name: <
    fullName: <
  - uid: com.azure.search.documents.indexes.models.TokenFilterName
    name: TokenFilterName
    fullName: com.azure.search.documents.indexes.models.TokenFilterName
  - name: '>'
    fullName: '>'
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenFilters*
  name: getTokenFilters
  nameWithType: CustomAnalyzer.getTokenFilters
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.getTokenFilters
  package: com.azure.search.documents.indexes.models
- uid: com.azure.search.documents.indexes.models.TokenFilterName[]
  spec.java:
  - uid: com.azure.search.documents.indexes.models.TokenFilterName
    name: TokenFilterName
    fullName: com.azure.search.documents.indexes.models.TokenFilterName
  - name: '[]'
    fullName: '[]'
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.setTokenFilters*
  name: setTokenFilters
  nameWithType: CustomAnalyzer.setTokenFilters
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.setTokenFilters
  package: com.azure.search.documents.indexes.models
- uid: java.util.List<com.azure.search.documents.indexes.models.CharFilterName>
  spec.java:
  - uid: java.util.List
    name: List
    fullName: java.util.List
  - name: <
    fullName: <
  - uid: com.azure.search.documents.indexes.models.CharFilterName
    name: CharFilterName
    fullName: com.azure.search.documents.indexes.models.CharFilterName
  - name: '>'
    fullName: '>'
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.getCharFilters*
  name: getCharFilters
  nameWithType: CustomAnalyzer.getCharFilters
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.getCharFilters
  package: com.azure.search.documents.indexes.models
- uid: com.azure.search.documents.indexes.models.CharFilterName[]
  spec.java:
  - uid: com.azure.search.documents.indexes.models.CharFilterName
    name: CharFilterName
    fullName: com.azure.search.documents.indexes.models.CharFilterName
  - name: '[]'
    fullName: '[]'
- uid: com.azure.search.documents.indexes.models.CustomAnalyzer.setCharFilters*
  name: setCharFilters
  nameWithType: CustomAnalyzer.setCharFilters
  fullName: com.azure.search.documents.indexes.models.CustomAnalyzer.setCharFilters
  package: com.azure.search.documents.indexes.models
- uid: com.azure.search.documents.indexes.models.LexicalAnalyzer
  name: LexicalAnalyzer
  nameWithType: LexicalAnalyzer
  fullName: com.azure.search.documents.indexes.models.LexicalAnalyzer
- uid: java.lang.Object.notify()
  name: Object.notify()
  nameWithType: Object.notify()
  fullName: java.lang.Object.notify()
- uid: java.lang.Object.wait()
  name: Object.wait()
  nameWithType: Object.wait()
  fullName: java.lang.Object.wait()
- uid: java.lang.Object.finalize()
  name: Object.finalize()
  nameWithType: Object.finalize()
  fullName: java.lang.Object.finalize()
- uid: java.lang.Object.clone()
  name: Object.clone()
  nameWithType: Object.clone()
  fullName: java.lang.Object.clone()
- uid: java.lang.Object.notifyAll()
  name: Object.notifyAll()
  nameWithType: Object.notifyAll()
  fullName: java.lang.Object.notifyAll()
- uid: java.lang.Object.equals(java.lang.Object)
  name: Object.equals(Object)
  nameWithType: Object.equals(Object)
  fullName: java.lang.Object.equals(java.lang.Object)
- uid: java.lang.Object.getClass()
  name: Object.getClass()
  nameWithType: Object.getClass()
  fullName: java.lang.Object.getClass()
- uid: java.lang.Object.wait(long)
  name: Object.wait(long)
  nameWithType: Object.wait(long)
  fullName: java.lang.Object.wait(long)
- uid: java.lang.Object.hashCode()
  name: Object.hashCode()
  nameWithType: Object.hashCode()
  fullName: java.lang.Object.hashCode()
- uid: com.azure.search.documents.indexes.models.LexicalAnalyzer.getName()
  name: LexicalAnalyzer.getName()
  nameWithType: LexicalAnalyzer.getName()
  fullName: com.azure.search.documents.indexes.models.LexicalAnalyzer.getName()
- uid: java.lang.Object.wait(long,int)
  name: Object.wait(long,int)
  nameWithType: Object.wait(long,int)
  fullName: java.lang.Object.wait(long,int)
- uid: java.lang.Object.toString()
  name: Object.toString()
  nameWithType: Object.toString()
  fullName: java.lang.Object.toString()
- uid: java.util.List
  name: List
  nameWithType: List
  fullName: java.util.List
- uid: com.azure.search.documents.indexes.models.TokenFilterName
  name: TokenFilterName
  nameWithType: TokenFilterName
  fullName: com.azure.search.documents.indexes.models.TokenFilterName
- uid: com.azure.search.documents.indexes.models.CharFilterName
  name: CharFilterName
  nameWithType: CharFilterName
  fullName: com.azure.search.documents.indexes.models.CharFilterName
