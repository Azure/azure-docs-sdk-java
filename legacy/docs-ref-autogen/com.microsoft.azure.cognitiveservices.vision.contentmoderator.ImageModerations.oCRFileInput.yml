### YamlMime:JavaMember
nameWithType: ImageModerations.oCRFileInput
type: method
members:
- fullName: com.microsoft.azure.cognitiveservices.vision.contentmoderator.ImageModerations.oCRFileInput()
  name: oCRFileInput()
  nameWithType: ImageModerations.oCRFileInput()
  returns:
    description: <p>the first stage of the oCRFileInput call </p>
    type: <xref href="ImageModerationsOCRFileInputDefinitionStages.WithLanguage?alt=ImageModerationsOCRFileInputDefinitionStages.WithLanguage&text=ImageModerationsOCRFileInputDefinitionStages.WithLanguage" data-throw-if-not-resolved="False"/>
  summary: >-
    <p>Returns any text found in the image for the language specified. If no language is specified in input then the detection defaults to English.</p>

    <p></p>
  syntax: public ImageModerationsOCRFileInputDefinitionStages.WithLanguage oCRFileInput()
  uid: com.microsoft.azure.cognitiveservices.vision.contentmoderator.ImageModerations.oCRFileInput()
- fullName: com.microsoft.azure.cognitiveservices.vision.contentmoderator.ImageModerations.oCRFileInput(String language, byte[] imageStream, OCRFileInputOptionalParameter oCRFileInputOptionalParameter)
  name: oCRFileInput(String language, byte[] imageStream, OCRFileInputOptionalParameter oCRFileInputOptionalParameter)
  nameWithType: ImageModerations.oCRFileInput(String language, byte[] imageStream, OCRFileInputOptionalParameter oCRFileInputOptionalParameter)
  parameters:
  - description: <p>Language of the terms. </p>
    name: language
    type: <xref href="String?alt=String&text=String" data-throw-if-not-resolved="False"/>
  - description: <p>The image file. </p>
    name: imageStream
    type: <xref href="byte+%5B%5D?alt=byte+%5B%5D&text=byte+%5B%5D" data-throw-if-not-resolved="False"/>
  - description: <p>the object representing the optional parameters to be set before calling this API </p>
    name: oCRFileInputOptionalParameter
    type: <xref href="com.microsoft.azure.cognitiveservices.vision.contentmoderator.models.OCRFileInputOptionalParameter?alt=com.microsoft.azure.cognitiveservices.vision.contentmoderator.models.OCRFileInputOptionalParameter&text=OCRFileInputOptionalParameter" data-throw-if-not-resolved="False"/>
  exceptions:
  - type: <xref href="IllegalArgumentException?alt=IllegalArgumentException&text=IllegalArgumentException" data-throw-if-not-resolved="False"/>
    description: <p>thrown if parameters fail the validation </p>
  - type: <xref href="APIErrorException?alt=APIErrorException&text=APIErrorException" data-throw-if-not-resolved="False"/>
    description: <p>thrown if the request is rejected by server </p>
  - type: <xref href="RuntimeException?alt=RuntimeException&text=RuntimeException" data-throw-if-not-resolved="False"/>
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
  returns:
    description: <p>the OCR object if successful. </p>
    type: <xref href="com.microsoft.azure.cognitiveservices.vision.contentmoderator.models.OCR?alt=com.microsoft.azure.cognitiveservices.vision.contentmoderator.models.OCR&text=OCR" data-throw-if-not-resolved="False"/>
  summary: >-
    <p>Returns any text found in the image for the language specified. If no language is specified in input then the detection defaults to English.</p>

    <p></p>
  syntax: public OCR oCRFileInput(String language, byte[] imageStream, OCRFileInputOptionalParameter oCRFileInputOptionalParameter)
  uid: com.microsoft.azure.cognitiveservices.vision.contentmoderator.ImageModerations.oCRFileInput(String,byte [],OCRFileInputOptionalParameter)
uid: com.microsoft.azure.cognitiveservices.vision.contentmoderator.ImageModerations.oCRFileInput*
fullName: com.microsoft.azure.cognitiveservices.vision.contentmoderator.ImageModerations.oCRFileInput
name: oCRFileInput()
package: com.microsoft.azure.cognitiveservices.vision.contentmoderator
metadata: {}
