### YamlMime:JavaType
constructors:
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.IntentRecognizer(com.microsoft.cognitiveservices.speech.SpeechConfig speechConfig)
  name: IntentRecognizer(com.microsoft.cognitiveservices.speech.SpeechConfig speechConfig)
  nameWithType: IntentRecognizer.IntentRecognizer(com.microsoft.cognitiveservices.speech.SpeechConfig speechConfig)
  parameters:
  - description: <p>speech configuration. </p>
    name: speechConfig
    type: <xref href="com.microsoft.cognitiveservices.speech.SpeechConfig?alt=com.microsoft.cognitiveservices.speech.SpeechConfig&text=SpeechConfig" data-throw-if-not-resolved="False"/>
  summary: <p>Creates a new instance of an intent recognizer. </p>
  syntax: public IntentRecognizer(com.microsoft.cognitiveservices.speech.SpeechConfig speechConfig)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.IntentRecognizer(com.microsoft.cognitiveservices.speech.SpeechConfig)
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.IntentRecognizer(com.microsoft.cognitiveservices.speech.SpeechConfig speechConfig, AudioConfig audioConfig)
  name: IntentRecognizer(com.microsoft.cognitiveservices.speech.SpeechConfig speechConfig, AudioConfig audioConfig)
  nameWithType: IntentRecognizer.IntentRecognizer(com.microsoft.cognitiveservices.speech.SpeechConfig speechConfig, AudioConfig audioConfig)
  parameters:
  - description: <p>speech configuration. </p>
    name: speechConfig
    type: <xref href="com.microsoft.cognitiveservices.speech.SpeechConfig?alt=com.microsoft.cognitiveservices.speech.SpeechConfig&text=SpeechConfig" data-throw-if-not-resolved="False"/>
  - description: <p>audio configuration. </p>
    name: audioConfig
    type: <xref href="com.microsoft.cognitiveservices.speech.audio.AudioConfig?alt=com.microsoft.cognitiveservices.speech.audio.AudioConfig&text=AudioConfig" data-throw-if-not-resolved="False"/>
  summary: <p>Creates a new instance of an intent recognizer. </p>
  syntax: public IntentRecognizer(com.microsoft.cognitiveservices.speech.SpeechConfig speechConfig, AudioConfig audioConfig)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.IntentRecognizer(com.microsoft.cognitiveservices.speech.SpeechConfig,AudioConfig)
fields:
- field:
    type: final EventHandlerImpl&lt;<xref href="com.microsoft.cognitiveservices.speech.intent.IntentRecognitionCanceledEventArgs?alt=com.microsoft.cognitiveservices.speech.intent.IntentRecognitionCanceledEventArgs&text=IntentRecognitionCanceledEventArgs" data-throw-if-not-resolved="False"/>&gt;
  fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.canceled
  name: canceled
  nameWithType: IntentRecognizer.canceled
  summary: <p>The event canceled signals that the intent recognition was canceled. </p>
  syntax: public final EventHandlerImpl<IntentRecognitionCanceledEventArgs> canceled= new EventHandlerImpl<IntentRecognitionCanceledEventArgs>(eventCounter)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.canceled
- field:
    type: final EventHandlerImpl&lt;<xref href="com.microsoft.cognitiveservices.speech.intent.IntentRecognitionEventArgs?alt=com.microsoft.cognitiveservices.speech.intent.IntentRecognitionEventArgs&text=IntentRecognitionEventArgs" data-throw-if-not-resolved="False"/>&gt;
  fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.recognized
  name: recognized
  nameWithType: IntentRecognizer.recognized
  summary: <p>The event recognized signals that a final recognition result is received. </p>
  syntax: public final EventHandlerImpl<IntentRecognitionEventArgs> recognized= new EventHandlerImpl<IntentRecognitionEventArgs>(eventCounter)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.recognized
- field:
    type: final EventHandlerImpl&lt;<xref href="com.microsoft.cognitiveservices.speech.intent.IntentRecognitionEventArgs?alt=com.microsoft.cognitiveservices.speech.intent.IntentRecognitionEventArgs&text=IntentRecognitionEventArgs" data-throw-if-not-resolved="False"/>&gt;
  fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.recognizing
  name: recognizing
  nameWithType: IntentRecognizer.recognizing
  summary: <p>The event recognizing signals that an intermediate recognition result is received. </p>
  syntax: public final EventHandlerImpl<IntentRecognitionEventArgs> recognizing= new EventHandlerImpl<IntentRecognitionEventArgs>(eventCounter)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.recognizing
inheritances:
- <xref href="java.lang.Object" data-throw-if-not-resolved="False"/>
- <xref href="AutoCloseable" data-throw-if-not-resolved="False"/>
- <xref href="com.microsoft.cognitiveservices.speech.Recognizer?alt=com.microsoft.cognitiveservices.speech.Recognizer&text=Recognizer" data-throw-if-not-resolved="False"/>
inheritedMembers:
- com.microsoft.cognitiveservices.speech.Recognizer.close()
- com.microsoft.cognitiveservices.speech.Recognizer.sessionStarted
- com.microsoft.cognitiveservices.speech.Recognizer.sessionStopped
- com.microsoft.cognitiveservices.speech.Recognizer.speechEndDetected
- com.microsoft.cognitiveservices.speech.Recognizer.speechStartDetected
methods:
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addAllIntents(LanguageUnderstandingModel model)
  name: addAllIntents(LanguageUnderstandingModel model)
  nameWithType: IntentRecognizer.addAllIntents(LanguageUnderstandingModel model)
  parameters:
  - description: <p>The language understanding model containing the intents. </p>
    name: model
    type: <xref href="com.microsoft.cognitiveservices.speech.intent.LanguageUnderstandingModel?alt=com.microsoft.cognitiveservices.speech.intent.LanguageUnderstandingModel&text=LanguageUnderstandingModel" data-throw-if-not-resolved="False"/>
  summary: <p>Adds all intents from the specified Language Understanding Model. </p>
  syntax: public void addAllIntents(LanguageUnderstandingModel model)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addAllIntents(LanguageUnderstandingModel)
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addAllIntents(LanguageUnderstandingModel model, String intentId)
  name: addAllIntents(LanguageUnderstandingModel model, String intentId)
  nameWithType: IntentRecognizer.addAllIntents(LanguageUnderstandingModel model, String intentId)
  parameters:
  - description: <p>The language understanding model containing the intents. </p>
    name: model
    type: <xref href="com.microsoft.cognitiveservices.speech.intent.LanguageUnderstandingModel?alt=com.microsoft.cognitiveservices.speech.intent.LanguageUnderstandingModel&text=LanguageUnderstandingModel" data-throw-if-not-resolved="False"/>
  - description: <p>A custom id String to be returned in the IntentRecognitionResult's getIntentId() method. </p>
    name: intentId
    type: <xref href="String?alt=String&text=String" data-throw-if-not-resolved="False"/>
  summary: <p>Adds all intents from the specified Language Understanding Model. </p>
  syntax: public void addAllIntents(LanguageUnderstandingModel model, String intentId)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addAllIntents(LanguageUnderstandingModel,String)
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addIntent(LanguageUnderstandingModel model, String intentName)
  name: addIntent(LanguageUnderstandingModel model, String intentName)
  nameWithType: IntentRecognizer.addIntent(LanguageUnderstandingModel model, String intentName)
  parameters:
  - description: <p>The language understanding model containing the intent. </p>
    name: model
    type: <xref href="com.microsoft.cognitiveservices.speech.intent.LanguageUnderstandingModel?alt=com.microsoft.cognitiveservices.speech.intent.LanguageUnderstandingModel&text=LanguageUnderstandingModel" data-throw-if-not-resolved="False"/>
  - description: <p>The name of the single intent to be included from the language understanding model. </p>
    name: intentName
    type: <xref href="String?alt=String&text=String" data-throw-if-not-resolved="False"/>
  summary: <p>Adds a single intent by name from the specified Language Understanding Model. </p>
  syntax: public void addIntent(LanguageUnderstandingModel model, String intentName)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addIntent(LanguageUnderstandingModel,String)
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addIntent(LanguageUnderstandingModel model, String intentName, String intentId)
  name: addIntent(LanguageUnderstandingModel model, String intentName, String intentId)
  nameWithType: IntentRecognizer.addIntent(LanguageUnderstandingModel model, String intentName, String intentId)
  parameters:
  - description: <p>The language understanding model containing the intent. </p>
    name: model
    type: <xref href="com.microsoft.cognitiveservices.speech.intent.LanguageUnderstandingModel?alt=com.microsoft.cognitiveservices.speech.intent.LanguageUnderstandingModel&text=LanguageUnderstandingModel" data-throw-if-not-resolved="False"/>
  - description: <p>The name of the single intent to be included from the language understanding model. </p>
    name: intentName
    type: <xref href="String?alt=String&text=String" data-throw-if-not-resolved="False"/>
  - description: <p>A custom id String to be returned in the IntentRecognitionResult's getIntentId() method. </p>
    name: intentId
    type: <xref href="String?alt=String&text=String" data-throw-if-not-resolved="False"/>
  summary: <p>Adds a single intent by name from the specified Language Understanding Model. </p>
  syntax: public void addIntent(LanguageUnderstandingModel model, String intentName, String intentId)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addIntent(LanguageUnderstandingModel,String,String)
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addIntent(String simplePhrase)
  name: addIntent(String simplePhrase)
  nameWithType: IntentRecognizer.addIntent(String simplePhrase)
  parameters:
  - description: <p>The phrase corresponding to the intent. </p>
    name: simplePhrase
    type: <xref href="String?alt=String&text=String" data-throw-if-not-resolved="False"/>
  summary: <p>Adds a simple phrase that may be spoken by the user, indicating a specific user intent. </p>
  syntax: public void addIntent(String simplePhrase)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addIntent(String)
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addIntent(String simplePhrase, String intentId)
  name: addIntent(String simplePhrase, String intentId)
  nameWithType: IntentRecognizer.addIntent(String simplePhrase, String intentId)
  parameters:
  - description: <p>The phrase corresponding to the intent. </p>
    name: simplePhrase
    type: <xref href="String?alt=String&text=String" data-throw-if-not-resolved="False"/>
  - description: <p>A custom id String to be returned in the IntentRecognitionResult's getIntentId() method. </p>
    name: intentId
    type: <xref href="String?alt=String&text=String" data-throw-if-not-resolved="False"/>
  summary: <p>Adds a simple phrase that may be spoken by the user, indicating a specific user intent. </p>
  syntax: public void addIntent(String simplePhrase, String intentId)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.addIntent(String,String)
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.getAuthorizationToken()
  name: getAuthorizationToken()
  nameWithType: IntentRecognizer.getAuthorizationToken()
  returns:
    description: <p>Authorization token. </p>
    type: <xref href="String?alt=String&text=String" data-throw-if-not-resolved="False"/>
  summary: <p>Gets the authorization token used to communicate with the service. </p>
  syntax: public String getAuthorizationToken()
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.getAuthorizationToken()
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.getProperties()
  name: getProperties()
  nameWithType: IntentRecognizer.getProperties()
  returns:
    description: <p>The collection of properties and their values defined for this IntentRecognizer. </p>
    type: <xref href="com.microsoft.cognitiveservices.speech.PropertyCollection?alt=com.microsoft.cognitiveservices.speech.PropertyCollection&text=PropertyCollection" data-throw-if-not-resolved="False"/>
  summary: <p>The collection of properties and their values defined for this IntentRecognizer. </p>
  syntax: public PropertyCollection getProperties()
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.getProperties()
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.getSpeechRecognitionLanguage()
  name: getSpeechRecognitionLanguage()
  nameWithType: IntentRecognizer.getSpeechRecognitionLanguage()
  returns:
    description: <p>the spoken language of recognition. </p>
    type: <xref href="String?alt=String&text=String" data-throw-if-not-resolved="False"/>
  summary: <p>Gets the spoken language of recognition. </p>
  syntax: public String getSpeechRecognitionLanguage()
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.getSpeechRecognitionLanguage()
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.recognizeOnceAsync()
  name: recognizeOnceAsync()
  nameWithType: IntentRecognizer.recognizeOnceAsync()
  returns:
    description: <p>A task representing the recognition operation. The task returns a value of IntentRecognitionResult </p>
    type: Future&lt;<xref href="com.microsoft.cognitiveservices.speech.intent.IntentRecognitionResult?alt=com.microsoft.cognitiveservices.speech.intent.IntentRecognitionResult&text=IntentRecognitionResult" data-throw-if-not-resolved="False"/>&gt;
  summary: '<p>Starts intent recognition, and returns after a single utterance is recognized. The end of a single utterance is determined by listening for silence at the end or until a maximum of 15 seconds of audio is processed. The task returns the recognition text as result. Note: Since recognizeOnceAsync() returns only a single utterance, it is suitable only for single shot recognition like command or query. For long-running multi-utterance recognition, use startContinuousRecognitionAsync() instead. </p>'
  syntax: public Future<IntentRecognitionResult> recognizeOnceAsync()
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.recognizeOnceAsync()
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.setAuthorizationToken(String token)
  name: setAuthorizationToken(String token)
  nameWithType: IntentRecognizer.setAuthorizationToken(String token)
  parameters:
  - description: <p>Authorization token. </p>
    name: token
    type: <xref href="String?alt=String&text=String" data-throw-if-not-resolved="False"/>
  summary: '<p>Sets the authorization token used to communicate with the service. Note: The caller needs to ensure that the authorization token is valid. Before the authorization token expires, the caller needs to refresh it by calling this setter with a new valid token. Otherwise, the recognizer will encounter errors during recognition. </p>'
  syntax: public void setAuthorizationToken(String token)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.setAuthorizationToken(String)
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.startContinuousRecognitionAsync()
  name: startContinuousRecognitionAsync()
  nameWithType: IntentRecognizer.startContinuousRecognitionAsync()
  returns:
    description: <p>A task representing the asynchronous operation that starts the recognition. </p>
    type: <xref href="Future%3CVoid%3E?alt=Future%3CVoid%3E&text=Future%3CVoid%3E" data-throw-if-not-resolved="False"/>
  summary: <p>Starts speech recognition on a continuous audio stream, until stopContinuousRecognitionAsync() is called. User must subscribe to events to receive recognition results. </p>
  syntax: public Future<Void> startContinuousRecognitionAsync()
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.startContinuousRecognitionAsync()
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.startKeywordRecognitionAsync(KeywordRecognitionModel model)
  name: startKeywordRecognitionAsync(KeywordRecognitionModel model)
  nameWithType: IntentRecognizer.startKeywordRecognitionAsync(KeywordRecognitionModel model)
  parameters:
  - description: <p>The keyword recognition model that specifies the keyword to be recognized. </p>
    name: model
    type: <xref href="com.microsoft.cognitiveservices.speech.KeywordRecognitionModel?alt=com.microsoft.cognitiveservices.speech.KeywordRecognitionModel&text=KeywordRecognitionModel" data-throw-if-not-resolved="False"/>
  returns:
    description: <p>A task representing the asynchronous operation that starts the recognition. </p>
    type: <xref href="Future%3CVoid%3E?alt=Future%3CVoid%3E&text=Future%3CVoid%3E" data-throw-if-not-resolved="False"/>
  summary: '<p>Configures the recognizer with the given keyword model. After calling this method, the recognizer is listening for the keyword to start the recognition. Call stopKeywordRecognitionAsync() to end the keyword initiated recognition. User must subscribe to events to receive recognition results. Note: Keyword spotting (KWS) functionality might work with any microphone type, official KWS support, however, is currently limited to the microphone arrays found in the Azure Kinect DK hardware or the Speech Devices SDK. </p>'
  syntax: public Future<Void> startKeywordRecognitionAsync(KeywordRecognitionModel model)
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.startKeywordRecognitionAsync(KeywordRecognitionModel)
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.stopContinuousRecognitionAsync()
  name: stopContinuousRecognitionAsync()
  nameWithType: IntentRecognizer.stopContinuousRecognitionAsync()
  returns:
    description: <p>A future that will complete when input processing has been stopped. Result generation, if applicable for the input provided, may happen after this task completes and should be handled with the appropriate event. </p>
    type: <xref href="Future%3CVoid%3E?alt=Future%3CVoid%3E&text=Future%3CVoid%3E" data-throw-if-not-resolved="False"/>
  summary: <p>Stops a running recognition operation as soon as possible and immediately requests a result based on the the input that has been processed so far. This works for all recognition operations, not just continuous ones, and facilitates the use of push-to-talk or "finish now" buttons for manual audio endpointing. </p>
  syntax: public Future<Void> stopContinuousRecognitionAsync()
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.stopContinuousRecognitionAsync()
- fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.stopKeywordRecognitionAsync()
  name: stopKeywordRecognitionAsync()
  nameWithType: IntentRecognizer.stopKeywordRecognitionAsync()
  returns:
    description: <p>A task representing the asynchronous operation that stops the recognition. </p>
    type: <xref href="Future%3CVoid%3E?alt=Future%3CVoid%3E&text=Future%3CVoid%3E" data-throw-if-not-resolved="False"/>
  summary: '<p>Ends the keyword initiated recognition. Note: Keyword spotting (KWS) functionality might work with any microphone type, official KWS support, however, is currently limited to the microphone arrays found in the Azure Kinect DK hardware or the Speech Devices SDK. </p>'
  syntax: public Future<Void> stopKeywordRecognitionAsync()
  uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer.stopKeywordRecognitionAsync()
nameWithType: IntentRecognizer
syntax: public class IntentRecognizer extends Recognizer
type: class
uid: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer
fullName: com.microsoft.cognitiveservices.speech.intent.IntentRecognizer
name: IntentRecognizer
package: com.microsoft.cognitiveservices.speech.intent
summary: '<p>Performs intent recognition on the speech input. It returns both recognized text and recognized intent. Note: close() must be called in order to release underlying resources held by the object. </p>'
metadata: {}
